{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u2693 \u2009 VidGear is a cross-platform High-Performance Video-Processing Framework for building complex real-time media applications in python VidGear provides an easy-to-use, highly extensible, Multi-Threaded + Asyncio API Framework on top of many state-of-the-art specialized libraries like OpenCV , FFmpeg , ZeroMQ , picamera , starlette , yt_dlp , pyscreenshot , aiortc and python-mss at its backend, and enable us to flexibly exploit their internal parameters and methods, while silently delivering robust error-handling and real-time performance \u26a1\ufe0f. \"Write Less and Accomplish More\" \u2014 VidGear's Motto VidGear focuses on simplicity, and thereby lets programmers and software developers to easily integrate and perform Complex Video Processing Tasks without going through hefty documentation and in just a few lines of code. \u2009 Getting Started \u2693 In case you're run into any problems, consult the Help section. If this is your first time using VidGear, head straight to the Installation to install VidGear. Once you have VidGear installed, Checkout its Function-Specific Gears . Also, if you're already familar with OpenCV library, then see Switching from OpenCV Library . If you're just getting started with OpenCV-Python programming, then refer this FAQ \u27b6 \u2009 Gears \u2693 VidGear is built with multiple Gears each with some unique functionality. Each Gear is designed exclusively to handle/control/process different data-specific & device-specific video streams, network streams, and media encoders/decoders. These Gears can be classified as follows: VideoCapture Gears \u2693 CamGear : Multi-Threaded API targeting various IP-USB-Cameras/Network-Streams/Streaming-Sites-URLs. PiGear : Multi-Threaded API targeting various Raspberry-Pi Camera Modules. ScreenGear : Multi-Threaded API targeting ultra-fast Screencasting. VideoGear : Common Video-Capture API with internal Video Stabilizer wrapper. VideoWriter Gears \u2693 WriteGear : Handles Lossless Video-Writer for file/stream/frames Encoding and Compression. Streaming Gears \u2693 StreamGear : Handles Transcoding of High-Quality, Dynamic & Adaptive Streaming Formats. Asynchronous I/O Streaming Gear: WebGear : ASGI Video-Server that broadcasts Live MJPEG-Frames to any web-browser on the network. WebGear_RTC : Real-time Asyncio WebRTC media server for streaming directly to peer clients over the network. Network Gears \u2693 NetGear : Handles High-Performance Video-Frames & Data Transfer between interconnecting systems over the network. Asynchronous I/O Network Gear: NetGear_Async : Immensely Memory-Efficient Asyncio Video-Frames Network Messaging Framework. \u2009 Contributions \u2693 Contributions are welcome, and greatly appreciated! Please see our Contribution Guidelines for more details. \u2009 Community Channel \u2693 If you've come up with some new idea, or looking for the fastest way troubleshoot your problems. Please checkout our Gitter community channel \u27b6 \u2009 Become a Stargazer \u2693 You can be a Stargazer by starring us on Github, it helps us a lot and you're making it easier for others to find & trust this library. Thanks! \u2009 Donations \u2693 VidGear is free and open source and will always remain so. It is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); \u2009 Citation \u2693 Here is a Bibtex entry you can use to cite this project in a publication: @software { vidgear , author = {Abhishek Thakur and Zoe Papakipos and Christian Clauss and Christian Hollinger and Vincent Boivin and Benjamin Lowe and Micka\u00ebl Schoentgen and Renaud Bouckenooghe} , title = {abhiTronix/vidgear: VidGear v0.2.5} , month = feb , year = 2022 , publisher = {Zenodo} , version = {vidgear-0.2.5} , doi = {10.5281/zenodo.6046843} , url = {https://doi.org/10.5281/zenodo.6046843} }","title":"Overview"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#getting-started","text":"In case you're run into any problems, consult the Help section. If this is your first time using VidGear, head straight to the Installation to install VidGear. Once you have VidGear installed, Checkout its Function-Specific Gears . Also, if you're already familar with OpenCV library, then see Switching from OpenCV Library . If you're just getting started with OpenCV-Python programming, then refer this FAQ \u27b6","title":"Getting Started"},{"location":"#gears","text":"VidGear is built with multiple Gears each with some unique functionality. Each Gear is designed exclusively to handle/control/process different data-specific & device-specific video streams, network streams, and media encoders/decoders. These Gears can be classified as follows:","title":"Gears"},{"location":"#videocapture-gears","text":"CamGear : Multi-Threaded API targeting various IP-USB-Cameras/Network-Streams/Streaming-Sites-URLs. PiGear : Multi-Threaded API targeting various Raspberry-Pi Camera Modules. ScreenGear : Multi-Threaded API targeting ultra-fast Screencasting. VideoGear : Common Video-Capture API with internal Video Stabilizer wrapper.","title":"VideoCapture Gears"},{"location":"#videowriter-gears","text":"WriteGear : Handles Lossless Video-Writer for file/stream/frames Encoding and Compression.","title":"VideoWriter Gears"},{"location":"#streaming-gears","text":"StreamGear : Handles Transcoding of High-Quality, Dynamic & Adaptive Streaming Formats. Asynchronous I/O Streaming Gear: WebGear : ASGI Video-Server that broadcasts Live MJPEG-Frames to any web-browser on the network. WebGear_RTC : Real-time Asyncio WebRTC media server for streaming directly to peer clients over the network.","title":"Streaming Gears"},{"location":"#network-gears","text":"NetGear : Handles High-Performance Video-Frames & Data Transfer between interconnecting systems over the network. Asynchronous I/O Network Gear: NetGear_Async : Immensely Memory-Efficient Asyncio Video-Frames Network Messaging Framework.","title":"Network Gears"},{"location":"#contributions","text":"Contributions are welcome, and greatly appreciated! Please see our Contribution Guidelines for more details.","title":"Contributions"},{"location":"#community-channel","text":"If you've come up with some new idea, or looking for the fastest way troubleshoot your problems. Please checkout our Gitter community channel \u27b6","title":"Community Channel"},{"location":"#become-a-stargazer","text":"You can be a Stargazer by starring us on Github, it helps us a lot and you're making it easier for others to find & trust this library. Thanks!","title":"Become a Stargazer"},{"location":"#donations","text":"VidGear is free and open source and will always remain so. It is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw();","title":"Donations"},{"location":"#citation","text":"Here is a Bibtex entry you can use to cite this project in a publication: @software { vidgear , author = {Abhishek Thakur and Zoe Papakipos and Christian Clauss and Christian Hollinger and Vincent Boivin and Benjamin Lowe and Micka\u00ebl Schoentgen and Renaud Bouckenooghe} , title = {abhiTronix/vidgear: VidGear v0.2.5} , month = feb , year = 2022 , publisher = {Zenodo} , version = {vidgear-0.2.5} , doi = {10.5281/zenodo.6046843} , url = {https://doi.org/10.5281/zenodo.6046843} }","title":"Citation"},{"location":"changelog/","text":"Release Notes \u2693 v0.2.6 (2022-07-05) \u2693 New Features Docs: Added new bonus example for RSTP/RTP Live-Streaming using WriteGear's Compression Mode. Added \"How to resolve zmq.error.ZMQError\" FAQ for NetGear API.(PR by @iandol ) Added new ko-fi button to README.md Added new contributors block to changelog.md Maintenance: Added new patterns to .gitignore to ignore pypi's build directory and egg-info files. CI: Switched to new Issue GitHub's form schema using YAML Added new bug_report.yaml . Added new question.yaml . Added new proposal.yaml . Deleted depreciated markdown files. Polished forms. Updates/Improvements Setup.py: Bumped version to 0.2.6 . Updated logic operators and dependency. Replaced >= comparsion operator with more flexible ~= . Replaced distutils.version.LooseVersion with pkg_resources.parse_version . Docs: Updated Site Navigation. Added new notices to inform users more effectively about bonus examples. Added new Bonus section to navigation and moved suitable pages under it. Updated headings and URLs. Redesigned and Rewritten Donation and Contribution section to README.md Updated Zenodo badge and bibtex entry. Updated Admonition Icon, FAQs and site-links. Reformatted code and its comments. Updated changelog.md . API: Updated depreciated tostring() to tobytes(). tostring was renamed to tobytes for the purposes for clarity in Python 3.2. https://docs.python.org/3/library/array.html#array.array.tobytes CI: Added more paths and files to skip commits. Breaking Updates/Changes -input_framerate parameter now accepts any positive value for WriteGear and StreamGear APIs. Bug-fixes API: Fixed -input_framerate less than 5 does not get used in WriteGear and StreamGear APIs.(PR by @freol35241 ) CamGear: Fixed Yt-dlp generated HTTP DASH Segments URLs not supported by OpenCV's VideoCapture(PR by @DynamiteC ) StreamGear: Fixed hls_segment_type not working bug. (PR by @enarche-ahn ) Fixed critical logging parameter bug Fixed debug logs even when logging=False in StreamGear's Real-time Mode. (patch suggested by @enarche-ahn ) Added length check to -video_source attribute to correctly infers it as empty(or invalid). CI: Xfailed RSTP CamGear CI test. Fixed pinned version syntax bug in docs_deployer workflow. Fixed typos in Github forms and its context. Added missing dependency. Docs: Fixed jinja2 3.1.0 or above breaks mkdocs. jinja2>=3.1.0 breaks mkdocs ( mkdocs/mkdocs#2799 ), therefore pinned jinja2 version to <3.1.0 . Fixed support for new mkdocstring versions Replaced rendering sub-value with options. Removed pinned mkdocstrings==0.17.0 version. Fixed Netgear+Webgear bonus example code bugs.(PR by @iandol ) Added a missing import. Removed self. typo. Replaced the return value with break in the async as it triggers an error. Fixed external bug that causing \"Home\" tab to irresponsive randomly when accessed from other tabs. Fixed indentation and spacing. Fixed typos and updated context. Removed dead code. Pull Requests PR #288 PR #290 PR #293 PR #295 PR #307 PR #313 PR #320 New Contributors @iandol @freol35241 @enarche-ahn @DynamiteC v0.2.5 (2021-02-11) \u2693 New Features WriteGear: Add support for GStreamer pipeline in WriteGear API's Non-Compression mode: Implemented GStreamer Pipeline Mode to accept GStreamer pipeline as string to its output_filename parameter. Added new special -gst_pipeline_mode attribute for its output_params parameter. This feature provides flexible way to directly write video frames into GStreamer Pipeline with controlled bitrate. Added new docs and updated existing docs with related changes. Added new -ffpreheaders special attribute to WriteGear's options parameter: This attribute is specifically required to set special FFmpeg parameters in Compression Mode that are present at the starting of command(such as -re ). This attribute only accepts list datatype as value. Added related docs. NetGear: Added bidirectional data transfer support by extending Bidirectional mode support to exclusive Multi-Clients and Multi-Servers modes: Users will now able to send data bidirectionally in both Multi-Clients and Multi-Servers exclusive modes. Bidirectional mode will no longer disables automatically when Multi-Clients and Multi-Servers modes already enabled. Added new docs and updated existing docs with related changes. Maintenance: Added official support for Python-3.10 legacies. Added float value support to THREAD_TIMEOUT optional parameter. Added info about dropped support for Python-3.6 legacies through announcement bar. Added config.md file for Issue templates. Added title to Issue templates. Docs: Added new Code Annotations Added new icons to headings. Added Advanced VideoGear usage example with CamGear backend. Updates/Improvements Setup.py: Dropped support for Python-3.6 and below legacies. Updated logging formatting. Updated python_requires to >=3.7 . Bumped version to 0.2.5 . Helper: Vidgear will now report current version on every run. Docs: Updated SSH tunneling docs context. Excluded docs directory from CI envs. Updated Zenodo badge and BibTeX entry. Updated dark theme hue to 260 . Updated Admonitions. Additional warnings against pushing PR against VidGear's testing branch only. Updated code comments. CI: Removed support for Python-3.6 legacies from all workflows. Updated NetGear's Exclusive Mode tests. Added GStreamer Pipeline Mode tests. Maintenance: Updated Issue and PR templates. Updated metadata. Breaking Updates/Changes Dropped support for Python-3.6 legacies from vidgear. Bug-fixes NetGear: Fixed bidirectional mode overriding multi-clients mode's data. WriteGear: Fixed wrongly defined ffmpeg_preheaders. Fixed condition logic bugs. Fixed UnboundLocalError bug. Setup: Fixed uvicorn and aiortc dropped support for Python-3.6 legacies. CI: Fixed GitHub Actions interprets 3.10 as 3.1 if used without strings. Fixed naming error in azure YAML. Docs: Fixed codecov badge URL in README.md Fixed hyperlinks in README. Fixed indentation and spacing. Fixed typos and updated context. Removed dead code. Maintenance: Removed depreciated condition checks. Pull Requests PR #283 PR #284 v0.2.4 (2021-12-05) \u2693 New Features CamGear: Added a new YT_backend Internal Class with YT-DLP backend: Implemented YT_backend a new CamGear's Internal YT-DLP backend class for extracting metadata from Streaming URLs. Added support for pipeling (live) video-frames from all yt-dlp supported streaming sites: https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md#supported-sites Implemented algorithm from scratch for auto-extracting resolution specific streamable URLs for pipelineing. Implemented logic for auto-calculating best and worst resolutions. Added new ytv_metadata global parameter to CamGear for accessing video's metadata(such as duration, title, description) on-the-go. \u26a0\ufe0f Playlists are still unsupported. WebGear_RTC: Implemented a new easy way of defining Custom Streaming Class with suitable source(such as OpenCV): Added new custom_stream attribute with WebGear_RTC options parameter that allows you to easily define your own Custom Streaming Class with suitable source(such as OpenCV). This implementation supports repeated Auto-Reconnection or Auto-Refresh out-of-the-box. This implementation is more user-friendly and easy to integrate within complex APIs. This implementation requires at-least read() and stop() methods implemented within Custom Streaming Class, otherwise WebGear_RTC will throw ValueError. This implementation supports all vidgear's VideoCapture APIs readily as input. Maintenance: Added new .gitignore for specifying intentionally untracked files to ignore Added more files entries to .gitignore . Added new .gitattributes to manage how Git reads line endings. Enabled auto default behavior, in case people don't have core.autocrlf set. Enforced LF line-endings for selective files types. Added Binary data files that specifies they are not text, and git should not try to change them. Added Language aware diff headers. Added Linguist language overrides. Docs: Added bonus example to add real-time file audio encoding with VideoGear and Stabilizer class. Added complete usage docs with new CamGear's Internal Class with YT-DLP backend. Added instructions to extract video's metadata in CamGear. Added donation link in page footer with bouncing heart animation through pure CSS. Added info about critical changes in v0.2.4 and above installation through new announcement bar. Added related usage docs for new WebGear_RTC custom streaming class. Added changes for upgrading mkdocs-material from v7.x to newer v8.x . Added outdated version warning block. Updates/Improvements CamGear: Added is_livestream global YT_backend parameters. Added default options for yt-dlp for extracting info_dict(metadata) of the video as a single JSON line. Completely removed old logic for extracting streams using pafy. Removed all dead code related to streamlink backend. Setup.py: Moved all API specific dependencies to extra_requires under the name \"core\" . [PR #268 by @zpapakipos ] Added rule to replace GitHub heading links in description. Updated extra_require dependencies. Removed streamlink dependency. Removed pafy dependency. Removed pyzmq from latest_version group. Updated SEO Keywords. Docs: Re-written pip and source installation docs. Added warning for using -disable_force_termination flag for short duration videos. Added permalink_title entry to mkdocs.yml. Updated CamGear parameters. Updated Admonitions with related information. Updated Functional Block Diagram( gears_fbd.png ) image. Updated installation instructions. Updated Advanced examples using WebGear_RTC's custom streaming class. Updated code highlighting. Updated zenodo badge. Updated BibTex for project citation. Replaced incorrect API parameter docs. Updated WebGear_RTC parameters. CI: Updated CI tests for new WebGear_RTC custom streaming class. Restored test_stream_mode CamGear test. Updated Streaming Sites test links. Added more tests cases. Maintenance: Updated spacing in logger formatting. Renamed Asyncio Helper logger name. Changed logging colors. Updated logging messages. Breaking Updates/Changes Installation command with pip has been changed in v0.2.4 : The legacy pip install vidgear command now installs critical bare-minimum dependencies only. Therefore in order to automatically install all the API specific dependencies as previous versions, use pip install vidgear [ core ] command instead. CamGear: Removed streamlink backend support from stream_mode in favor of more reliable CamGear's Internal YT-DLP backend class for extracting metadata from Streaming URLs. CamGear will raise ValueError if streaming site URL is unsupported by yt-dlp backend. CamGear will raise ValueError if yt-dlp isn't installed and stream_mode is enabled. Removed automatic enforcing of GStreamer backend for YouTube-livestreams and made it optional. The CamGear will not raise ValueError if GStreamer support is missing in OpenCV backends. WebGear_RTC: Removed support for assigning Custom Media Server Class(inherited from aiortc's VideoStreamTrack) in WebGear_RTC through its config global parameter. WebGear_RTC API will now throws ValueError if source parameter is NoneType as well as custom_stream attribute is undefined. Helper: Removed restore_levelnames method. Removed youtube_url_validator helper method. Bug-fixes CamGear: Fixed KeyError Bug for missing attributed in meta_data json in some streaming sites. Helper: Removed unused imports. Docs: Removed slugify from mkdocs which was causing invalid hyperlinks in docs. Fixed GitHub hyperlinks in README.md. Fixed hyperlink in announcement bar. Fixed content tabs failing to work. Fixed line-endings and usage example code. Removed any pafy and streamlink references. Fixed context and typos. CI: Fixed NameError bugs in WebGear_RTC CI test. Maintenance: Removed dead logger code causing Python's Built-in logging module to hide logs. Removed unused logging import. Updated code comments. Pull Requests PR #268 PR #272 PR #274 New Contributors @zpapakipos v0.2.3 (2021-10-27) \u2693 New Features CamGear: Added support for 4K Streaming URLs. Helper: Implemented logging ColorFormatter string alignment. Center aligned logging Level-name and Class-name. Changed % formatting style with modern { . Re-added asctime value to Formatter string. Re-arranged parameter positions in Formatter string. Maintenance: Added new .gitignore for specifying intentionally untracked files to ignore Added more files entries to .gitignore . Added new .gitattributes to manage how Git reads line endings. Enabled auto default behavior, in case people don't have core.autocrlf set. Enforced LF line-endings for selective files types. Added Binary data files that specifies they are not text, and git should not try to change them. Added Language aware diff headers. Added Linguist language overrides. Docs: Added new ScreenGear with WebGear_RTC API bonus example. Added support for hl_lines argument for highlighting specific code lines. Added drop-shadow effects for its slate theme to improve visibility. Updates/Improvements CamGear: Replaced youtube-dl with yt-dlp as pafy backend for YouTube videos pipelining. Implemented hack to trick pafy into assuming yt-dlp as youtube-dl . Using sys.modules to present yt-dlp as youtube-dl . yt-dlp python API functions exactly similar to youtube-dl . Replaced youtube-dl dependency with yt-dlp . Replaced youtube-dl imports with yt-dlp . StreamGear: Updated default stream_count internal dict key value to 1. Maintenance: Introduced python short-circuiting for handling logging logic. Enabled logging for check_WriteAccess method in WriteGear, StreamGear and NetGear APIs. Docs: Added warning for ScreenGear outputting RGBA frames instead of default BGR frames with mss backend. Added warnings for properly formatting output_params when assigning external audio-source in WriteGear. Added depreciation notice for Python 3.6 legacies. Restructured docs to make it more user-friendly. Updated, Extended and Improved context. Improved code comments. Updated docs admonitions. Updated Zenodo badge. CI: Migrated to new Codecov Uploader in Azure Pipelines. Support for the Bash Uploader will be deprecated on February 1 st , 2022. See: https://docs.codecov.com/docs/about-the-codecov-bash-uploader Added commands for signature and SHASUM verification to ensure integrity of the Uploader before use. Replaced related bash commands. Replaced env with export in ci_linux.yml. Replaced bubkoo/needs-more-info@v1 with wow-actions/needs-more-info@v1 . Added codecov secret token through env variable. Added wildcard to skip CI tests for doc( .md ) files. Added .md files to Codecov ignore list. Update vidgear's banner image. Breaking Updates/Changes check_WriteAccess will now return as invalid path if writing directory does not exists. This will effect output file handling in WriteGear and StreamGear APIs. Bug-fixes StreamGear: Fixed StreamGear Malformed URI Error with HLS Segments [PR #243 by @Vboivin ] Removed the extra '%' character from the naming convention for segment files. Used stream_count internal dict variable to alter template for HLS segment filenames. WriteGear: Fixed bug in disable_force_termination logic which accidentally disables force termination. WebGear_RTC: Fixed name 'VideoStreamTrack' is not defined bug. Setup.py: Fixed TypeError bug. Fixed invalid latest_version retrieval. Helper: Fixed check_WriteAccess failing to recognize correct permission for writing the output file on windows platform. Implemented separate logic for Windows and *nix platforms. Added new stat import. Improved warnings and error handling. Added logging parameter to check_WriteAccess . Fixed bug in check_WriteAccess that throws OSError while handling URLs. Docs: Fixed bugs in WriteGear's Compression Mode with Live Audio Input example. Fixed \"drop-shadow\" property via filter function conflicting with sidecard button. Added new CSS classes for image, admonitions and code highlight in dark theme. Several internal and external webpage links typos fixed. Fixed several language typos. CI: Fixed Azure Pipeline coverage upload bugs. Fixed random errors in CamGear stream_mode test. Bash: Removed the Windows carriage returns from the shell scripts to be able to execute them on Linux. Fixed logging comments. Pull Requests PR #249 PR #262 New Contributors @Vboivin v0.2.2 (2021-09-02) \u2693 New Features StreamGear: Native Support for Apple HLS Multi-Bitrate Streaming format: Added support for new Apple HLS (HTTP Live Streaming) HTTP streaming format in StreamGear. Implemented default workflow for auto-generating primary HLS stream of same resolution and framerate as source. Added HLS support in Single-Source and Real-time Frames Modes. Implemented inherit support for fmp4 and mpegts HLS segment types. Added adequate default parameters required for trans-coding HLS streams. Added native support for HLS live-streaming. Added \"hls\" value to format parameter for easily selecting HLS format. Added HLS support in -streams attribute for transcoding additional streams. Added support for .m3u8 and .ts extensions in clear_prev_assets workflow. Added validity check for .m3u8 extension in output when HLS format is used. Separated DASH and HLS command handlers. Created HLS format exclusive parameters. Implemented -hls_base_url FFMpeg parameter support. Added support for audio input from external device: Implemented support for audio input from external device. Users can now easily add audio device and decoder by formatting them as python list. Modified -audio parameter to support list data type as value. Modified validate_audio helper function to validate external audio devices. Added -seg_duration to control segment duration. NetGear: New SSH Tunneling Mode for remote connection: New SSH Tunneling Mode for connecting ZMQ sockets across machines via SSH tunneling. Added new ssh_tunnel_mode attribute to enable ssh tunneling at provide address at server end only. Implemented new check_open_port helper method to validate availability of host at given open port. Added new attributes ssh_tunnel_keyfile and ssh_tunnel_pwd to easily validate ssh connection. Extended this feature to be compatible with bi-directional mode and auto-reconnection. Disabled support for exclusive Multi-Server and Multi-Clients modes. Implemented logic to automatically enable paramiko support if installed. Reserved port- 47 for testing. Additional colorspace support for input frames with Frame-Compression enabled: Allowed to manually select colorspace on-the-fly with JPEG frame compression. Updated jpeg_compression dict parameter to support colorspace string values. Added all supported colorspace values by underline simplejpeg library. Server enforced frame-compression colorspace on client(s). Enable \"BGR\" colorspace by default. Added Example for changing incoming frames colorspace with NetGear's Frame Compression. Updated Frame Compression parameters in NetGear docs. Updated existing CI tests to cover new frame compression functionality. NetGear_Async: New exclusive Bidirectional Mode for bidirectional data transfer: NetGear_Async's first-ever exclusive Bidirectional mode with pure asyncio implementation. Bidirectional mode is only available with User-defined Custom Source(i.e. source=None ) Added support for PAIR & REQ/REP bidirectional patterns for this mode. Added powerful asyncio.Queues for handling user data and frames in real-time. Implemented new transceive_data method to Transmit (in Recieve mode) and Receive (in Send mode) data in real-time. Implemented terminate_connection internal asyncio method to safely terminate ZMQ connection and queues. Added msgpack automatic compression encoding and decoding of data and frames in bidirectional mode. Added support for np.ndarray video frames. Added new bidirectional_mode attribute for enabling this mode. Added 8-digit random alphanumeric id generator for each device. NetGear_Async will throw RuntimeError if bidirectional mode is disabled at server or client but not both. Added new disable_confirmation used to force disable termination confirmation from client in terminate_connection . Added task_done() method after every get() call to gracefully terminate queues. Added new secrets and string imports. WebGear: Updated JPEG Frame compression with simplejpeg : Implemented JPEG compression algorithm for 4-5% performance boost at cost of minor loss in quality. Utilized encode_jpeg and decode_jpeg methods to implement turbo-JPEG transcoding with simplejpeg . Added new options to control JPEG frames quality , enable fastest dct , fast upsampling to boost performance. Added new jpeg_compression , jpeg_compression_quality , jpeg_compression_fastdct , jpeg_compression_fastupsample attributes. Enabled fast dct by default with JPEG frames at 90% . Incremented default frame reduction to 25% . Implemented automated grayscale colorspace frames handling. Updated old and added new usage examples. Dropped support for depreciated attributes from WebGear and added new attributes. Added new WebGear Theme: (Checkout at https://github.com/abhiTronix/vidgear-vitals ) Added responsive image scaling according to screen aspect ratios. Added responsive text scaling. Added rounded border and auto-center to image tag. Added bootstrap css properties to implement auto-scaling. Removed old resize() hack. Improved text spacing and weight. Integrated toggle full-screen to new implementation. Hide Scrollbar both in WebGear_RTC and WebGear Themes. Beautify files syntax and updated files checksum. Refactor files and removed redundant code. Bumped theme version to v0.1.2 . WebGear_RTC: Added native support for middlewares: Added new global middleware variable for easily defining Middlewares as list. Added validity check for Middlewares. Added tests for middlewares support. Added example for middlewares support. Extended middlewares support to WebGear API too. Added related imports. Added new WebGear_RTC Theme: (Checkout at https://github.com/abhiTronix/vidgear-vitals ) Implemented new responsive video scaling according to screen aspect ratios. Added bootstrap CSS properties to implement auto-scaling. Removed old resize() hack. Beautify files syntax and updated files checksum. Refactored files and removed redundant code. Bumped theme version to v0.1.2 Helper: New automated interpolation selection for gears: Implemented retrieve_best_interpolation method to automatically select best available interpolation within OpenCV. Added support for this method in WebGear, WebGear_RTC and Stabilizer Classes/APIs. Added new CI tests for this feature. Implemented get_supported_demuxers method to get list of supported demuxers. CI: Added new no-response work-flow for stale issues. Added new CI tests for SSH Tunneling Mode. Added paramiko to CI dependencies. Added support for \"hls\" format in existing CI tests. Added new functions check_valid_m3u8 and extract_meta_video for validating HLS files. Added new m3u8 dependency to CI workflows. Added complete CI tests for NetGear_Async's new Bidirectional Mode: Implemented new exclusive Custom_Generator class for testing bidirectional data dynamically on server-end. Implemented new exclusive client_dataframe_iterator method for testing bidirectional data on client-end. Implemented test_netgear_async_options and test_netgear_async_bidirectionalmode two new tests. Added timeout value on server end in CI tests. Setup.py: Added new cython and msgpack dependency. Added msgpack and msgpack_numpy to auto-install latest. BASH: Added new temp_m3u8 folder for generating M3U8 assets in CI tests. Docs: Added docs for new Apple HLS StreamGear format: Added StreamGear HLS transcoding examples for both StreamGear modes. Updated StreamGear parameters to w.r.t new HLS configurations. Added open-sourced \"Sintel\" - project Durian Teaser Demo with StreamGear's HLS stream using Clappr and raw.githack.com. Added new HLS chunks at https://github.com/abhiTronix/vidgear-docs-additionals for StreamGear Added support for HLS video in Clappr within custom.js using HlsjsPlayback plugin. Added support for Video Thumbnail preview for HLS video in Clappr within custom.js Added hlsjs-playback.min.js JS script and suitable configuration for HlsjsPlayback plugin. Added custom labels for quality levels selector in custom.js . Added new docs content related to new Apple HLS format. Updated DASH chunk folder at https://github.com/abhiTronix/vidgear-docs-additionals . Added example for audio input support from external device in StreamGear. Added steps for using -audio attribute on different OS platforms in StreamGear. Added usage examples for NetGear_Async's Bidirectional Mode: Added new Usage examples and Reference doc for NetGear_Async's Bidirectional Mode. Added new image asset for NetGear_Async's Bidirectional Mode. Added NetGear_Async's option parameter reference. Updated NetGear_Async definition in docs. Changed font size for Helper methods. Renamed Bonus section to References in mkdocs.yml . Added Gitter sidecard embed widget: Imported gitter-sidecar script to main.html . Updated custom.js to set global window option. Updated Sidecard UI in custom.css . Added bonus examples to help section: Implemented a curated list of more advanced examples with unusual configuration for each API. Added several new contents and updated context. Added support for search suggestions, search highlighting and search sharing (i.e. deep linking) Added more content to docs to make it more user-friendly. Added warning that JPEG Frame-Compression is disabled with Custom Source in WebGear. Added steps for identifying and specifying sound card on different OS platforms in WriteGear. Added Zenodo DOI badge and its reference in BibTex citations. Added extra.homepage parameter, which allows for setting a dedicated URL for site_url . Added pymdownx.striphtml plugin for stripping comments. Added complete docs for SSH Tunneling Mode. Added complete docs for NetGear's SSH Tunneling Mode. Added pip upgrade related docs. Added docs for installing vidgear with only selective dependencies Added new advance / experiment admonition with new background color. Added new icons SVGs for advance and warning admonition. Added new usage example and related information. Added new image assets for ssh tunneling example. Added new admonitions Added new FAQs. Updates/Improvements VidGear Core: New behavior to virtually isolate optional API specific dependencies by silencing ImportError on all VidGear's APIs import. Implemented algorithm to cache all imports on startup but silence any ImportError on missing optional dependency. Now ImportError will be raised only any certain API specific dependency is missing during given API's initialization. New import_dependency_safe to imports specified dependency safely with importlib module. Replaced all APIs imports with import_dependency_safe . Added support for relative imports in import_dependency_safe . Implemented error parameter to by default ImportError with a meaningful message if a dependency is missing, Otherwise if error = log a warning will be logged and on error = silent everything will be quit. But If a dependency is present, but older than specified, an error is raised if specified. Implemented behavior that if a dependency is present, but older than min_version specified, an error is raised always. Implemented custom_message to display custom message on error instead of default one. Implemented separate import_core_dependency function to import and check for specified core dependency. ImportError will be raised immediately if core dependency not found. StreamGear: Replaced depreciated -min_seg_duration flag with -seg_duration . Removed redundant -re flag from RTFM. Improved Live-Streaming performance by disabling SegmentTimline Improved DASH assets detection for removal by using filename prefixes. NetGear: Replaced np.newaxis with np.expand_dims . Replaced random module with secrets while generating system ID. Update array indexing with np.copy . NetGear_Async: Improved custom source handling. Removed deprecated loop parameter from asyncio methods. Re-implemented skip_loop parameter in close() method. run_until_complete will not used if skip_loop is enabled. skip_loop now will create asyncio task instead and will enable disable_confirmation by default. Replaced create_task with ensure_future to ensure backward compatibility with python-3.6 legacies. Simplified code for transceive_data method. WebGear_RTC: Improved handling of failed ICE connection. Made is_running variable globally available for internal use. Helper: Added 4320p resolution support to dimensions_to_resolutions method. Implemented new delete_file_safe to safely delete files at given path. Replaced os.remove calls with delete_file_safe . Added support for filename prefixes in delete_ext_safe method. Improved and simplified create_blank_frame functions frame channels detection. Added logging parameter to capPropId function to forcefully discard any error(if required). Setup.py: Added patch for numpy dependency, numpy recently dropped support for python 3.6.x legacies. See https://github.com/numpy/numpy/releases/tag/v1.20.0 Removed version check on certain dependencies. Re-added aiortc to auto-install latest version. Asyncio: Changed asyncio.sleep value to 0 . The amount of time sleep is irrelevant; the only purpose await asyncio.sleep() serves is to force asyncio to suspend execution to the event loop, and give other tasks a chance to run. Also, await asyncio.sleep(0) will achieve the same effect. https://stackoverflow.com/a/55782965/10158117 License: Dropped publication year range to avoid confusion. (Signed and Approved by @abhiTronix ) Updated Vidgear license's year of first publication of the work in accordance with US copyright notices defined by Title 17, Chapter 4(Visually perceptible copies): https://www.copyright.gov/title17/92chap4.html Reflected changes in all copyright notices. CI: Updated macOS VM Image to latest in azure devops. Updated VidGear Docs Deployer Workflow. Updated WebGear_RTC CI tests. Removed redundant code from CI tests. Updated tests to increase coverage. Enabled Helper tests for python 3.8+ legacies. Enabled logging in validate_video method. Added -hls_base_url to streamgear tests. Update mpegdash dependency to 0.3.0-dev2 version in Appveyor. Updated CI tests for new HLS support Updated CI tests from scratch for new native HLS support in StreamGear. Updated test patch for StreamGear. Added exception for RunTimeErrors in NetGear CI tests. Added more directories to Codecov ignore list. Imported relative logger_handler for asyncio tests. Docs: Re-positioned few docs comments at bottom for easier detection during stripping. Updated to new extra analytics parameter in Material Mkdocs. Updated dark theme to dark orange . Changed fonts => text: Muli & code: Fira Code Updated fonts to Source Sans Pro . Updated setup.py update-link for modules. Re-added missing StreamGear Code docs. Several minor tweaks and typos fixed. Updated 404.html page. Updated admonitions colors and beautified custom.css . Replaced VideoGear & CamGear with OpenCV in CPU intensive examples. Updated mkdocs.yml with new changes and URLs. Moved FAQ examples to bonus examples. Moved StreamGear primary modes to separate sections for better readability. Implemented separate overview and usage example pages for StreamGear primary modes. Improved StreamGear docs context and simplified language. Renamed StreamGear overview page to introduction . Re-written Threaded-Queue-Mode from scratch with elaborated functioning. Replace Paypal with Liberpay in FUNDING.yml . Updated FFmpeg Download links. Reverted UI change in CSS. Updated changelog.md and fixed clutter. Updated README.md and mkdocs.yml with new additions Updated context for CamGear example. Restructured and added more content to docs. Updated comments in source code. Removed redundant data table tweaks from custom.css . Re-aligned badges in README.md. Beautify custom.css . Updated mkdocs.yml . Updated context and fixed typos. Added missing helper methods in Reference. Updated Admonitions. Updates images assets. Bumped CodeCov. Logging: Improved logging level-names. Updated logging messages. Minor tweaks to needs-more-info template. Updated issue templates and labels. Removed redundant imports. Breaking Updates/Changes Virtually isolated all API specific dependencies, Now ImportError for API-specific dependencies will be raised only when any of them is missing at API's initialization. Renamed delete_safe to delete_ext_safe . Dropped support for frame_jpeg_quality , frame_jpeg_optimize , frame_jpeg_progressive attributes from WebGear. Bug-fixes CamGear: Hot-fix for Live Camera Streams: Added new event flag to keep check on stream read. Implemented event wait for read() to block it when source stream is busy. Added and Linked THREAD_TIMEOUT with event wait timout. Improved backward compatibility of new additions. Enforced logging for YouTube live. NetGear: Fixed Bidirectional Video-Frame Transfer broken with frame-compression: Fixed return_data interfering with return JSON-data in receive mode. Fixed logic. Fixed color-subsampling interfering with colorspace. Patched external simplejpeg bug. Issue: https://gitlab.com/jfolz/simplejpeg/-/issues/11 Added np.squeeze to drop grayscale frame's 3 rd dimension on Client's end. Fixed bug that cause server end frame dimensions differ from client's end when frame compression enabled. NetGear_Async: Fixed bug related asyncio queue freezing on calling join() . Fixed ZMQ connection bugs in bidirectional mode. Fixed several critical bugs in event loop handling. Fixed several bugs in bidirectional mode implementation. Fixed missing socket termination in both server and client end. Fixed timeout parameter logic. Fixed typos in error messages. WebGear_RTC: Fixed stream freezes after web-page reloading: Implemented new algorithm to continue stream even when webpage is reloaded. Inherit and modified next_timestamp VideoStreamTrack method for generating accurate timestamps. Implemented reset_connections callable to reset all peer connections and recreate Video-Server timestamps. (Implemented by @kpetrykin ) Added close_connection endpoint in JavaScript to inform server page refreshing.(Thanks to @kpetrykin ) Added exclusive reset connection node /close_connection in routes. Added reset() method to Video-Server class for manually resetting timestamp clock. Added reset_enabled flag to keep check on reloads. Fixed premature webpage auto-reloading. Added additional related imports. Fixed web-page reloading bug after stream ended: Disable webpage reload behavior handling for Live broadcasting. Disable reload CI test on Windows machines due to random failures. Improved handling of failed ICE connection. Fixed Assertion error bug: Source must raise MediaStreamError when stream ends instead of returning None-type. WebGear Removed format specific OpenCV decoding and encoding support for WebGear. Helper: Regex bugs fixed: New improved regex for discovering supported encoders in get_supported_vencoders . Re-implemented check for extracting only valid output protocols in is_valid_url . Minor tweaks for better regex compatibility. Bugfix related to OpenCV import: Bug fixed for OpenCV import comparison test failing with Legacy versions and throwing ImportError . Replaced packaging.parse_version with more robust distutils.version . Fixed bug with create_blank_frame that throws error with gray frames: Implemented automatic output channel correction inside create_blank_frame function. Extended automatic output channel correction support to asyncio package. Implemented RSTP protocol validation as demuxer , since it's not a protocol but a demuxer. Removed redundant logger_handler , mkdir_safe , retrieve_best_interpolation , capPropId helper functions from asyncio package. Relatively imported helper functions from non-asyncio package. Removed unused aiohttp dependency. Removed asctime formatting from logging. StreamGear: Fixed Multi-Bitrate HLS VOD streams: Re-implemented complete workflow for Multi-Bitrate HLS VOD streams. Extended support to both Single-Source and Real-time Frames Modes. Fixed bugs with audio-video mapping. Fixed master playlist not generating in output. Fixed improper -seg_duration value resulting in broken pipeline. Fixed expected aspect ratio not calculated correctly for additional streams. Fixed stream not terminating when provided input from external audio device. Fixed bugs related to external audio not mapped correctly in HLS format. Fixed OPUS audio fragments not supported with MP4 video in HLS. Fixed unsupported high audio bit-rate bug. Setup.py: Fixed latest_version returning incorrect version for some PYPI packages. Removed latest_version variable support from simplejpeg . Fixed streamlink only supporting requests==2.25.1 on Windows. Removed all redundant dependencies like colorama , aiofiles , aiohttp . Fixed typos in dependencies. Setup.cfg: Replaced dashes with underscores to remove warnings. CI: Replaced buggy starlette.TestClient with async-asgi-testclient in WebGear_RTC Removed run() method and replaced with pure asyncio implementation. Added new async-asgi-testclient CI dependency. Fixed fake_picamera class logger calling vidgear imports prematurely before importing picamera class in tests. Implemented new fake_picamera class logger inherently with logging module. Moved sys.module logic for faking to init.py . Added __init__.py to ignore in Codecov. Fixed event loop closing prematurely while reloading: Internally disabled suspending event loop while reloading. Event Policy Loop patcher added for WebGear_RTC tests. Fixed return_assets_path path bug. Fixed typo in TimeoutError exception import. Fixed eventloop is already closed bug. Fixed eventloop bugs in Helper CI tests. Fixed several minor bugs related to new CI tests. Fixed bug in PiGear tests. Docs: Fixed 404 page does not work outside the site root with mkdocs. Fixed markdown files comments not stripped when converted to HTML. Fixed missing heading in VideoGear. Typos in links and code comments fixed. Several minor tweaks and typos fixed. Fixed improper URLs/Hyperlinks and related typos. Fixed typos in usage examples. Fixed redundant properties in CSS. Fixed bugs in mkdocs.yml . Fixed docs contexts and typos. Fixed stream.release() missing in docs. Fixed several typos in code comments. Removed dead code from docs. Refactored Code and reduced redundancy. Fixed shutdown in main.py . Fixed logging comments. Pull Requests PR #210 PR #215 PR #222 PR #223 PR #227 PR #231 PR #233 PR #237 PR #239 PR #243 New Contributors @kpetrykin v0.2.1 (2021-04-25) \u2693 New Features WebGear_RTC: A new API that is similar to WeGear API in all aspects but utilizes WebRTC standard instead of Motion JPEG for streaming. Now it is possible to share data and perform teleconferencing peer-to-peer, without requiring that the user install plugins or any other third-party software. Added a flexible backend for aiortc - a python library for Web Real-Time Communication (WebRTC). Integrated all functionality and parameters of WebGear into WebGear_RTC API. Implemented JSON Response with a WebRTC Peer Connection of Video Server. Added a internal RTC_VideoServer server on WebGear_RTC, a inherit-class to aiortc's VideoStreamTrack API. New Standalone UI Default theme v0.1.1 for WebGear_RTC from scratch without using 3 rd -party assets. (by @abhiTronix ) New custom.js and custom.css for custom responsive behavior. Added WebRTC support to custom.js and ensured compatibility with WebGear_RTC. Added example support for ICE framework and STUN protocol like WebRTC features to custom.js . Added resize() function to custom.js to automatically adjust video & img tags for smaller screens. Added WebGear_RTC support in main.py for easy access through terminal using --mode flag. Integrated all WebGear_RTC enhancements to WebGear Themes. Added CI test for WebGear_RTC. Added complete docs for WebGear_RTC API. Added bare-minimum as well as advanced examples usage code. Added new theme images. Added Reference and FAQs. CamGear API: New Improved Pure-Python Multiple-Threaded Implementation: Optimized Threaded-Queue-Mode Performance. (PR by @bml1g12 ) Replaced regular queue.full checks followed by sleep with implicit sleep with blocking queue.put . Replaced regular queue.empty checks followed by queue. Replaced nowait_get with a blocking queue.get natural empty check. Up-to 2x performance boost than previous implementations. New THREAD_TIMEOUT attribute to prevent deadlocks: Added support for THREAD_TIMEOUT attribute to its options parameter. Updated CI Tests and docs. WriteGear API: New more robust handling of default video-encoder in compression mode: Implemented auto-switching of default video-encoder automatically based on availability. API now selects Default encoder based on priority: \"libx264\" > \"libx265\" > \"libxvid\" > \"mpeg4\" . Added get_supported_vencoders Helper method to enumerate Supported Video Encoders. Added common handler for -c:v and -vcodec flags. NetGear API: New Turbo-JPEG compression with simplejpeg Implemented JPEG compression algorithm for 4-5% performance boost at cost of minor loss in quality. Utilized encode_jpeg and decode_jpeg methods to implement turbo-JPEG transcoding with simplejpeg . Added options to control JPEG frames quality, enable fastest dct, fast upsampling to boost performance. Added new jpeg_compression , jpeg_compression_quality , jpeg_compression_fastdct , jpeg_compression_fastupsample attributes. Enabled fast dct by default with JPEG frames at 90%. Added Docs for JPEG Frame Compression. WebGear API: New modular and flexible configuration for Custom Sources: Implemented more convenient approach for handling custom source configuration. Added new config global variable for this new behavior. Now None-type source parameter value is allowed for defining own custom sources. Added new Example case and Updates Docs for this feature. Added new CI Tests. New Browser UI Updates: New Standalone UI Default theme v0.1.0 for browser (by @abhiTronix ) Completely rewritten theme from scratch with only local resources. New custom.js and custom.css for custom responsive behavior. New sample glow effect with css. New sample click to full-screen behavior with javascript. Removed all third-party theme dependencies. Update links to new github server abhiTronix/vidgear-vitals Updated docs with new theme's screenshots. Added enable_infinite_frames attribute for enabling infinite frames. Added New modular and flexible configuration for Custom Sources. Bumped WebGear Theme Version to v0.1.1. Updated Docs and CI tests. ScreenGear API: Implemented Improved Pure-Python Multiple-Threaded like CamGear. Added support for THREAD_TIMEOUT attribute to its options parameter. StreamGear API: Enabled pseudo live-streaming flag re for live content. Docs: Added new native docs versioning to mkdocs-material. Added new examples and few visual tweaks. Updated Stylesheet for versioning. Added new DASH video chunks at https://github.com/abhiTronix/vidgear-docs-additionals for StreamGear and Stabilizer streams. Added open-sourced \"Tears of Steel\" * project Mango Teaser video chunks. Added open-sourced \"Subspace Video Stabilization\" http://web.cecs.pdx.edu/~fliu/project/subspace_stabilization/ video chunks. Added support for DASH Video Thumbnail preview in Clappr within custom.js . Added responsive clappr DASH player with bootstrap's embed-responsive . Added new permalink icon and slugify to toc. Added \"back-to-top\" button for easy navigation. Helper: New GitHub Mirror with latest Auto-built FFmpeg Static Binaries: Replaced new GitHub Mirror abhiTronix/FFmpeg-Builds in helper.py New CI maintained Auto-built FFmpeg Static Binaries. Removed all 3 rd -party and old links for better compatibility and Open-Source reliability. Updated Related CI tests. Added auto-font-scaling for create_blank_frame method. Added c_name parameter to generate_webdata and download_webdata to specify class. A more robust Implementation of Downloading Artifacts: Added a custom HTTP TimeoutHTTPAdapter Adapter with a default timeout for all HTTP calls based on this GitHub comment . Implemented http client and the send() method to ensure that the default timeout is used if a timeout argument isn't provided. Implemented Requests session with block to exit properly even if there are unhandled exceptions. Add a retry strategy to custom TimeoutHTTPAdapter Adapter with max 3 retries and sleep( backoff_factor=1 ) between failed requests. Added create_blank_frame method to create bland frames with suitable text. [CI] Continuous Integration: Added new fake frame generated for fake picamera class with numpy. Added new create_bug parameter to fake picamera class for emulating various artificial bugs. Added float/int instance check on time_delay for camgear and pigear. Added EXIT_CODE to new timeout implementation for pytests to upload codecov report when no timeout. Added auxiliary classes to fake picamera for facilitating the emulation. Added new CI tests for PiGear Class for testing on all platforms. Added shutdown() function to gracefully terminate WebGear_RTC API. Added new coreutils brew dependency. Added handler for variable check on exit and codecov upload. Added is_running flag to WebGear_RTC to exit safely. Setup: New automated latest version retriever for packages: Implemented new latest_version method to automatically retrieve latest version for packages. Added Some Dependencies. Added simplejpeg package for all platforms. Updates/Improvements Added exception for RunTimeErrors in NetGear CI tests. WriteGear: Critical file write access checking method: Added new check_WriteAccess Helper method. Implemented a new robust algorithm to check if given directory has write-access. Removed old behavior which gives irregular results. Helper: Maintenance Updates Added workaround for Python bug. Added safe_mkdir to check_WriteAccess to automatically create non-existential parent folder in path. Extended check_WriteAccess Patch to StreamGear. Simplified check_WriteAccess to handle Windows envs easily. Updated FFmpeg Static Download URL for WriteGear. Implemented fallback option for auto-calculating bitrate from extracted audio sample-rate in validate_audio method. Docs: General UI Updates Updated Meta tags for og site and twitter cards. Replaced Custom dark theme toggle with mkdocs-material's official Color palette toggle Added example for external audio input and creating segmented MP4 video in WriteGear FAQ. Added example for YouTube streaming with WriteGear. Removed custom dark-material.js and header.html files from theme. Added blogpost link for detailed information on Stabilizer Working. Updated mkdocs.yml and custom.css configuration. Remove old hack to resize clappr DASH player with css. Updated Admonitions. Improved docs contexts. Updated CSS for version-selector-button. Adjusted files to match new themes. Updated welcome-bot message for typos. Removed redundant FAQs from NetGear Docs. Updated Assets Images. Updated spacing. CI: Removed unused github.ref from yaml. Updated OpenCV Bash Script for Linux envs. Added timeout-minutes flag to github-actions workflow. Added timeout flag to pytest. Replaced Threaded Gears with OpenCV VideoCapture API. Moved files and Removed redundant code. Replaced grayscale frames with color frames for WebGear tests. Updated pytest timeout value to 15mins. Removed aiortc automated install on Windows platform within setup.py. Added new timeout logic to continue to run on external timeout for GitHub Actions Workflows. Removed unreliable old timeout solution from WebGear_RTC. Removed timeout_decorator and asyncio_timeout dependencies for CI. Removed WebGear_RTC API exception from codecov. Implemented new fake picamera class to CI utils for emulating RPi Camera-Module Real-time capabilities. Implemented new get_RTCPeer_payload method to receive WebGear_RTC peer payload. Removed PiGear from Codecov exceptions. Disable Frame Compression in few NetGear tests failing on frame matching. Updated NetGear CI tests to support new attributes Removed warnings and updated yaml Added pytest.ini to address multiple warnings. Updated azure workflow condition syntax. Update mike settings for mkdocs versioning. Updated codecov configurations. Minor logging and docs updates. Implemented pytest timeout for azure pipelines for macOS envs. Added aiortc as external dependency in appveyor.yml . Re-implemented WebGear_RTC improper offer-answer handshake in CI tests. WebGear_RTC CI Updated with VideoTransformTrack to test stream play. Implemented fake AttributeError for fake picamera class. Updated PiGear CI tests to increment codecov. Update Tests docs and other minor tweaks to increase overall coverage. Enabled debugging and disabled exit 1 on error in azure pipeline. Removed redundant benchmark tests. Helper: Added missing RSTP URL scheme to is_valid_url method. NetGear_Async: Added fix for uvloop only supporting python>=3.7 legacies. Extended WebGear's Video-Handler scope to https . CI: Remove all redundant 32-bit Tests from Appveyor: Appveyor 32-bit Windows envs are actually running on 64-bit machines. More information here: https://help.appveyor.com/discussions/questions/20637-is-it-possible-to-force-running-tests-on-both-32-bit-and-64-bit-windows Setup: Removed latest_version behavior from some packages. NetGear_Async: Revised logic for handling uvloop for all platforms and legacies. Setup: Updated logic to install uvloop-\"v0.14.0\" for python-3.6 legacies. Removed any redundant code from webgear. StreamGear: Replaced Ordinary dict with Ordered Dict to use move_to_end method. Moved external audio input to output parameters dict. Added additional imports. Updated docs to reflect changes. Numerous Updates to Readme and mkdocs.yml . Updated font to FONT_HERSHEY_SCRIPT_COMPLEX and enabled logging in create_blank_frame. Separated channels for downloading and storing theme files for WebGear and WebGear_RTC APIs. Removed logging condition to always inform user in a event of FFmpeg binary download failure. WebGear_RTC: Improved auto internal termination. More Performance updates through setCodecPreferences . Moved default Video RTC video launcher to __offer . NetGear_Async: Added timeout to client in CI tests. Reimplemented and updated changelog.md . Updated code comments. Setup: Updated keywords and classifiers. Bumped codecov. Breaking Updates/Changes WriteGear will automatically switch video encoder to default if specified encoder not found. WriteGear will throw RuntimeError if no suitable default encoder found! Removed format specific OpenCV decoding and encoding support for NetGear. Dropped support for compression_format , compression_param attributes from NetGear. Non-existent parent folder in output_filename value will no longer be considered as invalid in StreamGear and WriteGear APIs. None-type source parameter value is allowed for WebGear and NetGear_Async for defining custom sources. Bug-fixes CamGear: Fixed F821 undefined name 'queue' bug. NetGear_Async: Fixed source parameter missing None as default value. Fixed uvloops only supporting python>=3.7 in NetGear_Async. Helper: Fixed Zombie processes in check_output method due a hidden bug in python. For reference: https://bugs.python.org/issue37380 Fixed regex in validate_video method. Docs: Invalid site_url bug patched in mkdocs.yml Remove redundant mike theme support and its files. Fixed video not centered when DASH video in fullscreen mode with clappr. Fixed Incompatible new mkdocs-docs theme. Fixed missing hyperlinks. CI: Fixed NetGear Address bug Fixed bugs related to termination in WebGear_RTC. Fixed random CI test failures and code cleanup. Fixed string formating bug in Helper.py. Fixed F821 undefined name bugs in WebGear_RTC tests. NetGear_Async Tests fixes. Fixed F821 undefined name bugs. Fixed typo bugs in main.py . Fixed Relative import bug in PiGear. Fixed regex bug in warning filter. Fixed WebGear_RTC frozen threads on exit. Fixed bugs in codecov bash uploader setting for azure pipelines. Fixed False-positive picamera import due to improper sys.module settings. Fixed Frozen Threads on exit in WebGear_RTC API. Fixed deploy error in VidGear Docs Deployer workflow Fixed low timeout bug. Fixed bugs in PiGear tests. Patched F821 undefined name bug. StreamGear: Fixed StreamGear throwing Picture size 0x0 is invalid bug with external audio. Fixed default input framerate value getting discarded in Real-time Frame Mode. Fixed internal list-formatting bug. Fixed E999 SyntaxError bug in main.py . Fixed Typo in bash script. Fixed WebGear freeze on reloading bug. Fixed anomalies in install_opencv bash script. Helper: Bug Fixed in download_ffmpeg_binaries method. Helper: Fixed OSError bug in check_WriteAccess method. Helper: Fixed Input Audio stream bitrate test failing to detect audio-bitrate in certain videos with validate_audio method. Fixed bugs in requests module's function arguments. Fixed None-type stream bug in WebGear. Fixed random crashes in WebGear. Fixed numerous CI test bugs. Fixed several typos. Pull Requests PR #192 PR #196 PR #203 PR #206 New Contributors @bml1g12 v0.2.0 (2021-01-01) \u2693 New Features CamGear API: Support for various Live-Video-Streaming services: Added seamless support for live video streaming sites like Twitch, LiveStream, Dailymotion etc. Implemented flexible framework around streamlink python library with easy control over parameters and quality. Stream Mode can now automatically detects whether source belong to YouTube or elsewhere, and handles it with appropriate API. Re-implemented YouTube URLs Handler: Re-implemented CamGear's YouTube URLs Handler completely from scratch. New Robust Logic to flexibly handing video and video-audio streams. Intelligent stream selector for selecting best possible stream compatible with OpenCV. Added support for selecting stream qualities and parameters. Implemented new get_supported_quality helper method for handling specified qualities Fixed Live-Stream URLs not supported by OpenCV's Videocapture and its FFmpeg. Added additional STREAM_QUALITY and STREAM_PARAMS attributes. ScreenGear API: Multiple Backends Support: Added new multiple backend support with new pyscreenshot python library. Made pyscreenshot the default API for ScreenGear, replaces mss . Added new backend parameter for this feature while retaining previous behavior. Added native automated RGB to BGR conversion for default PIL backend. Kept support for old mss for old compatibility and multi-screen support. Added native dimensional support for multi-screen. Added support all input from all multiple screens. Updated ScreenGear Docs. Updated ScreenGear CI tests. StreamGear API: Changed default behaviour to support complete video transcoding. Added -livestream attribute to support live-streaming. Added additional parameters for -livestream attribute functionality. Updated StreamGear Tests. Updated StreamGear docs. Stabilizer Class: New Robust Error Handling with Blank Frames: Elegantly handles all crashes due to Empty/Blank/Dark frames. Stabilizer throws Warning with this new behavior instead of crashing. Updated CI test for this feature. Docs: Automated Docs Versioning: Implemented Docs versioning through mike API. Separate new workflow steps to handle different versions. Updated docs deploy worflow to support release and dev builds. Added automatic version extraction from github events. Added version-select.js and version-select.css files. Toggleable Dark-White Docs Support: Toggle-button to easily switch dark, white and preferred theme. New Updated Assets for dark backgrounds New css, js files/content to implement this behavior. New material icons for button. Updated scheme to slate in mkdocs.yml . New Theme and assets: New purple theme with dark-purple accent color. New images assets with updated transparent background. Support for both dark and white theme. Increased rebufferingGoal for dash videos. New updated custom 404 page for docs. Issue and PR automated-bots changes New need_info.yml YAML Workflow. New needs-more-info.yml Request-Info template. Replaced Request-Info templates. Improved PR and Issue welcome formatting. Added custom HTML pages. Added show_root_heading flag to disable headings in References. Added new inserAfter function to version-select.js. Adjusted hue for dark-theme for better contrast. New usage examples and FAQs. Added gitmoji for commits. Continuous Integration: Maintenance Updates: Added support for new VIDGEAR_LOGFILE environment variable in Travis CI. Added missing CI tests. Added logging for helper functions. Azure-Pipeline workflow for MacOS envs Added Azure-Pipeline Workflow for testing MacOS environment. Added codecov support. GitHub Actions workflow for Linux envs Added GitHub Action work-flow for testing Linux environment. New YAML to implement GitHub Action workflow for python 3.6, 3.7, 3,8 & 3.9 matrices. Added Upload coverage to Codecov GitHub Action workflow. New codecov-bash uploader for Azure Pipelines. Logging: Added file support Added VIDGEAR_LOGFILE environment variable to manually add file/dir path. Reworked logger_handler() Helper methods (in asyncio too). Added new formatter and Filehandler for handling logger files. Added restore_levelnames auxiliary method for restoring logging levelnames. Added auto version extraction from package version.py in setup.py. Updates/Improvements Added missing Lazy-pirate auto-reconnection support for Multi-Servers and Multi-Clients Mode in NetGear API. Added new FFmpeg test path to Bash-Script and updated README broken links. Asset Cleanup: Removed all third-party javascripts from projects. Linked all third-party javascript directly. Cleaned up necessary code from CSS and JS files. Removed any copyrighted material or links. Rewritten Docs from scratch: Improved complete docs formatting. Simplified language for easier understanding. Fixed mkdocstrings showing root headings. Included all APIs methods to mkdocstrings docs. Removed unnecessary information from docs. Corrected Spelling and typos. Fixed context and grammar. Removed motivation.md . Renamed many terms. Fixed hyper-links. Reformatted missing or improper information. Fixed context and spellings in Docs files. Simplified language for easy understanding. Updated image sizes for better visibility. Bash Script: Updated to Latest OpenCV Binaries version and related changes Docs: Moved version-selector to header and changed default to alias. Docs: Updated deploy_docs.yml for releasing dev, stable, and release versions. Re-implemented overridden material theme. Updated docs with all new additions and examples. CamGear: CI Stream Mode test updated. Updated ReadMe.md badges. Updated CI tests. Updated setup.py with new features. Updated contributing.md and ReadMe.md . Updated OpenCV version to 4.5.1-dev in bash scripts Updated changelog.md . Moved WebGear API to Streaming Gears. Bumped Codecov. UI changes to version-select.js Docs: Retitle the versions and mkdocs.yml formatting updated. Docs: Version Selector UI reworked and other minor changes. Breaking Updates/Changes y_tube parameter renamed as stream_mode in CamGear API! Removed Travis support and travis.yml deleted. Bug-fixes Fixed StreamGear API Limited Segments Bug Fixed Missing links in docs and bump up version. CI: Fixed Appveyor need newer VM image to support Python 3.9.x matrix. ScreenGear BugFix: Fixed Error Handling and updated CI Tests. Fixed improper mkdocs.yml variables. Fixed GStreamer plugin support in bash scripts. Fixed typos in YAMLs and docs. Docs: Fixed Docs Deployer YAML bug for CI envs. Fixed wrong import in YAML. Fixed visible hyperlink on hover in dark-toggle button. Docs: Deployer YAML bug fixed. Docs YAML: issue jimporter/mike#33 patched and fixed fetch-depth=0 . Docs: version-select.js bug fixed. Docs: UI Bugs Fixed. CI: Codecov bugfixes. Azure-Pipelines Codecov BugFixes. Fixed version.json not detecting properly in version-select.js . Fixed images not centered inside <figure> tag. Fixed Asset Colors. Fixed failing CI tests. Fixed Several logging bugs. Pull Requests PR #164 PR #170 PR #173 PR #181 PR #183 PR #184 v0.1.9 (2020-08-31) \u2693 New Features StreamGear API: New API that automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats. Implemented multi-platform , standalone, highly extensible and flexible wrapper around FFmpeg for generating chunked-encoded media segments of the media, and easily accessing almost all of its parameters. API automatically transcodes videos/audio files & real-time frames into a sequence of multiple smaller chunks/segments and also creates a Manifest file. Added initial support for MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) . Constructed default behavior in StreamGear, for auto-creating a Primary Stream of same resolution and framerate as source. Added TQDM progress bar in non-debugged output for visual representation of internal processes. Implemented several internal methods for preprocessing FFmpeg and internal parameters for producing streams. Several standalone internal checks to ensure robust performance. New terminate() function to terminate StremGear Safely. New StreamGear Dual Modes of Operation: Implemented Single-Source and Real-time Frames like independent Transcoding Modes. Linked -video_source attribute for activating these modes Single-Source Mode , transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller segments for streaming Real-time Frames Mode , directly transcodes video-frames (as opposed to a entire file) , into a sequence of multiple smaller segments for streaming Added separate functions, stream() for Real-time Frame Mode and transcode_source() for Single-Source Mode for easy transcoding. Included auto-colorspace detection and RGB Mode like features (extracted from WriteGear) , into StreamGear. New StreamGear Parameters: Developed several new parameters such as: output : handles assets directory formats : handles adaptive HTTP streaming format. custom_ffmpeg : handles custom FFmpeg location. stream_params : handles internal and FFmpeg parameter seamlessly. logging : turns logging on or off. New stream_params parameter allows us to exploit almost all FFmpeg parameters and flexibly change its internal settings, and seamlessly generating high-quality streams with its attributes: -streams (list of dictionaries) for building additional streams with -resolution , -video_bitrate & -framerate like sub-attributes. -audio for specifying external audio. -video_source for specifying Single-Source Mode source. -input_framerate for handling input framerate in Real-time Frames Mode. -bpp attribute for handling bits-per-pixels used to auto-calculate video-bitrate. -gop to manually specify GOP length. -ffmpeg_download_path to handle custom FFmpeg download path on windows. -clear_prev_assets to remove any previous copies of SteamGear Assets. New StreamGear docs, MPEG-DASH demo, and recommended DASH players list: Added new StreamGear docs, usage examples, parameters, references, new FAQs. Added Several StreamGear usage examples w.r.t Mode of Operation. Implemented Clappr based on Shaka-Player , as Demo Player. Added Adaptive-dimensional behavior for Demo-player, purely in css. Hosted StreamGear generated DASH chunks on GitHub and served with raw.githack.com . Introduced variable quality level-selector plugin for Clapper Player. Provide various required javascripts and implemented additional functionality for player in extra.js . Recommended tested Online, Command-line and GUI Adaptive Stream players. Implemented separate FFmpeg installation doc for StreamGear API. Reduced rebufferingGoal for faster response. New StreamGear CI tests: Added IO and API initialization CI tests for its Modes. Added various mode Streaming check CI tests. NetGear_Async API: Added new send_terminate_signal internal method. Added WindowsSelectorEventLoopPolicy() for windows 3.8+ envs. Moved Client auto-termination to separate method. Implemented graceful termination with signal API on UNIX machines. Added new timeout attribute for controlling Timeout in Connections. Added missing termination optimizer ( linger=0 ) flag. Several ZMQ Optimizer Flags added to boost performance. WriteGear API: Added support for adding duplicate FFmpeg parameters to output_params : Added new -clones attribute in output_params parameter for handing this behavior.. Support to pass FFmpeg parameters as list, while maintaining the exact order it was specified. Built support for zmq.REQ/zmq.REP and zmq.PUB/zmq.SUB patterns in this mode. Added new CI tests debugging this behavior. Updated docs accordingly. Added support for Networks URLs in Compression Mode: output_filename parameter supports Networks URLs in compression modes only Added automated handling of non path/file Networks URLs as input. Implemented new is_valid_url helper method to easily validate assigned URLs value. Validates whether the given URL value has scheme/protocol supported by assigned/installed ffmpeg or not. WriteGear will throw ValueError if -output_filename is not supported. Added related CI tests and docs. Added disable_force_termination attribute in WriteGear to disable force-termination. NetGear API: Added option to completely disable Native Frame-Compression: Checks if any Incorrect/Invalid value is assigned on compression_format attribute. Completely disables Native Frame-Compression. Updated docs accordingly. CamGear API: Added new and robust regex for identifying YouTube URLs. Moved youtube_url_validator to Helper. New helper.py methods: Added validate_video function to validate video_source. Added extract_time Extract time from give string value. Added get_video_bitrate to calculate video birate from resolution, framerate, bits-per-pixels values. Added delete_safe to safely delete files of given extension. Added validate_audio to validate audio source. Added new Helper CI tests. Added new check_valid_mpd function to test MPD files validity. Added mpegdash library to CI requirements. Deployed New Docs Upgrades: Added new assets like images, gifs, custom scripts, javascripts fonts etc. for achieving better visual graphics in docs. Added clappr.min.js , dash-shaka-playback.js , clappr-level-selector.min.js third-party javascripts locally. Extended Overview docs Hyperlinks to include all major sub-pages (such as Usage Examples, Reference, FAQs etc.) . Replaced GIF with interactive MPEG-DASH Video Example in Stabilizer Docs. Added new pymdownx.keys to replace [Ctrl+C]/[\u2318+C] formats. Added new custom.css stylescripts variables for fluid animations in docs. Overridden announce bar and added donation button. Lossless WEBP compressed all PNG assets for faster loading. Enabled lazy-loading for GIFS and Images for performance. Reimplemented Admonitions contexts and added new ones. Added StreamGear and its different modes Docs Assets. Added patch for images & unicodes for PiP flavored markdown in setup.py . Added Request Info and Welcome GitHub Apps to automate PR and issue workflow Added new config.yml for customizations. Added various suitable configurations. Added new -clones attribute to handle FFmpeg parameter clones in StreamGear and WriteGear API. Added new Video-only and Audio-Only sources in bash script. Added new paths in bash script for storing StreamGear & WriteGear assets temporarily. Updates/Improvements Added patch for NotImplementedError in NetGear_Async API on Windows 3.8+ envs. Check for valid output file extension according to format selected in StreamGear. Completed migration to travis.com . Created new temp_write temp directory for WriteGear Assets in bash script. Deleted old Redundant assets and added new ones. Employed isort library to sort and group imports in Vidgear APIs. Enabled exception for list, tuple, int, float in WriteGear API's output_params dict. Enabled missing support for frame-compression in its primary Receive Mode. Enforced pixel formats for streams. Improved check for valid system path detection in WriteGear API. Overrided pytest-asyncio fixture in NetGear_Async API. Quoted Gear Headline for understanding each gear easily. Re-Positioned Gear's banner images in overview for better readability. Reduced redundant try-except blocks in NetGear Async. Reformatted and Simplified Docs context. Reimplemented return_testvideo_path CI function with variable streams. Reimplemented skip_loop in NetGear_Async to fix asyncio.CancelledError . Reimplemented buggy audio handler in StreamGear. Reimplemented images with <figure> and <figurecaption> like tags. Removed Python < 3.8 condition from all CI tests. Removed or Grouped redundant code for increasing codecov. Removed redundant code and simplified algorithmic complexities in Gears. Replaced ;nbsp with ;thinsp and ;emsp . Replaced IOError with more reliable RuntimeError in StreamGear Pipelines. Replaced del with pop in dicts. Replaced all Netgear CI tests with more reliable try-except-final blocks. Replaced simple lists with pymdownx.tasklist . Replaced subprocess call() with run() for better error handling in execute_ffmpeg_cmd function. Resized over-sized docs images. Simplified delete_safe Helper function. Simplified default audio-bitrate logic in StreamGear Updated CI tests and cleared redundant code from NetGear_Async API. Updated CI with new tests and Bumped Codecov. Updated Issue and PR templates. Updated Licenses for new files and shrink images dimensions. Updated Missing Helpful tips and increased logging. Updated PR guidelines for more clarity. Updated WebGear examples addresses from 0.0.0.0 to localhost . Updated WriteGear and StreamGear CI tests for not supporting temp directory. Updated README.md and changelog.md with new changes. Updated check_output and added force_retrieve_stderr support to **kwargs to extract stderr output even on FFmpeg error. Updated dicts2args to support internal repeated coreX FFmpeg parameters for StreamGear. Updated mkdocs.yml , changelog.md and README.md with latest changes. Updated validate_audio Helper function will now retrieve audio-bitrate for validation. Updated buggy mpegdash dependency with custom dev fork for Windows machines. Updated core parameters for audio handling. Updated logging for debugging selected eventloops in NetGear_Async API. Updated termination linger to zero at Server's end. Breaking Updates/Changes Changed Webgear API default address to localhost for cross-compatibility between different platforms. In Netgear_Async API, source value can now be NoneType for a custom frame-generator at Server-end only. Temp (such as /tmp in linux) is now not a valid directory for WriteGear & StreamGear API outputs. Moved vidgear docs assets (i.e images, gifs, javascripts and stylescripts) to override directory. Bug-fixes Added workaround for system path not handle correctly. Fixed Bug: URL Audio format not being handled properly. Fixed Critical Bug in NetGear_Async throwing ValueError with None-type Source. Fixed Critical StreamGear Bug: FFmpeg pipeline terminating prematurely in Single-Source Mode. Fixed Critical external audio handler bug: moved audio-input to input_parameters. Fixed Frozen-threads bug in CI tests. Fixed Mkdocs only accepting Relative paths. Fixed OSError in WriteGear's compression mode. Fixed StreamGear CI bugs for Windows and CI envs. Fixed Typos and Indentation bugs in NetGear API. Fixed ZMQ throwing error on termination if all max-tries exhausted. Fixed NameError bug in NetGear API and CI tests. Fixed TimeoutError bug in NetGear_Async CI tests. Fixed get_valid_ffmpeg_path throwing TypeError with non-string values. Fixed broken links in docs. Fixed critical duplicate logging bug. Fixed default gop value not handle correctly. Fixed handling of incorrect paths detection. Fixed incorrect definitions in NetGear_Async. Fixed left-over attribute bug in WriteGear. Fixed logic and indentation bugs in CI tests. Fixed logic for handling output parameters in WriteGear API. Fixed missing definitions and logic bug in StreamGear. Fixed missing import and incorrect CI definitions. Fixed missing source dimensions from extract_resolutions output in StreamGear API. Fixed missing support for compression parameters in Multi-Clients Mode. Fixed round off error in FPS. Fixed several CI bugs and updated extract_resolutions method. Fixed several bugs from CI Bidirectional Mode tests. Fixed several typos in docs usage examples. Fixed various AttributeError with wrong attribute names and definition in CI Helper functions. Fixed wrong and missing definitions in docs. Fixed wrong logic for extracting OpenCV frames. Fixed wrong type bug in StreamGear API. Fixed wrong type error bug in WriteGear API. Fixed wrong variable assignments bug in WriteGear API. Fixes to CLI tests and missing docs imports. Many minor typos and wrong definitions. Pull Requests PR #129 PR #130 PR #155 v0.1.8 (2020-06-12) \u2693 New Features NetGear API: Multiple Clients support: Implemented support for handling any number of Clients simultaneously with a single Server in this mode. Added new multiclient_mode attribute for enabling this mode easily. Built support for zmq.REQ/zmq.REP and zmq.PUB/zmq.SUB patterns in this mode. Implemented ability to receive data from all Client(s) along with frames with zmq.REQ/zmq.REP pattern only. Updated related CI tests Support for robust Lazy Pirate pattern(auto-reconnection) in NetGear API for both server and client ends: Implemented a algorithm where NetGear rather than doing a blocking receive, will now: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. Implemented its default support for REQ/REP and PAIR messaging patterns internally. Added new max_retries and request_timeout (in seconds) for handling polling. Added DONTWAIT flag for interruption-free data receiving. Both Server and Client can now reconnect even after a premature termination. Performance Updates: Added default Frame Compression support for Bidirectional frame transmission in Bidirectional mode. Added support for Reducer() function in Helper.py to aid reducing frame-size on-the-go for more performance. Added small delay in recv() function at client's end to reduce system load. Reworked and Optimized NetGear termination, and also removed/changed redundant definitions and flags. Docs: Migration to Mkdocs Implemented a beautiful, static documentation site based on MkDocs which will then be hosted on GitHub Pages. Crafted base mkdocs with third-party elegant & simplistic mkdocs-material theme. Implemented new mkdocs.yml for Mkdocs with relevant data. Added new docs folder to handle markdown pages and its assets. Added new Markdown pages( .md ) to docs folder, which are carefully crafted documents - [x] based on previous Wiki's docs, and some completely new additions. Added navigation under tabs for easily accessing each document. New Assets: Added new assets like gifs, images, custom scripts, favicons, site.webmanifest etc. for bringing standard and quality to docs visual design. Designed brand new logo and banner for VidGear Documents. Deployed all assets under separate Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License . Added Required Plugins and Extensions: Added support for all pymarkdown-extensions . Added support for some important admonition , attr_list , codehilite , def_list , footnotes , meta , and toc like Mkdocs extensions. Enabled search , minify and git-revision-date-localized plugins support. Added various VidGear's social links to yaml. Added support for en (English) language. Auto-Build API Reference with mkdocstrings: Added support for mkdocstrings plugin for auto-building each VidGear's API references. Added python handler for parsing python source-code to mkdocstrings . Auto-Deploy Docs with GitHub Actions: Implemented Automated Docs Deployment on gh-pages through GitHub Actions workflow. Added new workflow yaml with minimal configuration for automated docs deployment. Added all required python dependencies and environment for this workflow. Added master branch on Ubuntu machine to build matrix. Updates/Improvements Added in-built support for bidirectional frames( NDarray ) transfer in Bidirectional mode. Added support for User-Defined compression params in Bidirectional frames transfer. Added workaround for address already in use bug at client's end. Unified Bidirectional and Multi-Clients mode for client's return data transmission. Replaced ValueError with more suitable RuntimeError . Updated logging for better readability. Added CI test for Multi-Clients mode. Reformatted and grouped imports in VidGear. Added Reducer Helper function CI test. Added Reliability tests for both Server and Client end. Disabled reliable reconnection for Multi-Clients mode. Replaced os.devnull with suprocess's inbuilt function. Updated README.md, Issue and PR templates with new information and updates. Moved changelog.md to /docs and updated contribution guidelines. Improved source-code docs for compatibility with mkdocstrings . Added additional dependency mkdocs-exclude , for excluding files from Mkdocs builds. Updated license and compressed images/diagrams. Added new CI tests and Bumped Codecov. Changed YouTube video URL for CI tests to Creative Commons(CC) video. Removed redundant code. Breaking Updates/Changes VidGear Docs moved to GitHub Pages, Now Available at https://abhitronix.github.io/vidgear . Removed filter attribute from options parameter in NetGear API. Removed force_terminate parameter support from NetGear API. Disabled additional data of datatype numpy.ndarray for Server end in Bidirectional Mode. Bug-fixes Fixed 'NoneType' object is not subscriptable bug. Fixed bugs related to delayed termination in NetGear API. Reduced default request_timeout value to 4 and also lowered cut-off limit for the same. Removed redundant ZMQ context termination and similar variables. Added missing VidGear installation in workflow. Excluded conflicting assets README.md from Mkdocs builds. Fixed pattern value check bypassed if wrong value is assigned. Fixed incorrect handling of additional data transferred in synchronous mode at both Server and Client end. Replaced Netgear CI test with more reliable try-except-final blocks. Updated termination linger to zero at Server's end. Fixed NameError bug in NetGear API. Fixed missing support for compression parameters in Multi-Clients Mode. Fixed ZMQ throwing error on termination if all max-tries exhausted. Enabled missing support for frame compression in its primary receive mode. Fixed several bugs from CI Bidirectional Mode tests. Removed or Grouped redundant code for increasing codecov. Fixed Mkdocs only accepting Relative paths. Fixed broken links in docs. Fixed round off error in FPS. Many small typos and bugs fixes. Pull Requests PR #129 PR #130 v0.1.7 (2020-04-29) \u2693 New Features WebGear API: Added a robust Live Video Server API that can transfer live video frames to any web browser on the network in real-time. Implemented a flexible asyncio wrapper around starlette ASGI Application Server. Added seamless access to various starlette's Response classes, Routing tables, Static Files, Template engine(with Jinja2), etc. Added a special internal access to VideoGear API and all its parameters. Implemented a new Auto-Generation Work-flow to generate/download & thereby validate WebGear API data files from its GitHub server automatically. Added on-the-go dictionary parameter in WebGear to tweak performance, Route Tables and other internal properties easily. Added new simple & elegant default Bootstrap Cover Template for WebGear Server. Added __main__.py to directly run WebGear Server through the terminal. Added new gif and related docs for WebGear API. Added and Updated various CI tests for this API. NetGear_Async API: Designed NetGear_Async asynchronous network API built upon ZeroMQ's asyncio API. Implemented support for state-of-the-art asyncio event loop uvloop at its backend. Achieved Unmatchable high-speed and lag-free video streaming over the network with minimal resource constraint. Added exclusive internal wrapper around VideoGear API for this API. Implemented complete server-client handling and options to use variable protocols/patterns for this API. Implemented support for all four ZeroMQ messaging patterns: i.e zmq.PAIR , zmq.REQ/zmq.REP , zmq.PUB/zmq.SUB , and zmq.PUSH/zmq.PULL . Implemented initial support for tcp and ipc protocols. Added new Coverage CI tests for NetGear_Async Network Gear. Added new Benchmark tests for benchmarking NetGear_Async against NetGear. Asynchronous Enhancements: Added asyncio package to for handling asynchronous APIs. Moved WebGear API(webgear.py) to asyncio and created separate asyncio helper.py for it. Various Performance tweaks for Asyncio APIs with concurrency within a single thread. Moved __main__.py to asyncio for easier access to WebGear API through the terminal. Updated setup.py with new dependencies and separated asyncio dependencies. General Enhancements: Added new highly-precise Threaded FPS class for accurate benchmarking with time.perf_counter python module. Added a new Gitter community channel. Added a new Reducer function to reduce the frame size on-the-go. Add Flake8 tests to Travis CI to find undefined names. (PR by @cclauss ) Added a new unified logging handler helper function for vidgear. Updates/Improvements Re-implemented and simplified logic for NetGear Async server-end. Added new dependencies for upcoming asyncio updates to setup.py . Added retry function and replaced wget with curl for Linux test envs. Bumped OpenCV to latest 4.2.0-dev for Linux test envs. Updated YAML files to reflect new changes to different CI envs. Separated each API logger with a common helper method to avoid multiple copies. Limited Importing OpenCV API version check's scope to helper.py only. Implemented case for incorrect color_space value in ScreenGear API. Removed old conflicting logging formatter with a common method and expanded logging. Improved and added shutdown function for safely stopping frame producer threads in WebGear API. Re-implemented and simplified all CI tests with maximum code-coverage in mind. Replaced old mkdir function with new mkdir_safe helper function for creating directories safely. Updated ReadMe.md with updated diagrams, gifs and information. Improve, structured and Simplified the Contribution Guidelines. Bundled CI requirements in a single command.(Suggested by @cclauss ) Replaced line endings CRLF with LF endings. Added dos2unix for Travis OSX envs. Bumped Codecov to maximum. Breaking Updates/Changes Dropped support for Python 3.5 and below legacies. (See issue #99 ) Dropped and replaced Python 3.5 matrices with new Python 3.8 matrices in all CI environments. Implemented PEP-8 Styled Black formatting throughout the source-code. Limited protocols support to tcp and ipc only, in NetGear API. Bug-fixes Fixed Major NetGear_Async bug where __address and __port are not set in async mode.(PR by @otter-in-a-suit ) Fixed Major PiGear Color-space Conversion logic bug. Workaround for CAP_IMAGES error in YouTube Mode. Replaced incorrect terminate() with join() in PiGear. Removed uvloop for windows as still NOT yet supported . Refactored Asynchronous Package name async to asyncio , since it is used as Keyword in python>=3.7 (raises SyntaxError) . Fixed unfinished close of event loops bug in WebGear API. Fixed NameError in helper.py. Added fix for OpenCV installer failure on Linux test envs. Fixed undefined NameError in helper.py context. ( @cclauss ) Fixed incorrect logic while pulling frames from ScreenGear API. Fixed missing functions in __main__.py . Fixed Typos and definitions in docs. Added missing camera_num parameter to VideoGear. Added OpenSSL's [SSL: CERTIFICATE_VERIFY_FAILED] bug workaround for macOS envs. Removed download_url meta from setup.py. Removed PiGear from CI completely due to hardware emulation limitation. Removed VideoCapture benchmark tests for macOS envs. Removed trivial __main__.py from codecov. Removed several redundant try-catch loops. Renamed youtube_url_validation as youtube_url_validator . Several minor wrong/duplicate variable definitions and various bugs fixed. Fixed, Improved & removed many Redundant CI tests for various APIs. Pull Requests PR #88 PR #91 PR #93 PR #95 PR #98 PR #101 PR #114 PR #118 PR #124 New Contributors @cclauss @chollinger93 v0.1.6 (2020-01-01) \u2693 New Features NetGear API: Added powerful ZMQ Authentication & Data Encryption features for NetGear API: Added exclusive secure_mode param for enabling it. Added support for two most powerful Stonehouse & Ironhouse ZMQ security mechanisms. Added smart auth-certificates/key generation and validation features. Implemented Robust Multi-Servers support for NetGear API: Enables Multiple Servers messaging support with a single client. Added exclusive multiserver_mode param for enabling it. Added support for REQ/REP & PUB/SUB patterns for this mode. Added ability to send additional data of any datatype along with the frame in realtime in this mode. Introducing exclusive Bidirectional Mode for bidirectional data transmission: Added new return_data parameter to recv() function. Added new bidirectional_mode attribute for enabling this mode. Added support for PAIR & REQ/REP patterns for this mode Added support for sending data of any python datatype. Added support for message parameter for non-exclusive primary modes for this mode. Implemented compression support with on-the-fly flexible frame encoding for the Server-end: Added initial support for JPEG , PNG & BMP encoding formats . Added exclusive options attribute compression_format & compression_param to tweak this feature. Client-end will now decode frame automatically based on the encoding as well as support decoding flags. Added force_terminate attribute flag for handling force socket termination at the Server-end if there's latency in the network. Implemented new Publish/Subscribe( zmq.PUB/zmq.SUB ) pattern for seamless Live Streaming in NetGear API. PiGear API: Added new threaded internal timing function for PiGear to handle any hardware failures/frozen threads. PiGear will not exit safely with SystemError if Picamera ribbon cable is pulled out to save resources. Added support for new user-defined HWFAILURE_TIMEOUT options attribute to alter timeout. VideoGear API: Added framerate global variable and removed redundant function. Added CROP_N_ZOOM attribute in Videogear API for supporting Crop and Zoom stabilizer feature. WriteGear API: Added new execute_ffmpeg_cmd function to pass a custom command to its FFmpeg pipeline. Stabilizer class: Added new Crop and Zoom feature. Added crop_n_zoom param for enabling this feature. Updated docs. CI & Tests updates: Replaced python 3.5 matrices with latest python 3.8 matrices in Linux environment. Added full support for Codecov in all CI environments. Updated OpenCV to v4.2.0-pre(master branch). Added various Netgear API tests. Added initial Screengear API test. More test RTSP feeds added with better error handling in CamGear network test. Added tests for ZMQ authentication certificate generation. Added badge and Minor doc updates. Added VidGear's official native support for MacOS environments. Updates/Improvements Replace print logging commands with python's logging module completely. Implemented encapsulation for class functions and variables on all gears. Updated support for screen casting from multiple/all monitors in ScreenGear API. Updated ScreenGear API to use Threaded Queue Mode by default, thereby removed redundant THREADED_QUEUE_MODE param. Updated bash script path to download test dataset in $TMPDIR rather than $HOME directory for downloading testdata. Implemented better error handling of colorspace in various videocapture APIs. Updated bash scripts, Moved FFmpeg static binaries to github.com . Updated bash scripts, Added additional flag to support un-secure apt sources. CamGear API will now throw RuntimeError if source provided is invalid. Updated threaded Queue mode in CamGear API for more robust performance. Added new camera_num to support multiple Picameras. Moved thread exceptions to the main thread and then re-raised. Added alternate github mirror for FFmpeg static binaries auto-installation on windows oses. Added colorlog python module for presentable colored logging. Replaced traceback with sys.exc_info . Overall APIs Code and Docs optimizations. Updated Code Readability and Wiki Docs. Updated ReadMe & Changelog with the latest changes. Updated Travis CI Tests with support for macOS environment. Reformatted & implemented necessary MacOS related changes and dependencies in travis.yml . Breaking Updates/Changes Python 2.7 legacy support dropped completely. Source-code Relicensed to Apache 2.0 License. Python 3+ are only supported legacies for installing v0.1.6 and above. Python 2.7 and 3.4 legacies support dropped from CI tests. Bug-fixes Reimplemented Pub/Sub pattern for smoother performance on various networks. Fixed Assertion error in CamGear API during colorspace manipulation. Fixed random freezing in Secure Mode and several related performance updates Fixed multiserver_mode not working properly over some networks. Fixed assigned Port address ignored bug (commit 073bca1). Fixed several wrong definition bugs from NetGear API(commit 8f7153c). Fixed unreliable dataset video URL(rehosted file on github.com ). Disabled overwrite_cert for client-end in NetGear API. Disabled Universal Python wheel builds in setup.cfg file. Removed duplicate code to import MSS( @BoboTiG ) from ScreenGear API. Eliminated unused redundant code blocks from library. Fixed Code indentation in setup.py and updated new release information. Fixed code definitions & Typos. Fixed several bugs related to secure_mode & multiserver_mode Modes. Fixed various macOS environment bugs. Pull Requests PR #39 PR #42 PR #44 PR #52 PR #55 PR #62 PR #67 PR #72 PR #77 PR #78 PR #82 PR #84 New Contributors @BoboTiG v0.1.5 (2019-07-24) \u2693 New Features Added new ScreenGear API, supports Live ScreenCasting. Added new NetGear API, aids real-time frame transfer through messaging(ZmQ) over network. Added new new Stabilizer Class, for minimum latency Video Stabilization with OpenCV. Added Option to use API's standalone. Added Option to use VideoGear API as internal wrapper around Stabilizer Class. Added new parameter stabilize to API, to enable or disable Video Stabilization. Added support for **option dict attributes to update VidGear's video stabilizer parameters directly. Added brand new logo and functional block diagram ( .svg ) in readme.md Added new pictures and GIFs for improving readme.md readability Added new contributing.md and changelog.md for reference. Added collections.deque import in Threaded Queue Mode for performance consideration Added new install_opencv.sh bash scripts for Travis cli, to handle OpenCV installation. Added new Project Issue & PR Templates Added new Sponsor Button( FUNDING.yml ) Updates/Improvements Updated New dependencies: mss , pyzmq and rejected redundant ones. Revamped and refreshed look for readme.md and added new badges. Updated Releases Documentation completely. Updated CI tests for new changes Updated Code Documentation. Updated bash scripts and removed redundant information Updated Youtube video URL in tests Completely Reformatted and Updated Wiki Docs with new changes. Breaking Updates/Changes Implemented experimental Threaded Queue Mode( a.k.a Blocking Mode ) for fast, synchronized, error-free multi-threading. Renamed bash script pre-install.sh to prepare_dataset.sh - [x] downloads opensourced test datasets and static FFmpeg binaries for debugging. Changed script folder location to bash/script . Python 3.4 removed from Travis CI tests. Bug-fixes Temporarily fixed Travis CI bug: Replaced opencv-contrib-python with OpenCV built from scratch as dependency. Fixed CI Timeout Bug: Disable Threaded Queue Mode for CI Tests Fixes** sys.stderr.close() throws ValueError bug: Replaced sys.close() with DEVNULL.close() Fixed Youtube Live Stream bug that return NonType frames in CamGear API. Fixed NoneType frames bug in PiGear class on initialization. Fixed Wrong function definitions Removed /xe2 unicode bug from Stabilizer class. Fixed **output_params KeyError bug in WriteGear API Fixed subprocess not closing properly on exit in WriteGear API. Fixed bugs in ScreenGear: Non-negative monitor values Fixed missing import, typos, wrong variable definitions Removed redundant hack from setup.py Fixed Minor YouTube playback Test CI Bug Fixed new Twitter Intent Fixed bug in bash script that not working properly due to changes at server end. Pull Requests PR #17 PR #21 PR #22 PR #27 PR #31 PR #32 PR #33 PR #34 v0.1.4 (2019-05-11) \u2693 New Features Added new WriteGear API: for enabling lossless video encoding and compression(built around FFmpeg and OpenCV Video Writer) Added YouTube Mode for direct Video Pipelining from YouTube in CamGear API Added new y_tube to access YouTube Mode in CamGear API. Added flexible Output file Compression control capabilities in compression-mode(WriteGear). Added -output_dimensions special parameter to WriteGear API. Added new helper.py to handle special helper functions. Added feature to auto-download and configure FFmpeg Static binaries(if not found) on Windows platforms. Added -input_framerate special parameter to WriteGear class to change/control output constant framerate in compression mode(WriteGear). Added new Direct Video colorspace Conversion capabilities in CamGear and PiGear API. Added new framerate class variable for CamGear API, to retrieve input framerate. Added new parameter backend - [x] changes the backend of CamGear's API Added automatic required prerequisites installation ability, when installation from source. Added Travis CI Complete Integration for Linux-based Testing for VidGear. Added and configured travis.yml Added Appveyor CI Complete Integration for Windows-based Testing in VidGear. Added and configured new appveyor.yml Added new bash script pre-install.sh to download opensourced test datasets and static FFmpeg binaries for debugging. Added several new Tests(including Benchmarking Tests) for each API for testing with pytest . Added license to code docs. Added Say Thank you! badge to Readme.md . Updates/Improvements Removed redundant dependencies Updated youtube-dl as a dependency, as required by pafy 's backend. Updated common VideoGear API with new parameter. Update robust algorithm to auto-detect FFmpeg executables and test them, if failed, auto fallback to OpenCV's VideoWriter API. Improved system previously installed OpenCV detection in setup.py. Updated setup.py with hack to remove bullets from pypi description. Updated Code Documentation Reformatted & Modernized readme.md with new badges. Reformatted and Updated Wiki Docs. Breaking Updates/Changes Removed -height and -width parameter from CamGear API. Replaced dependency opencv-python with opencv-contrib-python completely Bug-fixes Windows Cross-Platform fix: replaced dependency os with platform in setup.py. Fixed Bug: Arises due to spaces in input **options / **output_param dictionary keys. Fixed several wrong/missing variable & function definitions. Fixed code uneven indentation. Fixed several typos in docs. Pull Requests PR #7 PR #8 PR #10 PR #12 v0.1.3 (2019-04-07) \u2693 Bug-fixes Patched Major PiGear Bug: Incorrect import of PiRGBArray function in PiGear Class Several Fixes for backend picamera API handling during frame capture(PiGear) Fixed missing frame variable initialization. Fixed minor typos Pull Requests PR #6 PR #5 v0.1.2 (2019-03-27) \u2693 New Features Added easy Source manipulation feature in CamGear API, to control features like resolution, brightness, framerate etc. Added new **option parameter to CamGear API, provides the flexibility to manipulate input stream directly. Added new parameters for Camgear API for time delay and logging. Added new Logo to readme.md Added new Wiki Documentation. Updates/Improvements Reformatted readme.md. Updated Wiki Docs with new changes. Bug-fixes Improved Error Handling in CamGear & PiGear API. Fixed minor typos in docs. Pull Requests PR #4 v0.1.1 (2019-03-24) \u2693 New Features Release ViGear binaries on the Python Package Index (PyPI) Added new and configured setup.py & setup.cfg Bug-fixes Fixed PEP bugs: added and configured properly __init__.py in each folder Fixed PEP bugs: improved code Indentation Fixed wrong imports: replaced distutils.core with setuptools Fixed readme.md v0.1.0 (2019-03-17) \u2693 New Features Initial Release Converted my imutils PR into Python Project. Renamed conventions and reformatted complete source-code from scratch. Added support for both python 2.7 and 3 legacies Added new multi-threaded CamGear, PiGear, and VideoGear APIs Added multi-platform compatibility Added robust & flexible control over the source in PiGear API.","title":"Release Notes"},{"location":"changelog/#release-notes","text":"","title":"Release Notes"},{"location":"changelog/#v026-2022-07-05","text":"New Features Docs: Added new bonus example for RSTP/RTP Live-Streaming using WriteGear's Compression Mode. Added \"How to resolve zmq.error.ZMQError\" FAQ for NetGear API.(PR by @iandol ) Added new ko-fi button to README.md Added new contributors block to changelog.md Maintenance: Added new patterns to .gitignore to ignore pypi's build directory and egg-info files. CI: Switched to new Issue GitHub's form schema using YAML Added new bug_report.yaml . Added new question.yaml . Added new proposal.yaml . Deleted depreciated markdown files. Polished forms. Updates/Improvements Setup.py: Bumped version to 0.2.6 . Updated logic operators and dependency. Replaced >= comparsion operator with more flexible ~= . Replaced distutils.version.LooseVersion with pkg_resources.parse_version . Docs: Updated Site Navigation. Added new notices to inform users more effectively about bonus examples. Added new Bonus section to navigation and moved suitable pages under it. Updated headings and URLs. Redesigned and Rewritten Donation and Contribution section to README.md Updated Zenodo badge and bibtex entry. Updated Admonition Icon, FAQs and site-links. Reformatted code and its comments. Updated changelog.md . API: Updated depreciated tostring() to tobytes(). tostring was renamed to tobytes for the purposes for clarity in Python 3.2. https://docs.python.org/3/library/array.html#array.array.tobytes CI: Added more paths and files to skip commits. Breaking Updates/Changes -input_framerate parameter now accepts any positive value for WriteGear and StreamGear APIs. Bug-fixes API: Fixed -input_framerate less than 5 does not get used in WriteGear and StreamGear APIs.(PR by @freol35241 ) CamGear: Fixed Yt-dlp generated HTTP DASH Segments URLs not supported by OpenCV's VideoCapture(PR by @DynamiteC ) StreamGear: Fixed hls_segment_type not working bug. (PR by @enarche-ahn ) Fixed critical logging parameter bug Fixed debug logs even when logging=False in StreamGear's Real-time Mode. (patch suggested by @enarche-ahn ) Added length check to -video_source attribute to correctly infers it as empty(or invalid). CI: Xfailed RSTP CamGear CI test. Fixed pinned version syntax bug in docs_deployer workflow. Fixed typos in Github forms and its context. Added missing dependency. Docs: Fixed jinja2 3.1.0 or above breaks mkdocs. jinja2>=3.1.0 breaks mkdocs ( mkdocs/mkdocs#2799 ), therefore pinned jinja2 version to <3.1.0 . Fixed support for new mkdocstring versions Replaced rendering sub-value with options. Removed pinned mkdocstrings==0.17.0 version. Fixed Netgear+Webgear bonus example code bugs.(PR by @iandol ) Added a missing import. Removed self. typo. Replaced the return value with break in the async as it triggers an error. Fixed external bug that causing \"Home\" tab to irresponsive randomly when accessed from other tabs. Fixed indentation and spacing. Fixed typos and updated context. Removed dead code. Pull Requests PR #288 PR #290 PR #293 PR #295 PR #307 PR #313 PR #320 New Contributors @iandol @freol35241 @enarche-ahn @DynamiteC","title":"v0.2.6 (2022-07-05)"},{"location":"changelog/#v025-2021-02-11","text":"New Features WriteGear: Add support for GStreamer pipeline in WriteGear API's Non-Compression mode: Implemented GStreamer Pipeline Mode to accept GStreamer pipeline as string to its output_filename parameter. Added new special -gst_pipeline_mode attribute for its output_params parameter. This feature provides flexible way to directly write video frames into GStreamer Pipeline with controlled bitrate. Added new docs and updated existing docs with related changes. Added new -ffpreheaders special attribute to WriteGear's options parameter: This attribute is specifically required to set special FFmpeg parameters in Compression Mode that are present at the starting of command(such as -re ). This attribute only accepts list datatype as value. Added related docs. NetGear: Added bidirectional data transfer support by extending Bidirectional mode support to exclusive Multi-Clients and Multi-Servers modes: Users will now able to send data bidirectionally in both Multi-Clients and Multi-Servers exclusive modes. Bidirectional mode will no longer disables automatically when Multi-Clients and Multi-Servers modes already enabled. Added new docs and updated existing docs with related changes. Maintenance: Added official support for Python-3.10 legacies. Added float value support to THREAD_TIMEOUT optional parameter. Added info about dropped support for Python-3.6 legacies through announcement bar. Added config.md file for Issue templates. Added title to Issue templates. Docs: Added new Code Annotations Added new icons to headings. Added Advanced VideoGear usage example with CamGear backend. Updates/Improvements Setup.py: Dropped support for Python-3.6 and below legacies. Updated logging formatting. Updated python_requires to >=3.7 . Bumped version to 0.2.5 . Helper: Vidgear will now report current version on every run. Docs: Updated SSH tunneling docs context. Excluded docs directory from CI envs. Updated Zenodo badge and BibTeX entry. Updated dark theme hue to 260 . Updated Admonitions. Additional warnings against pushing PR against VidGear's testing branch only. Updated code comments. CI: Removed support for Python-3.6 legacies from all workflows. Updated NetGear's Exclusive Mode tests. Added GStreamer Pipeline Mode tests. Maintenance: Updated Issue and PR templates. Updated metadata. Breaking Updates/Changes Dropped support for Python-3.6 legacies from vidgear. Bug-fixes NetGear: Fixed bidirectional mode overriding multi-clients mode's data. WriteGear: Fixed wrongly defined ffmpeg_preheaders. Fixed condition logic bugs. Fixed UnboundLocalError bug. Setup: Fixed uvicorn and aiortc dropped support for Python-3.6 legacies. CI: Fixed GitHub Actions interprets 3.10 as 3.1 if used without strings. Fixed naming error in azure YAML. Docs: Fixed codecov badge URL in README.md Fixed hyperlinks in README. Fixed indentation and spacing. Fixed typos and updated context. Removed dead code. Maintenance: Removed depreciated condition checks. Pull Requests PR #283 PR #284","title":"v0.2.5 (2021-02-11)"},{"location":"changelog/#v024-2021-12-05","text":"New Features CamGear: Added a new YT_backend Internal Class with YT-DLP backend: Implemented YT_backend a new CamGear's Internal YT-DLP backend class for extracting metadata from Streaming URLs. Added support for pipeling (live) video-frames from all yt-dlp supported streaming sites: https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md#supported-sites Implemented algorithm from scratch for auto-extracting resolution specific streamable URLs for pipelineing. Implemented logic for auto-calculating best and worst resolutions. Added new ytv_metadata global parameter to CamGear for accessing video's metadata(such as duration, title, description) on-the-go. \u26a0\ufe0f Playlists are still unsupported. WebGear_RTC: Implemented a new easy way of defining Custom Streaming Class with suitable source(such as OpenCV): Added new custom_stream attribute with WebGear_RTC options parameter that allows you to easily define your own Custom Streaming Class with suitable source(such as OpenCV). This implementation supports repeated Auto-Reconnection or Auto-Refresh out-of-the-box. This implementation is more user-friendly and easy to integrate within complex APIs. This implementation requires at-least read() and stop() methods implemented within Custom Streaming Class, otherwise WebGear_RTC will throw ValueError. This implementation supports all vidgear's VideoCapture APIs readily as input. Maintenance: Added new .gitignore for specifying intentionally untracked files to ignore Added more files entries to .gitignore . Added new .gitattributes to manage how Git reads line endings. Enabled auto default behavior, in case people don't have core.autocrlf set. Enforced LF line-endings for selective files types. Added Binary data files that specifies they are not text, and git should not try to change them. Added Language aware diff headers. Added Linguist language overrides. Docs: Added bonus example to add real-time file audio encoding with VideoGear and Stabilizer class. Added complete usage docs with new CamGear's Internal Class with YT-DLP backend. Added instructions to extract video's metadata in CamGear. Added donation link in page footer with bouncing heart animation through pure CSS. Added info about critical changes in v0.2.4 and above installation through new announcement bar. Added related usage docs for new WebGear_RTC custom streaming class. Added changes for upgrading mkdocs-material from v7.x to newer v8.x . Added outdated version warning block. Updates/Improvements CamGear: Added is_livestream global YT_backend parameters. Added default options for yt-dlp for extracting info_dict(metadata) of the video as a single JSON line. Completely removed old logic for extracting streams using pafy. Removed all dead code related to streamlink backend. Setup.py: Moved all API specific dependencies to extra_requires under the name \"core\" . [PR #268 by @zpapakipos ] Added rule to replace GitHub heading links in description. Updated extra_require dependencies. Removed streamlink dependency. Removed pafy dependency. Removed pyzmq from latest_version group. Updated SEO Keywords. Docs: Re-written pip and source installation docs. Added warning for using -disable_force_termination flag for short duration videos. Added permalink_title entry to mkdocs.yml. Updated CamGear parameters. Updated Admonitions with related information. Updated Functional Block Diagram( gears_fbd.png ) image. Updated installation instructions. Updated Advanced examples using WebGear_RTC's custom streaming class. Updated code highlighting. Updated zenodo badge. Updated BibTex for project citation. Replaced incorrect API parameter docs. Updated WebGear_RTC parameters. CI: Updated CI tests for new WebGear_RTC custom streaming class. Restored test_stream_mode CamGear test. Updated Streaming Sites test links. Added more tests cases. Maintenance: Updated spacing in logger formatting. Renamed Asyncio Helper logger name. Changed logging colors. Updated logging messages. Breaking Updates/Changes Installation command with pip has been changed in v0.2.4 : The legacy pip install vidgear command now installs critical bare-minimum dependencies only. Therefore in order to automatically install all the API specific dependencies as previous versions, use pip install vidgear [ core ] command instead. CamGear: Removed streamlink backend support from stream_mode in favor of more reliable CamGear's Internal YT-DLP backend class for extracting metadata from Streaming URLs. CamGear will raise ValueError if streaming site URL is unsupported by yt-dlp backend. CamGear will raise ValueError if yt-dlp isn't installed and stream_mode is enabled. Removed automatic enforcing of GStreamer backend for YouTube-livestreams and made it optional. The CamGear will not raise ValueError if GStreamer support is missing in OpenCV backends. WebGear_RTC: Removed support for assigning Custom Media Server Class(inherited from aiortc's VideoStreamTrack) in WebGear_RTC through its config global parameter. WebGear_RTC API will now throws ValueError if source parameter is NoneType as well as custom_stream attribute is undefined. Helper: Removed restore_levelnames method. Removed youtube_url_validator helper method. Bug-fixes CamGear: Fixed KeyError Bug for missing attributed in meta_data json in some streaming sites. Helper: Removed unused imports. Docs: Removed slugify from mkdocs which was causing invalid hyperlinks in docs. Fixed GitHub hyperlinks in README.md. Fixed hyperlink in announcement bar. Fixed content tabs failing to work. Fixed line-endings and usage example code. Removed any pafy and streamlink references. Fixed context and typos. CI: Fixed NameError bugs in WebGear_RTC CI test. Maintenance: Removed dead logger code causing Python's Built-in logging module to hide logs. Removed unused logging import. Updated code comments. Pull Requests PR #268 PR #272 PR #274 New Contributors @zpapakipos","title":"v0.2.4 (2021-12-05)"},{"location":"changelog/#v023-2021-10-27","text":"New Features CamGear: Added support for 4K Streaming URLs. Helper: Implemented logging ColorFormatter string alignment. Center aligned logging Level-name and Class-name. Changed % formatting style with modern { . Re-added asctime value to Formatter string. Re-arranged parameter positions in Formatter string. Maintenance: Added new .gitignore for specifying intentionally untracked files to ignore Added more files entries to .gitignore . Added new .gitattributes to manage how Git reads line endings. Enabled auto default behavior, in case people don't have core.autocrlf set. Enforced LF line-endings for selective files types. Added Binary data files that specifies they are not text, and git should not try to change them. Added Language aware diff headers. Added Linguist language overrides. Docs: Added new ScreenGear with WebGear_RTC API bonus example. Added support for hl_lines argument for highlighting specific code lines. Added drop-shadow effects for its slate theme to improve visibility. Updates/Improvements CamGear: Replaced youtube-dl with yt-dlp as pafy backend for YouTube videos pipelining. Implemented hack to trick pafy into assuming yt-dlp as youtube-dl . Using sys.modules to present yt-dlp as youtube-dl . yt-dlp python API functions exactly similar to youtube-dl . Replaced youtube-dl dependency with yt-dlp . Replaced youtube-dl imports with yt-dlp . StreamGear: Updated default stream_count internal dict key value to 1. Maintenance: Introduced python short-circuiting for handling logging logic. Enabled logging for check_WriteAccess method in WriteGear, StreamGear and NetGear APIs. Docs: Added warning for ScreenGear outputting RGBA frames instead of default BGR frames with mss backend. Added warnings for properly formatting output_params when assigning external audio-source in WriteGear. Added depreciation notice for Python 3.6 legacies. Restructured docs to make it more user-friendly. Updated, Extended and Improved context. Improved code comments. Updated docs admonitions. Updated Zenodo badge. CI: Migrated to new Codecov Uploader in Azure Pipelines. Support for the Bash Uploader will be deprecated on February 1 st , 2022. See: https://docs.codecov.com/docs/about-the-codecov-bash-uploader Added commands for signature and SHASUM verification to ensure integrity of the Uploader before use. Replaced related bash commands. Replaced env with export in ci_linux.yml. Replaced bubkoo/needs-more-info@v1 with wow-actions/needs-more-info@v1 . Added codecov secret token through env variable. Added wildcard to skip CI tests for doc( .md ) files. Added .md files to Codecov ignore list. Update vidgear's banner image. Breaking Updates/Changes check_WriteAccess will now return as invalid path if writing directory does not exists. This will effect output file handling in WriteGear and StreamGear APIs. Bug-fixes StreamGear: Fixed StreamGear Malformed URI Error with HLS Segments [PR #243 by @Vboivin ] Removed the extra '%' character from the naming convention for segment files. Used stream_count internal dict variable to alter template for HLS segment filenames. WriteGear: Fixed bug in disable_force_termination logic which accidentally disables force termination. WebGear_RTC: Fixed name 'VideoStreamTrack' is not defined bug. Setup.py: Fixed TypeError bug. Fixed invalid latest_version retrieval. Helper: Fixed check_WriteAccess failing to recognize correct permission for writing the output file on windows platform. Implemented separate logic for Windows and *nix platforms. Added new stat import. Improved warnings and error handling. Added logging parameter to check_WriteAccess . Fixed bug in check_WriteAccess that throws OSError while handling URLs. Docs: Fixed bugs in WriteGear's Compression Mode with Live Audio Input example. Fixed \"drop-shadow\" property via filter function conflicting with sidecard button. Added new CSS classes for image, admonitions and code highlight in dark theme. Several internal and external webpage links typos fixed. Fixed several language typos. CI: Fixed Azure Pipeline coverage upload bugs. Fixed random errors in CamGear stream_mode test. Bash: Removed the Windows carriage returns from the shell scripts to be able to execute them on Linux. Fixed logging comments. Pull Requests PR #249 PR #262 New Contributors @Vboivin","title":"v0.2.3 (2021-10-27)"},{"location":"changelog/#v022-2021-09-02","text":"New Features StreamGear: Native Support for Apple HLS Multi-Bitrate Streaming format: Added support for new Apple HLS (HTTP Live Streaming) HTTP streaming format in StreamGear. Implemented default workflow for auto-generating primary HLS stream of same resolution and framerate as source. Added HLS support in Single-Source and Real-time Frames Modes. Implemented inherit support for fmp4 and mpegts HLS segment types. Added adequate default parameters required for trans-coding HLS streams. Added native support for HLS live-streaming. Added \"hls\" value to format parameter for easily selecting HLS format. Added HLS support in -streams attribute for transcoding additional streams. Added support for .m3u8 and .ts extensions in clear_prev_assets workflow. Added validity check for .m3u8 extension in output when HLS format is used. Separated DASH and HLS command handlers. Created HLS format exclusive parameters. Implemented -hls_base_url FFMpeg parameter support. Added support for audio input from external device: Implemented support for audio input from external device. Users can now easily add audio device and decoder by formatting them as python list. Modified -audio parameter to support list data type as value. Modified validate_audio helper function to validate external audio devices. Added -seg_duration to control segment duration. NetGear: New SSH Tunneling Mode for remote connection: New SSH Tunneling Mode for connecting ZMQ sockets across machines via SSH tunneling. Added new ssh_tunnel_mode attribute to enable ssh tunneling at provide address at server end only. Implemented new check_open_port helper method to validate availability of host at given open port. Added new attributes ssh_tunnel_keyfile and ssh_tunnel_pwd to easily validate ssh connection. Extended this feature to be compatible with bi-directional mode and auto-reconnection. Disabled support for exclusive Multi-Server and Multi-Clients modes. Implemented logic to automatically enable paramiko support if installed. Reserved port- 47 for testing. Additional colorspace support for input frames with Frame-Compression enabled: Allowed to manually select colorspace on-the-fly with JPEG frame compression. Updated jpeg_compression dict parameter to support colorspace string values. Added all supported colorspace values by underline simplejpeg library. Server enforced frame-compression colorspace on client(s). Enable \"BGR\" colorspace by default. Added Example for changing incoming frames colorspace with NetGear's Frame Compression. Updated Frame Compression parameters in NetGear docs. Updated existing CI tests to cover new frame compression functionality. NetGear_Async: New exclusive Bidirectional Mode for bidirectional data transfer: NetGear_Async's first-ever exclusive Bidirectional mode with pure asyncio implementation. Bidirectional mode is only available with User-defined Custom Source(i.e. source=None ) Added support for PAIR & REQ/REP bidirectional patterns for this mode. Added powerful asyncio.Queues for handling user data and frames in real-time. Implemented new transceive_data method to Transmit (in Recieve mode) and Receive (in Send mode) data in real-time. Implemented terminate_connection internal asyncio method to safely terminate ZMQ connection and queues. Added msgpack automatic compression encoding and decoding of data and frames in bidirectional mode. Added support for np.ndarray video frames. Added new bidirectional_mode attribute for enabling this mode. Added 8-digit random alphanumeric id generator for each device. NetGear_Async will throw RuntimeError if bidirectional mode is disabled at server or client but not both. Added new disable_confirmation used to force disable termination confirmation from client in terminate_connection . Added task_done() method after every get() call to gracefully terminate queues. Added new secrets and string imports. WebGear: Updated JPEG Frame compression with simplejpeg : Implemented JPEG compression algorithm for 4-5% performance boost at cost of minor loss in quality. Utilized encode_jpeg and decode_jpeg methods to implement turbo-JPEG transcoding with simplejpeg . Added new options to control JPEG frames quality , enable fastest dct , fast upsampling to boost performance. Added new jpeg_compression , jpeg_compression_quality , jpeg_compression_fastdct , jpeg_compression_fastupsample attributes. Enabled fast dct by default with JPEG frames at 90% . Incremented default frame reduction to 25% . Implemented automated grayscale colorspace frames handling. Updated old and added new usage examples. Dropped support for depreciated attributes from WebGear and added new attributes. Added new WebGear Theme: (Checkout at https://github.com/abhiTronix/vidgear-vitals ) Added responsive image scaling according to screen aspect ratios. Added responsive text scaling. Added rounded border and auto-center to image tag. Added bootstrap css properties to implement auto-scaling. Removed old resize() hack. Improved text spacing and weight. Integrated toggle full-screen to new implementation. Hide Scrollbar both in WebGear_RTC and WebGear Themes. Beautify files syntax and updated files checksum. Refactor files and removed redundant code. Bumped theme version to v0.1.2 . WebGear_RTC: Added native support for middlewares: Added new global middleware variable for easily defining Middlewares as list. Added validity check for Middlewares. Added tests for middlewares support. Added example for middlewares support. Extended middlewares support to WebGear API too. Added related imports. Added new WebGear_RTC Theme: (Checkout at https://github.com/abhiTronix/vidgear-vitals ) Implemented new responsive video scaling according to screen aspect ratios. Added bootstrap CSS properties to implement auto-scaling. Removed old resize() hack. Beautify files syntax and updated files checksum. Refactored files and removed redundant code. Bumped theme version to v0.1.2 Helper: New automated interpolation selection for gears: Implemented retrieve_best_interpolation method to automatically select best available interpolation within OpenCV. Added support for this method in WebGear, WebGear_RTC and Stabilizer Classes/APIs. Added new CI tests for this feature. Implemented get_supported_demuxers method to get list of supported demuxers. CI: Added new no-response work-flow for stale issues. Added new CI tests for SSH Tunneling Mode. Added paramiko to CI dependencies. Added support for \"hls\" format in existing CI tests. Added new functions check_valid_m3u8 and extract_meta_video for validating HLS files. Added new m3u8 dependency to CI workflows. Added complete CI tests for NetGear_Async's new Bidirectional Mode: Implemented new exclusive Custom_Generator class for testing bidirectional data dynamically on server-end. Implemented new exclusive client_dataframe_iterator method for testing bidirectional data on client-end. Implemented test_netgear_async_options and test_netgear_async_bidirectionalmode two new tests. Added timeout value on server end in CI tests. Setup.py: Added new cython and msgpack dependency. Added msgpack and msgpack_numpy to auto-install latest. BASH: Added new temp_m3u8 folder for generating M3U8 assets in CI tests. Docs: Added docs for new Apple HLS StreamGear format: Added StreamGear HLS transcoding examples for both StreamGear modes. Updated StreamGear parameters to w.r.t new HLS configurations. Added open-sourced \"Sintel\" - project Durian Teaser Demo with StreamGear's HLS stream using Clappr and raw.githack.com. Added new HLS chunks at https://github.com/abhiTronix/vidgear-docs-additionals for StreamGear Added support for HLS video in Clappr within custom.js using HlsjsPlayback plugin. Added support for Video Thumbnail preview for HLS video in Clappr within custom.js Added hlsjs-playback.min.js JS script and suitable configuration for HlsjsPlayback plugin. Added custom labels for quality levels selector in custom.js . Added new docs content related to new Apple HLS format. Updated DASH chunk folder at https://github.com/abhiTronix/vidgear-docs-additionals . Added example for audio input support from external device in StreamGear. Added steps for using -audio attribute on different OS platforms in StreamGear. Added usage examples for NetGear_Async's Bidirectional Mode: Added new Usage examples and Reference doc for NetGear_Async's Bidirectional Mode. Added new image asset for NetGear_Async's Bidirectional Mode. Added NetGear_Async's option parameter reference. Updated NetGear_Async definition in docs. Changed font size for Helper methods. Renamed Bonus section to References in mkdocs.yml . Added Gitter sidecard embed widget: Imported gitter-sidecar script to main.html . Updated custom.js to set global window option. Updated Sidecard UI in custom.css . Added bonus examples to help section: Implemented a curated list of more advanced examples with unusual configuration for each API. Added several new contents and updated context. Added support for search suggestions, search highlighting and search sharing (i.e. deep linking) Added more content to docs to make it more user-friendly. Added warning that JPEG Frame-Compression is disabled with Custom Source in WebGear. Added steps for identifying and specifying sound card on different OS platforms in WriteGear. Added Zenodo DOI badge and its reference in BibTex citations. Added extra.homepage parameter, which allows for setting a dedicated URL for site_url . Added pymdownx.striphtml plugin for stripping comments. Added complete docs for SSH Tunneling Mode. Added complete docs for NetGear's SSH Tunneling Mode. Added pip upgrade related docs. Added docs for installing vidgear with only selective dependencies Added new advance / experiment admonition with new background color. Added new icons SVGs for advance and warning admonition. Added new usage example and related information. Added new image assets for ssh tunneling example. Added new admonitions Added new FAQs. Updates/Improvements VidGear Core: New behavior to virtually isolate optional API specific dependencies by silencing ImportError on all VidGear's APIs import. Implemented algorithm to cache all imports on startup but silence any ImportError on missing optional dependency. Now ImportError will be raised only any certain API specific dependency is missing during given API's initialization. New import_dependency_safe to imports specified dependency safely with importlib module. Replaced all APIs imports with import_dependency_safe . Added support for relative imports in import_dependency_safe . Implemented error parameter to by default ImportError with a meaningful message if a dependency is missing, Otherwise if error = log a warning will be logged and on error = silent everything will be quit. But If a dependency is present, but older than specified, an error is raised if specified. Implemented behavior that if a dependency is present, but older than min_version specified, an error is raised always. Implemented custom_message to display custom message on error instead of default one. Implemented separate import_core_dependency function to import and check for specified core dependency. ImportError will be raised immediately if core dependency not found. StreamGear: Replaced depreciated -min_seg_duration flag with -seg_duration . Removed redundant -re flag from RTFM. Improved Live-Streaming performance by disabling SegmentTimline Improved DASH assets detection for removal by using filename prefixes. NetGear: Replaced np.newaxis with np.expand_dims . Replaced random module with secrets while generating system ID. Update array indexing with np.copy . NetGear_Async: Improved custom source handling. Removed deprecated loop parameter from asyncio methods. Re-implemented skip_loop parameter in close() method. run_until_complete will not used if skip_loop is enabled. skip_loop now will create asyncio task instead and will enable disable_confirmation by default. Replaced create_task with ensure_future to ensure backward compatibility with python-3.6 legacies. Simplified code for transceive_data method. WebGear_RTC: Improved handling of failed ICE connection. Made is_running variable globally available for internal use. Helper: Added 4320p resolution support to dimensions_to_resolutions method. Implemented new delete_file_safe to safely delete files at given path. Replaced os.remove calls with delete_file_safe . Added support for filename prefixes in delete_ext_safe method. Improved and simplified create_blank_frame functions frame channels detection. Added logging parameter to capPropId function to forcefully discard any error(if required). Setup.py: Added patch for numpy dependency, numpy recently dropped support for python 3.6.x legacies. See https://github.com/numpy/numpy/releases/tag/v1.20.0 Removed version check on certain dependencies. Re-added aiortc to auto-install latest version. Asyncio: Changed asyncio.sleep value to 0 . The amount of time sleep is irrelevant; the only purpose await asyncio.sleep() serves is to force asyncio to suspend execution to the event loop, and give other tasks a chance to run. Also, await asyncio.sleep(0) will achieve the same effect. https://stackoverflow.com/a/55782965/10158117 License: Dropped publication year range to avoid confusion. (Signed and Approved by @abhiTronix ) Updated Vidgear license's year of first publication of the work in accordance with US copyright notices defined by Title 17, Chapter 4(Visually perceptible copies): https://www.copyright.gov/title17/92chap4.html Reflected changes in all copyright notices. CI: Updated macOS VM Image to latest in azure devops. Updated VidGear Docs Deployer Workflow. Updated WebGear_RTC CI tests. Removed redundant code from CI tests. Updated tests to increase coverage. Enabled Helper tests for python 3.8+ legacies. Enabled logging in validate_video method. Added -hls_base_url to streamgear tests. Update mpegdash dependency to 0.3.0-dev2 version in Appveyor. Updated CI tests for new HLS support Updated CI tests from scratch for new native HLS support in StreamGear. Updated test patch for StreamGear. Added exception for RunTimeErrors in NetGear CI tests. Added more directories to Codecov ignore list. Imported relative logger_handler for asyncio tests. Docs: Re-positioned few docs comments at bottom for easier detection during stripping. Updated to new extra analytics parameter in Material Mkdocs. Updated dark theme to dark orange . Changed fonts => text: Muli & code: Fira Code Updated fonts to Source Sans Pro . Updated setup.py update-link for modules. Re-added missing StreamGear Code docs. Several minor tweaks and typos fixed. Updated 404.html page. Updated admonitions colors and beautified custom.css . Replaced VideoGear & CamGear with OpenCV in CPU intensive examples. Updated mkdocs.yml with new changes and URLs. Moved FAQ examples to bonus examples. Moved StreamGear primary modes to separate sections for better readability. Implemented separate overview and usage example pages for StreamGear primary modes. Improved StreamGear docs context and simplified language. Renamed StreamGear overview page to introduction . Re-written Threaded-Queue-Mode from scratch with elaborated functioning. Replace Paypal with Liberpay in FUNDING.yml . Updated FFmpeg Download links. Reverted UI change in CSS. Updated changelog.md and fixed clutter. Updated README.md and mkdocs.yml with new additions Updated context for CamGear example. Restructured and added more content to docs. Updated comments in source code. Removed redundant data table tweaks from custom.css . Re-aligned badges in README.md. Beautify custom.css . Updated mkdocs.yml . Updated context and fixed typos. Added missing helper methods in Reference. Updated Admonitions. Updates images assets. Bumped CodeCov. Logging: Improved logging level-names. Updated logging messages. Minor tweaks to needs-more-info template. Updated issue templates and labels. Removed redundant imports. Breaking Updates/Changes Virtually isolated all API specific dependencies, Now ImportError for API-specific dependencies will be raised only when any of them is missing at API's initialization. Renamed delete_safe to delete_ext_safe . Dropped support for frame_jpeg_quality , frame_jpeg_optimize , frame_jpeg_progressive attributes from WebGear. Bug-fixes CamGear: Hot-fix for Live Camera Streams: Added new event flag to keep check on stream read. Implemented event wait for read() to block it when source stream is busy. Added and Linked THREAD_TIMEOUT with event wait timout. Improved backward compatibility of new additions. Enforced logging for YouTube live. NetGear: Fixed Bidirectional Video-Frame Transfer broken with frame-compression: Fixed return_data interfering with return JSON-data in receive mode. Fixed logic. Fixed color-subsampling interfering with colorspace. Patched external simplejpeg bug. Issue: https://gitlab.com/jfolz/simplejpeg/-/issues/11 Added np.squeeze to drop grayscale frame's 3 rd dimension on Client's end. Fixed bug that cause server end frame dimensions differ from client's end when frame compression enabled. NetGear_Async: Fixed bug related asyncio queue freezing on calling join() . Fixed ZMQ connection bugs in bidirectional mode. Fixed several critical bugs in event loop handling. Fixed several bugs in bidirectional mode implementation. Fixed missing socket termination in both server and client end. Fixed timeout parameter logic. Fixed typos in error messages. WebGear_RTC: Fixed stream freezes after web-page reloading: Implemented new algorithm to continue stream even when webpage is reloaded. Inherit and modified next_timestamp VideoStreamTrack method for generating accurate timestamps. Implemented reset_connections callable to reset all peer connections and recreate Video-Server timestamps. (Implemented by @kpetrykin ) Added close_connection endpoint in JavaScript to inform server page refreshing.(Thanks to @kpetrykin ) Added exclusive reset connection node /close_connection in routes. Added reset() method to Video-Server class for manually resetting timestamp clock. Added reset_enabled flag to keep check on reloads. Fixed premature webpage auto-reloading. Added additional related imports. Fixed web-page reloading bug after stream ended: Disable webpage reload behavior handling for Live broadcasting. Disable reload CI test on Windows machines due to random failures. Improved handling of failed ICE connection. Fixed Assertion error bug: Source must raise MediaStreamError when stream ends instead of returning None-type. WebGear Removed format specific OpenCV decoding and encoding support for WebGear. Helper: Regex bugs fixed: New improved regex for discovering supported encoders in get_supported_vencoders . Re-implemented check for extracting only valid output protocols in is_valid_url . Minor tweaks for better regex compatibility. Bugfix related to OpenCV import: Bug fixed for OpenCV import comparison test failing with Legacy versions and throwing ImportError . Replaced packaging.parse_version with more robust distutils.version . Fixed bug with create_blank_frame that throws error with gray frames: Implemented automatic output channel correction inside create_blank_frame function. Extended automatic output channel correction support to asyncio package. Implemented RSTP protocol validation as demuxer , since it's not a protocol but a demuxer. Removed redundant logger_handler , mkdir_safe , retrieve_best_interpolation , capPropId helper functions from asyncio package. Relatively imported helper functions from non-asyncio package. Removed unused aiohttp dependency. Removed asctime formatting from logging. StreamGear: Fixed Multi-Bitrate HLS VOD streams: Re-implemented complete workflow for Multi-Bitrate HLS VOD streams. Extended support to both Single-Source and Real-time Frames Modes. Fixed bugs with audio-video mapping. Fixed master playlist not generating in output. Fixed improper -seg_duration value resulting in broken pipeline. Fixed expected aspect ratio not calculated correctly for additional streams. Fixed stream not terminating when provided input from external audio device. Fixed bugs related to external audio not mapped correctly in HLS format. Fixed OPUS audio fragments not supported with MP4 video in HLS. Fixed unsupported high audio bit-rate bug. Setup.py: Fixed latest_version returning incorrect version for some PYPI packages. Removed latest_version variable support from simplejpeg . Fixed streamlink only supporting requests==2.25.1 on Windows. Removed all redundant dependencies like colorama , aiofiles , aiohttp . Fixed typos in dependencies. Setup.cfg: Replaced dashes with underscores to remove warnings. CI: Replaced buggy starlette.TestClient with async-asgi-testclient in WebGear_RTC Removed run() method and replaced with pure asyncio implementation. Added new async-asgi-testclient CI dependency. Fixed fake_picamera class logger calling vidgear imports prematurely before importing picamera class in tests. Implemented new fake_picamera class logger inherently with logging module. Moved sys.module logic for faking to init.py . Added __init__.py to ignore in Codecov. Fixed event loop closing prematurely while reloading: Internally disabled suspending event loop while reloading. Event Policy Loop patcher added for WebGear_RTC tests. Fixed return_assets_path path bug. Fixed typo in TimeoutError exception import. Fixed eventloop is already closed bug. Fixed eventloop bugs in Helper CI tests. Fixed several minor bugs related to new CI tests. Fixed bug in PiGear tests. Docs: Fixed 404 page does not work outside the site root with mkdocs. Fixed markdown files comments not stripped when converted to HTML. Fixed missing heading in VideoGear. Typos in links and code comments fixed. Several minor tweaks and typos fixed. Fixed improper URLs/Hyperlinks and related typos. Fixed typos in usage examples. Fixed redundant properties in CSS. Fixed bugs in mkdocs.yml . Fixed docs contexts and typos. Fixed stream.release() missing in docs. Fixed several typos in code comments. Removed dead code from docs. Refactored Code and reduced redundancy. Fixed shutdown in main.py . Fixed logging comments. Pull Requests PR #210 PR #215 PR #222 PR #223 PR #227 PR #231 PR #233 PR #237 PR #239 PR #243 New Contributors @kpetrykin","title":"v0.2.2 (2021-09-02)"},{"location":"changelog/#v021-2021-04-25","text":"New Features WebGear_RTC: A new API that is similar to WeGear API in all aspects but utilizes WebRTC standard instead of Motion JPEG for streaming. Now it is possible to share data and perform teleconferencing peer-to-peer, without requiring that the user install plugins or any other third-party software. Added a flexible backend for aiortc - a python library for Web Real-Time Communication (WebRTC). Integrated all functionality and parameters of WebGear into WebGear_RTC API. Implemented JSON Response with a WebRTC Peer Connection of Video Server. Added a internal RTC_VideoServer server on WebGear_RTC, a inherit-class to aiortc's VideoStreamTrack API. New Standalone UI Default theme v0.1.1 for WebGear_RTC from scratch without using 3 rd -party assets. (by @abhiTronix ) New custom.js and custom.css for custom responsive behavior. Added WebRTC support to custom.js and ensured compatibility with WebGear_RTC. Added example support for ICE framework and STUN protocol like WebRTC features to custom.js . Added resize() function to custom.js to automatically adjust video & img tags for smaller screens. Added WebGear_RTC support in main.py for easy access through terminal using --mode flag. Integrated all WebGear_RTC enhancements to WebGear Themes. Added CI test for WebGear_RTC. Added complete docs for WebGear_RTC API. Added bare-minimum as well as advanced examples usage code. Added new theme images. Added Reference and FAQs. CamGear API: New Improved Pure-Python Multiple-Threaded Implementation: Optimized Threaded-Queue-Mode Performance. (PR by @bml1g12 ) Replaced regular queue.full checks followed by sleep with implicit sleep with blocking queue.put . Replaced regular queue.empty checks followed by queue. Replaced nowait_get with a blocking queue.get natural empty check. Up-to 2x performance boost than previous implementations. New THREAD_TIMEOUT attribute to prevent deadlocks: Added support for THREAD_TIMEOUT attribute to its options parameter. Updated CI Tests and docs. WriteGear API: New more robust handling of default video-encoder in compression mode: Implemented auto-switching of default video-encoder automatically based on availability. API now selects Default encoder based on priority: \"libx264\" > \"libx265\" > \"libxvid\" > \"mpeg4\" . Added get_supported_vencoders Helper method to enumerate Supported Video Encoders. Added common handler for -c:v and -vcodec flags. NetGear API: New Turbo-JPEG compression with simplejpeg Implemented JPEG compression algorithm for 4-5% performance boost at cost of minor loss in quality. Utilized encode_jpeg and decode_jpeg methods to implement turbo-JPEG transcoding with simplejpeg . Added options to control JPEG frames quality, enable fastest dct, fast upsampling to boost performance. Added new jpeg_compression , jpeg_compression_quality , jpeg_compression_fastdct , jpeg_compression_fastupsample attributes. Enabled fast dct by default with JPEG frames at 90%. Added Docs for JPEG Frame Compression. WebGear API: New modular and flexible configuration for Custom Sources: Implemented more convenient approach for handling custom source configuration. Added new config global variable for this new behavior. Now None-type source parameter value is allowed for defining own custom sources. Added new Example case and Updates Docs for this feature. Added new CI Tests. New Browser UI Updates: New Standalone UI Default theme v0.1.0 for browser (by @abhiTronix ) Completely rewritten theme from scratch with only local resources. New custom.js and custom.css for custom responsive behavior. New sample glow effect with css. New sample click to full-screen behavior with javascript. Removed all third-party theme dependencies. Update links to new github server abhiTronix/vidgear-vitals Updated docs with new theme's screenshots. Added enable_infinite_frames attribute for enabling infinite frames. Added New modular and flexible configuration for Custom Sources. Bumped WebGear Theme Version to v0.1.1. Updated Docs and CI tests. ScreenGear API: Implemented Improved Pure-Python Multiple-Threaded like CamGear. Added support for THREAD_TIMEOUT attribute to its options parameter. StreamGear API: Enabled pseudo live-streaming flag re for live content. Docs: Added new native docs versioning to mkdocs-material. Added new examples and few visual tweaks. Updated Stylesheet for versioning. Added new DASH video chunks at https://github.com/abhiTronix/vidgear-docs-additionals for StreamGear and Stabilizer streams. Added open-sourced \"Tears of Steel\" * project Mango Teaser video chunks. Added open-sourced \"Subspace Video Stabilization\" http://web.cecs.pdx.edu/~fliu/project/subspace_stabilization/ video chunks. Added support for DASH Video Thumbnail preview in Clappr within custom.js . Added responsive clappr DASH player with bootstrap's embed-responsive . Added new permalink icon and slugify to toc. Added \"back-to-top\" button for easy navigation. Helper: New GitHub Mirror with latest Auto-built FFmpeg Static Binaries: Replaced new GitHub Mirror abhiTronix/FFmpeg-Builds in helper.py New CI maintained Auto-built FFmpeg Static Binaries. Removed all 3 rd -party and old links for better compatibility and Open-Source reliability. Updated Related CI tests. Added auto-font-scaling for create_blank_frame method. Added c_name parameter to generate_webdata and download_webdata to specify class. A more robust Implementation of Downloading Artifacts: Added a custom HTTP TimeoutHTTPAdapter Adapter with a default timeout for all HTTP calls based on this GitHub comment . Implemented http client and the send() method to ensure that the default timeout is used if a timeout argument isn't provided. Implemented Requests session with block to exit properly even if there are unhandled exceptions. Add a retry strategy to custom TimeoutHTTPAdapter Adapter with max 3 retries and sleep( backoff_factor=1 ) between failed requests. Added create_blank_frame method to create bland frames with suitable text. [CI] Continuous Integration: Added new fake frame generated for fake picamera class with numpy. Added new create_bug parameter to fake picamera class for emulating various artificial bugs. Added float/int instance check on time_delay for camgear and pigear. Added EXIT_CODE to new timeout implementation for pytests to upload codecov report when no timeout. Added auxiliary classes to fake picamera for facilitating the emulation. Added new CI tests for PiGear Class for testing on all platforms. Added shutdown() function to gracefully terminate WebGear_RTC API. Added new coreutils brew dependency. Added handler for variable check on exit and codecov upload. Added is_running flag to WebGear_RTC to exit safely. Setup: New automated latest version retriever for packages: Implemented new latest_version method to automatically retrieve latest version for packages. Added Some Dependencies. Added simplejpeg package for all platforms. Updates/Improvements Added exception for RunTimeErrors in NetGear CI tests. WriteGear: Critical file write access checking method: Added new check_WriteAccess Helper method. Implemented a new robust algorithm to check if given directory has write-access. Removed old behavior which gives irregular results. Helper: Maintenance Updates Added workaround for Python bug. Added safe_mkdir to check_WriteAccess to automatically create non-existential parent folder in path. Extended check_WriteAccess Patch to StreamGear. Simplified check_WriteAccess to handle Windows envs easily. Updated FFmpeg Static Download URL for WriteGear. Implemented fallback option for auto-calculating bitrate from extracted audio sample-rate in validate_audio method. Docs: General UI Updates Updated Meta tags for og site and twitter cards. Replaced Custom dark theme toggle with mkdocs-material's official Color palette toggle Added example for external audio input and creating segmented MP4 video in WriteGear FAQ. Added example for YouTube streaming with WriteGear. Removed custom dark-material.js and header.html files from theme. Added blogpost link for detailed information on Stabilizer Working. Updated mkdocs.yml and custom.css configuration. Remove old hack to resize clappr DASH player with css. Updated Admonitions. Improved docs contexts. Updated CSS for version-selector-button. Adjusted files to match new themes. Updated welcome-bot message for typos. Removed redundant FAQs from NetGear Docs. Updated Assets Images. Updated spacing. CI: Removed unused github.ref from yaml. Updated OpenCV Bash Script for Linux envs. Added timeout-minutes flag to github-actions workflow. Added timeout flag to pytest. Replaced Threaded Gears with OpenCV VideoCapture API. Moved files and Removed redundant code. Replaced grayscale frames with color frames for WebGear tests. Updated pytest timeout value to 15mins. Removed aiortc automated install on Windows platform within setup.py. Added new timeout logic to continue to run on external timeout for GitHub Actions Workflows. Removed unreliable old timeout solution from WebGear_RTC. Removed timeout_decorator and asyncio_timeout dependencies for CI. Removed WebGear_RTC API exception from codecov. Implemented new fake picamera class to CI utils for emulating RPi Camera-Module Real-time capabilities. Implemented new get_RTCPeer_payload method to receive WebGear_RTC peer payload. Removed PiGear from Codecov exceptions. Disable Frame Compression in few NetGear tests failing on frame matching. Updated NetGear CI tests to support new attributes Removed warnings and updated yaml Added pytest.ini to address multiple warnings. Updated azure workflow condition syntax. Update mike settings for mkdocs versioning. Updated codecov configurations. Minor logging and docs updates. Implemented pytest timeout for azure pipelines for macOS envs. Added aiortc as external dependency in appveyor.yml . Re-implemented WebGear_RTC improper offer-answer handshake in CI tests. WebGear_RTC CI Updated with VideoTransformTrack to test stream play. Implemented fake AttributeError for fake picamera class. Updated PiGear CI tests to increment codecov. Update Tests docs and other minor tweaks to increase overall coverage. Enabled debugging and disabled exit 1 on error in azure pipeline. Removed redundant benchmark tests. Helper: Added missing RSTP URL scheme to is_valid_url method. NetGear_Async: Added fix for uvloop only supporting python>=3.7 legacies. Extended WebGear's Video-Handler scope to https . CI: Remove all redundant 32-bit Tests from Appveyor: Appveyor 32-bit Windows envs are actually running on 64-bit machines. More information here: https://help.appveyor.com/discussions/questions/20637-is-it-possible-to-force-running-tests-on-both-32-bit-and-64-bit-windows Setup: Removed latest_version behavior from some packages. NetGear_Async: Revised logic for handling uvloop for all platforms and legacies. Setup: Updated logic to install uvloop-\"v0.14.0\" for python-3.6 legacies. Removed any redundant code from webgear. StreamGear: Replaced Ordinary dict with Ordered Dict to use move_to_end method. Moved external audio input to output parameters dict. Added additional imports. Updated docs to reflect changes. Numerous Updates to Readme and mkdocs.yml . Updated font to FONT_HERSHEY_SCRIPT_COMPLEX and enabled logging in create_blank_frame. Separated channels for downloading and storing theme files for WebGear and WebGear_RTC APIs. Removed logging condition to always inform user in a event of FFmpeg binary download failure. WebGear_RTC: Improved auto internal termination. More Performance updates through setCodecPreferences . Moved default Video RTC video launcher to __offer . NetGear_Async: Added timeout to client in CI tests. Reimplemented and updated changelog.md . Updated code comments. Setup: Updated keywords and classifiers. Bumped codecov. Breaking Updates/Changes WriteGear will automatically switch video encoder to default if specified encoder not found. WriteGear will throw RuntimeError if no suitable default encoder found! Removed format specific OpenCV decoding and encoding support for NetGear. Dropped support for compression_format , compression_param attributes from NetGear. Non-existent parent folder in output_filename value will no longer be considered as invalid in StreamGear and WriteGear APIs. None-type source parameter value is allowed for WebGear and NetGear_Async for defining custom sources. Bug-fixes CamGear: Fixed F821 undefined name 'queue' bug. NetGear_Async: Fixed source parameter missing None as default value. Fixed uvloops only supporting python>=3.7 in NetGear_Async. Helper: Fixed Zombie processes in check_output method due a hidden bug in python. For reference: https://bugs.python.org/issue37380 Fixed regex in validate_video method. Docs: Invalid site_url bug patched in mkdocs.yml Remove redundant mike theme support and its files. Fixed video not centered when DASH video in fullscreen mode with clappr. Fixed Incompatible new mkdocs-docs theme. Fixed missing hyperlinks. CI: Fixed NetGear Address bug Fixed bugs related to termination in WebGear_RTC. Fixed random CI test failures and code cleanup. Fixed string formating bug in Helper.py. Fixed F821 undefined name bugs in WebGear_RTC tests. NetGear_Async Tests fixes. Fixed F821 undefined name bugs. Fixed typo bugs in main.py . Fixed Relative import bug in PiGear. Fixed regex bug in warning filter. Fixed WebGear_RTC frozen threads on exit. Fixed bugs in codecov bash uploader setting for azure pipelines. Fixed False-positive picamera import due to improper sys.module settings. Fixed Frozen Threads on exit in WebGear_RTC API. Fixed deploy error in VidGear Docs Deployer workflow Fixed low timeout bug. Fixed bugs in PiGear tests. Patched F821 undefined name bug. StreamGear: Fixed StreamGear throwing Picture size 0x0 is invalid bug with external audio. Fixed default input framerate value getting discarded in Real-time Frame Mode. Fixed internal list-formatting bug. Fixed E999 SyntaxError bug in main.py . Fixed Typo in bash script. Fixed WebGear freeze on reloading bug. Fixed anomalies in install_opencv bash script. Helper: Bug Fixed in download_ffmpeg_binaries method. Helper: Fixed OSError bug in check_WriteAccess method. Helper: Fixed Input Audio stream bitrate test failing to detect audio-bitrate in certain videos with validate_audio method. Fixed bugs in requests module's function arguments. Fixed None-type stream bug in WebGear. Fixed random crashes in WebGear. Fixed numerous CI test bugs. Fixed several typos. Pull Requests PR #192 PR #196 PR #203 PR #206 New Contributors @bml1g12","title":"v0.2.1 (2021-04-25)"},{"location":"changelog/#v020-2021-01-01","text":"New Features CamGear API: Support for various Live-Video-Streaming services: Added seamless support for live video streaming sites like Twitch, LiveStream, Dailymotion etc. Implemented flexible framework around streamlink python library with easy control over parameters and quality. Stream Mode can now automatically detects whether source belong to YouTube or elsewhere, and handles it with appropriate API. Re-implemented YouTube URLs Handler: Re-implemented CamGear's YouTube URLs Handler completely from scratch. New Robust Logic to flexibly handing video and video-audio streams. Intelligent stream selector for selecting best possible stream compatible with OpenCV. Added support for selecting stream qualities and parameters. Implemented new get_supported_quality helper method for handling specified qualities Fixed Live-Stream URLs not supported by OpenCV's Videocapture and its FFmpeg. Added additional STREAM_QUALITY and STREAM_PARAMS attributes. ScreenGear API: Multiple Backends Support: Added new multiple backend support with new pyscreenshot python library. Made pyscreenshot the default API for ScreenGear, replaces mss . Added new backend parameter for this feature while retaining previous behavior. Added native automated RGB to BGR conversion for default PIL backend. Kept support for old mss for old compatibility and multi-screen support. Added native dimensional support for multi-screen. Added support all input from all multiple screens. Updated ScreenGear Docs. Updated ScreenGear CI tests. StreamGear API: Changed default behaviour to support complete video transcoding. Added -livestream attribute to support live-streaming. Added additional parameters for -livestream attribute functionality. Updated StreamGear Tests. Updated StreamGear docs. Stabilizer Class: New Robust Error Handling with Blank Frames: Elegantly handles all crashes due to Empty/Blank/Dark frames. Stabilizer throws Warning with this new behavior instead of crashing. Updated CI test for this feature. Docs: Automated Docs Versioning: Implemented Docs versioning through mike API. Separate new workflow steps to handle different versions. Updated docs deploy worflow to support release and dev builds. Added automatic version extraction from github events. Added version-select.js and version-select.css files. Toggleable Dark-White Docs Support: Toggle-button to easily switch dark, white and preferred theme. New Updated Assets for dark backgrounds New css, js files/content to implement this behavior. New material icons for button. Updated scheme to slate in mkdocs.yml . New Theme and assets: New purple theme with dark-purple accent color. New images assets with updated transparent background. Support for both dark and white theme. Increased rebufferingGoal for dash videos. New updated custom 404 page for docs. Issue and PR automated-bots changes New need_info.yml YAML Workflow. New needs-more-info.yml Request-Info template. Replaced Request-Info templates. Improved PR and Issue welcome formatting. Added custom HTML pages. Added show_root_heading flag to disable headings in References. Added new inserAfter function to version-select.js. Adjusted hue for dark-theme for better contrast. New usage examples and FAQs. Added gitmoji for commits. Continuous Integration: Maintenance Updates: Added support for new VIDGEAR_LOGFILE environment variable in Travis CI. Added missing CI tests. Added logging for helper functions. Azure-Pipeline workflow for MacOS envs Added Azure-Pipeline Workflow for testing MacOS environment. Added codecov support. GitHub Actions workflow for Linux envs Added GitHub Action work-flow for testing Linux environment. New YAML to implement GitHub Action workflow for python 3.6, 3.7, 3,8 & 3.9 matrices. Added Upload coverage to Codecov GitHub Action workflow. New codecov-bash uploader for Azure Pipelines. Logging: Added file support Added VIDGEAR_LOGFILE environment variable to manually add file/dir path. Reworked logger_handler() Helper methods (in asyncio too). Added new formatter and Filehandler for handling logger files. Added restore_levelnames auxiliary method for restoring logging levelnames. Added auto version extraction from package version.py in setup.py. Updates/Improvements Added missing Lazy-pirate auto-reconnection support for Multi-Servers and Multi-Clients Mode in NetGear API. Added new FFmpeg test path to Bash-Script and updated README broken links. Asset Cleanup: Removed all third-party javascripts from projects. Linked all third-party javascript directly. Cleaned up necessary code from CSS and JS files. Removed any copyrighted material or links. Rewritten Docs from scratch: Improved complete docs formatting. Simplified language for easier understanding. Fixed mkdocstrings showing root headings. Included all APIs methods to mkdocstrings docs. Removed unnecessary information from docs. Corrected Spelling and typos. Fixed context and grammar. Removed motivation.md . Renamed many terms. Fixed hyper-links. Reformatted missing or improper information. Fixed context and spellings in Docs files. Simplified language for easy understanding. Updated image sizes for better visibility. Bash Script: Updated to Latest OpenCV Binaries version and related changes Docs: Moved version-selector to header and changed default to alias. Docs: Updated deploy_docs.yml for releasing dev, stable, and release versions. Re-implemented overridden material theme. Updated docs with all new additions and examples. CamGear: CI Stream Mode test updated. Updated ReadMe.md badges. Updated CI tests. Updated setup.py with new features. Updated contributing.md and ReadMe.md . Updated OpenCV version to 4.5.1-dev in bash scripts Updated changelog.md . Moved WebGear API to Streaming Gears. Bumped Codecov. UI changes to version-select.js Docs: Retitle the versions and mkdocs.yml formatting updated. Docs: Version Selector UI reworked and other minor changes. Breaking Updates/Changes y_tube parameter renamed as stream_mode in CamGear API! Removed Travis support and travis.yml deleted. Bug-fixes Fixed StreamGear API Limited Segments Bug Fixed Missing links in docs and bump up version. CI: Fixed Appveyor need newer VM image to support Python 3.9.x matrix. ScreenGear BugFix: Fixed Error Handling and updated CI Tests. Fixed improper mkdocs.yml variables. Fixed GStreamer plugin support in bash scripts. Fixed typos in YAMLs and docs. Docs: Fixed Docs Deployer YAML bug for CI envs. Fixed wrong import in YAML. Fixed visible hyperlink on hover in dark-toggle button. Docs: Deployer YAML bug fixed. Docs YAML: issue jimporter/mike#33 patched and fixed fetch-depth=0 . Docs: version-select.js bug fixed. Docs: UI Bugs Fixed. CI: Codecov bugfixes. Azure-Pipelines Codecov BugFixes. Fixed version.json not detecting properly in version-select.js . Fixed images not centered inside <figure> tag. Fixed Asset Colors. Fixed failing CI tests. Fixed Several logging bugs. Pull Requests PR #164 PR #170 PR #173 PR #181 PR #183 PR #184","title":"v0.2.0 (2021-01-01)"},{"location":"changelog/#v019-2020-08-31","text":"New Features StreamGear API: New API that automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats. Implemented multi-platform , standalone, highly extensible and flexible wrapper around FFmpeg for generating chunked-encoded media segments of the media, and easily accessing almost all of its parameters. API automatically transcodes videos/audio files & real-time frames into a sequence of multiple smaller chunks/segments and also creates a Manifest file. Added initial support for MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) . Constructed default behavior in StreamGear, for auto-creating a Primary Stream of same resolution and framerate as source. Added TQDM progress bar in non-debugged output for visual representation of internal processes. Implemented several internal methods for preprocessing FFmpeg and internal parameters for producing streams. Several standalone internal checks to ensure robust performance. New terminate() function to terminate StremGear Safely. New StreamGear Dual Modes of Operation: Implemented Single-Source and Real-time Frames like independent Transcoding Modes. Linked -video_source attribute for activating these modes Single-Source Mode , transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller segments for streaming Real-time Frames Mode , directly transcodes video-frames (as opposed to a entire file) , into a sequence of multiple smaller segments for streaming Added separate functions, stream() for Real-time Frame Mode and transcode_source() for Single-Source Mode for easy transcoding. Included auto-colorspace detection and RGB Mode like features (extracted from WriteGear) , into StreamGear. New StreamGear Parameters: Developed several new parameters such as: output : handles assets directory formats : handles adaptive HTTP streaming format. custom_ffmpeg : handles custom FFmpeg location. stream_params : handles internal and FFmpeg parameter seamlessly. logging : turns logging on or off. New stream_params parameter allows us to exploit almost all FFmpeg parameters and flexibly change its internal settings, and seamlessly generating high-quality streams with its attributes: -streams (list of dictionaries) for building additional streams with -resolution , -video_bitrate & -framerate like sub-attributes. -audio for specifying external audio. -video_source for specifying Single-Source Mode source. -input_framerate for handling input framerate in Real-time Frames Mode. -bpp attribute for handling bits-per-pixels used to auto-calculate video-bitrate. -gop to manually specify GOP length. -ffmpeg_download_path to handle custom FFmpeg download path on windows. -clear_prev_assets to remove any previous copies of SteamGear Assets. New StreamGear docs, MPEG-DASH demo, and recommended DASH players list: Added new StreamGear docs, usage examples, parameters, references, new FAQs. Added Several StreamGear usage examples w.r.t Mode of Operation. Implemented Clappr based on Shaka-Player , as Demo Player. Added Adaptive-dimensional behavior for Demo-player, purely in css. Hosted StreamGear generated DASH chunks on GitHub and served with raw.githack.com . Introduced variable quality level-selector plugin for Clapper Player. Provide various required javascripts and implemented additional functionality for player in extra.js . Recommended tested Online, Command-line and GUI Adaptive Stream players. Implemented separate FFmpeg installation doc for StreamGear API. Reduced rebufferingGoal for faster response. New StreamGear CI tests: Added IO and API initialization CI tests for its Modes. Added various mode Streaming check CI tests. NetGear_Async API: Added new send_terminate_signal internal method. Added WindowsSelectorEventLoopPolicy() for windows 3.8+ envs. Moved Client auto-termination to separate method. Implemented graceful termination with signal API on UNIX machines. Added new timeout attribute for controlling Timeout in Connections. Added missing termination optimizer ( linger=0 ) flag. Several ZMQ Optimizer Flags added to boost performance. WriteGear API: Added support for adding duplicate FFmpeg parameters to output_params : Added new -clones attribute in output_params parameter for handing this behavior.. Support to pass FFmpeg parameters as list, while maintaining the exact order it was specified. Built support for zmq.REQ/zmq.REP and zmq.PUB/zmq.SUB patterns in this mode. Added new CI tests debugging this behavior. Updated docs accordingly. Added support for Networks URLs in Compression Mode: output_filename parameter supports Networks URLs in compression modes only Added automated handling of non path/file Networks URLs as input. Implemented new is_valid_url helper method to easily validate assigned URLs value. Validates whether the given URL value has scheme/protocol supported by assigned/installed ffmpeg or not. WriteGear will throw ValueError if -output_filename is not supported. Added related CI tests and docs. Added disable_force_termination attribute in WriteGear to disable force-termination. NetGear API: Added option to completely disable Native Frame-Compression: Checks if any Incorrect/Invalid value is assigned on compression_format attribute. Completely disables Native Frame-Compression. Updated docs accordingly. CamGear API: Added new and robust regex for identifying YouTube URLs. Moved youtube_url_validator to Helper. New helper.py methods: Added validate_video function to validate video_source. Added extract_time Extract time from give string value. Added get_video_bitrate to calculate video birate from resolution, framerate, bits-per-pixels values. Added delete_safe to safely delete files of given extension. Added validate_audio to validate audio source. Added new Helper CI tests. Added new check_valid_mpd function to test MPD files validity. Added mpegdash library to CI requirements. Deployed New Docs Upgrades: Added new assets like images, gifs, custom scripts, javascripts fonts etc. for achieving better visual graphics in docs. Added clappr.min.js , dash-shaka-playback.js , clappr-level-selector.min.js third-party javascripts locally. Extended Overview docs Hyperlinks to include all major sub-pages (such as Usage Examples, Reference, FAQs etc.) . Replaced GIF with interactive MPEG-DASH Video Example in Stabilizer Docs. Added new pymdownx.keys to replace [Ctrl+C]/[\u2318+C] formats. Added new custom.css stylescripts variables for fluid animations in docs. Overridden announce bar and added donation button. Lossless WEBP compressed all PNG assets for faster loading. Enabled lazy-loading for GIFS and Images for performance. Reimplemented Admonitions contexts and added new ones. Added StreamGear and its different modes Docs Assets. Added patch for images & unicodes for PiP flavored markdown in setup.py . Added Request Info and Welcome GitHub Apps to automate PR and issue workflow Added new config.yml for customizations. Added various suitable configurations. Added new -clones attribute to handle FFmpeg parameter clones in StreamGear and WriteGear API. Added new Video-only and Audio-Only sources in bash script. Added new paths in bash script for storing StreamGear & WriteGear assets temporarily. Updates/Improvements Added patch for NotImplementedError in NetGear_Async API on Windows 3.8+ envs. Check for valid output file extension according to format selected in StreamGear. Completed migration to travis.com . Created new temp_write temp directory for WriteGear Assets in bash script. Deleted old Redundant assets and added new ones. Employed isort library to sort and group imports in Vidgear APIs. Enabled exception for list, tuple, int, float in WriteGear API's output_params dict. Enabled missing support for frame-compression in its primary Receive Mode. Enforced pixel formats for streams. Improved check for valid system path detection in WriteGear API. Overrided pytest-asyncio fixture in NetGear_Async API. Quoted Gear Headline for understanding each gear easily. Re-Positioned Gear's banner images in overview for better readability. Reduced redundant try-except blocks in NetGear Async. Reformatted and Simplified Docs context. Reimplemented return_testvideo_path CI function with variable streams. Reimplemented skip_loop in NetGear_Async to fix asyncio.CancelledError . Reimplemented buggy audio handler in StreamGear. Reimplemented images with <figure> and <figurecaption> like tags. Removed Python < 3.8 condition from all CI tests. Removed or Grouped redundant code for increasing codecov. Removed redundant code and simplified algorithmic complexities in Gears. Replaced ;nbsp with ;thinsp and ;emsp . Replaced IOError with more reliable RuntimeError in StreamGear Pipelines. Replaced del with pop in dicts. Replaced all Netgear CI tests with more reliable try-except-final blocks. Replaced simple lists with pymdownx.tasklist . Replaced subprocess call() with run() for better error handling in execute_ffmpeg_cmd function. Resized over-sized docs images. Simplified delete_safe Helper function. Simplified default audio-bitrate logic in StreamGear Updated CI tests and cleared redundant code from NetGear_Async API. Updated CI with new tests and Bumped Codecov. Updated Issue and PR templates. Updated Licenses for new files and shrink images dimensions. Updated Missing Helpful tips and increased logging. Updated PR guidelines for more clarity. Updated WebGear examples addresses from 0.0.0.0 to localhost . Updated WriteGear and StreamGear CI tests for not supporting temp directory. Updated README.md and changelog.md with new changes. Updated check_output and added force_retrieve_stderr support to **kwargs to extract stderr output even on FFmpeg error. Updated dicts2args to support internal repeated coreX FFmpeg parameters for StreamGear. Updated mkdocs.yml , changelog.md and README.md with latest changes. Updated validate_audio Helper function will now retrieve audio-bitrate for validation. Updated buggy mpegdash dependency with custom dev fork for Windows machines. Updated core parameters for audio handling. Updated logging for debugging selected eventloops in NetGear_Async API. Updated termination linger to zero at Server's end. Breaking Updates/Changes Changed Webgear API default address to localhost for cross-compatibility between different platforms. In Netgear_Async API, source value can now be NoneType for a custom frame-generator at Server-end only. Temp (such as /tmp in linux) is now not a valid directory for WriteGear & StreamGear API outputs. Moved vidgear docs assets (i.e images, gifs, javascripts and stylescripts) to override directory. Bug-fixes Added workaround for system path not handle correctly. Fixed Bug: URL Audio format not being handled properly. Fixed Critical Bug in NetGear_Async throwing ValueError with None-type Source. Fixed Critical StreamGear Bug: FFmpeg pipeline terminating prematurely in Single-Source Mode. Fixed Critical external audio handler bug: moved audio-input to input_parameters. Fixed Frozen-threads bug in CI tests. Fixed Mkdocs only accepting Relative paths. Fixed OSError in WriteGear's compression mode. Fixed StreamGear CI bugs for Windows and CI envs. Fixed Typos and Indentation bugs in NetGear API. Fixed ZMQ throwing error on termination if all max-tries exhausted. Fixed NameError bug in NetGear API and CI tests. Fixed TimeoutError bug in NetGear_Async CI tests. Fixed get_valid_ffmpeg_path throwing TypeError with non-string values. Fixed broken links in docs. Fixed critical duplicate logging bug. Fixed default gop value not handle correctly. Fixed handling of incorrect paths detection. Fixed incorrect definitions in NetGear_Async. Fixed left-over attribute bug in WriteGear. Fixed logic and indentation bugs in CI tests. Fixed logic for handling output parameters in WriteGear API. Fixed missing definitions and logic bug in StreamGear. Fixed missing import and incorrect CI definitions. Fixed missing source dimensions from extract_resolutions output in StreamGear API. Fixed missing support for compression parameters in Multi-Clients Mode. Fixed round off error in FPS. Fixed several CI bugs and updated extract_resolutions method. Fixed several bugs from CI Bidirectional Mode tests. Fixed several typos in docs usage examples. Fixed various AttributeError with wrong attribute names and definition in CI Helper functions. Fixed wrong and missing definitions in docs. Fixed wrong logic for extracting OpenCV frames. Fixed wrong type bug in StreamGear API. Fixed wrong type error bug in WriteGear API. Fixed wrong variable assignments bug in WriteGear API. Fixes to CLI tests and missing docs imports. Many minor typos and wrong definitions. Pull Requests PR #129 PR #130 PR #155","title":"v0.1.9 (2020-08-31)"},{"location":"changelog/#v018-2020-06-12","text":"New Features NetGear API: Multiple Clients support: Implemented support for handling any number of Clients simultaneously with a single Server in this mode. Added new multiclient_mode attribute for enabling this mode easily. Built support for zmq.REQ/zmq.REP and zmq.PUB/zmq.SUB patterns in this mode. Implemented ability to receive data from all Client(s) along with frames with zmq.REQ/zmq.REP pattern only. Updated related CI tests Support for robust Lazy Pirate pattern(auto-reconnection) in NetGear API for both server and client ends: Implemented a algorithm where NetGear rather than doing a blocking receive, will now: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. Implemented its default support for REQ/REP and PAIR messaging patterns internally. Added new max_retries and request_timeout (in seconds) for handling polling. Added DONTWAIT flag for interruption-free data receiving. Both Server and Client can now reconnect even after a premature termination. Performance Updates: Added default Frame Compression support for Bidirectional frame transmission in Bidirectional mode. Added support for Reducer() function in Helper.py to aid reducing frame-size on-the-go for more performance. Added small delay in recv() function at client's end to reduce system load. Reworked and Optimized NetGear termination, and also removed/changed redundant definitions and flags. Docs: Migration to Mkdocs Implemented a beautiful, static documentation site based on MkDocs which will then be hosted on GitHub Pages. Crafted base mkdocs with third-party elegant & simplistic mkdocs-material theme. Implemented new mkdocs.yml for Mkdocs with relevant data. Added new docs folder to handle markdown pages and its assets. Added new Markdown pages( .md ) to docs folder, which are carefully crafted documents - [x] based on previous Wiki's docs, and some completely new additions. Added navigation under tabs for easily accessing each document. New Assets: Added new assets like gifs, images, custom scripts, favicons, site.webmanifest etc. for bringing standard and quality to docs visual design. Designed brand new logo and banner for VidGear Documents. Deployed all assets under separate Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License . Added Required Plugins and Extensions: Added support for all pymarkdown-extensions . Added support for some important admonition , attr_list , codehilite , def_list , footnotes , meta , and toc like Mkdocs extensions. Enabled search , minify and git-revision-date-localized plugins support. Added various VidGear's social links to yaml. Added support for en (English) language. Auto-Build API Reference with mkdocstrings: Added support for mkdocstrings plugin for auto-building each VidGear's API references. Added python handler for parsing python source-code to mkdocstrings . Auto-Deploy Docs with GitHub Actions: Implemented Automated Docs Deployment on gh-pages through GitHub Actions workflow. Added new workflow yaml with minimal configuration for automated docs deployment. Added all required python dependencies and environment for this workflow. Added master branch on Ubuntu machine to build matrix. Updates/Improvements Added in-built support for bidirectional frames( NDarray ) transfer in Bidirectional mode. Added support for User-Defined compression params in Bidirectional frames transfer. Added workaround for address already in use bug at client's end. Unified Bidirectional and Multi-Clients mode for client's return data transmission. Replaced ValueError with more suitable RuntimeError . Updated logging for better readability. Added CI test for Multi-Clients mode. Reformatted and grouped imports in VidGear. Added Reducer Helper function CI test. Added Reliability tests for both Server and Client end. Disabled reliable reconnection for Multi-Clients mode. Replaced os.devnull with suprocess's inbuilt function. Updated README.md, Issue and PR templates with new information and updates. Moved changelog.md to /docs and updated contribution guidelines. Improved source-code docs for compatibility with mkdocstrings . Added additional dependency mkdocs-exclude , for excluding files from Mkdocs builds. Updated license and compressed images/diagrams. Added new CI tests and Bumped Codecov. Changed YouTube video URL for CI tests to Creative Commons(CC) video. Removed redundant code. Breaking Updates/Changes VidGear Docs moved to GitHub Pages, Now Available at https://abhitronix.github.io/vidgear . Removed filter attribute from options parameter in NetGear API. Removed force_terminate parameter support from NetGear API. Disabled additional data of datatype numpy.ndarray for Server end in Bidirectional Mode. Bug-fixes Fixed 'NoneType' object is not subscriptable bug. Fixed bugs related to delayed termination in NetGear API. Reduced default request_timeout value to 4 and also lowered cut-off limit for the same. Removed redundant ZMQ context termination and similar variables. Added missing VidGear installation in workflow. Excluded conflicting assets README.md from Mkdocs builds. Fixed pattern value check bypassed if wrong value is assigned. Fixed incorrect handling of additional data transferred in synchronous mode at both Server and Client end. Replaced Netgear CI test with more reliable try-except-final blocks. Updated termination linger to zero at Server's end. Fixed NameError bug in NetGear API. Fixed missing support for compression parameters in Multi-Clients Mode. Fixed ZMQ throwing error on termination if all max-tries exhausted. Enabled missing support for frame compression in its primary receive mode. Fixed several bugs from CI Bidirectional Mode tests. Removed or Grouped redundant code for increasing codecov. Fixed Mkdocs only accepting Relative paths. Fixed broken links in docs. Fixed round off error in FPS. Many small typos and bugs fixes. Pull Requests PR #129 PR #130","title":"v0.1.8 (2020-06-12)"},{"location":"changelog/#v017-2020-04-29","text":"New Features WebGear API: Added a robust Live Video Server API that can transfer live video frames to any web browser on the network in real-time. Implemented a flexible asyncio wrapper around starlette ASGI Application Server. Added seamless access to various starlette's Response classes, Routing tables, Static Files, Template engine(with Jinja2), etc. Added a special internal access to VideoGear API and all its parameters. Implemented a new Auto-Generation Work-flow to generate/download & thereby validate WebGear API data files from its GitHub server automatically. Added on-the-go dictionary parameter in WebGear to tweak performance, Route Tables and other internal properties easily. Added new simple & elegant default Bootstrap Cover Template for WebGear Server. Added __main__.py to directly run WebGear Server through the terminal. Added new gif and related docs for WebGear API. Added and Updated various CI tests for this API. NetGear_Async API: Designed NetGear_Async asynchronous network API built upon ZeroMQ's asyncio API. Implemented support for state-of-the-art asyncio event loop uvloop at its backend. Achieved Unmatchable high-speed and lag-free video streaming over the network with minimal resource constraint. Added exclusive internal wrapper around VideoGear API for this API. Implemented complete server-client handling and options to use variable protocols/patterns for this API. Implemented support for all four ZeroMQ messaging patterns: i.e zmq.PAIR , zmq.REQ/zmq.REP , zmq.PUB/zmq.SUB , and zmq.PUSH/zmq.PULL . Implemented initial support for tcp and ipc protocols. Added new Coverage CI tests for NetGear_Async Network Gear. Added new Benchmark tests for benchmarking NetGear_Async against NetGear. Asynchronous Enhancements: Added asyncio package to for handling asynchronous APIs. Moved WebGear API(webgear.py) to asyncio and created separate asyncio helper.py for it. Various Performance tweaks for Asyncio APIs with concurrency within a single thread. Moved __main__.py to asyncio for easier access to WebGear API through the terminal. Updated setup.py with new dependencies and separated asyncio dependencies. General Enhancements: Added new highly-precise Threaded FPS class for accurate benchmarking with time.perf_counter python module. Added a new Gitter community channel. Added a new Reducer function to reduce the frame size on-the-go. Add Flake8 tests to Travis CI to find undefined names. (PR by @cclauss ) Added a new unified logging handler helper function for vidgear. Updates/Improvements Re-implemented and simplified logic for NetGear Async server-end. Added new dependencies for upcoming asyncio updates to setup.py . Added retry function and replaced wget with curl for Linux test envs. Bumped OpenCV to latest 4.2.0-dev for Linux test envs. Updated YAML files to reflect new changes to different CI envs. Separated each API logger with a common helper method to avoid multiple copies. Limited Importing OpenCV API version check's scope to helper.py only. Implemented case for incorrect color_space value in ScreenGear API. Removed old conflicting logging formatter with a common method and expanded logging. Improved and added shutdown function for safely stopping frame producer threads in WebGear API. Re-implemented and simplified all CI tests with maximum code-coverage in mind. Replaced old mkdir function with new mkdir_safe helper function for creating directories safely. Updated ReadMe.md with updated diagrams, gifs and information. Improve, structured and Simplified the Contribution Guidelines. Bundled CI requirements in a single command.(Suggested by @cclauss ) Replaced line endings CRLF with LF endings. Added dos2unix for Travis OSX envs. Bumped Codecov to maximum. Breaking Updates/Changes Dropped support for Python 3.5 and below legacies. (See issue #99 ) Dropped and replaced Python 3.5 matrices with new Python 3.8 matrices in all CI environments. Implemented PEP-8 Styled Black formatting throughout the source-code. Limited protocols support to tcp and ipc only, in NetGear API. Bug-fixes Fixed Major NetGear_Async bug where __address and __port are not set in async mode.(PR by @otter-in-a-suit ) Fixed Major PiGear Color-space Conversion logic bug. Workaround for CAP_IMAGES error in YouTube Mode. Replaced incorrect terminate() with join() in PiGear. Removed uvloop for windows as still NOT yet supported . Refactored Asynchronous Package name async to asyncio , since it is used as Keyword in python>=3.7 (raises SyntaxError) . Fixed unfinished close of event loops bug in WebGear API. Fixed NameError in helper.py. Added fix for OpenCV installer failure on Linux test envs. Fixed undefined NameError in helper.py context. ( @cclauss ) Fixed incorrect logic while pulling frames from ScreenGear API. Fixed missing functions in __main__.py . Fixed Typos and definitions in docs. Added missing camera_num parameter to VideoGear. Added OpenSSL's [SSL: CERTIFICATE_VERIFY_FAILED] bug workaround for macOS envs. Removed download_url meta from setup.py. Removed PiGear from CI completely due to hardware emulation limitation. Removed VideoCapture benchmark tests for macOS envs. Removed trivial __main__.py from codecov. Removed several redundant try-catch loops. Renamed youtube_url_validation as youtube_url_validator . Several minor wrong/duplicate variable definitions and various bugs fixed. Fixed, Improved & removed many Redundant CI tests for various APIs. Pull Requests PR #88 PR #91 PR #93 PR #95 PR #98 PR #101 PR #114 PR #118 PR #124 New Contributors @cclauss @chollinger93","title":"v0.1.7 (2020-04-29)"},{"location":"changelog/#v016-2020-01-01","text":"New Features NetGear API: Added powerful ZMQ Authentication & Data Encryption features for NetGear API: Added exclusive secure_mode param for enabling it. Added support for two most powerful Stonehouse & Ironhouse ZMQ security mechanisms. Added smart auth-certificates/key generation and validation features. Implemented Robust Multi-Servers support for NetGear API: Enables Multiple Servers messaging support with a single client. Added exclusive multiserver_mode param for enabling it. Added support for REQ/REP & PUB/SUB patterns for this mode. Added ability to send additional data of any datatype along with the frame in realtime in this mode. Introducing exclusive Bidirectional Mode for bidirectional data transmission: Added new return_data parameter to recv() function. Added new bidirectional_mode attribute for enabling this mode. Added support for PAIR & REQ/REP patterns for this mode Added support for sending data of any python datatype. Added support for message parameter for non-exclusive primary modes for this mode. Implemented compression support with on-the-fly flexible frame encoding for the Server-end: Added initial support for JPEG , PNG & BMP encoding formats . Added exclusive options attribute compression_format & compression_param to tweak this feature. Client-end will now decode frame automatically based on the encoding as well as support decoding flags. Added force_terminate attribute flag for handling force socket termination at the Server-end if there's latency in the network. Implemented new Publish/Subscribe( zmq.PUB/zmq.SUB ) pattern for seamless Live Streaming in NetGear API. PiGear API: Added new threaded internal timing function for PiGear to handle any hardware failures/frozen threads. PiGear will not exit safely with SystemError if Picamera ribbon cable is pulled out to save resources. Added support for new user-defined HWFAILURE_TIMEOUT options attribute to alter timeout. VideoGear API: Added framerate global variable and removed redundant function. Added CROP_N_ZOOM attribute in Videogear API for supporting Crop and Zoom stabilizer feature. WriteGear API: Added new execute_ffmpeg_cmd function to pass a custom command to its FFmpeg pipeline. Stabilizer class: Added new Crop and Zoom feature. Added crop_n_zoom param for enabling this feature. Updated docs. CI & Tests updates: Replaced python 3.5 matrices with latest python 3.8 matrices in Linux environment. Added full support for Codecov in all CI environments. Updated OpenCV to v4.2.0-pre(master branch). Added various Netgear API tests. Added initial Screengear API test. More test RTSP feeds added with better error handling in CamGear network test. Added tests for ZMQ authentication certificate generation. Added badge and Minor doc updates. Added VidGear's official native support for MacOS environments. Updates/Improvements Replace print logging commands with python's logging module completely. Implemented encapsulation for class functions and variables on all gears. Updated support for screen casting from multiple/all monitors in ScreenGear API. Updated ScreenGear API to use Threaded Queue Mode by default, thereby removed redundant THREADED_QUEUE_MODE param. Updated bash script path to download test dataset in $TMPDIR rather than $HOME directory for downloading testdata. Implemented better error handling of colorspace in various videocapture APIs. Updated bash scripts, Moved FFmpeg static binaries to github.com . Updated bash scripts, Added additional flag to support un-secure apt sources. CamGear API will now throw RuntimeError if source provided is invalid. Updated threaded Queue mode in CamGear API for more robust performance. Added new camera_num to support multiple Picameras. Moved thread exceptions to the main thread and then re-raised. Added alternate github mirror for FFmpeg static binaries auto-installation on windows oses. Added colorlog python module for presentable colored logging. Replaced traceback with sys.exc_info . Overall APIs Code and Docs optimizations. Updated Code Readability and Wiki Docs. Updated ReadMe & Changelog with the latest changes. Updated Travis CI Tests with support for macOS environment. Reformatted & implemented necessary MacOS related changes and dependencies in travis.yml . Breaking Updates/Changes Python 2.7 legacy support dropped completely. Source-code Relicensed to Apache 2.0 License. Python 3+ are only supported legacies for installing v0.1.6 and above. Python 2.7 and 3.4 legacies support dropped from CI tests. Bug-fixes Reimplemented Pub/Sub pattern for smoother performance on various networks. Fixed Assertion error in CamGear API during colorspace manipulation. Fixed random freezing in Secure Mode and several related performance updates Fixed multiserver_mode not working properly over some networks. Fixed assigned Port address ignored bug (commit 073bca1). Fixed several wrong definition bugs from NetGear API(commit 8f7153c). Fixed unreliable dataset video URL(rehosted file on github.com ). Disabled overwrite_cert for client-end in NetGear API. Disabled Universal Python wheel builds in setup.cfg file. Removed duplicate code to import MSS( @BoboTiG ) from ScreenGear API. Eliminated unused redundant code blocks from library. Fixed Code indentation in setup.py and updated new release information. Fixed code definitions & Typos. Fixed several bugs related to secure_mode & multiserver_mode Modes. Fixed various macOS environment bugs. Pull Requests PR #39 PR #42 PR #44 PR #52 PR #55 PR #62 PR #67 PR #72 PR #77 PR #78 PR #82 PR #84 New Contributors @BoboTiG","title":"v0.1.6 (2020-01-01)"},{"location":"changelog/#v015-2019-07-24","text":"New Features Added new ScreenGear API, supports Live ScreenCasting. Added new NetGear API, aids real-time frame transfer through messaging(ZmQ) over network. Added new new Stabilizer Class, for minimum latency Video Stabilization with OpenCV. Added Option to use API's standalone. Added Option to use VideoGear API as internal wrapper around Stabilizer Class. Added new parameter stabilize to API, to enable or disable Video Stabilization. Added support for **option dict attributes to update VidGear's video stabilizer parameters directly. Added brand new logo and functional block diagram ( .svg ) in readme.md Added new pictures and GIFs for improving readme.md readability Added new contributing.md and changelog.md for reference. Added collections.deque import in Threaded Queue Mode for performance consideration Added new install_opencv.sh bash scripts for Travis cli, to handle OpenCV installation. Added new Project Issue & PR Templates Added new Sponsor Button( FUNDING.yml ) Updates/Improvements Updated New dependencies: mss , pyzmq and rejected redundant ones. Revamped and refreshed look for readme.md and added new badges. Updated Releases Documentation completely. Updated CI tests for new changes Updated Code Documentation. Updated bash scripts and removed redundant information Updated Youtube video URL in tests Completely Reformatted and Updated Wiki Docs with new changes. Breaking Updates/Changes Implemented experimental Threaded Queue Mode( a.k.a Blocking Mode ) for fast, synchronized, error-free multi-threading. Renamed bash script pre-install.sh to prepare_dataset.sh - [x] downloads opensourced test datasets and static FFmpeg binaries for debugging. Changed script folder location to bash/script . Python 3.4 removed from Travis CI tests. Bug-fixes Temporarily fixed Travis CI bug: Replaced opencv-contrib-python with OpenCV built from scratch as dependency. Fixed CI Timeout Bug: Disable Threaded Queue Mode for CI Tests Fixes** sys.stderr.close() throws ValueError bug: Replaced sys.close() with DEVNULL.close() Fixed Youtube Live Stream bug that return NonType frames in CamGear API. Fixed NoneType frames bug in PiGear class on initialization. Fixed Wrong function definitions Removed /xe2 unicode bug from Stabilizer class. Fixed **output_params KeyError bug in WriteGear API Fixed subprocess not closing properly on exit in WriteGear API. Fixed bugs in ScreenGear: Non-negative monitor values Fixed missing import, typos, wrong variable definitions Removed redundant hack from setup.py Fixed Minor YouTube playback Test CI Bug Fixed new Twitter Intent Fixed bug in bash script that not working properly due to changes at server end. Pull Requests PR #17 PR #21 PR #22 PR #27 PR #31 PR #32 PR #33 PR #34","title":"v0.1.5 (2019-07-24)"},{"location":"changelog/#v014-2019-05-11","text":"New Features Added new WriteGear API: for enabling lossless video encoding and compression(built around FFmpeg and OpenCV Video Writer) Added YouTube Mode for direct Video Pipelining from YouTube in CamGear API Added new y_tube to access YouTube Mode in CamGear API. Added flexible Output file Compression control capabilities in compression-mode(WriteGear). Added -output_dimensions special parameter to WriteGear API. Added new helper.py to handle special helper functions. Added feature to auto-download and configure FFmpeg Static binaries(if not found) on Windows platforms. Added -input_framerate special parameter to WriteGear class to change/control output constant framerate in compression mode(WriteGear). Added new Direct Video colorspace Conversion capabilities in CamGear and PiGear API. Added new framerate class variable for CamGear API, to retrieve input framerate. Added new parameter backend - [x] changes the backend of CamGear's API Added automatic required prerequisites installation ability, when installation from source. Added Travis CI Complete Integration for Linux-based Testing for VidGear. Added and configured travis.yml Added Appveyor CI Complete Integration for Windows-based Testing in VidGear. Added and configured new appveyor.yml Added new bash script pre-install.sh to download opensourced test datasets and static FFmpeg binaries for debugging. Added several new Tests(including Benchmarking Tests) for each API for testing with pytest . Added license to code docs. Added Say Thank you! badge to Readme.md . Updates/Improvements Removed redundant dependencies Updated youtube-dl as a dependency, as required by pafy 's backend. Updated common VideoGear API with new parameter. Update robust algorithm to auto-detect FFmpeg executables and test them, if failed, auto fallback to OpenCV's VideoWriter API. Improved system previously installed OpenCV detection in setup.py. Updated setup.py with hack to remove bullets from pypi description. Updated Code Documentation Reformatted & Modernized readme.md with new badges. Reformatted and Updated Wiki Docs. Breaking Updates/Changes Removed -height and -width parameter from CamGear API. Replaced dependency opencv-python with opencv-contrib-python completely Bug-fixes Windows Cross-Platform fix: replaced dependency os with platform in setup.py. Fixed Bug: Arises due to spaces in input **options / **output_param dictionary keys. Fixed several wrong/missing variable & function definitions. Fixed code uneven indentation. Fixed several typos in docs. Pull Requests PR #7 PR #8 PR #10 PR #12","title":"v0.1.4 (2019-05-11)"},{"location":"changelog/#v013-2019-04-07","text":"Bug-fixes Patched Major PiGear Bug: Incorrect import of PiRGBArray function in PiGear Class Several Fixes for backend picamera API handling during frame capture(PiGear) Fixed missing frame variable initialization. Fixed minor typos Pull Requests PR #6 PR #5","title":"v0.1.3 (2019-04-07)"},{"location":"changelog/#v012-2019-03-27","text":"New Features Added easy Source manipulation feature in CamGear API, to control features like resolution, brightness, framerate etc. Added new **option parameter to CamGear API, provides the flexibility to manipulate input stream directly. Added new parameters for Camgear API for time delay and logging. Added new Logo to readme.md Added new Wiki Documentation. Updates/Improvements Reformatted readme.md. Updated Wiki Docs with new changes. Bug-fixes Improved Error Handling in CamGear & PiGear API. Fixed minor typos in docs. Pull Requests PR #4","title":"v0.1.2 (2019-03-27)"},{"location":"changelog/#v011-2019-03-24","text":"New Features Release ViGear binaries on the Python Package Index (PyPI) Added new and configured setup.py & setup.cfg Bug-fixes Fixed PEP bugs: added and configured properly __init__.py in each folder Fixed PEP bugs: improved code Indentation Fixed wrong imports: replaced distutils.core with setuptools Fixed readme.md","title":"v0.1.1 (2019-03-24)"},{"location":"changelog/#v010-2019-03-17","text":"New Features Initial Release Converted my imutils PR into Python Project. Renamed conventions and reformatted complete source-code from scratch. Added support for both python 2.7 and 3 legacies Added new multi-threaded CamGear, PiGear, and VideoGear APIs Added multi-platform compatibility Added robust & flexible control over the source in PiGear API.","title":"v0.1.0 (2019-03-17)"},{"location":"contribution/","text":"Contribution Overview \u2693 Contributions are welcome, We'd love your contribution to VidGear in order to fix bugs or to implement new features! Contribution Opportunities If you're looking for something to work on, check for the PR WELCOMED labeled issues on our GitHub Repository. \u2009 Submission Guidelines \u2693 Submitting an Issue Guidelines \u27b6 Submitting Pull Request(PR) Guidelines \u27b6 \u2009 Submission Contexts \u2693 Got a question or problem? \u2693 For quick questions, please refrain from opening an issue, instead read our FAQ & Troubleshooting section or you can reach us on Gitter community channel. Found a typo? \u2693 There's no need to contribute for some typos. Just reach us on Gitter \u27b6 community channel, We will correct them in (less than) no time. Found a bug? \u2693 If you encountered a bug, you can help us by submitting an issue in our GitHub repository. Even better, you can submit a Pull Request(PR) with a fix, but make sure to read the guidelines \u27b6 . Request for a feature/improvement? \u2693 Subscribe to Github Repository You can subscribe our GitHub Repository to receive notifications through email for new pull requests, commits and issues that are created in VidGear. Learn more about it here \u27b6 You can request our GitHub Repository for a new feature/improvement based on the type of request: Please submit an issue with a proposal template for your request to explain how it benefits everyone in the community. Major Feature Requests: If you require a major feature for VidGear, then first open an issue and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. The purposed feature, if accepted, may take time based on its complexity and availability/time-schedule of our maintainers, but once it's completed, you will be notified right away. Please be patient! Minor Feature Requests: Small features and bugs resolved on priority. You just have to submit an issue to our GitHub Repository.","title":"Contribution Overview"},{"location":"contribution/#contribution-overview","text":"Contributions are welcome, We'd love your contribution to VidGear in order to fix bugs or to implement new features! Contribution Opportunities If you're looking for something to work on, check for the PR WELCOMED labeled issues on our GitHub Repository.","title":"Contribution Overview"},{"location":"contribution/#submission-guidelines","text":"Submitting an Issue Guidelines \u27b6 Submitting Pull Request(PR) Guidelines \u27b6","title":"Submission Guidelines"},{"location":"contribution/#submission-contexts","text":"","title":"Submission Contexts"},{"location":"contribution/#got-a-question-or-problem","text":"For quick questions, please refrain from opening an issue, instead read our FAQ & Troubleshooting section or you can reach us on Gitter community channel.","title":"Got a question or problem?"},{"location":"contribution/#found-a-typo","text":"There's no need to contribute for some typos. Just reach us on Gitter \u27b6 community channel, We will correct them in (less than) no time.","title":"Found a typo?"},{"location":"contribution/#found-a-bug","text":"If you encountered a bug, you can help us by submitting an issue in our GitHub repository. Even better, you can submit a Pull Request(PR) with a fix, but make sure to read the guidelines \u27b6 .","title":"Found a bug?"},{"location":"contribution/#request-for-a-featureimprovement","text":"Subscribe to Github Repository You can subscribe our GitHub Repository to receive notifications through email for new pull requests, commits and issues that are created in VidGear. Learn more about it here \u27b6 You can request our GitHub Repository for a new feature/improvement based on the type of request: Please submit an issue with a proposal template for your request to explain how it benefits everyone in the community. Major Feature Requests: If you require a major feature for VidGear, then first open an issue and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. The purposed feature, if accepted, may take time based on its complexity and availability/time-schedule of our maintainers, but once it's completed, you will be notified right away. Please be patient! Minor Feature Requests: Small features and bugs resolved on priority. You just have to submit an issue to our GitHub Repository.","title":"Request for a feature/improvement?"},{"location":"gears/","text":"Introduction \u2693 Gears: generalized workflow Gears , What are these? \u2693 VidGear is built on Standalone APIs - also known as Gears , each with some unique functionality. Each Gears is designed exclusively to handle/control/process different data-specific & device-specific video streams, network streams, and media encoders/decoders. Gears allows users to work with an inherently optimized, easy-to-use, extensible, and exposed API Framework on top of many state-of-the-art libraries, while silently delivering robust error handling and unmatched real-time performance. Gears Classification \u2693 These Gears can be classified as follows: A. VideoCapture Gears \u2693 Basic Function: Retrieves numpy.ndarray frames from various sources. CamGear : Multi-Threaded API targeting various IP-USB-Cameras/Network-Streams/Streaming-Sites-URLs. PiGear : Multi-Threaded API targeting various Raspberry-Pi Camera Modules. ScreenGear : Multi-Threaded API targeting ultra-fast Screencasting. VideoGear : Common Video-Capture API with internal Video Stabilizer wrapper. B. VideoWriter Gears \u2693 Basic Function: Writes numpy.ndarray frames to a video file or network stream. WriteGear : Handles Lossless Video-Writer for file/stream/frames Encoding and Compression. C. Streaming Gears \u2693 Basic Function: Transcodes/Broadcasts files and numpy.ndarray frames for streaming. You can also use WriteGear for streaming with traditional protocols such as RTMP, RTSP/RTP. StreamGear : Handles Transcoding of High-Quality, Dynamic & Adaptive Streaming Formats. Asynchronous I/O Streaming Gear: WebGear : ASGI Video-Server that broadcasts Live MJPEG-Frames to any web-browser on the network. WebGear_RTC : Real-time Asyncio WebRTC media server for streaming directly to peer clients over the network. D. Network Gears \u2693 Basic Function: Sends/Receives data and numpy.ndarray frames over connected networks. NetGear : Handles High-Performance Video-Frames & Data Transfer between interconnecting systems over the network. Asynchronous I/O Network Gear: NetGear_Async : Immensely Memory-Efficient Asyncio Video-Frames Network Messaging Framework.","title":"Introduction"},{"location":"gears/#introduction","text":"Gears: generalized workflow","title":"Introduction"},{"location":"gears/#gears-what-are-these","text":"VidGear is built on Standalone APIs - also known as Gears , each with some unique functionality. Each Gears is designed exclusively to handle/control/process different data-specific & device-specific video streams, network streams, and media encoders/decoders. Gears allows users to work with an inherently optimized, easy-to-use, extensible, and exposed API Framework on top of many state-of-the-art libraries, while silently delivering robust error handling and unmatched real-time performance.","title":"Gears , What are these?"},{"location":"gears/#gears-classification","text":"These Gears can be classified as follows:","title":"Gears Classification"},{"location":"gears/#a-videocapture-gears","text":"Basic Function: Retrieves numpy.ndarray frames from various sources. CamGear : Multi-Threaded API targeting various IP-USB-Cameras/Network-Streams/Streaming-Sites-URLs. PiGear : Multi-Threaded API targeting various Raspberry-Pi Camera Modules. ScreenGear : Multi-Threaded API targeting ultra-fast Screencasting. VideoGear : Common Video-Capture API with internal Video Stabilizer wrapper.","title":"A. VideoCapture Gears"},{"location":"gears/#b-videowriter-gears","text":"Basic Function: Writes numpy.ndarray frames to a video file or network stream. WriteGear : Handles Lossless Video-Writer for file/stream/frames Encoding and Compression.","title":"B. VideoWriter Gears"},{"location":"gears/#c-streaming-gears","text":"Basic Function: Transcodes/Broadcasts files and numpy.ndarray frames for streaming. You can also use WriteGear for streaming with traditional protocols such as RTMP, RTSP/RTP. StreamGear : Handles Transcoding of High-Quality, Dynamic & Adaptive Streaming Formats. Asynchronous I/O Streaming Gear: WebGear : ASGI Video-Server that broadcasts Live MJPEG-Frames to any web-browser on the network. WebGear_RTC : Real-time Asyncio WebRTC media server for streaming directly to peer clients over the network.","title":"C. Streaming Gears"},{"location":"gears/#d-network-gears","text":"Basic Function: Sends/Receives data and numpy.ndarray frames over connected networks. NetGear : Handles High-Performance Video-Frames & Data Transfer between interconnecting systems over the network. Asynchronous I/O Network Gear: NetGear_Async : Immensely Memory-Efficient Asyncio Video-Frames Network Messaging Framework.","title":"D. Network Gears"},{"location":"help/","text":"Helping VidGear \u2693 Liked VidGear? Would you like to help VidGear, other users, and the author? There are very simple ways to help us: Star VidGear on GitHub \u2693 You can star VidGear on GitHub: It helps us a lot by making it easier for others to find & trust this library. Thanks! Help others with issues on GitHub \u2693 You can see through any opened or pinned existing issues on our GitHub repository, and try helping others, wherever possible: Watch the GitHub repository \u2693 You can watch \ud83d\udc40 VidGear Activities on GitHub: When you watch a repository, you will be notified of all conversations for that repository, including when someone creates a new issue, or pushes a new pull request. You can try helping solving those issues, or give valuable feedback/review on new Pull Requests. Tweet about VidGear \u2693 Tweet about VidGear and Spread the word \ud83d\udde3: Tweet #vidgear Let others know how you are using VidGear and why you like it! Helping Author \u2693 Donations help keep VidGear's development alive and motivate me (as author) . It is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); Thanks a million! Connect with Author \u2693 You can connect with me, the author \ud83d\udc4b: Follow author on GitHub: Follow author on Twitter: Follow @abhi_una12 Get in touch with author on Linkedin:","title":"Helping VidGear"},{"location":"help/#helping-vidgear","text":"Liked VidGear? Would you like to help VidGear, other users, and the author? There are very simple ways to help us:","title":"Helping VidGear"},{"location":"help/#star-vidgear-on-github","text":"You can star VidGear on GitHub: It helps us a lot by making it easier for others to find & trust this library. Thanks!","title":" Star VidGear on GitHub"},{"location":"help/#help-others-with-issues-on-github","text":"You can see through any opened or pinned existing issues on our GitHub repository, and try helping others, wherever possible:","title":" Help others with issues on GitHub"},{"location":"help/#watch-the-github-repository","text":"You can watch \ud83d\udc40 VidGear Activities on GitHub: When you watch a repository, you will be notified of all conversations for that repository, including when someone creates a new issue, or pushes a new pull request. You can try helping solving those issues, or give valuable feedback/review on new Pull Requests.","title":" Watch the GitHub repository"},{"location":"help/#tweet-about-vidgear","text":"Tweet about VidGear and Spread the word \ud83d\udde3: Tweet #vidgear Let others know how you are using VidGear and why you like it!","title":" Tweet about VidGear"},{"location":"help/#helping-author","text":"Donations help keep VidGear's development alive and motivate me (as author) . It is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); Thanks a million!","title":" Helping Author"},{"location":"help/#connect-with-author","text":"You can connect with me, the author \ud83d\udc4b: Follow author on GitHub: Follow author on Twitter: Follow @abhi_una12 Get in touch with author on Linkedin:","title":" Connect with Author"},{"location":"installation/","text":"Installation Overview \u2693 Supported Systems \u2693 VidGear is well-tested and supported on the following systems(but not limited to), with python 3.7+ and pip installed: Any Linux distro released in 2016 or later Windows 7 or later MacOS 10.12.6 (Sierra) or later \u2009 Supported Python legacies \u2693 Depreciation Notice Python-3.6 legacies support has been dropped from Vidgear. Python 3.7+ are only supported legacies for installing Vidgear v0.2.5 and above. \u2009 Installation methods \u2693 Install using pip (recommended) Install from source","title":"Installation Overview"},{"location":"installation/#installation-overview","text":"","title":"Installation Overview"},{"location":"installation/#supported-systems","text":"VidGear is well-tested and supported on the following systems(but not limited to), with python 3.7+ and pip installed: Any Linux distro released in 2016 or later Windows 7 or later MacOS 10.12.6 (Sierra) or later","title":"Supported Systems"},{"location":"installation/#supported-python-legacies","text":"Depreciation Notice Python-3.6 legacies support has been dropped from Vidgear. Python 3.7+ are only supported legacies for installing Vidgear v0.2.5 and above.","title":"Supported Python legacies"},{"location":"installation/#installation-methods","text":"Install using pip (recommended) Install from source","title":"Installation methods"},{"location":"license/","text":"License \u2693 This library is released under the Apache 2.0 License . Copyright Notice \u2693 Copyright (c) 2019 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com> Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"license/#license","text":"This library is released under the Apache 2.0 License .","title":"License"},{"location":"license/#copyright-notice","text":"Copyright (c) 2019 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com> Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"Copyright Notice"},{"location":"switch_from_cv/","text":"Switching from OpenCV Library \u2693 Switching OpenCV with VidGear APIs is fairly painless process, and will just require changing a few lines in your python script. This document is intended to software developers who want to migrate their python code from OpenCV Library to VidGear APIs. Prior knowledge of Python or OpenCV won't be covered in this guide. Proficiency with OpenCV-Python (Python API for OpenCV) is a must in order understand this document. If you're just getting started with OpenCV-Python programming, then refer this FAQ \u27b6 Why VidGear is better than OpenCV? \u2693 Learn more about OpenCV here \u27b6 VidGear employs OpenCV at its backend and enhances its existing capabilities even further by introducing many new state-of-the-art functionalities such as: Accelerated Multi-Threaded Performance. Out-of-the-box support for OpenCV APIs. Real-time Stabilization ready. Lossless hardware enabled video encoding and transcoding . Inherited multi-backend support for various video sources and devices. Screen-casting, Multi-bitrate network-streaming, and way much more \u27b6 Vidgear offers all this at once while maintaining the same standard OpenCV-Python (Python API for OpenCV) coding syntax for all of its APIs, thereby making it even easier to implement complex real-time OpenCV applications in python code without changing things much. Switching the VideoCapture APIs \u2693 Let's compare a bare-minimum python code for extracting frames out of any Webcam/USB-camera (connected at index 0) , between OpenCV's VideoCapture Class and VidGear's CamGear VideoCapture API side-by-side: CamGear API share the same syntax as other VideoCapture APIs , thereby you can easily switch to any of those APIs in a similar manner. OpenCV VideoCapture Class VidGear's CamGear API # import required libraries import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # import required libraries from vidgear.gears import CamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () and both syntax almost looks the same, easy, isn't it? \u2009 Differences \u2693 Let's breakdown a few noteworthy difference in both syntaxes: Task OpenCV VideoCapture Class VidGear's CamGear API Initiating stream = cv2 . VideoCapture ( 0 ) stream = CamGear ( source = 0 ) . start () Reading frames ( grabbed , frame ) = stream . read () frame = stream . read () Checking empty frame if not grabbed : if frame is None : Terminating stream . release () stream . stop () Now checkout other VideoCapture Gears \u27b6 Switching the VideoWriter API \u2693 Let's extend previous bare-minimum python code and save those extracted frames to disk as a valid file, with OpenCV's VideoWriter Class and VidGear's WriteGear (with FFmpeg backend) , compared side-to-side: WriteGear API also provides backend for OpenCV's VideoWriter Class. More information here \u27b6 OpenCV VideoWriter Class VidGear's WriteGear API # import required libraries import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define the codec and create VideoWriter object with suitable output filename for e.g. `Output.avi` fourcc = cv2 . VideoWriter_fourcc ( * 'XVID' ) writer = cv2 . VideoWriter ( 'output.avi' , fourcc , 20.0 , ( 640 , 480 )) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . release () # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # Define WriteGear Object with suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Noticed WriteGear's coding syntax looks similar but less complex? \u2009 Differences \u2693 Let's breakdown a few noteworthy difference in both syntaxes: Task OpenCV VideoWriter Class VidGear's WriteGear API Initiating writer = cv2 . VideoWriter ( 'output.avi' , cv2 . VideoWriter_fourcc ( * 'XVID' ), 20.0 , ( 640 , 480 )) writer = WriteGear ( output_filename = 'Output.mp4' ) Writing frames writer . write ( frame ) writer . write ( frame ) Terminating writer . release () writer . close () Now checkout more about WriteGear API here \u27b6","title":"Switching from OpenCV"},{"location":"switch_from_cv/#switching-from-opencv-library","text":"Switching OpenCV with VidGear APIs is fairly painless process, and will just require changing a few lines in your python script. This document is intended to software developers who want to migrate their python code from OpenCV Library to VidGear APIs. Prior knowledge of Python or OpenCV won't be covered in this guide. Proficiency with OpenCV-Python (Python API for OpenCV) is a must in order understand this document. If you're just getting started with OpenCV-Python programming, then refer this FAQ \u27b6","title":"Switching from OpenCV Library"},{"location":"switch_from_cv/#why-vidgear-is-better-than-opencv","text":"Learn more about OpenCV here \u27b6 VidGear employs OpenCV at its backend and enhances its existing capabilities even further by introducing many new state-of-the-art functionalities such as: Accelerated Multi-Threaded Performance. Out-of-the-box support for OpenCV APIs. Real-time Stabilization ready. Lossless hardware enabled video encoding and transcoding . Inherited multi-backend support for various video sources and devices. Screen-casting, Multi-bitrate network-streaming, and way much more \u27b6 Vidgear offers all this at once while maintaining the same standard OpenCV-Python (Python API for OpenCV) coding syntax for all of its APIs, thereby making it even easier to implement complex real-time OpenCV applications in python code without changing things much.","title":"Why VidGear is better than OpenCV?"},{"location":"switch_from_cv/#switching-the-videocapture-apis","text":"Let's compare a bare-minimum python code for extracting frames out of any Webcam/USB-camera (connected at index 0) , between OpenCV's VideoCapture Class and VidGear's CamGear VideoCapture API side-by-side: CamGear API share the same syntax as other VideoCapture APIs , thereby you can easily switch to any of those APIs in a similar manner. OpenCV VideoCapture Class VidGear's CamGear API # import required libraries import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # import required libraries from vidgear.gears import CamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () and both syntax almost looks the same, easy, isn't it?","title":"Switching the VideoCapture APIs"},{"location":"switch_from_cv/#differences","text":"Let's breakdown a few noteworthy difference in both syntaxes: Task OpenCV VideoCapture Class VidGear's CamGear API Initiating stream = cv2 . VideoCapture ( 0 ) stream = CamGear ( source = 0 ) . start () Reading frames ( grabbed , frame ) = stream . read () frame = stream . read () Checking empty frame if not grabbed : if frame is None : Terminating stream . release () stream . stop () Now checkout other VideoCapture Gears \u27b6","title":"Differences"},{"location":"switch_from_cv/#switching-the-videowriter-api","text":"Let's extend previous bare-minimum python code and save those extracted frames to disk as a valid file, with OpenCV's VideoWriter Class and VidGear's WriteGear (with FFmpeg backend) , compared side-to-side: WriteGear API also provides backend for OpenCV's VideoWriter Class. More information here \u27b6 OpenCV VideoWriter Class VidGear's WriteGear API # import required libraries import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define the codec and create VideoWriter object with suitable output filename for e.g. `Output.avi` fourcc = cv2 . VideoWriter_fourcc ( * 'XVID' ) writer = cv2 . VideoWriter ( 'output.avi' , fourcc , 20.0 , ( 640 , 480 )) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . release () # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # Define WriteGear Object with suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Noticed WriteGear's coding syntax looks similar but less complex?","title":"Switching the VideoWriter API"},{"location":"switch_from_cv/#differences_1","text":"Let's breakdown a few noteworthy difference in both syntaxes: Task OpenCV VideoWriter Class VidGear's WriteGear API Initiating writer = cv2 . VideoWriter ( 'output.avi' , cv2 . VideoWriter_fourcc ( * 'XVID' ), 20.0 , ( 640 , 480 )) writer = WriteGear ( output_filename = 'Output.mp4' ) Writing frames writer . write ( frame ) writer . write ( frame ) Terminating writer . release () writer . close () Now checkout more about WriteGear API here \u27b6","title":"Differences"},{"location":"bonus/TQM/","text":"Threaded Queue Mode \u2693 Overview \u2693 Threaded-Queue-Mode: generalized timing diagram Threaded Queue Mode is designed exclusively for VidGear's Videocapture Gears (namely CamGear, ScreenGear, VideoGear) and few Network Gears (such as NetGear(Client's end)) for achieving high-performance, asynchronous, error-free video-frames handling. Threaded-Queue-Mode is enabled by default, but can be disabled , only if extremely necessary. Threaded-Queue-Mode is NOT required and thereby automatically disabled for Live feed such as Camera Devices/Modules, since . What does Threaded-Queue-Mode exactly do? \u2693 Threaded-Queue-Mode helps VidGear do the Threaded Video-Processing tasks in highly optimized, well-organized, and most competent way possible: A. Enables Multi-Threading \u2693 In case you don't already know, OpenCV's' read() is a Blocking I/O function for reading and decoding the next video-frame, and consumes much of the I/O bound memory depending upon our video source properties & system hardware. This essentially means, the corresponding thread that reads data from it, is continuously blocked from retrieving the next frame. As a result, our python program appears slow and sluggish even without any type of computationally expensive image processing operations. This problem is far more severe on low memory SBCs like Raspberry Pis. In Threaded-Queue-Mode, VidGear creates several Python Threads within one process to offload the frame-decoding task to a different thread. Thereby, VidGear is able to execute different Video I/O-bounded operations at the same time by overlapping there waiting times. Moreover, threads are managed by operating system itself and is capable of distributing them between available CPU cores efficiently. In this way, Threaded-Queue-Mode keeps on processing frames faster in the background without affecting by sluggishness in our main python program thread. B. Utilizes Fixed-Size Queues \u2693 Although Multi-threading is fast, easy, and efficient, it can lead to some serious undesired effects like frame-skipping, Global Interpreter Lock , race conditions, etc. This is because there is no isolation whatsoever in python threads, and in case there is any crash it will cause the whole process to crash. That's not all, the memory of the process is shared by different threads and that may result in random process crashes due to unwanted race conditions. These problems are avoided in Threaded-Queue-Mode by utilizing Thread-Safe, Memory-Efficient, and Fixed-Size Queues (with approximately same O(1) performance in both directions) , that isolates the frame-decoding thread from other parallel threads and provide synchronized access to incoming frames without any obstruction. C. Accelerates Frame Processing \u2693 With queues, VidGear always maintains a fixed-length frames buffer in the memory and blocks the thread temporarily if the queue is full to avoid possible frame drops or otherwise pops out the frames synchronously without any obstructions. This significantly accelerates frame processing rate (and therefore our overall video processing pipeline) comes from dramatically reducing latency \u2014 since we don\u2019t have to wait for the read() method to finish reading and decoding a frame; instead, there is always a pre-decoded frame ready for us to process. What are the advantages of Threaded-Queue-Mode? \u2693 Enables Blocking, Sequential and Threaded LIFO Frame Handling. Sequentially adds and releases frames from queues and handles the overflow. Utilizes thread-safe, memory efficient queues that appends and pops frames with same O(1) performance from either side. Faster frame access due to buffered frames in the queue . Provides isolation for source thread and prevents GIL. Manually disabling Threaded-Queue-Mode \u2693 To manually disable Threaded-Queue-Mode, VidGear provides THREADED_QUEUE_MODE boolean attribute for options dictionary parameter in respective VideoCapture APIs : Important Warnings Disabling Threaded-Queue-Mode does NOT disables Multi-Threading. THREADED_QUEUE_MODE attribute does NOT work with Live feed, such as Camera Devices/Modules. THREADED_QUEUE_MODE attribute is NOT supported by ScreenGear & NetGear APIs, as Threaded Queue Mode is essential for their core operations. Disabling Threaded-Queue-Mode may lead to Random Intermittent Bugs that can be quite difficult to discover. More insight can be found here \u27b6 THREADED_QUEUE_MODE (boolean) : This attribute can be used to override Threaded-Queue-Mode mode to manually disable it: options = { 'THREADED_QUEUE_MODE' : False } # to disable Threaded Queue Mode. and you can pass it to options dictionary parameter of the respective API.","title":"Threaded Queue Mode"},{"location":"bonus/TQM/#threaded-queue-mode","text":"","title":"Threaded Queue Mode"},{"location":"bonus/TQM/#overview","text":"Threaded-Queue-Mode: generalized timing diagram Threaded Queue Mode is designed exclusively for VidGear's Videocapture Gears (namely CamGear, ScreenGear, VideoGear) and few Network Gears (such as NetGear(Client's end)) for achieving high-performance, asynchronous, error-free video-frames handling. Threaded-Queue-Mode is enabled by default, but can be disabled , only if extremely necessary. Threaded-Queue-Mode is NOT required and thereby automatically disabled for Live feed such as Camera Devices/Modules, since .","title":"Overview"},{"location":"bonus/TQM/#what-does-threaded-queue-mode-exactly-do","text":"Threaded-Queue-Mode helps VidGear do the Threaded Video-Processing tasks in highly optimized, well-organized, and most competent way possible:","title":"What does Threaded-Queue-Mode exactly do?"},{"location":"bonus/TQM/#a-enables-multi-threading","text":"In case you don't already know, OpenCV's' read() is a Blocking I/O function for reading and decoding the next video-frame, and consumes much of the I/O bound memory depending upon our video source properties & system hardware. This essentially means, the corresponding thread that reads data from it, is continuously blocked from retrieving the next frame. As a result, our python program appears slow and sluggish even without any type of computationally expensive image processing operations. This problem is far more severe on low memory SBCs like Raspberry Pis. In Threaded-Queue-Mode, VidGear creates several Python Threads within one process to offload the frame-decoding task to a different thread. Thereby, VidGear is able to execute different Video I/O-bounded operations at the same time by overlapping there waiting times. Moreover, threads are managed by operating system itself and is capable of distributing them between available CPU cores efficiently. In this way, Threaded-Queue-Mode keeps on processing frames faster in the background without affecting by sluggishness in our main python program thread.","title":"A. Enables Multi-Threading"},{"location":"bonus/TQM/#b-utilizes-fixed-size-queues","text":"Although Multi-threading is fast, easy, and efficient, it can lead to some serious undesired effects like frame-skipping, Global Interpreter Lock , race conditions, etc. This is because there is no isolation whatsoever in python threads, and in case there is any crash it will cause the whole process to crash. That's not all, the memory of the process is shared by different threads and that may result in random process crashes due to unwanted race conditions. These problems are avoided in Threaded-Queue-Mode by utilizing Thread-Safe, Memory-Efficient, and Fixed-Size Queues (with approximately same O(1) performance in both directions) , that isolates the frame-decoding thread from other parallel threads and provide synchronized access to incoming frames without any obstruction.","title":"B. Utilizes Fixed-Size Queues"},{"location":"bonus/TQM/#c-accelerates-frame-processing","text":"With queues, VidGear always maintains a fixed-length frames buffer in the memory and blocks the thread temporarily if the queue is full to avoid possible frame drops or otherwise pops out the frames synchronously without any obstructions. This significantly accelerates frame processing rate (and therefore our overall video processing pipeline) comes from dramatically reducing latency \u2014 since we don\u2019t have to wait for the read() method to finish reading and decoding a frame; instead, there is always a pre-decoded frame ready for us to process.","title":"C. Accelerates Frame Processing"},{"location":"bonus/TQM/#what-are-the-advantages-of-threaded-queue-mode","text":"Enables Blocking, Sequential and Threaded LIFO Frame Handling. Sequentially adds and releases frames from queues and handles the overflow. Utilizes thread-safe, memory efficient queues that appends and pops frames with same O(1) performance from either side. Faster frame access due to buffered frames in the queue . Provides isolation for source thread and prevents GIL.","title":"What are the advantages of Threaded-Queue-Mode?"},{"location":"bonus/TQM/#manually-disabling-threaded-queue-mode","text":"To manually disable Threaded-Queue-Mode, VidGear provides THREADED_QUEUE_MODE boolean attribute for options dictionary parameter in respective VideoCapture APIs : Important Warnings Disabling Threaded-Queue-Mode does NOT disables Multi-Threading. THREADED_QUEUE_MODE attribute does NOT work with Live feed, such as Camera Devices/Modules. THREADED_QUEUE_MODE attribute is NOT supported by ScreenGear & NetGear APIs, as Threaded Queue Mode is essential for their core operations. Disabling Threaded-Queue-Mode may lead to Random Intermittent Bugs that can be quite difficult to discover. More insight can be found here \u27b6 THREADED_QUEUE_MODE (boolean) : This attribute can be used to override Threaded-Queue-Mode mode to manually disable it: options = { 'THREADED_QUEUE_MODE' : False } # to disable Threaded Queue Mode. and you can pass it to options dictionary parameter of the respective API.","title":"Manually disabling Threaded-Queue-Mode"},{"location":"bonus/colorspace_manipulation/","text":"Colorspace Manipulation for VideoCapture Gears \u2693 Source ColorSpace manipulation \u2693 All VidGear's Videocapture Gears (namely CamGear, ScreenGear, VideoGear) and some Streaming Gears (namely WebGear, WebGear_RTC) and Network Gears (Client's end) - provides exclusive internal support for Source Color Space manipulation . There are two ways to alter source colorspace: Using colorspace parameter \u2693 Primarily, the safest way is by colorspace (string) parameter of the respective VideoCapture API, that can be used to easily alter the colorspace of the input source, during initialization. But on the downside, colorspace parameter value CANNOT be changed/altered at runtime. All possible values for this parameter are discussed below \u27b6 Using color_space global variable \u2693 Alternatively, a more direct approach is by using color_space (integer) global variable the respective VideoCapture API, can be used for directly changing the source colorspace at runtime. It can be used in conjunction with colorspace parameter easily. Supported Colorspace Conversions Any conversion from default Source colorspace (i.e. BGR in case of OpenCV) , to any other colorspace and vice-versa (use None to revert) , is supported. Important Information Using color_space global variable is NOT Supported in VideoGear API, calling it will result in AttribueError . Any incorrect or None-type value, will immediately revert the colorspace to default (i.e. BGR ) . Using color_space global variable with Threaded Queue Mode may have minor lag, User discretion is advised. Tip It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. Supported colorspace parameter values \u2693 All supported string values for colorspace parameter are as follows: You can check all OpenCV Colorspace Conversion Codes here \u27b6 . Supported Conversion Values Description COLOR_BGR2BGRA BGR to BGRA COLOR_BGR2RGBA BGR to RGBA COLOR_BGR2RGB BGR to RGB backward conversions to RGB/BGR COLOR_BGR2GRAY BGR to GRAY COLOR_BGR2BGR565 BGR to BGR565 COLOR_BGR2BGR555 BGR to BGR555 COLOR_BGR2XYZ BGR to CIE XYZ COLOR_BGR2YCrCb BGR to luma-chroma (aka YCC) COLOR_BGR2HSV BGR to HSV (hue saturation value) COLOR_BGR2Lab BGR to CIE Lab COLOR_BGR2Luv BGR to CIE Luv COLOR_BGR2HLS BGR to HLS (hue lightness saturation) COLOR_BGR2HSV_FULL BGR to HSV_FULL COLOR_BGR2HLS_FULL BGR to HLS_FULL COLOR_BGR2YUV BGR to YUV COLOR_BGR2YUV_I420 BGR to YUV 4:2:0 family COLOR_BGR2YUV_IYUV BGR to IYUV COLOR_BGR2YUV_YV12 BGR to YUV_YV12 None Back to default colorspace (i.e. BGR) Usage examples \u2693 Using CamGear with Direct Colorspace Manipulation \u2693 The complete usage example can be found here \u27b6 Using PiGear with Direct Colorspace Manipulation \u2693 The complete usage example can be found here \u27b6 Using VideoGear with Colorspace Manipulation \u2693 The complete usage example can be found here \u27b6 Using ScreenGear with Direct Colorspace Manipulation \u2693 The complete usage example can be found here \u27b6","title":"Colorspace Manipulation"},{"location":"bonus/colorspace_manipulation/#colorspace-manipulation-for-videocapture-gears","text":"","title":"Colorspace Manipulation for VideoCapture Gears"},{"location":"bonus/colorspace_manipulation/#source-colorspace-manipulation","text":"All VidGear's Videocapture Gears (namely CamGear, ScreenGear, VideoGear) and some Streaming Gears (namely WebGear, WebGear_RTC) and Network Gears (Client's end) - provides exclusive internal support for Source Color Space manipulation . There are two ways to alter source colorspace:","title":"Source ColorSpace manipulation"},{"location":"bonus/colorspace_manipulation/#using-colorspace-parameter","text":"Primarily, the safest way is by colorspace (string) parameter of the respective VideoCapture API, that can be used to easily alter the colorspace of the input source, during initialization. But on the downside, colorspace parameter value CANNOT be changed/altered at runtime. All possible values for this parameter are discussed below \u27b6","title":"Using colorspace parameter"},{"location":"bonus/colorspace_manipulation/#using-color_space-global-variable","text":"Alternatively, a more direct approach is by using color_space (integer) global variable the respective VideoCapture API, can be used for directly changing the source colorspace at runtime. It can be used in conjunction with colorspace parameter easily. Supported Colorspace Conversions Any conversion from default Source colorspace (i.e. BGR in case of OpenCV) , to any other colorspace and vice-versa (use None to revert) , is supported. Important Information Using color_space global variable is NOT Supported in VideoGear API, calling it will result in AttribueError . Any incorrect or None-type value, will immediately revert the colorspace to default (i.e. BGR ) . Using color_space global variable with Threaded Queue Mode may have minor lag, User discretion is advised. Tip It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Using color_space global variable"},{"location":"bonus/colorspace_manipulation/#supported-colorspace-parameter-values","text":"All supported string values for colorspace parameter are as follows: You can check all OpenCV Colorspace Conversion Codes here \u27b6 . Supported Conversion Values Description COLOR_BGR2BGRA BGR to BGRA COLOR_BGR2RGBA BGR to RGBA COLOR_BGR2RGB BGR to RGB backward conversions to RGB/BGR COLOR_BGR2GRAY BGR to GRAY COLOR_BGR2BGR565 BGR to BGR565 COLOR_BGR2BGR555 BGR to BGR555 COLOR_BGR2XYZ BGR to CIE XYZ COLOR_BGR2YCrCb BGR to luma-chroma (aka YCC) COLOR_BGR2HSV BGR to HSV (hue saturation value) COLOR_BGR2Lab BGR to CIE Lab COLOR_BGR2Luv BGR to CIE Luv COLOR_BGR2HLS BGR to HLS (hue lightness saturation) COLOR_BGR2HSV_FULL BGR to HSV_FULL COLOR_BGR2HLS_FULL BGR to HLS_FULL COLOR_BGR2YUV BGR to YUV COLOR_BGR2YUV_I420 BGR to YUV 4:2:0 family COLOR_BGR2YUV_IYUV BGR to IYUV COLOR_BGR2YUV_YV12 BGR to YUV_YV12 None Back to default colorspace (i.e. BGR)","title":"Supported colorspace parameter values"},{"location":"bonus/colorspace_manipulation/#usage-examples","text":"","title":"Usage examples"},{"location":"bonus/colorspace_manipulation/#using-camgear-with-direct-colorspace-manipulation","text":"The complete usage example can be found here \u27b6","title":"Using CamGear with Direct Colorspace Manipulation"},{"location":"bonus/colorspace_manipulation/#using-pigear-with-direct-colorspace-manipulation","text":"The complete usage example can be found here \u27b6","title":"Using PiGear with Direct Colorspace Manipulation"},{"location":"bonus/colorspace_manipulation/#using-videogear-with-colorspace-manipulation","text":"The complete usage example can be found here \u27b6","title":"Using VideoGear with Colorspace Manipulation"},{"location":"bonus/colorspace_manipulation/#using-screengear-with-direct-colorspace-manipulation","text":"The complete usage example can be found here \u27b6","title":"Using ScreenGear with Direct Colorspace Manipulation"},{"location":"bonus/reference/camgear/","text":"CamGear API usage examples can be found here \u27b6 CamGear API parameters are explained here \u27b6 CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format (upto 4k tested), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. It also supports Gstreamer's RAW pipelines. CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture API with direct access to almost all of its available parameters. It relies on Threaded Queue mode for threaded, error-free and synchronized frame handling. CamGear internally implements yt_dlp backend class for seamlessly pipelining live video-frames and metadata from various streaming services like YouTube, Dailymotion, Twitch, and many more \u27b6 Source code in vidgear/gears/camgear.py class CamGear : \"\"\" CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format (upto 4k tested), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. It also supports Gstreamer's RAW pipelines. CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture API with direct access to almost all of its available parameters. It relies on Threaded Queue mode for threaded, error-free and synchronized frame handling. CamGear internally implements `yt_dlp` backend class for seamlessly pipelining live video-frames and metadata from various streaming services like YouTube, Dailymotion, Twitch, and [many more \u27b6](https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md#supported-sites) \"\"\" def __init__ ( self , source = 0 , stream_mode = False , backend = 0 , colorspace = None , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the CamGear class. Parameters: source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive **Stream Mode** for handling streaming URLs. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Source Tweak Parameters. \"\"\" # enable logging if specified self . __logging = False if logging : self . __logging = logging # initialize global self . ytv_metadata = {} # check if Stream-Mode is ON (True) if stream_mode : # check GStreamer backend support gst_support = check_gstreamer_support ( logging = logging ) # handle special Stream Mode parameters stream_resolution = get_supported_resolution ( options . pop ( \"STREAM_RESOLUTION\" , \"best\" ), logging = logging ) # handle Stream-Mode if not ( yt_dlp is None ): # extract user-defined params yt_stream_params = options . pop ( \"STREAM_PARAMS\" , {}) if isinstance ( yt_stream_params , dict ): yt_stream_params = { str ( k ) . strip (): v for k , v in yt_stream_params . items () } else : yt_stream_params = {} try : # Validate source for Yt_dlp backend logger . info ( \"Verifying Streaming URL using yt-dlp backend. Please wait...\" ) # initialize YT_backend ytbackend = YT_backend ( source_url = source , logging = logging , ** yt_stream_params ) if ytbackend : # save video metadata self . ytv_metadata = ytbackend . meta_data # handle live-streams if ytbackend . is_livestream : # Throw warning for livestreams logger . warning ( \"Livestream URL detected. It is advised to use GStreamer backend(`cv2.CAP_GSTREAMER`) with it.\" ) # check whether stream-resolution was specified and available if not ( stream_resolution in ytbackend . streams . keys ()): logger . warning ( \"Specified stream-resolution ` {} ` is not available. Reverting to `best`!\" . format ( stream_resolution ) ) # revert to best stream_resolution = \"best\" else : if self . __logging : logger . debug ( \"Using ` {} ` resolution for streaming.\" . format ( stream_resolution ) ) # extract stream URL as source using stream-resolution source = ytbackend . streams [ stream_resolution ] # log progress self . __logging and logger . debug ( \"YouTube source ID: ` {} `, Title: ` {} `, Quality: ` {} `\" . format ( self . ytv_metadata [ \"id\" ], self . ytv_metadata [ \"title\" ], stream_resolution , ) ) except Exception as e : # raise error if something went wrong raise ValueError ( \"[CamGear:ERROR] :: Stream Mode is enabled but Input URL is invalid!\" ) else : # raise import errors import_dependency_safe ( \"yt_dlp\" ) # youtube mode variable initialization self . __youtube_mode = stream_mode # assigns special parameter to global variable and clear # Threaded Queue Mode self . __threaded_queue_mode = options . pop ( \"THREADED_QUEUE_MODE\" , True ) if not isinstance ( self . __threaded_queue_mode , bool ): # reset improper values self . __threaded_queue_mode = True # Thread Timeout self . __thread_timeout = options . pop ( \"THREAD_TIMEOUT\" , None ) if self . __thread_timeout and isinstance ( self . __thread_timeout , ( int , float )): # set values self . __thread_timeout = float ( self . __thread_timeout ) else : # defaults to 5mins timeout self . __thread_timeout = None self . __queue = None # initialize queue for video files only if self . __threaded_queue_mode and isinstance ( source , str ): # define queue and assign it to global var self . __queue = queue . Queue ( maxsize = 96 ) # max bufferlen 96 to check overflow # log it self . __logging and logger . debug ( \"Enabling Threaded Queue Mode for the current video source!\" ) else : # otherwise disable it self . __threaded_queue_mode = False # log it self . __logging and logger . warning ( \"Threaded Queue Mode is disabled for the current video source!\" ) if self . __thread_timeout : logger . debug ( \"Setting Video-Thread Timeout to {} s.\" . format ( self . __thread_timeout ) ) # stream variable initialization self . stream = None if backend and isinstance ( backend , int ): # add backend if specified and initialize the camera stream if check_CV_version () == 3 : # Different OpenCV 3.4.x statement self . stream = cv2 . VideoCapture ( source + backend ) else : # Two parameters are available since OpenCV 4+ (master branch) self . stream = cv2 . VideoCapture ( source , backend ) logger . debug ( \"Setting backend ` {} ` for this source.\" . format ( backend )) else : # initialize the camera stream self . stream = cv2 . VideoCapture ( source ) # initializing colorspace variable self . color_space = None # apply attributes to source if specified options = { str ( k ) . strip (): v for k , v in options . items ()} for key , value in options . items (): property = capPropId ( key ) if not ( property is None ): self . stream . set ( property , value ) # handle colorspace value if not ( colorspace is None ): self . color_space = capPropId ( colorspace . strip ()) if self . __logging and not ( self . color_space is None ): logger . debug ( \"Enabling ` {} ` colorspace for this video stream!\" . format ( colorspace . strip () ) ) # initialize and assign frame-rate variable self . framerate = 0.0 _fps = self . stream . get ( cv2 . CAP_PROP_FPS ) if _fps > 1.0 : self . framerate = _fps # applying time delay to warm-up webcam only if specified if time_delay and isinstance ( time_delay , ( int , float )): time . sleep ( time_delay ) # frame variable initialization ( grabbed , self . frame ) = self . stream . read () # check if valid stream if grabbed : # render colorspace if defined if not ( self . color_space is None ): self . frame = cv2 . cvtColor ( self . frame , self . color_space ) if self . __threaded_queue_mode : # initialize and append to queue self . __queue . put ( self . frame ) else : raise RuntimeError ( \"[CamGear:ERROR] :: Source is invalid, CamGear failed to initialize stream on this source!\" ) # thread initialization self . __thread = None # initialize termination flag event self . __terminate = Event () # initialize stream read flag event self . __stream_read = Event () def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon. **Returns:** A reference to the CamGear class object. \"\"\" self . __thread = Thread ( target = self . __update , name = \"CamGear\" , args = ()) self . __thread . daemon = True self . __thread . start () return self def __update ( self ): \"\"\" A **Threaded Frames Extractor**, that keep iterating frames from OpenCV's VideoCapture API to a internal monitored queue, until the thread is terminated, or frames runs out. \"\"\" # keep iterating infinitely # until the thread is terminated # or frames runs out while True : # if the thread indicator variable is set, stop the thread if self . __terminate . is_set (): break # stream not read yet self . __stream_read . clear () # otherwise, read the next frame from the stream ( grabbed , frame ) = self . stream . read () # stream read completed self . __stream_read . set () # check for valid frame if received if not grabbed : # no frames received, then safely exit if self . __threaded_queue_mode : if self . __queue . empty (): break else : continue else : break # apply colorspace to frames if valid if not ( self . color_space is None ): color_frame = None try : if isinstance ( self . color_space , int ): color_frame = cv2 . cvtColor ( frame , self . color_space ) else : raise ValueError ( \"Global color_space parameter value ` {} ` is not a valid!\" . format ( self . color_space ) ) except Exception as e : # Catch if any error occurred self . color_space = None if self . __logging : logger . exception ( str ( e )) logger . warning ( \"Input colorspace is not a valid colorspace!\" ) if not ( color_frame is None ): self . frame = color_frame else : self . frame = frame else : self . frame = frame # append to queue if self . __threaded_queue_mode : self . __queue . put ( self . frame ) # indicate immediate termination self . __threaded_queue_mode = False self . __terminate . set () self . __stream_read . set () # release resources self . stream . release () def read ( self ): \"\"\" Extracts frames synchronously from monitored queue, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the queue is full. **Returns:** A n-dimensional numpy array. \"\"\" while self . __threaded_queue_mode : return self . __queue . get ( timeout = self . __thread_timeout ) # return current frame # only after stream is read return ( self . frame if not self . __terminate . is_set () # check if already terminated and self . __stream_read . wait ( timeout = self . __thread_timeout ) # wait for it else None ) def stop ( self ): \"\"\" Safely terminates the thread, and release the VideoStream resources. \"\"\" self . __logging and logger . debug ( \"Terminating processes.\" ) # terminate Threaded queue mode separately if self . __threaded_queue_mode : self . __threaded_queue_mode = False # indicate that the thread # should be terminated immediately self . __terminate . set () self . __stream_read . set () # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : if not ( self . __queue is None ): while not self . __queue . empty (): try : self . __queue . get_nowait () except queue . Empty : continue self . __queue . task_done () self . __thread . join () __init__ ( self , source = 0 , stream_mode = False , backend = 0 , colorspace = None , logging = False , time_delay = 0 , ** options ) special \u2693 This constructor method initializes the object state and attributes of the CamGear class. Parameters: Name Type Description Default source based on input defines the source for the input stream. 0 stream_mode bool controls the exclusive Stream Mode for handling streaming URLs. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Source Tweak Parameters. {} Source code in vidgear/gears/camgear.py def __init__ ( self , source = 0 , stream_mode = False , backend = 0 , colorspace = None , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the CamGear class. Parameters: source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive **Stream Mode** for handling streaming URLs. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Source Tweak Parameters. \"\"\" # enable logging if specified self . __logging = False if logging : self . __logging = logging # initialize global self . ytv_metadata = {} # check if Stream-Mode is ON (True) if stream_mode : # check GStreamer backend support gst_support = check_gstreamer_support ( logging = logging ) # handle special Stream Mode parameters stream_resolution = get_supported_resolution ( options . pop ( \"STREAM_RESOLUTION\" , \"best\" ), logging = logging ) # handle Stream-Mode if not ( yt_dlp is None ): # extract user-defined params yt_stream_params = options . pop ( \"STREAM_PARAMS\" , {}) if isinstance ( yt_stream_params , dict ): yt_stream_params = { str ( k ) . strip (): v for k , v in yt_stream_params . items () } else : yt_stream_params = {} try : # Validate source for Yt_dlp backend logger . info ( \"Verifying Streaming URL using yt-dlp backend. Please wait...\" ) # initialize YT_backend ytbackend = YT_backend ( source_url = source , logging = logging , ** yt_stream_params ) if ytbackend : # save video metadata self . ytv_metadata = ytbackend . meta_data # handle live-streams if ytbackend . is_livestream : # Throw warning for livestreams logger . warning ( \"Livestream URL detected. It is advised to use GStreamer backend(`cv2.CAP_GSTREAMER`) with it.\" ) # check whether stream-resolution was specified and available if not ( stream_resolution in ytbackend . streams . keys ()): logger . warning ( \"Specified stream-resolution ` {} ` is not available. Reverting to `best`!\" . format ( stream_resolution ) ) # revert to best stream_resolution = \"best\" else : if self . __logging : logger . debug ( \"Using ` {} ` resolution for streaming.\" . format ( stream_resolution ) ) # extract stream URL as source using stream-resolution source = ytbackend . streams [ stream_resolution ] # log progress self . __logging and logger . debug ( \"YouTube source ID: ` {} `, Title: ` {} `, Quality: ` {} `\" . format ( self . ytv_metadata [ \"id\" ], self . ytv_metadata [ \"title\" ], stream_resolution , ) ) except Exception as e : # raise error if something went wrong raise ValueError ( \"[CamGear:ERROR] :: Stream Mode is enabled but Input URL is invalid!\" ) else : # raise import errors import_dependency_safe ( \"yt_dlp\" ) # youtube mode variable initialization self . __youtube_mode = stream_mode # assigns special parameter to global variable and clear # Threaded Queue Mode self . __threaded_queue_mode = options . pop ( \"THREADED_QUEUE_MODE\" , True ) if not isinstance ( self . __threaded_queue_mode , bool ): # reset improper values self . __threaded_queue_mode = True # Thread Timeout self . __thread_timeout = options . pop ( \"THREAD_TIMEOUT\" , None ) if self . __thread_timeout and isinstance ( self . __thread_timeout , ( int , float )): # set values self . __thread_timeout = float ( self . __thread_timeout ) else : # defaults to 5mins timeout self . __thread_timeout = None self . __queue = None # initialize queue for video files only if self . __threaded_queue_mode and isinstance ( source , str ): # define queue and assign it to global var self . __queue = queue . Queue ( maxsize = 96 ) # max bufferlen 96 to check overflow # log it self . __logging and logger . debug ( \"Enabling Threaded Queue Mode for the current video source!\" ) else : # otherwise disable it self . __threaded_queue_mode = False # log it self . __logging and logger . warning ( \"Threaded Queue Mode is disabled for the current video source!\" ) if self . __thread_timeout : logger . debug ( \"Setting Video-Thread Timeout to {} s.\" . format ( self . __thread_timeout ) ) # stream variable initialization self . stream = None if backend and isinstance ( backend , int ): # add backend if specified and initialize the camera stream if check_CV_version () == 3 : # Different OpenCV 3.4.x statement self . stream = cv2 . VideoCapture ( source + backend ) else : # Two parameters are available since OpenCV 4+ (master branch) self . stream = cv2 . VideoCapture ( source , backend ) logger . debug ( \"Setting backend ` {} ` for this source.\" . format ( backend )) else : # initialize the camera stream self . stream = cv2 . VideoCapture ( source ) # initializing colorspace variable self . color_space = None # apply attributes to source if specified options = { str ( k ) . strip (): v for k , v in options . items ()} for key , value in options . items (): property = capPropId ( key ) if not ( property is None ): self . stream . set ( property , value ) # handle colorspace value if not ( colorspace is None ): self . color_space = capPropId ( colorspace . strip ()) if self . __logging and not ( self . color_space is None ): logger . debug ( \"Enabling ` {} ` colorspace for this video stream!\" . format ( colorspace . strip () ) ) # initialize and assign frame-rate variable self . framerate = 0.0 _fps = self . stream . get ( cv2 . CAP_PROP_FPS ) if _fps > 1.0 : self . framerate = _fps # applying time delay to warm-up webcam only if specified if time_delay and isinstance ( time_delay , ( int , float )): time . sleep ( time_delay ) # frame variable initialization ( grabbed , self . frame ) = self . stream . read () # check if valid stream if grabbed : # render colorspace if defined if not ( self . color_space is None ): self . frame = cv2 . cvtColor ( self . frame , self . color_space ) if self . __threaded_queue_mode : # initialize and append to queue self . __queue . put ( self . frame ) else : raise RuntimeError ( \"[CamGear:ERROR] :: Source is invalid, CamGear failed to initialize stream on this source!\" ) # thread initialization self . __thread = None # initialize termination flag event self . __terminate = Event () # initialize stream read flag event self . __stream_read = Event () read ( self ) \u2693 Extracts frames synchronously from monitored queue, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the queue is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/camgear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored queue, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the queue is full. **Returns:** A n-dimensional numpy array. \"\"\" while self . __threaded_queue_mode : return self . __queue . get ( timeout = self . __thread_timeout ) # return current frame # only after stream is read return ( self . frame if not self . __terminate . is_set () # check if already terminated and self . __stream_read . wait ( timeout = self . __thread_timeout ) # wait for it else None ) start ( self ) \u2693 Launches the internal Threaded Frames Extractor daemon. Returns: A reference to the CamGear class object. Source code in vidgear/gears/camgear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon. **Returns:** A reference to the CamGear class object. \"\"\" self . __thread = Thread ( target = self . __update , name = \"CamGear\" , args = ()) self . __thread . daemon = True self . __thread . start () return self stop ( self ) \u2693 Safely terminates the thread, and release the VideoStream resources. Source code in vidgear/gears/camgear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the VideoStream resources. \"\"\" self . __logging and logger . debug ( \"Terminating processes.\" ) # terminate Threaded queue mode separately if self . __threaded_queue_mode : self . __threaded_queue_mode = False # indicate that the thread # should be terminated immediately self . __terminate . set () self . __stream_read . set () # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : if not ( self . __queue is None ): while not self . __queue . empty (): try : self . __queue . get_nowait () except queue . Empty : continue self . __queue . task_done () self . __thread . join ()","title":"CamGear API"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.__init__","text":"This constructor method initializes the object state and attributes of the CamGear class. Parameters: Name Type Description Default source based on input defines the source for the input stream. 0 stream_mode bool controls the exclusive Stream Mode for handling streaming URLs. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Source Tweak Parameters. {} Source code in vidgear/gears/camgear.py def __init__ ( self , source = 0 , stream_mode = False , backend = 0 , colorspace = None , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the CamGear class. Parameters: source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive **Stream Mode** for handling streaming URLs. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Source Tweak Parameters. \"\"\" # enable logging if specified self . __logging = False if logging : self . __logging = logging # initialize global self . ytv_metadata = {} # check if Stream-Mode is ON (True) if stream_mode : # check GStreamer backend support gst_support = check_gstreamer_support ( logging = logging ) # handle special Stream Mode parameters stream_resolution = get_supported_resolution ( options . pop ( \"STREAM_RESOLUTION\" , \"best\" ), logging = logging ) # handle Stream-Mode if not ( yt_dlp is None ): # extract user-defined params yt_stream_params = options . pop ( \"STREAM_PARAMS\" , {}) if isinstance ( yt_stream_params , dict ): yt_stream_params = { str ( k ) . strip (): v for k , v in yt_stream_params . items () } else : yt_stream_params = {} try : # Validate source for Yt_dlp backend logger . info ( \"Verifying Streaming URL using yt-dlp backend. Please wait...\" ) # initialize YT_backend ytbackend = YT_backend ( source_url = source , logging = logging , ** yt_stream_params ) if ytbackend : # save video metadata self . ytv_metadata = ytbackend . meta_data # handle live-streams if ytbackend . is_livestream : # Throw warning for livestreams logger . warning ( \"Livestream URL detected. It is advised to use GStreamer backend(`cv2.CAP_GSTREAMER`) with it.\" ) # check whether stream-resolution was specified and available if not ( stream_resolution in ytbackend . streams . keys ()): logger . warning ( \"Specified stream-resolution ` {} ` is not available. Reverting to `best`!\" . format ( stream_resolution ) ) # revert to best stream_resolution = \"best\" else : if self . __logging : logger . debug ( \"Using ` {} ` resolution for streaming.\" . format ( stream_resolution ) ) # extract stream URL as source using stream-resolution source = ytbackend . streams [ stream_resolution ] # log progress self . __logging and logger . debug ( \"YouTube source ID: ` {} `, Title: ` {} `, Quality: ` {} `\" . format ( self . ytv_metadata [ \"id\" ], self . ytv_metadata [ \"title\" ], stream_resolution , ) ) except Exception as e : # raise error if something went wrong raise ValueError ( \"[CamGear:ERROR] :: Stream Mode is enabled but Input URL is invalid!\" ) else : # raise import errors import_dependency_safe ( \"yt_dlp\" ) # youtube mode variable initialization self . __youtube_mode = stream_mode # assigns special parameter to global variable and clear # Threaded Queue Mode self . __threaded_queue_mode = options . pop ( \"THREADED_QUEUE_MODE\" , True ) if not isinstance ( self . __threaded_queue_mode , bool ): # reset improper values self . __threaded_queue_mode = True # Thread Timeout self . __thread_timeout = options . pop ( \"THREAD_TIMEOUT\" , None ) if self . __thread_timeout and isinstance ( self . __thread_timeout , ( int , float )): # set values self . __thread_timeout = float ( self . __thread_timeout ) else : # defaults to 5mins timeout self . __thread_timeout = None self . __queue = None # initialize queue for video files only if self . __threaded_queue_mode and isinstance ( source , str ): # define queue and assign it to global var self . __queue = queue . Queue ( maxsize = 96 ) # max bufferlen 96 to check overflow # log it self . __logging and logger . debug ( \"Enabling Threaded Queue Mode for the current video source!\" ) else : # otherwise disable it self . __threaded_queue_mode = False # log it self . __logging and logger . warning ( \"Threaded Queue Mode is disabled for the current video source!\" ) if self . __thread_timeout : logger . debug ( \"Setting Video-Thread Timeout to {} s.\" . format ( self . __thread_timeout ) ) # stream variable initialization self . stream = None if backend and isinstance ( backend , int ): # add backend if specified and initialize the camera stream if check_CV_version () == 3 : # Different OpenCV 3.4.x statement self . stream = cv2 . VideoCapture ( source + backend ) else : # Two parameters are available since OpenCV 4+ (master branch) self . stream = cv2 . VideoCapture ( source , backend ) logger . debug ( \"Setting backend ` {} ` for this source.\" . format ( backend )) else : # initialize the camera stream self . stream = cv2 . VideoCapture ( source ) # initializing colorspace variable self . color_space = None # apply attributes to source if specified options = { str ( k ) . strip (): v for k , v in options . items ()} for key , value in options . items (): property = capPropId ( key ) if not ( property is None ): self . stream . set ( property , value ) # handle colorspace value if not ( colorspace is None ): self . color_space = capPropId ( colorspace . strip ()) if self . __logging and not ( self . color_space is None ): logger . debug ( \"Enabling ` {} ` colorspace for this video stream!\" . format ( colorspace . strip () ) ) # initialize and assign frame-rate variable self . framerate = 0.0 _fps = self . stream . get ( cv2 . CAP_PROP_FPS ) if _fps > 1.0 : self . framerate = _fps # applying time delay to warm-up webcam only if specified if time_delay and isinstance ( time_delay , ( int , float )): time . sleep ( time_delay ) # frame variable initialization ( grabbed , self . frame ) = self . stream . read () # check if valid stream if grabbed : # render colorspace if defined if not ( self . color_space is None ): self . frame = cv2 . cvtColor ( self . frame , self . color_space ) if self . __threaded_queue_mode : # initialize and append to queue self . __queue . put ( self . frame ) else : raise RuntimeError ( \"[CamGear:ERROR] :: Source is invalid, CamGear failed to initialize stream on this source!\" ) # thread initialization self . __thread = None # initialize termination flag event self . __terminate = Event () # initialize stream read flag event self . __stream_read = Event ()","title":"__init__()"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.read","text":"Extracts frames synchronously from monitored queue, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the queue is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/camgear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored queue, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the queue is full. **Returns:** A n-dimensional numpy array. \"\"\" while self . __threaded_queue_mode : return self . __queue . get ( timeout = self . __thread_timeout ) # return current frame # only after stream is read return ( self . frame if not self . __terminate . is_set () # check if already terminated and self . __stream_read . wait ( timeout = self . __thread_timeout ) # wait for it else None )","title":"read()"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.start","text":"Launches the internal Threaded Frames Extractor daemon. Returns: A reference to the CamGear class object. Source code in vidgear/gears/camgear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon. **Returns:** A reference to the CamGear class object. \"\"\" self . __thread = Thread ( target = self . __update , name = \"CamGear\" , args = ()) self . __thread . daemon = True self . __thread . start () return self","title":"start()"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.stop","text":"Safely terminates the thread, and release the VideoStream resources. Source code in vidgear/gears/camgear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the VideoStream resources. \"\"\" self . __logging and logger . debug ( \"Terminating processes.\" ) # terminate Threaded queue mode separately if self . __threaded_queue_mode : self . __threaded_queue_mode = False # indicate that the thread # should be terminated immediately self . __terminate . set () self . __stream_read . set () # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : if not ( self . __queue is None ): while not self . __queue . empty (): try : self . __queue . get_nowait () except queue . Empty : continue self . __queue . task_done () self . __thread . join ()","title":"stop()"},{"location":"bonus/reference/helper/","text":"logger_handler \u2693 Returns the logger handler Returns: A logger handler Source code in vidgear/gears/helper.py def logger_handler (): \"\"\" ## logger_handler Returns the logger handler **Returns:** A logger handler \"\"\" # logging formatter formatter = ColoredFormatter ( \" {green}{asctime}{reset} :: {bold_purple}{name:^13}{reset} :: {log_color}{levelname:^8}{reset} :: {bold_white}{message} \" , datefmt = \"%H:%M:%S\" , reset = True , log_colors = { \"INFO\" : \"bold_cyan\" , \"DEBUG\" : \"bold_yellow\" , \"WARNING\" : \"bold_red,fg_thin_yellow\" , \"ERROR\" : \"bold_red\" , \"CRITICAL\" : \"bold_red,bg_white\" , }, style = \"{\" , ) # check if VIDGEAR_LOGFILE defined file_mode = os . environ . get ( \"VIDGEAR_LOGFILE\" , False ) # define handler handler = log . StreamHandler () if file_mode and isinstance ( file_mode , str ): file_path = os . path . abspath ( file_mode ) if ( os . name == \"nt\" or os . access in os . supports_effective_ids ) and os . access ( os . path . dirname ( file_path ), os . W_OK ): file_path = ( os . path . join ( file_path , \"vidgear.log\" ) if os . path . isdir ( file_path ) else file_path ) handler = log . FileHandler ( file_path , mode = \"a\" ) formatter = log . Formatter ( \" {asctime} :: {name} :: {levelname} :: {message} \" , datefmt = \"%H:%M:%S\" , style = \"{\" , ) handler . setFormatter ( formatter ) return handler check_CV_version \u2693 Returns: OpenCV's version first bit Source code in vidgear/gears/helper.py def check_CV_version (): \"\"\" ## check_CV_version **Returns:** OpenCV's version first bit \"\"\" if LooseVersion ( cv2 . __version__ ) >= LooseVersion ( \"4\" ): return 4 else : return 3 check_gstreamer_support \u2693 Checks whether OpenCV is compiled with Gstreamer( >=1.0.0 ) support. Parameters: Name Type Description Default logging bool enables logging for its operations False Returns: A Boolean value Source code in vidgear/gears/helper.py def check_gstreamer_support ( logging = False ): \"\"\" ## check_gstreamer_support Checks whether OpenCV is compiled with Gstreamer(`>=1.0.0`) support. Parameters: logging (bool): enables logging for its operations **Returns:** A Boolean value \"\"\" raw = cv2 . getBuildInformation () gst = [ x . strip () for x in raw . split ( \" \\n \" ) if x and re . search ( r \"GStreamer[,-:]+\\s*(?:YES|NO)\" , x ) ] if gst and \"YES\" in gst [ 0 ]: version = re . search ( r \"(\\d+\\.)?(\\d+\\.)?(\\*|\\d+)\" , gst [ 0 ]) logging and logger . debug ( \"Found GStreamer version: {} \" . format ( version [ 0 ])) return version [ 0 ] >= \"1.0.0\" else : logger . warning ( \"GStreamer not found!\" ) return False get_supported_resolution \u2693 Parameters: Name Type Description Default value string value to be validated required logging bool enables logging for its operations False Returns: Valid stream resolution Source code in vidgear/gears/helper.py def get_supported_resolution ( value , logging = False ): \"\"\" ## get_supported_resolution Parameters: value (string): value to be validated logging (bool): enables logging for its operations **Returns:** Valid stream resolution \"\"\" # default to best stream_resolution = \"best\" supported_stream_qualities = [ \"144p\" , \"240p\" , \"360p\" , \"480p\" , \"720p\" , \"1080p\" , \"1440p\" , \"2160p\" , \"4320p\" , \"worst\" , \"best\" , ] if isinstance ( value , str ): if value . strip () . lower () in supported_stream_qualities : stream_resolution = value . strip () . lower () logging and logger . debug ( \"Selecting ` {} ` resolution for streams.\" . format ( stream_resolution ) ) else : logger . warning ( \"Specified stream-resolution ` {} ` is not supported. Reverting to `best`!\" . format ( value ) ) else : logger . warning ( \"Specified stream-resolution ` {} ` is Invalid. Reverting to `best`!\" . format ( value ) ) return stream_resolution dimensions_to_resolutions \u2693 Parameters: Name Type Description Default value list list of dimensions (e.g. 640x360 ) required Returns: list of resolutions (e.g. 360p ) Source code in vidgear/gears/helper.py def dimensions_to_resolutions ( value ): \"\"\" ## dimensions_to_resolutions Parameters: value (list): list of dimensions (e.g. `640x360`) **Returns:** list of resolutions (e.g. `360p`) \"\"\" supported_resolutions = { \"256x144\" : \"144p\" , \"426x240\" : \"240p\" , \"640x360\" : \"360p\" , \"854x480\" : \"480p\" , \"1280x720\" : \"720p\" , \"1920x1080\" : \"1080p\" , \"2560x1440\" : \"1440p\" , \"3840x2160\" : \"2160p\" , \"7680x4320\" : \"4320p\" , } return ( list ( map ( supported_resolutions . get , value , value )) if isinstance ( value , list ) else [] ) mkdir_safe \u2693 Safely creates directory at given path. Parameters: Name Type Description Default dir_path string path to the directory required logging bool enables logging for its operations False Source code in vidgear/gears/helper.py def mkdir_safe ( dir_path , logging = False ): \"\"\" ## mkdir_safe Safely creates directory at given path. Parameters: dir_path (string): path to the directory logging (bool): enables logging for its operations \"\"\" try : os . makedirs ( dir_path ) logging and logger . debug ( \"Created directory at ` {} `\" . format ( dir_path )) except ( OSError , IOError ) as e : if e . errno != errno . EACCES and e . errno != errno . EEXIST : raise delete_ext_safe \u2693 Safely deletes files with given extensions at given path. Parameters: Name Type Description Default dir_path string path to the directory required extensions list list of extensions to be deleted [] logging bool enables logging for its operations False Source code in vidgear/gears/helper.py def delete_ext_safe ( dir_path , extensions = [], logging = False ): \"\"\" ## delete_ext_safe Safely deletes files with given extensions at given path. Parameters: dir_path (string): path to the directory extensions (list): list of extensions to be deleted logging (bool): enables logging for its operations \"\"\" if not extensions or not os . path . exists ( dir_path ): logger . warning ( \"Invalid input provided for deleting!\" ) return logger . critical ( \"Clearing Assets at ` {} `!\" . format ( dir_path )) for ext in extensions : if len ( ext ) == 2 : files_ext = [ os . path . join ( dir_path , f ) for f in os . listdir ( dir_path ) if f . startswith ( ext [ 0 ]) and f . endswith ( ext [ 1 ]) ] else : files_ext = [ os . path . join ( dir_path , f ) for f in os . listdir ( dir_path ) if f . endswith ( ext ) ] for file in files_ext : delete_file_safe ( file ) logging and logger . debug ( \"Deleted file: ` {} `\" . format ( file )) capPropId \u2693 Retrieves the OpenCV property's Integer(Actual) value from string. Parameters: Name Type Description Default property string inputs OpenCV property as string. required logging bool enables logging for its operations True Returns: Resultant integer value. Source code in vidgear/gears/helper.py def capPropId ( property , logging = True ): \"\"\" ## capPropId Retrieves the OpenCV property's Integer(Actual) value from string. Parameters: property (string): inputs OpenCV property as string. logging (bool): enables logging for its operations **Returns:** Resultant integer value. \"\"\" integer_value = 0 try : integer_value = getattr ( cv2 , property ) except Exception as e : if logging : logger . exception ( str ( e )) logger . critical ( \"` {} ` is not a valid OpenCV property!\" . format ( property )) return None return integer_value reducer \u2693 Reduces frame size by given percentage Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None percentage int/float inputs size-reduction percentage. 0 interpolation int Change resize interpolation. 4 Returns: A reduced numpy ndarray array. Source code in vidgear/gears/helper.py def reducer ( frame = None , percentage = 0 , interpolation = cv2 . INTER_LANCZOS4 ): \"\"\" ## reducer Reduces frame size by given percentage Parameters: frame (numpy.ndarray): inputs numpy array(frame). percentage (int/float): inputs size-reduction percentage. interpolation (int): Change resize interpolation. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None : raise ValueError ( \"[Helper:ERROR] :: Input frame cannot be NoneType!\" ) # check if valid reduction percentage is given if not ( percentage > 0 and percentage < 90 ): raise ValueError ( \"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\" ) if not ( isinstance ( interpolation , int )): raise ValueError ( \"[Helper:ERROR] :: Given interpolation is invalid, Kindly refer docs.\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # calculate the ratio of the width from percentage reduction = (( 100 - percentage ) / 100 ) * width ratio = reduction / float ( width ) # construct the dimensions dimensions = ( int ( reduction ), int ( height * ratio )) # return the resized frame return cv2 . resize ( frame , dimensions , interpolation = interpolation ) create_blank_frame \u2693 Create blank frames of given frame size with text Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None text str Text to be written on frame. '' Returns: A reduced numpy ndarray array. Source code in vidgear/gears/helper.py def create_blank_frame ( frame = None , text = \"\" , logging = False ): \"\"\" ## create_blank_frame Create blank frames of given frame size with text Parameters: frame (numpy.ndarray): inputs numpy array(frame). text (str): Text to be written on frame. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None or not ( isinstance ( frame , np . ndarray )): raise ValueError ( \"[Helper:ERROR] :: Input frame is invalid!\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # create blank frame blank_frame = np . zeros ( frame . shape , frame . dtype ) # setup text if text and isinstance ( text , str ): logging and logger . debug ( \"Adding text: {} \" . format ( text )) # setup font font = cv2 . FONT_HERSHEY_SCRIPT_COMPLEX # get boundary of this text fontScale = min ( height , width ) / ( 25 / 0.25 ) textsize = cv2 . getTextSize ( text , font , fontScale , 5 )[ 0 ] # get coords based on boundary textX = ( width - textsize [ 0 ]) // 2 textY = ( height + textsize [ 1 ]) // 2 # put text cv2 . putText ( blank_frame , text , ( textX , textY ), font , fontScale , ( 125 , 125 , 125 ), 6 ) # return frame return blank_frame dict2Args \u2693 Converts dictionary attributes to list(args) Parameters: Name Type Description Default param_dict dict Parameters dictionary required Returns: Arguments list Source code in vidgear/gears/helper.py def dict2Args ( param_dict ): \"\"\" ## dict2Args Converts dictionary attributes to list(args) Parameters: param_dict (dict): Parameters dictionary **Returns:** Arguments list \"\"\" args = [] for key in param_dict . keys (): if key in [ \"-clones\" ] or key . startswith ( \"-core\" ): if isinstance ( param_dict [ key ], list ): args . extend ( param_dict [ key ]) else : logger . warning ( \" {} with invalid datatype:` {} `, Skipped!\" . format ( \"Core parameter\" if key . startswith ( \"-core\" ) else \"Clone\" , param_dict [ key ], ) ) else : args . append ( key ) args . append ( str ( param_dict [ key ])) return args get_valid_ffmpeg_path \u2693 Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: Name Type Description Default custom_ffmpeg string path to custom FFmpeg executables '' is_windows boolean is running on Windows OS? False ffmpeg_download_path string FFmpeg static binaries download location (Windows only) '' logging bool enables logging for its operations False Returns: A valid FFmpeg executable path string. Source code in vidgear/gears/helper.py def get_valid_ffmpeg_path ( custom_ffmpeg = \"\" , is_windows = False , ffmpeg_download_path = \"\" , logging = False ): \"\"\" ## get_valid_ffmpeg_path Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: custom_ffmpeg (string): path to custom FFmpeg executables is_windows (boolean): is running on Windows OS? ffmpeg_download_path (string): FFmpeg static binaries download location _(Windows only)_ logging (bool): enables logging for its operations **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if is_windows : # checks if current os is windows if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable final_path += custom_ffmpeg else : # otherwise auto-download them try : if not ( ffmpeg_download_path ): # otherwise save to Temp Directory import tempfile ffmpeg_download_path = tempfile . gettempdir () logging and logger . debug ( \"FFmpeg Windows Download Path: {} \" . format ( ffmpeg_download_path ) ) # download Binaries os_bit = ( ( \"win64\" if platform . machine () . endswith ( \"64\" ) else \"win32\" ) if is_windows else \"\" ) _path = download_ffmpeg_binaries ( path = ffmpeg_download_path , os_windows = is_windows , os_bit = os_bit ) # assign to local variable final_path += _path except Exception as e : # log if any error occurred logger . exception ( str ( e )) logger . error ( \"Error in downloading FFmpeg binaries, Check your network and Try again!\" ) return False if os . path . isfile ( final_path ): # check if valid FFmpeg file exist pass elif os . path . isfile ( os . path . join ( final_path , \"ffmpeg.exe\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( final_path , \"ffmpeg.exe\" ) else : # else return False logging and logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise perform test for Unix if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable if os . path . isfile ( custom_ffmpeg ): # check if valid FFmpeg file exist final_path += custom_ffmpeg elif os . path . isfile ( os . path . join ( custom_ffmpeg , \"ffmpeg\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( custom_ffmpeg , \"ffmpeg\" ) else : # else return False logging and logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise assign ffmpeg binaries from system final_path += \"ffmpeg\" logging and logger . debug ( \"Final FFmpeg Path: {} \" . format ( final_path )) # Final Auto-Validation for FFmeg Binaries. returns final path if test is passed return final_path if validate_ffmpeg ( final_path , logging = logging ) else False download_ffmpeg_binaries \u2693 Generates FFmpeg Static Binaries for windows(if not available) Parameters: Name Type Description Default path string path for downloading custom FFmpeg executables required os_windows boolean is running on Windows OS? False os_bit string 32-bit or 64-bit OS? '' Returns: A valid FFmpeg executable path string. Source code in vidgear/gears/helper.py def download_ffmpeg_binaries ( path , os_windows = False , os_bit = \"\" ): \"\"\" ## download_ffmpeg_binaries Generates FFmpeg Static Binaries for windows(if not available) Parameters: path (string): path for downloading custom FFmpeg executables os_windows (boolean): is running on Windows OS? os_bit (string): 32-bit or 64-bit OS? **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if os_windows and os_bit : # initialize with available FFmpeg Static Binaries GitHub Server file_url = \"https://github.com/abhiTronix/FFmpeg-Builds/releases/latest/download/ffmpeg-static- {} -gpl.zip\" . format ( os_bit ) file_name = os . path . join ( os . path . abspath ( path ), \"ffmpeg-static- {} -gpl.zip\" . format ( os_bit ) ) file_path = os . path . join ( os . path . abspath ( path ), \"ffmpeg-static- {} -gpl/bin/ffmpeg.exe\" . format ( os_bit ), ) base_path , _ = os . path . split ( file_name ) # extract file base path # check if file already exists if os . path . isfile ( file_path ): final_path += file_path # skip download if does else : # import libs import zipfile # check if given path has write access assert os . access ( path , os . W_OK ), ( \"[Helper:ERROR] :: Permission Denied, Cannot write binaries to directory = \" + path ) # remove leftovers if exists os . path . isfile ( file_name ) and delete_file_safe ( file_name ) # download and write file to the given path with open ( file_name , \"wb\" ) as f : logger . debug ( \"No Custom FFmpeg path provided. Auto-Installing FFmpeg static binaries from GitHub Mirror now. Please wait...\" ) # create session with requests . Session () as http : # setup retry strategy retries = Retry ( total = 3 , backoff_factor = 1 , status_forcelist = [ 429 , 500 , 502 , 503 , 504 ], ) # Mount it for https usage adapter = TimeoutHTTPAdapter ( timeout = 2.0 , max_retries = retries ) http . mount ( \"https://\" , adapter ) response = http . get ( file_url , stream = True ) response . raise_for_status () total_length = response . headers . get ( \"content-length\" ) assert not ( total_length is None ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\" bar = tqdm ( total = int ( total_length ), unit = \"B\" , unit_scale = True ) for data in response . iter_content ( chunk_size = 4096 ): f . write ( data ) len ( data ) > 0 and bar . update ( len ( data )) bar . close () logger . debug ( \"Extracting executables.\" ) with zipfile . ZipFile ( file_name , \"r\" ) as zip_ref : zip_fname , _ = os . path . split ( zip_ref . infolist ()[ 0 ] . filename ) zip_ref . extractall ( base_path ) # perform cleaning delete_file_safe ( file_name ) logger . debug ( \"FFmpeg binaries for Windows configured successfully!\" ) final_path += file_path # return final path return final_path validate_ffmpeg \u2693 Validate FFmeg Binaries. returns True if tests are passed. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required logging bool enables logging for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/helper.py def validate_ffmpeg ( path , logging = False ): \"\"\" ## validate_ffmpeg Validate FFmeg Binaries. returns `True` if tests are passed. Parameters: path (string): absolute path of FFmpeg binaries logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" try : # get the FFmpeg version version = check_output ([ path , \"-version\" ]) firstline = version . split ( b \" \\n \" )[ 0 ] version = firstline . split ( b \" \" )[ 2 ] . strip () if logging : # log if test are passed logger . debug ( \"FFmpeg validity Test Passed!\" ) logger . debug ( \"Found valid FFmpeg Version: ` {} ` installed on this system\" . format ( version ) ) except Exception as e : # log if test are failed if logging : logger . exception ( str ( e )) logger . warning ( \"FFmpeg validity Test Failed!\" ) return False return True check_output \u2693 Returns stdin output from subprocess module Source code in vidgear/gears/helper.py def check_output ( * args , ** kwargs ): \"\"\" ## check_output Returns stdin output from subprocess module \"\"\" # import libs import subprocess as sp # workaround for python bug: https://bugs.python.org/issue37380 if platform . system () == \"Windows\" : # see comment https://bugs.python.org/msg370334 sp . _cleanup = lambda : None # handle additional params retrieve_stderr = kwargs . pop ( \"force_retrieve_stderr\" , False ) # execute command in subprocess process = sp . Popen ( stdout = sp . PIPE , stderr = sp . DEVNULL if not ( retrieve_stderr ) else sp . PIPE , * args , ** kwargs , ) output , stderr = process . communicate () retcode = process . poll () # handle return code if retcode and not ( retrieve_stderr ): cmd = kwargs . get ( \"args\" ) if cmd is None : cmd = args [ 0 ] error = sp . CalledProcessError ( retcode , cmd ) error . output = output raise error return output if not ( retrieve_stderr ) else stderr generate_auth_certificates \u2693 Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode. Parameters: Name Type Description Default path string path for generating CURVE key-pairs required overwrite boolean overwrite existing key-pairs or not? False logging bool enables logging for its operations False Returns: A valid CURVE key-pairs path as string. Source code in vidgear/gears/helper.py def generate_auth_certificates ( path , overwrite = False , logging = False ): \"\"\" ## generate_auth_certificates Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode. Parameters: path (string): path for generating CURVE key-pairs overwrite (boolean): overwrite existing key-pairs or not? logging (bool): enables logging for its operations **Returns:** A valid CURVE key-pairs path as string. \"\"\" # import necessary lib import zmq.auth # check if path corresponds to vidgear only if os . path . basename ( path ) != \".vidgear\" : path = os . path . join ( path , \".vidgear\" ) # generate keys dir keys_dir = os . path . join ( path , \"keys\" ) mkdir_safe ( keys_dir , logging = logging ) # generate separate public and private key dirs public_keys_dir = os . path . join ( keys_dir , \"public_keys\" ) secret_keys_dir = os . path . join ( keys_dir , \"private_keys\" ) # check if overwriting is allowed if overwrite : # delete previous certificates for dirs in [ public_keys_dir , secret_keys_dir ]: if os . path . exists ( dirs ): shutil . rmtree ( dirs ) mkdir_safe ( dirs , logging = logging ) # generate new keys server_public_file , server_secret_file = zmq . auth . create_certificates ( keys_dir , \"server\" ) client_public_file , client_secret_file = zmq . auth . create_certificates ( keys_dir , \"client\" ) # move keys to their appropriate directory respectively for key_file in os . listdir ( keys_dir ): if key_file . endswith ( \".key\" ): shutil . move ( os . path . join ( keys_dir , key_file ), public_keys_dir ) elif key_file . endswith ( \".key_secret\" ): shutil . move ( os . path . join ( keys_dir , key_file ), secret_keys_dir ) else : # clean redundant keys if present redundant_key = os . path . join ( keys_dir , key_file ) if os . path . isfile ( redundant_key ): delete_file_safe ( redundant_key ) else : # otherwise validate available keys status_public_keys = validate_auth_keys ( public_keys_dir , \".key\" ) status_private_keys = validate_auth_keys ( secret_keys_dir , \".key_secret\" ) # check if all valid keys are found if status_private_keys and status_public_keys : return ( keys_dir , secret_keys_dir , public_keys_dir ) # check if valid public keys are found if not ( status_public_keys ): mkdir_safe ( public_keys_dir , logging = logging ) # check if valid private keys are found if not ( status_private_keys ): mkdir_safe ( secret_keys_dir , logging = logging ) # generate new keys server_public_file , server_secret_file = zmq . auth . create_certificates ( keys_dir , \"server\" ) client_public_file , client_secret_file = zmq . auth . create_certificates ( keys_dir , \"client\" ) # move keys to their appropriate directory respectively for key_file in os . listdir ( keys_dir ): if key_file . endswith ( \".key\" ) and not ( status_public_keys ): shutil . move ( os . path . join ( keys_dir , key_file ), os . path . join ( public_keys_dir , \".\" ) ) elif key_file . endswith ( \".key_secret\" ) and not ( status_private_keys ): shutil . move ( os . path . join ( keys_dir , key_file ), os . path . join ( secret_keys_dir , \".\" ) ) else : # clean redundant keys if present redundant_key = os . path . join ( keys_dir , key_file ) if os . path . isfile ( redundant_key ): delete_file_safe ( redundant_key ) # validate newly generated keys status_public_keys = validate_auth_keys ( public_keys_dir , \".key\" ) status_private_keys = validate_auth_keys ( secret_keys_dir , \".key_secret\" ) # raise error is validation test fails if not ( status_private_keys ) or not ( status_public_keys ): raise RuntimeError ( \"[Helper:ERROR] :: Unable to generate valid ZMQ authentication certificates at ` {} `!\" . format ( keys_dir ) ) # finally return valid key paths return ( keys_dir , secret_keys_dir , public_keys_dir ) validate_audio \u2693 Validates audio by retrieving audio-bitrate from file. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required source string/list source to be validated. None Returns: A string value, confirming whether audio is present, or not?. Source code in vidgear/gears/helper.py def validate_audio ( path , source = None ): \"\"\" ## validate_audio Validates audio by retrieving audio-bitrate from file. Parameters: path (string): absolute path of FFmpeg binaries source (string/list): source to be validated. **Returns:** A string value, confirming whether audio is present, or not?. \"\"\" if source is None or not ( source ): logger . warning ( \"Audio input source is empty!\" ) return \"\" # create ffmpeg command cmd = [ path , \"-hide_banner\" ] + ( source if isinstance ( source , list ) else [ \"-i\" , source ] ) # extract audio sample-rate from metadata metadata = check_output ( cmd , force_retrieve_stderr = True ) audio_bitrate = re . findall ( r \"fltp,\\s[0-9]+\\s\\w\\w[/]s\" , metadata . decode ( \"utf-8\" )) sample_rate_identifiers = [ \"Audio\" , \"Hz\" ] + ( [ \"fltp\" ] if isinstance ( source , str ) else [] ) audio_sample_rate = [ line . strip () for line in metadata . decode ( \"utf-8\" ) . split ( \" \\n \" ) if all ( x in line for x in sample_rate_identifiers ) ] if audio_bitrate : filtered = audio_bitrate [ 0 ] . split ( \" \" )[ 1 : 3 ] final_bitrate = \" {}{} \" . format ( int ( filtered [ 0 ] . strip ()), \"k\" if ( filtered [ 1 ] . strip () . startswith ( \"k\" )) else \"M\" , ) return final_bitrate elif audio_sample_rate : sample_rate = re . findall ( r \"[0-9]+\\sHz\" , audio_sample_rate [ 0 ])[ 0 ] sample_rate_value = int ( sample_rate . split ( \" \" )[ 0 ]) samplerate_2_bitrate = int ( ( sample_rate_value - 44100 ) * ( 320 - 96 ) / ( 48000 - 44100 ) + 96 ) return str ( samplerate_2_bitrate ) + \"k\" else : return \"\" extract_time \u2693 Extract time from give string value. Parameters: Name Type Description Default value string string value. required Returns: Time (in seconds) as integer. Source code in vidgear/gears/helper.py def extract_time ( value ): \"\"\" ## extract_time Extract time from give string value. Parameters: value (string): string value. **Returns:** Time _(in seconds)_ as integer. \"\"\" if not ( value ): logger . warning ( \"Value is empty!\" ) return 0 else : stripped_data = value . strip () t_duration = re . findall ( r \"(?:[01]\\d|2[0123]):(?:[012345]\\d):(?:[012345]\\d)\" , stripped_data ) return ( sum ( int ( x ) * 60 ** i for i , x in enumerate ( reversed ( t_duration [ 0 ] . split ( \":\" ))) ) if t_duration else 0 ) validate_video \u2693 Validates video by retrieving resolution/size and framerate from file. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required video_path string absolute path to Video. None Returns: A dictionary of retieved Video resolution (as tuple(width, height)) and framerate (as float) . Source code in vidgear/gears/helper.py def validate_video ( path , video_path = None , logging = False ): \"\"\" ## validate_video Validates video by retrieving resolution/size and framerate from file. Parameters: path (string): absolute path of FFmpeg binaries video_path (string): absolute path to Video. **Returns:** A dictionary of retieved Video resolution _(as tuple(width, height))_ and framerate _(as float)_. \"\"\" if video_path is None or not ( video_path ): logger . warning ( \"Video path is empty!\" ) return None # extract metadata metadata = check_output ( [ path , \"-hide_banner\" , \"-i\" , video_path ], force_retrieve_stderr = True ) # clean and search stripped_data = [ x . decode ( \"utf-8\" ) . strip () for x in metadata . split ( b \" \\n \" )] logging and logger . debug ( stripped_data ) result = {} for data in stripped_data : output_a = re . findall ( r \"([1-9]\\d+)x([1-9]\\d+)\" , data ) output_b = re . findall ( r \"\\d+(?:\\.\\d+)?\\sfps\" , data ) if len ( result ) == 2 : break if output_b and not \"framerate\" in result : result [ \"framerate\" ] = re . findall ( r \"[\\d\\.\\d]+\" , output_b [ 0 ])[ 0 ] if output_a and not \"resolution\" in result : result [ \"resolution\" ] = output_a [ - 1 ] # return values return result if ( len ( result ) == 2 ) else None is_valid_url \u2693 Checks URL validity by testing its scheme against FFmpeg's supported protocols Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required url string URL to be validated None logging bool enables logging for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/helper.py def is_valid_url ( path , url = None , logging = False ): \"\"\" ## is_valid_url Checks URL validity by testing its scheme against FFmpeg's supported protocols Parameters: path (string): absolute path of FFmpeg binaries url (string): URL to be validated logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" if url is None or not ( url ): logger . warning ( \"URL is empty!\" ) return False # extract URL scheme extracted_scheme_url = url . split ( \"://\" , 1 )[ 0 ] # extract all FFmpeg supported protocols protocols = check_output ([ path , \"-hide_banner\" , \"-protocols\" ]) splitted = [ x . decode ( \"utf-8\" ) . strip () for x in protocols . split ( b \" \\n \" )] supported_protocols = splitted [ splitted . index ( \"Output:\" ) + 1 : len ( splitted ) - 1 ] # rtsp is a demuxer somehow supported_protocols += [ \"rtsp\" ] if \"rtsp\" in get_supported_demuxers ( path ) else [] # Test and return result whether scheme is supported if extracted_scheme_url and extracted_scheme_url in supported_protocols : logging and logger . debug ( \"URL scheme ` {} ` is supported by FFmpeg.\" . format ( extracted_scheme_url ) ) return True else : logger . warning ( \"URL scheme ` {} ` isn't supported by FFmpeg!\" . format ( extracted_scheme_url ) ) return False import_dependency_safe \u2693 Imports specified dependency safely. By default( error = raise ), if a dependency is missing, an ImportError with a meaningful message will be raised. Otherwise if error = log a warning will be logged and on error = silent everything will be quit. But If a dependency is present, but older than specified, an error is raised if specified. Parameters: Name Type Description Default name string name of dependency to be imported. required error string raise or Log or silence ImportError. Possible values are \"raise\" , \"log\" and silent . Default is \"raise\" . 'raise' pkg_name string (Optional) package name of dependency(if different pip name). Otherwise name will be used. None min_version string (Optional) required minimum version of the dependency to be imported. None custom_message string (Optional) custom Import error message to be raised or logged. None Returns: The imported module, when found and the version is correct(if specified). Otherwise None . Source code in vidgear/gears/helper.py def import_dependency_safe ( name , error = \"raise\" , pkg_name = None , min_version = None , custom_message = None , ): \"\"\" ## import_dependency_safe Imports specified dependency safely. By default(`error = raise`), if a dependency is missing, an ImportError with a meaningful message will be raised. Otherwise if `error = log` a warning will be logged and on `error = silent` everything will be quit. But If a dependency is present, but older than specified, an error is raised if specified. Parameters: name (string): name of dependency to be imported. error (string): raise or Log or silence ImportError. Possible values are `\"raise\"`, `\"log\"` and `silent`. Default is `\"raise\"`. pkg_name (string): (Optional) package name of dependency(if different `pip` name). Otherwise `name` will be used. min_version (string): (Optional) required minimum version of the dependency to be imported. custom_message (string): (Optional) custom Import error message to be raised or logged. **Returns:** The imported module, when found and the version is correct(if specified). Otherwise `None`. \"\"\" # check specified parameters sub_class = \"\" if not name or not isinstance ( name , str ): return None else : # extract name in case of relative import name = name . strip () if name . startswith ( \"from\" ): name = name . split ( \" \" ) name , sub_class = ( name [ 1 ] . strip (), name [ - 1 ] . strip ()) assert error in [ \"raise\" , \"log\" , \"silent\" , ], \"[Vidgear:ERROR] :: Invalid value at `error` parameter.\" # specify package name of dependency(if defined). Otherwise use name install_name = pkg_name if not ( pkg_name is None ) else name # create message msg = ( custom_message if not ( custom_message is None ) else \"Failed to find required dependency ' {} '. Install it with `pip install {} ` command.\" . format ( name , install_name ) ) # try importing dependency try : module = importlib . import_module ( name ) if sub_class : module = getattr ( module , sub_class ) except Exception : # handle errors. if error == \"raise\" : raise ImportError ( msg ) from None elif error == \"log\" : logger . error ( msg ) return None else : return None # check if minimum required version if not ( min_version ) is None : # Handle submodules parent_module = name . split ( \".\" )[ 0 ] if parent_module != name : # grab parent module module_to_get = sys . modules [ parent_module ] else : module_to_get = module # extract version version = get_module_version ( module_to_get ) # verify if LooseVersion ( version ) < LooseVersion ( min_version ): # create message msg = \"\"\"Unsupported version ' {} ' found. Vidgear requires ' {} ' dependency installed with version ' {} ' or greater. Update it with `pip install -U {} ` command.\"\"\" . format ( parent_module , min_version , version , install_name ) # handle errors. if error == \"silent\" : return None else : # raise raise ImportError ( msg ) return module get_video_bitrate \u2693 Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values Parameters: Name Type Description Default width int video-width required height int video-height required fps float video-framerate required bpp float bit-per-pixels value required Returns: Video bitrate (in Kbps) as integer. Source code in vidgear/gears/helper.py def get_video_bitrate ( width , height , fps , bpp ): \"\"\" ## get_video_bitrate Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values Parameters: width (int): video-width height (int): video-height fps (float): video-framerate bpp (float): bit-per-pixels value **Returns:** Video bitrate _(in Kbps)_ as integer. \"\"\" return round (( width * height * bpp * fps ) / 1000 ) check_WriteAccess \u2693 Checks whether given path directory has Write-Access. Parameters: Name Type Description Default path string absolute path of directory required is_windows boolean is running on Windows OS? False logging bool enables logging for its operations False Returns: A boolean value, confirming whether Write-Access available, or not?. Source code in vidgear/gears/helper.py def check_WriteAccess ( path , is_windows = False , logging = False ): \"\"\" ## check_WriteAccess Checks whether given path directory has Write-Access. Parameters: path (string): absolute path of directory is_windows (boolean): is running on Windows OS? logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether Write-Access available, or not?. \"\"\" # check if path exists dirpath = Path ( path ) try : if not ( dirpath . exists () and dirpath . is_dir ()): logger . warning ( \"Specified directory ` {} ` doesn't exists or valid.\" . format ( path ) ) return False else : path = dirpath . resolve () except : return False # check filepath on *nix systems if not is_windows : uid = os . geteuid () gid = os . getegid () s = os . stat ( path ) mode = s [ stat . ST_MODE ] return ( (( s [ stat . ST_UID ] == uid ) and ( mode & stat . S_IWUSR )) or (( s [ stat . ST_GID ] == gid ) and ( mode & stat . S_IWGRP )) or ( mode & stat . S_IWOTH ) ) # otherwise, check filepath on windows else : write_accessible = False temp_fname = os . path . join ( path , \"temp.tmp\" ) try : fd = os . open ( temp_fname , os . O_WRONLY | os . O_CREAT | os . O_TRUNC ) os . close ( fd ) write_accessible = True except Exception as e : if isinstance ( e , PermissionError ): logger . error ( \"You don't have adequate access rights to use ` {} ` directory!\" . format ( path ) ) logging and logger . exception ( str ( e )) finally : delete_file_safe ( temp_fname ) return write_accessible check_open_port \u2693 Checks whether specified port open at given IP address. Parameters: Name Type Description Default address string given IP address. required port int check if port is open at given address. 22 Returns: A boolean value, confirming whether given port is open at given IP address. Source code in vidgear/gears/helper.py def check_open_port ( address , port = 22 ): \"\"\" ## check_open_port Checks whether specified port open at given IP address. Parameters: address (string): given IP address. port (int): check if port is open at given address. **Returns:** A boolean value, confirming whether given port is open at given IP address. \"\"\" if not address : return False with closing ( socket . socket ( socket . AF_INET , socket . SOCK_STREAM )) as sock : if sock . connect_ex (( address , port )) == 0 : return True else : return False delete_ext_safe \u2693 Safely deletes files at given path. Parameters: Name Type Description Default file_path string path to the file required Source code in vidgear/gears/helper.py def delete_file_safe ( file_path ): \"\"\" ## delete_ext_safe Safely deletes files at given path. Parameters: file_path (string): path to the file \"\"\" try : dfile = Path ( file_path ) if sys . version_info >= ( 3 , 8 , 0 ): dfile . unlink ( missing_ok = True ) else : dfile . exists () and dfile . unlink () except Exception as e : logger . exception ( str ( e )) get_supported_demuxers \u2693 Find and returns FFmpeg's supported demuxers Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required Returns: List of supported demuxers. Source code in vidgear/gears/helper.py def get_supported_demuxers ( path ): \"\"\" ## get_supported_demuxers Find and returns FFmpeg's supported demuxers Parameters: path (string): absolute path of FFmpeg binaries **Returns:** List of supported demuxers. \"\"\" demuxers = check_output ([ path , \"-hide_banner\" , \"-demuxers\" ]) splitted = [ x . decode ( \"utf-8\" ) . strip () for x in demuxers . split ( b \" \\n \" )] supported_demuxers = splitted [ splitted . index ( \"--\" ) + 1 : len ( splitted ) - 1 ] # compile regex finder = re . compile ( r \"\\s\\s[a-z0-9_,-]+\\s+\" ) # find all outputs outputs = finder . findall ( \" \\n \" . join ( supported_demuxers )) # return output findings return [ o . strip () for o in outputs ] get_supported_vencoders \u2693 Find and returns FFmpeg's supported video encoders Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required Returns: List of supported encoders. Source code in vidgear/gears/helper.py def get_supported_vencoders ( path ): \"\"\" ## get_supported_vencoders Find and returns FFmpeg's supported video encoders Parameters: path (string): absolute path of FFmpeg binaries **Returns:** List of supported encoders. \"\"\" encoders = check_output ([ path , \"-hide_banner\" , \"-encoders\" ]) splitted = encoders . split ( b \" \\n \" ) # extract video encoders supported_vencoders = [ x . decode ( \"utf-8\" ) . strip () for x in splitted [ 2 : len ( splitted ) - 1 ] if x . decode ( \"utf-8\" ) . strip () . startswith ( \"V\" ) ] # compile regex finder = re . compile ( r \"[A-Z]*[\\.]+[A-Z]*\\s[a-z0-9_-]*\" ) # find all outputs outputs = finder . findall ( \" \\n \" . join ( supported_vencoders )) # return output findings return [[ s for s in o . split ( \" \" )][ - 1 ] for o in outputs ] validate_auth_keys \u2693 Validates, and also maintains generated ZMQ CURVE Key-pairs. Parameters: Name Type Description Default path string path of generated CURVE key-pairs required extension string type of key-pair to be validated required Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/helper.py def validate_auth_keys ( path , extension ): \"\"\" ## validate_auth_keys Validates, and also maintains generated ZMQ CURVE Key-pairs. Parameters: path (string): path of generated CURVE key-pairs extension (string): type of key-pair to be validated **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" # check for valid path if not ( os . path . exists ( path )): return False # check if directory empty if not ( os . listdir ( path )): return False keys_buffer = [] # stores auth-keys # loop over auth-keys for key_file in os . listdir ( path ): key = os . path . splitext ( key_file ) # check if valid key is generated if key and ( key [ 0 ] in [ \"server\" , \"client\" ]) and ( key [ 1 ] == extension ): keys_buffer . append ( key_file ) # store it # remove invalid keys if found len ( keys_buffer ) == 1 and delete_file_safe ( os . path . join ( path , keys_buffer [ 0 ])) # return results return True if ( len ( keys_buffer ) == 2 ) else False","title":"Helper Methods"},{"location":"bonus/reference/helper/#vidgear.gears.helper.logger_handler--logger_handler","text":"Returns the logger handler Returns: A logger handler Source code in vidgear/gears/helper.py def logger_handler (): \"\"\" ## logger_handler Returns the logger handler **Returns:** A logger handler \"\"\" # logging formatter formatter = ColoredFormatter ( \" {green}{asctime}{reset} :: {bold_purple}{name:^13}{reset} :: {log_color}{levelname:^8}{reset} :: {bold_white}{message} \" , datefmt = \"%H:%M:%S\" , reset = True , log_colors = { \"INFO\" : \"bold_cyan\" , \"DEBUG\" : \"bold_yellow\" , \"WARNING\" : \"bold_red,fg_thin_yellow\" , \"ERROR\" : \"bold_red\" , \"CRITICAL\" : \"bold_red,bg_white\" , }, style = \"{\" , ) # check if VIDGEAR_LOGFILE defined file_mode = os . environ . get ( \"VIDGEAR_LOGFILE\" , False ) # define handler handler = log . StreamHandler () if file_mode and isinstance ( file_mode , str ): file_path = os . path . abspath ( file_mode ) if ( os . name == \"nt\" or os . access in os . supports_effective_ids ) and os . access ( os . path . dirname ( file_path ), os . W_OK ): file_path = ( os . path . join ( file_path , \"vidgear.log\" ) if os . path . isdir ( file_path ) else file_path ) handler = log . FileHandler ( file_path , mode = \"a\" ) formatter = log . Formatter ( \" {asctime} :: {name} :: {levelname} :: {message} \" , datefmt = \"%H:%M:%S\" , style = \"{\" , ) handler . setFormatter ( formatter ) return handler","title":"logger_handler"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_CV_version--check_cv_version","text":"Returns: OpenCV's version first bit Source code in vidgear/gears/helper.py def check_CV_version (): \"\"\" ## check_CV_version **Returns:** OpenCV's version first bit \"\"\" if LooseVersion ( cv2 . __version__ ) >= LooseVersion ( \"4\" ): return 4 else : return 3","title":"check_CV_version"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_gstreamer_support--check_gstreamer_support","text":"Checks whether OpenCV is compiled with Gstreamer( >=1.0.0 ) support. Parameters: Name Type Description Default logging bool enables logging for its operations False Returns: A Boolean value Source code in vidgear/gears/helper.py def check_gstreamer_support ( logging = False ): \"\"\" ## check_gstreamer_support Checks whether OpenCV is compiled with Gstreamer(`>=1.0.0`) support. Parameters: logging (bool): enables logging for its operations **Returns:** A Boolean value \"\"\" raw = cv2 . getBuildInformation () gst = [ x . strip () for x in raw . split ( \" \\n \" ) if x and re . search ( r \"GStreamer[,-:]+\\s*(?:YES|NO)\" , x ) ] if gst and \"YES\" in gst [ 0 ]: version = re . search ( r \"(\\d+\\.)?(\\d+\\.)?(\\*|\\d+)\" , gst [ 0 ]) logging and logger . debug ( \"Found GStreamer version: {} \" . format ( version [ 0 ])) return version [ 0 ] >= \"1.0.0\" else : logger . warning ( \"GStreamer not found!\" ) return False","title":"check_gstreamer_support"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_supported_resolution--get_supported_resolution","text":"Parameters: Name Type Description Default value string value to be validated required logging bool enables logging for its operations False Returns: Valid stream resolution Source code in vidgear/gears/helper.py def get_supported_resolution ( value , logging = False ): \"\"\" ## get_supported_resolution Parameters: value (string): value to be validated logging (bool): enables logging for its operations **Returns:** Valid stream resolution \"\"\" # default to best stream_resolution = \"best\" supported_stream_qualities = [ \"144p\" , \"240p\" , \"360p\" , \"480p\" , \"720p\" , \"1080p\" , \"1440p\" , \"2160p\" , \"4320p\" , \"worst\" , \"best\" , ] if isinstance ( value , str ): if value . strip () . lower () in supported_stream_qualities : stream_resolution = value . strip () . lower () logging and logger . debug ( \"Selecting ` {} ` resolution for streams.\" . format ( stream_resolution ) ) else : logger . warning ( \"Specified stream-resolution ` {} ` is not supported. Reverting to `best`!\" . format ( value ) ) else : logger . warning ( \"Specified stream-resolution ` {} ` is Invalid. Reverting to `best`!\" . format ( value ) ) return stream_resolution","title":"get_supported_resolution"},{"location":"bonus/reference/helper/#vidgear.gears.helper.dimensions_to_resolutions--dimensions_to_resolutions","text":"Parameters: Name Type Description Default value list list of dimensions (e.g. 640x360 ) required Returns: list of resolutions (e.g. 360p ) Source code in vidgear/gears/helper.py def dimensions_to_resolutions ( value ): \"\"\" ## dimensions_to_resolutions Parameters: value (list): list of dimensions (e.g. `640x360`) **Returns:** list of resolutions (e.g. `360p`) \"\"\" supported_resolutions = { \"256x144\" : \"144p\" , \"426x240\" : \"240p\" , \"640x360\" : \"360p\" , \"854x480\" : \"480p\" , \"1280x720\" : \"720p\" , \"1920x1080\" : \"1080p\" , \"2560x1440\" : \"1440p\" , \"3840x2160\" : \"2160p\" , \"7680x4320\" : \"4320p\" , } return ( list ( map ( supported_resolutions . get , value , value )) if isinstance ( value , list ) else [] )","title":"dimensions_to_resolutions"},{"location":"bonus/reference/helper/#vidgear.gears.helper.mkdir_safe--mkdir_safe","text":"Safely creates directory at given path. Parameters: Name Type Description Default dir_path string path to the directory required logging bool enables logging for its operations False Source code in vidgear/gears/helper.py def mkdir_safe ( dir_path , logging = False ): \"\"\" ## mkdir_safe Safely creates directory at given path. Parameters: dir_path (string): path to the directory logging (bool): enables logging for its operations \"\"\" try : os . makedirs ( dir_path ) logging and logger . debug ( \"Created directory at ` {} `\" . format ( dir_path )) except ( OSError , IOError ) as e : if e . errno != errno . EACCES and e . errno != errno . EEXIST : raise","title":"mkdir_safe"},{"location":"bonus/reference/helper/#vidgear.gears.helper.delete_ext_safe--delete_ext_safe","text":"Safely deletes files with given extensions at given path. Parameters: Name Type Description Default dir_path string path to the directory required extensions list list of extensions to be deleted [] logging bool enables logging for its operations False Source code in vidgear/gears/helper.py def delete_ext_safe ( dir_path , extensions = [], logging = False ): \"\"\" ## delete_ext_safe Safely deletes files with given extensions at given path. Parameters: dir_path (string): path to the directory extensions (list): list of extensions to be deleted logging (bool): enables logging for its operations \"\"\" if not extensions or not os . path . exists ( dir_path ): logger . warning ( \"Invalid input provided for deleting!\" ) return logger . critical ( \"Clearing Assets at ` {} `!\" . format ( dir_path )) for ext in extensions : if len ( ext ) == 2 : files_ext = [ os . path . join ( dir_path , f ) for f in os . listdir ( dir_path ) if f . startswith ( ext [ 0 ]) and f . endswith ( ext [ 1 ]) ] else : files_ext = [ os . path . join ( dir_path , f ) for f in os . listdir ( dir_path ) if f . endswith ( ext ) ] for file in files_ext : delete_file_safe ( file ) logging and logger . debug ( \"Deleted file: ` {} `\" . format ( file ))","title":"delete_ext_safe"},{"location":"bonus/reference/helper/#vidgear.gears.helper.capPropId--cappropid","text":"Retrieves the OpenCV property's Integer(Actual) value from string. Parameters: Name Type Description Default property string inputs OpenCV property as string. required logging bool enables logging for its operations True Returns: Resultant integer value. Source code in vidgear/gears/helper.py def capPropId ( property , logging = True ): \"\"\" ## capPropId Retrieves the OpenCV property's Integer(Actual) value from string. Parameters: property (string): inputs OpenCV property as string. logging (bool): enables logging for its operations **Returns:** Resultant integer value. \"\"\" integer_value = 0 try : integer_value = getattr ( cv2 , property ) except Exception as e : if logging : logger . exception ( str ( e )) logger . critical ( \"` {} ` is not a valid OpenCV property!\" . format ( property )) return None return integer_value","title":"capPropId"},{"location":"bonus/reference/helper/#vidgear.gears.helper.reducer--reducer","text":"Reduces frame size by given percentage Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None percentage int/float inputs size-reduction percentage. 0 interpolation int Change resize interpolation. 4 Returns: A reduced numpy ndarray array. Source code in vidgear/gears/helper.py def reducer ( frame = None , percentage = 0 , interpolation = cv2 . INTER_LANCZOS4 ): \"\"\" ## reducer Reduces frame size by given percentage Parameters: frame (numpy.ndarray): inputs numpy array(frame). percentage (int/float): inputs size-reduction percentage. interpolation (int): Change resize interpolation. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None : raise ValueError ( \"[Helper:ERROR] :: Input frame cannot be NoneType!\" ) # check if valid reduction percentage is given if not ( percentage > 0 and percentage < 90 ): raise ValueError ( \"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\" ) if not ( isinstance ( interpolation , int )): raise ValueError ( \"[Helper:ERROR] :: Given interpolation is invalid, Kindly refer docs.\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # calculate the ratio of the width from percentage reduction = (( 100 - percentage ) / 100 ) * width ratio = reduction / float ( width ) # construct the dimensions dimensions = ( int ( reduction ), int ( height * ratio )) # return the resized frame return cv2 . resize ( frame , dimensions , interpolation = interpolation )","title":"reducer"},{"location":"bonus/reference/helper/#vidgear.gears.helper.create_blank_frame--create_blank_frame","text":"Create blank frames of given frame size with text Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None text str Text to be written on frame. '' Returns: A reduced numpy ndarray array. Source code in vidgear/gears/helper.py def create_blank_frame ( frame = None , text = \"\" , logging = False ): \"\"\" ## create_blank_frame Create blank frames of given frame size with text Parameters: frame (numpy.ndarray): inputs numpy array(frame). text (str): Text to be written on frame. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None or not ( isinstance ( frame , np . ndarray )): raise ValueError ( \"[Helper:ERROR] :: Input frame is invalid!\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # create blank frame blank_frame = np . zeros ( frame . shape , frame . dtype ) # setup text if text and isinstance ( text , str ): logging and logger . debug ( \"Adding text: {} \" . format ( text )) # setup font font = cv2 . FONT_HERSHEY_SCRIPT_COMPLEX # get boundary of this text fontScale = min ( height , width ) / ( 25 / 0.25 ) textsize = cv2 . getTextSize ( text , font , fontScale , 5 )[ 0 ] # get coords based on boundary textX = ( width - textsize [ 0 ]) // 2 textY = ( height + textsize [ 1 ]) // 2 # put text cv2 . putText ( blank_frame , text , ( textX , textY ), font , fontScale , ( 125 , 125 , 125 ), 6 ) # return frame return blank_frame","title":"create_blank_frame"},{"location":"bonus/reference/helper/#vidgear.gears.helper.dict2Args--dict2args","text":"Converts dictionary attributes to list(args) Parameters: Name Type Description Default param_dict dict Parameters dictionary required Returns: Arguments list Source code in vidgear/gears/helper.py def dict2Args ( param_dict ): \"\"\" ## dict2Args Converts dictionary attributes to list(args) Parameters: param_dict (dict): Parameters dictionary **Returns:** Arguments list \"\"\" args = [] for key in param_dict . keys (): if key in [ \"-clones\" ] or key . startswith ( \"-core\" ): if isinstance ( param_dict [ key ], list ): args . extend ( param_dict [ key ]) else : logger . warning ( \" {} with invalid datatype:` {} `, Skipped!\" . format ( \"Core parameter\" if key . startswith ( \"-core\" ) else \"Clone\" , param_dict [ key ], ) ) else : args . append ( key ) args . append ( str ( param_dict [ key ])) return args","title":"dict2Args"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_valid_ffmpeg_path--get_valid_ffmpeg_path","text":"Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: Name Type Description Default custom_ffmpeg string path to custom FFmpeg executables '' is_windows boolean is running on Windows OS? False ffmpeg_download_path string FFmpeg static binaries download location (Windows only) '' logging bool enables logging for its operations False Returns: A valid FFmpeg executable path string. Source code in vidgear/gears/helper.py def get_valid_ffmpeg_path ( custom_ffmpeg = \"\" , is_windows = False , ffmpeg_download_path = \"\" , logging = False ): \"\"\" ## get_valid_ffmpeg_path Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: custom_ffmpeg (string): path to custom FFmpeg executables is_windows (boolean): is running on Windows OS? ffmpeg_download_path (string): FFmpeg static binaries download location _(Windows only)_ logging (bool): enables logging for its operations **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if is_windows : # checks if current os is windows if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable final_path += custom_ffmpeg else : # otherwise auto-download them try : if not ( ffmpeg_download_path ): # otherwise save to Temp Directory import tempfile ffmpeg_download_path = tempfile . gettempdir () logging and logger . debug ( \"FFmpeg Windows Download Path: {} \" . format ( ffmpeg_download_path ) ) # download Binaries os_bit = ( ( \"win64\" if platform . machine () . endswith ( \"64\" ) else \"win32\" ) if is_windows else \"\" ) _path = download_ffmpeg_binaries ( path = ffmpeg_download_path , os_windows = is_windows , os_bit = os_bit ) # assign to local variable final_path += _path except Exception as e : # log if any error occurred logger . exception ( str ( e )) logger . error ( \"Error in downloading FFmpeg binaries, Check your network and Try again!\" ) return False if os . path . isfile ( final_path ): # check if valid FFmpeg file exist pass elif os . path . isfile ( os . path . join ( final_path , \"ffmpeg.exe\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( final_path , \"ffmpeg.exe\" ) else : # else return False logging and logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise perform test for Unix if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable if os . path . isfile ( custom_ffmpeg ): # check if valid FFmpeg file exist final_path += custom_ffmpeg elif os . path . isfile ( os . path . join ( custom_ffmpeg , \"ffmpeg\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( custom_ffmpeg , \"ffmpeg\" ) else : # else return False logging and logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise assign ffmpeg binaries from system final_path += \"ffmpeg\" logging and logger . debug ( \"Final FFmpeg Path: {} \" . format ( final_path )) # Final Auto-Validation for FFmeg Binaries. returns final path if test is passed return final_path if validate_ffmpeg ( final_path , logging = logging ) else False","title":"get_valid_ffmpeg_path"},{"location":"bonus/reference/helper/#vidgear.gears.helper.download_ffmpeg_binaries--download_ffmpeg_binaries","text":"Generates FFmpeg Static Binaries for windows(if not available) Parameters: Name Type Description Default path string path for downloading custom FFmpeg executables required os_windows boolean is running on Windows OS? False os_bit string 32-bit or 64-bit OS? '' Returns: A valid FFmpeg executable path string. Source code in vidgear/gears/helper.py def download_ffmpeg_binaries ( path , os_windows = False , os_bit = \"\" ): \"\"\" ## download_ffmpeg_binaries Generates FFmpeg Static Binaries for windows(if not available) Parameters: path (string): path for downloading custom FFmpeg executables os_windows (boolean): is running on Windows OS? os_bit (string): 32-bit or 64-bit OS? **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if os_windows and os_bit : # initialize with available FFmpeg Static Binaries GitHub Server file_url = \"https://github.com/abhiTronix/FFmpeg-Builds/releases/latest/download/ffmpeg-static- {} -gpl.zip\" . format ( os_bit ) file_name = os . path . join ( os . path . abspath ( path ), \"ffmpeg-static- {} -gpl.zip\" . format ( os_bit ) ) file_path = os . path . join ( os . path . abspath ( path ), \"ffmpeg-static- {} -gpl/bin/ffmpeg.exe\" . format ( os_bit ), ) base_path , _ = os . path . split ( file_name ) # extract file base path # check if file already exists if os . path . isfile ( file_path ): final_path += file_path # skip download if does else : # import libs import zipfile # check if given path has write access assert os . access ( path , os . W_OK ), ( \"[Helper:ERROR] :: Permission Denied, Cannot write binaries to directory = \" + path ) # remove leftovers if exists os . path . isfile ( file_name ) and delete_file_safe ( file_name ) # download and write file to the given path with open ( file_name , \"wb\" ) as f : logger . debug ( \"No Custom FFmpeg path provided. Auto-Installing FFmpeg static binaries from GitHub Mirror now. Please wait...\" ) # create session with requests . Session () as http : # setup retry strategy retries = Retry ( total = 3 , backoff_factor = 1 , status_forcelist = [ 429 , 500 , 502 , 503 , 504 ], ) # Mount it for https usage adapter = TimeoutHTTPAdapter ( timeout = 2.0 , max_retries = retries ) http . mount ( \"https://\" , adapter ) response = http . get ( file_url , stream = True ) response . raise_for_status () total_length = response . headers . get ( \"content-length\" ) assert not ( total_length is None ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\" bar = tqdm ( total = int ( total_length ), unit = \"B\" , unit_scale = True ) for data in response . iter_content ( chunk_size = 4096 ): f . write ( data ) len ( data ) > 0 and bar . update ( len ( data )) bar . close () logger . debug ( \"Extracting executables.\" ) with zipfile . ZipFile ( file_name , \"r\" ) as zip_ref : zip_fname , _ = os . path . split ( zip_ref . infolist ()[ 0 ] . filename ) zip_ref . extractall ( base_path ) # perform cleaning delete_file_safe ( file_name ) logger . debug ( \"FFmpeg binaries for Windows configured successfully!\" ) final_path += file_path # return final path return final_path","title":"download_ffmpeg_binaries"},{"location":"bonus/reference/helper/#vidgear.gears.helper.validate_ffmpeg--validate_ffmpeg","text":"Validate FFmeg Binaries. returns True if tests are passed. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required logging bool enables logging for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/helper.py def validate_ffmpeg ( path , logging = False ): \"\"\" ## validate_ffmpeg Validate FFmeg Binaries. returns `True` if tests are passed. Parameters: path (string): absolute path of FFmpeg binaries logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" try : # get the FFmpeg version version = check_output ([ path , \"-version\" ]) firstline = version . split ( b \" \\n \" )[ 0 ] version = firstline . split ( b \" \" )[ 2 ] . strip () if logging : # log if test are passed logger . debug ( \"FFmpeg validity Test Passed!\" ) logger . debug ( \"Found valid FFmpeg Version: ` {} ` installed on this system\" . format ( version ) ) except Exception as e : # log if test are failed if logging : logger . exception ( str ( e )) logger . warning ( \"FFmpeg validity Test Failed!\" ) return False return True","title":"validate_ffmpeg"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_output--check_output","text":"Returns stdin output from subprocess module Source code in vidgear/gears/helper.py def check_output ( * args , ** kwargs ): \"\"\" ## check_output Returns stdin output from subprocess module \"\"\" # import libs import subprocess as sp # workaround for python bug: https://bugs.python.org/issue37380 if platform . system () == \"Windows\" : # see comment https://bugs.python.org/msg370334 sp . _cleanup = lambda : None # handle additional params retrieve_stderr = kwargs . pop ( \"force_retrieve_stderr\" , False ) # execute command in subprocess process = sp . Popen ( stdout = sp . PIPE , stderr = sp . DEVNULL if not ( retrieve_stderr ) else sp . PIPE , * args , ** kwargs , ) output , stderr = process . communicate () retcode = process . poll () # handle return code if retcode and not ( retrieve_stderr ): cmd = kwargs . get ( \"args\" ) if cmd is None : cmd = args [ 0 ] error = sp . CalledProcessError ( retcode , cmd ) error . output = output raise error return output if not ( retrieve_stderr ) else stderr","title":"check_output"},{"location":"bonus/reference/helper/#vidgear.gears.helper.generate_auth_certificates--generate_auth_certificates","text":"Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode. Parameters: Name Type Description Default path string path for generating CURVE key-pairs required overwrite boolean overwrite existing key-pairs or not? False logging bool enables logging for its operations False Returns: A valid CURVE key-pairs path as string. Source code in vidgear/gears/helper.py def generate_auth_certificates ( path , overwrite = False , logging = False ): \"\"\" ## generate_auth_certificates Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode. Parameters: path (string): path for generating CURVE key-pairs overwrite (boolean): overwrite existing key-pairs or not? logging (bool): enables logging for its operations **Returns:** A valid CURVE key-pairs path as string. \"\"\" # import necessary lib import zmq.auth # check if path corresponds to vidgear only if os . path . basename ( path ) != \".vidgear\" : path = os . path . join ( path , \".vidgear\" ) # generate keys dir keys_dir = os . path . join ( path , \"keys\" ) mkdir_safe ( keys_dir , logging = logging ) # generate separate public and private key dirs public_keys_dir = os . path . join ( keys_dir , \"public_keys\" ) secret_keys_dir = os . path . join ( keys_dir , \"private_keys\" ) # check if overwriting is allowed if overwrite : # delete previous certificates for dirs in [ public_keys_dir , secret_keys_dir ]: if os . path . exists ( dirs ): shutil . rmtree ( dirs ) mkdir_safe ( dirs , logging = logging ) # generate new keys server_public_file , server_secret_file = zmq . auth . create_certificates ( keys_dir , \"server\" ) client_public_file , client_secret_file = zmq . auth . create_certificates ( keys_dir , \"client\" ) # move keys to their appropriate directory respectively for key_file in os . listdir ( keys_dir ): if key_file . endswith ( \".key\" ): shutil . move ( os . path . join ( keys_dir , key_file ), public_keys_dir ) elif key_file . endswith ( \".key_secret\" ): shutil . move ( os . path . join ( keys_dir , key_file ), secret_keys_dir ) else : # clean redundant keys if present redundant_key = os . path . join ( keys_dir , key_file ) if os . path . isfile ( redundant_key ): delete_file_safe ( redundant_key ) else : # otherwise validate available keys status_public_keys = validate_auth_keys ( public_keys_dir , \".key\" ) status_private_keys = validate_auth_keys ( secret_keys_dir , \".key_secret\" ) # check if all valid keys are found if status_private_keys and status_public_keys : return ( keys_dir , secret_keys_dir , public_keys_dir ) # check if valid public keys are found if not ( status_public_keys ): mkdir_safe ( public_keys_dir , logging = logging ) # check if valid private keys are found if not ( status_private_keys ): mkdir_safe ( secret_keys_dir , logging = logging ) # generate new keys server_public_file , server_secret_file = zmq . auth . create_certificates ( keys_dir , \"server\" ) client_public_file , client_secret_file = zmq . auth . create_certificates ( keys_dir , \"client\" ) # move keys to their appropriate directory respectively for key_file in os . listdir ( keys_dir ): if key_file . endswith ( \".key\" ) and not ( status_public_keys ): shutil . move ( os . path . join ( keys_dir , key_file ), os . path . join ( public_keys_dir , \".\" ) ) elif key_file . endswith ( \".key_secret\" ) and not ( status_private_keys ): shutil . move ( os . path . join ( keys_dir , key_file ), os . path . join ( secret_keys_dir , \".\" ) ) else : # clean redundant keys if present redundant_key = os . path . join ( keys_dir , key_file ) if os . path . isfile ( redundant_key ): delete_file_safe ( redundant_key ) # validate newly generated keys status_public_keys = validate_auth_keys ( public_keys_dir , \".key\" ) status_private_keys = validate_auth_keys ( secret_keys_dir , \".key_secret\" ) # raise error is validation test fails if not ( status_private_keys ) or not ( status_public_keys ): raise RuntimeError ( \"[Helper:ERROR] :: Unable to generate valid ZMQ authentication certificates at ` {} `!\" . format ( keys_dir ) ) # finally return valid key paths return ( keys_dir , secret_keys_dir , public_keys_dir )","title":"generate_auth_certificates"},{"location":"bonus/reference/helper/#vidgear.gears.helper.validate_audio--validate_audio","text":"Validates audio by retrieving audio-bitrate from file. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required source string/list source to be validated. None Returns: A string value, confirming whether audio is present, or not?. Source code in vidgear/gears/helper.py def validate_audio ( path , source = None ): \"\"\" ## validate_audio Validates audio by retrieving audio-bitrate from file. Parameters: path (string): absolute path of FFmpeg binaries source (string/list): source to be validated. **Returns:** A string value, confirming whether audio is present, or not?. \"\"\" if source is None or not ( source ): logger . warning ( \"Audio input source is empty!\" ) return \"\" # create ffmpeg command cmd = [ path , \"-hide_banner\" ] + ( source if isinstance ( source , list ) else [ \"-i\" , source ] ) # extract audio sample-rate from metadata metadata = check_output ( cmd , force_retrieve_stderr = True ) audio_bitrate = re . findall ( r \"fltp,\\s[0-9]+\\s\\w\\w[/]s\" , metadata . decode ( \"utf-8\" )) sample_rate_identifiers = [ \"Audio\" , \"Hz\" ] + ( [ \"fltp\" ] if isinstance ( source , str ) else [] ) audio_sample_rate = [ line . strip () for line in metadata . decode ( \"utf-8\" ) . split ( \" \\n \" ) if all ( x in line for x in sample_rate_identifiers ) ] if audio_bitrate : filtered = audio_bitrate [ 0 ] . split ( \" \" )[ 1 : 3 ] final_bitrate = \" {}{} \" . format ( int ( filtered [ 0 ] . strip ()), \"k\" if ( filtered [ 1 ] . strip () . startswith ( \"k\" )) else \"M\" , ) return final_bitrate elif audio_sample_rate : sample_rate = re . findall ( r \"[0-9]+\\sHz\" , audio_sample_rate [ 0 ])[ 0 ] sample_rate_value = int ( sample_rate . split ( \" \" )[ 0 ]) samplerate_2_bitrate = int ( ( sample_rate_value - 44100 ) * ( 320 - 96 ) / ( 48000 - 44100 ) + 96 ) return str ( samplerate_2_bitrate ) + \"k\" else : return \"\"","title":"validate_audio"},{"location":"bonus/reference/helper/#vidgear.gears.helper.extract_time--extract_time","text":"Extract time from give string value. Parameters: Name Type Description Default value string string value. required Returns: Time (in seconds) as integer. Source code in vidgear/gears/helper.py def extract_time ( value ): \"\"\" ## extract_time Extract time from give string value. Parameters: value (string): string value. **Returns:** Time _(in seconds)_ as integer. \"\"\" if not ( value ): logger . warning ( \"Value is empty!\" ) return 0 else : stripped_data = value . strip () t_duration = re . findall ( r \"(?:[01]\\d|2[0123]):(?:[012345]\\d):(?:[012345]\\d)\" , stripped_data ) return ( sum ( int ( x ) * 60 ** i for i , x in enumerate ( reversed ( t_duration [ 0 ] . split ( \":\" ))) ) if t_duration else 0 )","title":"extract_time"},{"location":"bonus/reference/helper/#vidgear.gears.helper.validate_video--validate_video","text":"Validates video by retrieving resolution/size and framerate from file. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required video_path string absolute path to Video. None Returns: A dictionary of retieved Video resolution (as tuple(width, height)) and framerate (as float) . Source code in vidgear/gears/helper.py def validate_video ( path , video_path = None , logging = False ): \"\"\" ## validate_video Validates video by retrieving resolution/size and framerate from file. Parameters: path (string): absolute path of FFmpeg binaries video_path (string): absolute path to Video. **Returns:** A dictionary of retieved Video resolution _(as tuple(width, height))_ and framerate _(as float)_. \"\"\" if video_path is None or not ( video_path ): logger . warning ( \"Video path is empty!\" ) return None # extract metadata metadata = check_output ( [ path , \"-hide_banner\" , \"-i\" , video_path ], force_retrieve_stderr = True ) # clean and search stripped_data = [ x . decode ( \"utf-8\" ) . strip () for x in metadata . split ( b \" \\n \" )] logging and logger . debug ( stripped_data ) result = {} for data in stripped_data : output_a = re . findall ( r \"([1-9]\\d+)x([1-9]\\d+)\" , data ) output_b = re . findall ( r \"\\d+(?:\\.\\d+)?\\sfps\" , data ) if len ( result ) == 2 : break if output_b and not \"framerate\" in result : result [ \"framerate\" ] = re . findall ( r \"[\\d\\.\\d]+\" , output_b [ 0 ])[ 0 ] if output_a and not \"resolution\" in result : result [ \"resolution\" ] = output_a [ - 1 ] # return values return result if ( len ( result ) == 2 ) else None","title":"validate_video"},{"location":"bonus/reference/helper/#vidgear.gears.helper.is_valid_url--is_valid_url","text":"Checks URL validity by testing its scheme against FFmpeg's supported protocols Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required url string URL to be validated None logging bool enables logging for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/helper.py def is_valid_url ( path , url = None , logging = False ): \"\"\" ## is_valid_url Checks URL validity by testing its scheme against FFmpeg's supported protocols Parameters: path (string): absolute path of FFmpeg binaries url (string): URL to be validated logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" if url is None or not ( url ): logger . warning ( \"URL is empty!\" ) return False # extract URL scheme extracted_scheme_url = url . split ( \"://\" , 1 )[ 0 ] # extract all FFmpeg supported protocols protocols = check_output ([ path , \"-hide_banner\" , \"-protocols\" ]) splitted = [ x . decode ( \"utf-8\" ) . strip () for x in protocols . split ( b \" \\n \" )] supported_protocols = splitted [ splitted . index ( \"Output:\" ) + 1 : len ( splitted ) - 1 ] # rtsp is a demuxer somehow supported_protocols += [ \"rtsp\" ] if \"rtsp\" in get_supported_demuxers ( path ) else [] # Test and return result whether scheme is supported if extracted_scheme_url and extracted_scheme_url in supported_protocols : logging and logger . debug ( \"URL scheme ` {} ` is supported by FFmpeg.\" . format ( extracted_scheme_url ) ) return True else : logger . warning ( \"URL scheme ` {} ` isn't supported by FFmpeg!\" . format ( extracted_scheme_url ) ) return False","title":"is_valid_url"},{"location":"bonus/reference/helper/#vidgear.gears.helper.import_dependency_safe--import_dependency_safe","text":"Imports specified dependency safely. By default( error = raise ), if a dependency is missing, an ImportError with a meaningful message will be raised. Otherwise if error = log a warning will be logged and on error = silent everything will be quit. But If a dependency is present, but older than specified, an error is raised if specified. Parameters: Name Type Description Default name string name of dependency to be imported. required error string raise or Log or silence ImportError. Possible values are \"raise\" , \"log\" and silent . Default is \"raise\" . 'raise' pkg_name string (Optional) package name of dependency(if different pip name). Otherwise name will be used. None min_version string (Optional) required minimum version of the dependency to be imported. None custom_message string (Optional) custom Import error message to be raised or logged. None Returns: The imported module, when found and the version is correct(if specified). Otherwise None . Source code in vidgear/gears/helper.py def import_dependency_safe ( name , error = \"raise\" , pkg_name = None , min_version = None , custom_message = None , ): \"\"\" ## import_dependency_safe Imports specified dependency safely. By default(`error = raise`), if a dependency is missing, an ImportError with a meaningful message will be raised. Otherwise if `error = log` a warning will be logged and on `error = silent` everything will be quit. But If a dependency is present, but older than specified, an error is raised if specified. Parameters: name (string): name of dependency to be imported. error (string): raise or Log or silence ImportError. Possible values are `\"raise\"`, `\"log\"` and `silent`. Default is `\"raise\"`. pkg_name (string): (Optional) package name of dependency(if different `pip` name). Otherwise `name` will be used. min_version (string): (Optional) required minimum version of the dependency to be imported. custom_message (string): (Optional) custom Import error message to be raised or logged. **Returns:** The imported module, when found and the version is correct(if specified). Otherwise `None`. \"\"\" # check specified parameters sub_class = \"\" if not name or not isinstance ( name , str ): return None else : # extract name in case of relative import name = name . strip () if name . startswith ( \"from\" ): name = name . split ( \" \" ) name , sub_class = ( name [ 1 ] . strip (), name [ - 1 ] . strip ()) assert error in [ \"raise\" , \"log\" , \"silent\" , ], \"[Vidgear:ERROR] :: Invalid value at `error` parameter.\" # specify package name of dependency(if defined). Otherwise use name install_name = pkg_name if not ( pkg_name is None ) else name # create message msg = ( custom_message if not ( custom_message is None ) else \"Failed to find required dependency ' {} '. Install it with `pip install {} ` command.\" . format ( name , install_name ) ) # try importing dependency try : module = importlib . import_module ( name ) if sub_class : module = getattr ( module , sub_class ) except Exception : # handle errors. if error == \"raise\" : raise ImportError ( msg ) from None elif error == \"log\" : logger . error ( msg ) return None else : return None # check if minimum required version if not ( min_version ) is None : # Handle submodules parent_module = name . split ( \".\" )[ 0 ] if parent_module != name : # grab parent module module_to_get = sys . modules [ parent_module ] else : module_to_get = module # extract version version = get_module_version ( module_to_get ) # verify if LooseVersion ( version ) < LooseVersion ( min_version ): # create message msg = \"\"\"Unsupported version ' {} ' found. Vidgear requires ' {} ' dependency installed with version ' {} ' or greater. Update it with `pip install -U {} ` command.\"\"\" . format ( parent_module , min_version , version , install_name ) # handle errors. if error == \"silent\" : return None else : # raise raise ImportError ( msg ) return module","title":"import_dependency_safe"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_video_bitrate--get_video_bitrate","text":"Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values Parameters: Name Type Description Default width int video-width required height int video-height required fps float video-framerate required bpp float bit-per-pixels value required Returns: Video bitrate (in Kbps) as integer. Source code in vidgear/gears/helper.py def get_video_bitrate ( width , height , fps , bpp ): \"\"\" ## get_video_bitrate Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values Parameters: width (int): video-width height (int): video-height fps (float): video-framerate bpp (float): bit-per-pixels value **Returns:** Video bitrate _(in Kbps)_ as integer. \"\"\" return round (( width * height * bpp * fps ) / 1000 )","title":"get_video_bitrate"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_WriteAccess--check_writeaccess","text":"Checks whether given path directory has Write-Access. Parameters: Name Type Description Default path string absolute path of directory required is_windows boolean is running on Windows OS? False logging bool enables logging for its operations False Returns: A boolean value, confirming whether Write-Access available, or not?. Source code in vidgear/gears/helper.py def check_WriteAccess ( path , is_windows = False , logging = False ): \"\"\" ## check_WriteAccess Checks whether given path directory has Write-Access. Parameters: path (string): absolute path of directory is_windows (boolean): is running on Windows OS? logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether Write-Access available, or not?. \"\"\" # check if path exists dirpath = Path ( path ) try : if not ( dirpath . exists () and dirpath . is_dir ()): logger . warning ( \"Specified directory ` {} ` doesn't exists or valid.\" . format ( path ) ) return False else : path = dirpath . resolve () except : return False # check filepath on *nix systems if not is_windows : uid = os . geteuid () gid = os . getegid () s = os . stat ( path ) mode = s [ stat . ST_MODE ] return ( (( s [ stat . ST_UID ] == uid ) and ( mode & stat . S_IWUSR )) or (( s [ stat . ST_GID ] == gid ) and ( mode & stat . S_IWGRP )) or ( mode & stat . S_IWOTH ) ) # otherwise, check filepath on windows else : write_accessible = False temp_fname = os . path . join ( path , \"temp.tmp\" ) try : fd = os . open ( temp_fname , os . O_WRONLY | os . O_CREAT | os . O_TRUNC ) os . close ( fd ) write_accessible = True except Exception as e : if isinstance ( e , PermissionError ): logger . error ( \"You don't have adequate access rights to use ` {} ` directory!\" . format ( path ) ) logging and logger . exception ( str ( e )) finally : delete_file_safe ( temp_fname ) return write_accessible","title":"check_WriteAccess"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_open_port--check_open_port","text":"Checks whether specified port open at given IP address. Parameters: Name Type Description Default address string given IP address. required port int check if port is open at given address. 22 Returns: A boolean value, confirming whether given port is open at given IP address. Source code in vidgear/gears/helper.py def check_open_port ( address , port = 22 ): \"\"\" ## check_open_port Checks whether specified port open at given IP address. Parameters: address (string): given IP address. port (int): check if port is open at given address. **Returns:** A boolean value, confirming whether given port is open at given IP address. \"\"\" if not address : return False with closing ( socket . socket ( socket . AF_INET , socket . SOCK_STREAM )) as sock : if sock . connect_ex (( address , port )) == 0 : return True else : return False","title":"check_open_port"},{"location":"bonus/reference/helper/#vidgear.gears.helper.delete_file_safe--delete_ext_safe","text":"Safely deletes files at given path. Parameters: Name Type Description Default file_path string path to the file required Source code in vidgear/gears/helper.py def delete_file_safe ( file_path ): \"\"\" ## delete_ext_safe Safely deletes files at given path. Parameters: file_path (string): path to the file \"\"\" try : dfile = Path ( file_path ) if sys . version_info >= ( 3 , 8 , 0 ): dfile . unlink ( missing_ok = True ) else : dfile . exists () and dfile . unlink () except Exception as e : logger . exception ( str ( e ))","title":"delete_ext_safe"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_supported_demuxers--get_supported_demuxers","text":"Find and returns FFmpeg's supported demuxers Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required Returns: List of supported demuxers. Source code in vidgear/gears/helper.py def get_supported_demuxers ( path ): \"\"\" ## get_supported_demuxers Find and returns FFmpeg's supported demuxers Parameters: path (string): absolute path of FFmpeg binaries **Returns:** List of supported demuxers. \"\"\" demuxers = check_output ([ path , \"-hide_banner\" , \"-demuxers\" ]) splitted = [ x . decode ( \"utf-8\" ) . strip () for x in demuxers . split ( b \" \\n \" )] supported_demuxers = splitted [ splitted . index ( \"--\" ) + 1 : len ( splitted ) - 1 ] # compile regex finder = re . compile ( r \"\\s\\s[a-z0-9_,-]+\\s+\" ) # find all outputs outputs = finder . findall ( \" \\n \" . join ( supported_demuxers )) # return output findings return [ o . strip () for o in outputs ]","title":"get_supported_demuxers"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_supported_vencoders--get_supported_vencoders","text":"Find and returns FFmpeg's supported video encoders Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required Returns: List of supported encoders. Source code in vidgear/gears/helper.py def get_supported_vencoders ( path ): \"\"\" ## get_supported_vencoders Find and returns FFmpeg's supported video encoders Parameters: path (string): absolute path of FFmpeg binaries **Returns:** List of supported encoders. \"\"\" encoders = check_output ([ path , \"-hide_banner\" , \"-encoders\" ]) splitted = encoders . split ( b \" \\n \" ) # extract video encoders supported_vencoders = [ x . decode ( \"utf-8\" ) . strip () for x in splitted [ 2 : len ( splitted ) - 1 ] if x . decode ( \"utf-8\" ) . strip () . startswith ( \"V\" ) ] # compile regex finder = re . compile ( r \"[A-Z]*[\\.]+[A-Z]*\\s[a-z0-9_-]*\" ) # find all outputs outputs = finder . findall ( \" \\n \" . join ( supported_vencoders )) # return output findings return [[ s for s in o . split ( \" \" )][ - 1 ] for o in outputs ]","title":"get_supported_vencoders"},{"location":"bonus/reference/helper/#vidgear.gears.helper.validate_auth_keys--validate_auth_keys","text":"Validates, and also maintains generated ZMQ CURVE Key-pairs. Parameters: Name Type Description Default path string path of generated CURVE key-pairs required extension string type of key-pair to be validated required Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/helper.py def validate_auth_keys ( path , extension ): \"\"\" ## validate_auth_keys Validates, and also maintains generated ZMQ CURVE Key-pairs. Parameters: path (string): path of generated CURVE key-pairs extension (string): type of key-pair to be validated **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" # check for valid path if not ( os . path . exists ( path )): return False # check if directory empty if not ( os . listdir ( path )): return False keys_buffer = [] # stores auth-keys # loop over auth-keys for key_file in os . listdir ( path ): key = os . path . splitext ( key_file ) # check if valid key is generated if key and ( key [ 0 ] in [ \"server\" , \"client\" ]) and ( key [ 1 ] == extension ): keys_buffer . append ( key_file ) # store it # remove invalid keys if found len ( keys_buffer ) == 1 and delete_file_safe ( os . path . join ( path , keys_buffer [ 0 ])) # return results return True if ( len ( keys_buffer ) == 2 ) else False","title":"validate_auth_keys"},{"location":"bonus/reference/helper_async/","text":"reducer \u2693 Asynchronous method that reduces frame size by given percentage. Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None percentage int/float inputs size-reduction percentage. 0 interpolation int Change resize interpolation. 4 Returns: A reduced numpy ndarray array. Source code in vidgear/gears/asyncio/helper.py async def reducer ( frame = None , percentage = 0 , interpolation = cv2 . INTER_LANCZOS4 ): \"\"\" ## reducer Asynchronous method that reduces frame size by given percentage. Parameters: frame (numpy.ndarray): inputs numpy array(frame). percentage (int/float): inputs size-reduction percentage. interpolation (int): Change resize interpolation. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None : raise ValueError ( \"[Helper:ERROR] :: Input frame cannot be NoneType!\" ) # check if valid reduction percentage is given if not ( percentage > 0 and percentage < 90 ): raise ValueError ( \"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\" ) if not ( isinstance ( interpolation , int )): raise ValueError ( \"[Helper:ERROR] :: Given interpolation is invalid, Kindly refer docs.\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # calculate the ratio of the width from percentage reduction = (( 100 - percentage ) / 100 ) * width ratio = reduction / float ( width ) # construct the dimensions dimensions = ( int ( reduction ), int ( height * ratio )) # return the resized frame return cv2 . resize ( frame , dimensions , interpolation = interpolation ) create_blank_frame \u2693 Create blank frames of given frame size with text Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None text str Text to be written on frame. '' Returns: A reduced numpy ndarray array. Source code in vidgear/gears/asyncio/helper.py def create_blank_frame ( frame = None , text = \"\" , logging = False ): \"\"\" ## create_blank_frame Create blank frames of given frame size with text Parameters: frame (numpy.ndarray): inputs numpy array(frame). text (str): Text to be written on frame. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None or not ( isinstance ( frame , np . ndarray )): raise ValueError ( \"[Helper:ERROR] :: Input frame is invalid!\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # create blank frame blank_frame = np . zeros ( frame . shape , frame . dtype ) # setup text if text and isinstance ( text , str ): if logging : logger . debug ( \"Adding text: {} \" . format ( text )) # setup font font = cv2 . FONT_HERSHEY_SCRIPT_COMPLEX # get boundary of this text fontScale = min ( height , width ) / ( 25 / 0.25 ) textsize = cv2 . getTextSize ( text , font , fontScale , 5 )[ 0 ] # get coords based on boundary textX = ( width - textsize [ 0 ]) // 2 textY = ( height + textsize [ 1 ]) // 2 # put text cv2 . putText ( blank_frame , text , ( textX , textY ), font , fontScale , ( 125 , 125 , 125 ), 6 ) # return frame return blank_frame generate_webdata \u2693 Auto-Generates, and Auto-validates default data for WebGear API. Parameters: Name Type Description Default path string path for generating data required c_name string class name that is generating files 'webgear' overwrite_default boolean overwrite existing data or not? False logging bool enables logging for its operations False Returns: A valid data path as string. Source code in vidgear/gears/asyncio/helper.py def generate_webdata ( path , c_name = \"webgear\" , overwrite_default = False , logging = False ): \"\"\" ## generate_webdata Auto-Generates, and Auto-validates default data for WebGear API. Parameters: path (string): path for generating data c_name (string): class name that is generating files overwrite_default (boolean): overwrite existing data or not? logging (bool): enables logging for its operations **Returns:** A valid data path as string. \"\"\" # check if path corresponds to vidgear only if os . path . basename ( path ) != \".vidgear\" : path = os . path . join ( path , \".vidgear\" ) # generate parent directory path = os . path . join ( path , c_name ) mkdir_safe ( path , logging = logging ) # self-generate dirs template_dir = os . path . join ( path , \"templates\" ) # generates HTML templates dir static_dir = os . path . join ( path , \"static\" ) # generates static dir # generate js & css static and favicon img subdirs js_static_dir = os . path . join ( static_dir , \"js\" ) css_static_dir = os . path . join ( static_dir , \"css\" ) favicon_dir = os . path . join ( static_dir , \"img\" ) mkdir_safe ( static_dir , logging = logging ) mkdir_safe ( template_dir , logging = logging ) mkdir_safe ( js_static_dir , logging = logging ) mkdir_safe ( css_static_dir , logging = logging ) mkdir_safe ( favicon_dir , logging = logging ) # check if overwriting is enabled if overwrite_default or not validate_webdata ( template_dir , [ \"index.html\" , \"404.html\" , \"500.html\" ] ): logger . critical ( \"Overwriting existing WebGear data-files with default data-files from the server!\" if overwrite_default else \"Failed to detect critical WebGear data-files: index.html, 404.html & 500.html!\" ) # download default files if logging : logger . info ( \"Downloading default data-files from the GitHub Server.\" ) download_webdata ( template_dir , c_name = c_name , files = [ \"index.html\" , \"404.html\" , \"500.html\" , \"base.html\" ], logging = logging , ) download_webdata ( css_static_dir , c_name = c_name , files = [ \"custom.css\" ], logging = logging ) download_webdata ( js_static_dir , c_name = c_name , files = [ \"custom.js\" ], logging = logging , ) download_webdata ( favicon_dir , c_name = c_name , files = [ \"favicon-32x32.png\" ], logging = logging ) else : # validate important data-files if logging : logger . debug ( \"Found valid WebGear data-files successfully.\" ) return path download_webdata \u2693 Downloads given list of files for WebGear API(if not available) from GitHub Server, and also Validates them. Parameters: Name Type Description Default path string path for downloading data required c_name string class name that is generating files 'webgear' files list list of files to be downloaded [] logging bool enables logging for its operations False Returns: A valid path as string. Source code in vidgear/gears/asyncio/helper.py def download_webdata ( path , c_name = \"webgear\" , files = [], logging = False ): \"\"\" ## download_webdata Downloads given list of files for WebGear API(if not available) from GitHub Server, and also Validates them. Parameters: path (string): path for downloading data c_name (string): class name that is generating files files (list): list of files to be downloaded logging (bool): enables logging for its operations **Returns:** A valid path as string. \"\"\" basename = os . path . basename ( path ) if logging : logger . debug ( \"Downloading {} data-files at ` {} `\" . format ( basename , path )) # create session with requests . Session () as http : for file in files : # get filename file_name = os . path . join ( path , file ) # get URL file_url = \"https://raw.githubusercontent.com/abhiTronix/vidgear-vitals/master/ {}{} / {} / {} \" . format ( c_name , \"/static\" if basename != \"templates\" else \"\" , basename , file ) # download and write file to the given path if logging : logger . debug ( \"Downloading {} data-file: {} .\" . format ( basename , file )) with open ( file_name , \"wb\" ) as f : # setup retry strategy retries = Retry ( total = 3 , backoff_factor = 1 , status_forcelist = [ 429 , 500 , 502 , 503 , 504 ], ) # Mount it for https usage adapter = TimeoutHTTPAdapter ( timeout = 2.0 , max_retries = retries ) http . mount ( \"https://\" , adapter ) response = http . get ( file_url , stream = True ) response . raise_for_status () total_length = response . headers . get ( \"content-length\" ) assert not ( total_length is None ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\" bar = tqdm ( total = int ( total_length ), unit = \"B\" , unit_scale = True ) for data in response . iter_content ( chunk_size = 256 ): f . write ( data ) if len ( data ) > 0 : bar . update ( len ( data )) bar . close () if logging : logger . debug ( \"Verifying downloaded data:\" ) if validate_webdata ( path , files = files , logging = logging ): if logging : logger . info ( \"Successful!\" ) return path else : raise RuntimeError ( \"[Helper:ERROR] :: Failed to download required {} data-files at: {} , Check your Internet connectivity!\" . format ( basename , path ) ) validate_auth_keys \u2693 Validates, and also maintains downloaded list of files. Parameters: Name Type Description Default path string path of downloaded files required files list list of files to be validated [] logging bool enables logging for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/asyncio/helper.py def validate_webdata ( path , files = [], logging = False ): \"\"\" ## validate_auth_keys Validates, and also maintains downloaded list of files. Parameters: path (string): path of downloaded files files (list): list of files to be validated logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" # check if valid path or directory empty if not ( os . path . exists ( path )) or not ( os . listdir ( path )): return False files_buffer = [] # loop over files for file in os . listdir ( path ): if file in files : files_buffer . append ( file ) # store them # return results if len ( files_buffer ) < len ( files ): if logging : logger . warning ( \"` {} ` file(s) missing from data-files!\" . format ( \" ,\" . join ( list ( set ( files_buffer ) ^ set ( files ))) ) ) return False else : return True","title":"Helper Methods"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.reducer--reducer","text":"Asynchronous method that reduces frame size by given percentage. Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None percentage int/float inputs size-reduction percentage. 0 interpolation int Change resize interpolation. 4 Returns: A reduced numpy ndarray array. Source code in vidgear/gears/asyncio/helper.py async def reducer ( frame = None , percentage = 0 , interpolation = cv2 . INTER_LANCZOS4 ): \"\"\" ## reducer Asynchronous method that reduces frame size by given percentage. Parameters: frame (numpy.ndarray): inputs numpy array(frame). percentage (int/float): inputs size-reduction percentage. interpolation (int): Change resize interpolation. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None : raise ValueError ( \"[Helper:ERROR] :: Input frame cannot be NoneType!\" ) # check if valid reduction percentage is given if not ( percentage > 0 and percentage < 90 ): raise ValueError ( \"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\" ) if not ( isinstance ( interpolation , int )): raise ValueError ( \"[Helper:ERROR] :: Given interpolation is invalid, Kindly refer docs.\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # calculate the ratio of the width from percentage reduction = (( 100 - percentage ) / 100 ) * width ratio = reduction / float ( width ) # construct the dimensions dimensions = ( int ( reduction ), int ( height * ratio )) # return the resized frame return cv2 . resize ( frame , dimensions , interpolation = interpolation )","title":"reducer"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.create_blank_frame--create_blank_frame","text":"Create blank frames of given frame size with text Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None text str Text to be written on frame. '' Returns: A reduced numpy ndarray array. Source code in vidgear/gears/asyncio/helper.py def create_blank_frame ( frame = None , text = \"\" , logging = False ): \"\"\" ## create_blank_frame Create blank frames of given frame size with text Parameters: frame (numpy.ndarray): inputs numpy array(frame). text (str): Text to be written on frame. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None or not ( isinstance ( frame , np . ndarray )): raise ValueError ( \"[Helper:ERROR] :: Input frame is invalid!\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # create blank frame blank_frame = np . zeros ( frame . shape , frame . dtype ) # setup text if text and isinstance ( text , str ): if logging : logger . debug ( \"Adding text: {} \" . format ( text )) # setup font font = cv2 . FONT_HERSHEY_SCRIPT_COMPLEX # get boundary of this text fontScale = min ( height , width ) / ( 25 / 0.25 ) textsize = cv2 . getTextSize ( text , font , fontScale , 5 )[ 0 ] # get coords based on boundary textX = ( width - textsize [ 0 ]) // 2 textY = ( height + textsize [ 1 ]) // 2 # put text cv2 . putText ( blank_frame , text , ( textX , textY ), font , fontScale , ( 125 , 125 , 125 ), 6 ) # return frame return blank_frame","title":"create_blank_frame"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.generate_webdata--generate_webdata","text":"Auto-Generates, and Auto-validates default data for WebGear API. Parameters: Name Type Description Default path string path for generating data required c_name string class name that is generating files 'webgear' overwrite_default boolean overwrite existing data or not? False logging bool enables logging for its operations False Returns: A valid data path as string. Source code in vidgear/gears/asyncio/helper.py def generate_webdata ( path , c_name = \"webgear\" , overwrite_default = False , logging = False ): \"\"\" ## generate_webdata Auto-Generates, and Auto-validates default data for WebGear API. Parameters: path (string): path for generating data c_name (string): class name that is generating files overwrite_default (boolean): overwrite existing data or not? logging (bool): enables logging for its operations **Returns:** A valid data path as string. \"\"\" # check if path corresponds to vidgear only if os . path . basename ( path ) != \".vidgear\" : path = os . path . join ( path , \".vidgear\" ) # generate parent directory path = os . path . join ( path , c_name ) mkdir_safe ( path , logging = logging ) # self-generate dirs template_dir = os . path . join ( path , \"templates\" ) # generates HTML templates dir static_dir = os . path . join ( path , \"static\" ) # generates static dir # generate js & css static and favicon img subdirs js_static_dir = os . path . join ( static_dir , \"js\" ) css_static_dir = os . path . join ( static_dir , \"css\" ) favicon_dir = os . path . join ( static_dir , \"img\" ) mkdir_safe ( static_dir , logging = logging ) mkdir_safe ( template_dir , logging = logging ) mkdir_safe ( js_static_dir , logging = logging ) mkdir_safe ( css_static_dir , logging = logging ) mkdir_safe ( favicon_dir , logging = logging ) # check if overwriting is enabled if overwrite_default or not validate_webdata ( template_dir , [ \"index.html\" , \"404.html\" , \"500.html\" ] ): logger . critical ( \"Overwriting existing WebGear data-files with default data-files from the server!\" if overwrite_default else \"Failed to detect critical WebGear data-files: index.html, 404.html & 500.html!\" ) # download default files if logging : logger . info ( \"Downloading default data-files from the GitHub Server.\" ) download_webdata ( template_dir , c_name = c_name , files = [ \"index.html\" , \"404.html\" , \"500.html\" , \"base.html\" ], logging = logging , ) download_webdata ( css_static_dir , c_name = c_name , files = [ \"custom.css\" ], logging = logging ) download_webdata ( js_static_dir , c_name = c_name , files = [ \"custom.js\" ], logging = logging , ) download_webdata ( favicon_dir , c_name = c_name , files = [ \"favicon-32x32.png\" ], logging = logging ) else : # validate important data-files if logging : logger . debug ( \"Found valid WebGear data-files successfully.\" ) return path","title":"generate_webdata"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.download_webdata--download_webdata","text":"Downloads given list of files for WebGear API(if not available) from GitHub Server, and also Validates them. Parameters: Name Type Description Default path string path for downloading data required c_name string class name that is generating files 'webgear' files list list of files to be downloaded [] logging bool enables logging for its operations False Returns: A valid path as string. Source code in vidgear/gears/asyncio/helper.py def download_webdata ( path , c_name = \"webgear\" , files = [], logging = False ): \"\"\" ## download_webdata Downloads given list of files for WebGear API(if not available) from GitHub Server, and also Validates them. Parameters: path (string): path for downloading data c_name (string): class name that is generating files files (list): list of files to be downloaded logging (bool): enables logging for its operations **Returns:** A valid path as string. \"\"\" basename = os . path . basename ( path ) if logging : logger . debug ( \"Downloading {} data-files at ` {} `\" . format ( basename , path )) # create session with requests . Session () as http : for file in files : # get filename file_name = os . path . join ( path , file ) # get URL file_url = \"https://raw.githubusercontent.com/abhiTronix/vidgear-vitals/master/ {}{} / {} / {} \" . format ( c_name , \"/static\" if basename != \"templates\" else \"\" , basename , file ) # download and write file to the given path if logging : logger . debug ( \"Downloading {} data-file: {} .\" . format ( basename , file )) with open ( file_name , \"wb\" ) as f : # setup retry strategy retries = Retry ( total = 3 , backoff_factor = 1 , status_forcelist = [ 429 , 500 , 502 , 503 , 504 ], ) # Mount it for https usage adapter = TimeoutHTTPAdapter ( timeout = 2.0 , max_retries = retries ) http . mount ( \"https://\" , adapter ) response = http . get ( file_url , stream = True ) response . raise_for_status () total_length = response . headers . get ( \"content-length\" ) assert not ( total_length is None ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\" bar = tqdm ( total = int ( total_length ), unit = \"B\" , unit_scale = True ) for data in response . iter_content ( chunk_size = 256 ): f . write ( data ) if len ( data ) > 0 : bar . update ( len ( data )) bar . close () if logging : logger . debug ( \"Verifying downloaded data:\" ) if validate_webdata ( path , files = files , logging = logging ): if logging : logger . info ( \"Successful!\" ) return path else : raise RuntimeError ( \"[Helper:ERROR] :: Failed to download required {} data-files at: {} , Check your Internet connectivity!\" . format ( basename , path ) )","title":"download_webdata"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.validate_webdata--validate_auth_keys","text":"Validates, and also maintains downloaded list of files. Parameters: Name Type Description Default path string path of downloaded files required files list list of files to be validated [] logging bool enables logging for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/asyncio/helper.py def validate_webdata ( path , files = [], logging = False ): \"\"\" ## validate_auth_keys Validates, and also maintains downloaded list of files. Parameters: path (string): path of downloaded files files (list): list of files to be validated logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" # check if valid path or directory empty if not ( os . path . exists ( path )) or not ( os . listdir ( path )): return False files_buffer = [] # loop over files for file in os . listdir ( path ): if file in files : files_buffer . append ( file ) # store them # return results if len ( files_buffer ) < len ( files ): if logging : logger . warning ( \"` {} ` file(s) missing from data-files!\" . format ( \" ,\" . join ( list ( set ( files_buffer ) ^ set ( files ))) ) ) return False else : return True","title":"validate_auth_keys"},{"location":"bonus/reference/netgear/","text":"NetGear API usage examples can be found here \u27b6 NetGear API parameters are explained here \u27b6 NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time. NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. NetGear also supports real-time Frame Compression capabilities for optimizing performance while sending the frames directly over the network, by encoding the frame before sending it and decoding it on the client's end automatically in real-time. Info NetGear API now internally implements robust Lazy Pirate pattern (auto-reconnection) for its synchronous messaging patterns (i.e. zmq.PAIR & zmq.REQ/zmq.REP ) at both Server and Client ends, where its API instead of doing a blocking receive, will: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. NetGear as of now seamlessly supports three ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) whereas the supported protocol are: tcp and ipc . Modes of Operation Primary Modes NetGear API primarily has two modes of operations: Send Mode: which employs send() function to send video frames over the network in real-time. Receive Mode: which employs recv() function to receive frames, sent over the network with Send Mode in real-time. The mode sends back confirmation when the frame is received successfully in few patterns. Exclusive Modes In addition to these primary modes, NetGear API offers applications-specific Exclusive Modes: Multi-Servers Mode: In this exclusive mode, NetGear API robustly handles multiple servers at once , thereby providing seamless access to frames and unidirectional data transfer from multiple Servers/Publishers across the network in real-time. Multi-Clients Mode: In this exclusive mode, NetGear API robustly handles multiple clients at once , thereby providing seamless access to frames and unidirectional data transfer to multiple Client/Consumers across the network in real-time. Bidirectional Mode: This exclusive mode provides seamless support for bidirectional data transmission between between Server and Client along with video frames . Secure Mode: In this exclusive mode, NetGear API provides easy access to powerful, smart & secure ZeroMQ's Security Layers that enables strong encryption on data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication for distributed systems over the network. Source code in vidgear/gears/netgear.py class NetGear : \"\"\" NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time. NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. NetGear also supports real-time Frame Compression capabilities for optimizing performance while sending the frames directly over the network, by encoding the frame before sending it and decoding it on the client's end automatically in real-time. !!! info NetGear API now internally implements robust *Lazy Pirate pattern* (auto-reconnection) for its synchronous messaging patterns _(i.e. `zmq.PAIR` & `zmq.REQ/zmq.REP`)_ at both Server and Client ends, where its API instead of doing a blocking receive, will: * Poll the socket and receive from it only when it's sure a reply has arrived. * Attempt to reconnect, if no reply has arrived within a timeout period. * Abandon the connection if there is still no reply after several requests. NetGear as of now seamlessly supports three ZeroMQ messaging patterns: - `zmq.PAIR` _(ZMQ Pair Pattern)_ - `zmq.REQ/zmq.REP` _(ZMQ Request/Reply Pattern)_ - `zmq.PUB/zmq.SUB` _(ZMQ Publish/Subscribe Pattern)_ _whereas the supported protocol are: `tcp` and `ipc`_. ??? tip \"Modes of Operation\" * **Primary Modes** NetGear API primarily has two modes of operations: * **Send Mode:** _which employs `send()` function to send video frames over the network in real-time._ * **Receive Mode:** _which employs `recv()` function to receive frames, sent over the network with *Send Mode* in real-time. The mode sends back confirmation when the frame is received successfully in few patterns._ * **Exclusive Modes** In addition to these primary modes, NetGear API offers applications-specific Exclusive Modes: * **Multi-Servers Mode:** _In this exclusive mode, NetGear API robustly **handles multiple servers at once**, thereby providing seamless access to frames and unidirectional data transfer from multiple Servers/Publishers across the network in real-time._ * **Multi-Clients Mode:** _In this exclusive mode, NetGear API robustly **handles multiple clients at once**, thereby providing seamless access to frames and unidirectional data transfer to multiple Client/Consumers across the network in real-time._ * **Bidirectional Mode:** _This exclusive mode **provides seamless support for bidirectional data transmission between between Server and Client along with video frames**._ * **Secure Mode:** _In this exclusive mode, NetGear API **provides easy access to powerful, smart & secure ZeroMQ's Security Layers** that enables strong encryption on data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication for distributed systems over the network._ \"\"\" def __init__ ( self , address = None , port = None , protocol = None , pattern = 0 , receive_mode = False , logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the NetGear class. Parameters: address (str): sets the valid network address of the Server/Client. port (str): sets the valid Network Port of the Server/Client. protocol (str): sets the valid messaging protocol between Server/Client. pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client receive_mode (bool): select the Netgear's Mode of operation. logging (bool): enables/disables logging. options (dict): provides the flexibility to alter various NetGear internal properties. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"zmq\" if zmq is None else \"\" , min_version = \"4.0\" , pkg_name = \"pyzmq\" ) import_dependency_safe ( \"simplejpeg\" if simplejpeg is None else \"\" , error = \"log\" , min_version = \"1.6.1\" ) # enable logging if specified self . __logging = True if logging else False # define valid messaging patterns => `0`: zmq.PAIR, `1`:(zmq.REQ,zmq.REP), and `1`:(zmq.SUB,zmq.PUB) valid_messaging_patterns = { 0 : ( zmq . PAIR , zmq . PAIR ), 1 : ( zmq . REQ , zmq . REP ), 2 : ( zmq . PUB , zmq . SUB ), } # Handle messaging pattern msg_pattern = None # check whether user-defined messaging pattern is valid if isinstance ( pattern , int ) and pattern in valid_messaging_patterns . keys (): # assign value msg_pattern = valid_messaging_patterns [ pattern ] else : # otherwise default to 0:`zmq.PAIR` pattern = 0 msg_pattern = valid_messaging_patterns [ pattern ] self . __logging and logger . warning ( \"Wrong pattern value, Defaulting to `zmq.PAIR`! Kindly refer Docs for more Information.\" ) # assign pattern to global parameter for further use self . __pattern = pattern # Handle messaging protocol if protocol is None or not ( protocol in [ \"tcp\" , \"ipc\" ]): # else default to `tcp` protocol protocol = \"tcp\" # log it self . __logging and logger . warning ( \"Protocol is not supported or not provided. Defaulting to `tcp` protocol!\" ) # Handle connection params self . __msg_flag = 0 # handles connection flags self . __msg_copy = False # handles whether to copy data self . __msg_track = False # handles whether to track packets # Handle NetGear's internal exclusive modes and params # define SSH Tunneling Mode self . __ssh_tunnel_mode = None # handles ssh_tunneling mode state self . __ssh_tunnel_pwd = None self . __ssh_tunnel_keyfile = None self . __paramiko_present = False if paramiko is None else True # define Multi-Server mode self . __multiserver_mode = False # handles multi-server mode state # define Multi-Client mode self . __multiclient_mode = False # handles multi-client mode state # define Bidirectional mode self . __bi_mode = False # handles Bidirectional mode state # define Secure mode valid_security_mech = { 0 : \"Grasslands\" , 1 : \"StoneHouse\" , 2 : \"IronHouse\" } self . __secure_mode = 0 # handles ZMQ security layer status auth_cert_dir = \"\" # handles valid ZMQ certificates dir self . __auth_publickeys_dir = \"\" # handles valid ZMQ public certificates dir self . __auth_secretkeys_dir = \"\" # handles valid ZMQ private certificates dir overwrite_cert = False # checks if certificates overwriting allowed custom_cert_location = \"\" # handles custom ZMQ certificates path # define frame-compression handler self . __jpeg_compression = ( True if not ( simplejpeg is None ) else False ) # enabled by default for all connections if simplejpeg is installed self . __jpeg_compression_quality = 90 # 90% quality self . __jpeg_compression_fastdct = True # fastest DCT on by default self . __jpeg_compression_fastupsample = False # fastupsample off by default self . __jpeg_compression_colorspace = \"BGR\" # use BGR colorspace by default # defines frame compression on return data self . __ex_compression_params = None # define receiver return data handler self . __return_data = None # generate 8-digit random system id self . __id = \"\" . join ( secrets . choice ( string . ascii_uppercase + string . digits ) for i in range ( 8 ) ) # define termination flag self . __terminate = False # additional settings for reliability if pattern < 2 : # define zmq poller for reliable transmission self . __poll = zmq . Poller () # define max retries self . __max_retries = 3 # request timeout self . __request_timeout = 4000 # 4 secs # Handle user-defined options dictionary values # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # loop over dictionary key & values and assign to global variables if valid for key , value in options . items (): # handle multi-server mode if key == \"multiserver_mode\" and isinstance ( value , bool ): # check if valid pattern assigned if pattern > 0 : # activate Multi-server mode self . __multiserver_mode = value else : # otherwise disable it and raise error self . __multiserver_mode = False logger . critical ( \"Multi-Server Mode is disabled!\" ) raise ValueError ( \"[NetGear:ERROR] :: ` {} ` pattern is not valid when Multi-Server Mode is enabled. Kindly refer Docs for more Information.\" . format ( pattern ) ) # handle multi-client mode elif key == \"multiclient_mode\" and isinstance ( value , bool ): # check if valid pattern assigned if pattern > 0 : # activate Multi-client mode self . __multiclient_mode = value else : # otherwise disable it and raise error self . __multiclient_mode = False logger . critical ( \"Multi-Client Mode is disabled!\" ) raise ValueError ( \"[NetGear:ERROR] :: ` {} ` pattern is not valid when Multi-Client Mode is enabled. Kindly refer Docs for more Information.\" . format ( pattern ) ) # handle bidirectional mode elif key == \"bidirectional_mode\" and isinstance ( value , bool ): # check if pattern is valid if pattern < 2 : # activate Bidirectional mode if specified self . __bi_mode = value else : # otherwise disable it and raise error self . __bi_mode = False logger . warning ( \"Bidirectional data transmission is disabled!\" ) raise ValueError ( \"[NetGear:ERROR] :: ` {} ` pattern is not valid when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\" . format ( pattern ) ) # handle secure mode elif ( key == \"secure_mode\" and isinstance ( value , int ) and ( value in valid_security_mech ) ): self . __secure_mode = value elif key == \"custom_cert_location\" and isinstance ( value , str ): # verify custom auth certificates path for secure mode custom_cert_location = os . path . abspath ( value ) assert os . path . isdir ( custom_cert_location ), \"[NetGear:ERROR] :: `custom_cert_location` value must be the path to a valid directory!\" assert check_WriteAccess ( custom_cert_location , is_windows = True if os . name == \"nt\" else False , logging = self . __logging , ), \"[NetGear:ERROR] :: Permission Denied!, cannot write ZMQ authentication certificates to ' {} ' directory!\" . format ( value ) elif key == \"overwrite_cert\" and isinstance ( value , bool ): # enable/disable auth certificate overwriting in secure mode overwrite_cert = value # handle ssh-tunneling mode elif key == \"ssh_tunnel_mode\" and isinstance ( value , str ): # enable SSH Tunneling Mode self . __ssh_tunnel_mode = value . strip () elif key == \"ssh_tunnel_pwd\" and isinstance ( value , str ): # add valid SSH Tunneling password self . __ssh_tunnel_pwd = value elif key == \"ssh_tunnel_keyfile\" and isinstance ( value , str ): # add valid SSH Tunneling key-file self . __ssh_tunnel_keyfile = value if os . path . isfile ( value ) else None if self . __ssh_tunnel_keyfile is None : logger . warning ( \"Discarded invalid or non-existential SSH Tunnel Key-file at {} !\" . format ( value ) ) # handle jpeg compression elif ( key == \"jpeg_compression\" and not ( simplejpeg is None ) and isinstance ( value , ( bool , str )) ): if isinstance ( value , str ) and value . strip () . upper () in [ \"RGB\" , \"BGR\" , \"RGBX\" , \"BGRX\" , \"XBGR\" , \"XRGB\" , \"GRAY\" , \"RGBA\" , \"BGRA\" , \"ABGR\" , \"ARGB\" , \"CMYK\" , ]: # set encoding colorspace self . __jpeg_compression_colorspace = value . strip () . upper () # enable frame-compression encoding value self . __jpeg_compression = True else : # enable frame-compression encoding value self . __jpeg_compression = value elif key == \"jpeg_compression_quality\" and isinstance ( value , ( int , float )): # set valid jpeg quality if value >= 10 and value <= 100 : self . __jpeg_compression_quality = int ( value ) else : logger . warning ( \"Skipped invalid `jpeg_compression_quality` value!\" ) elif key == \"jpeg_compression_fastdct\" and isinstance ( value , bool ): # enable jpeg fastdct self . __jpeg_compression_fastdct = value elif key == \"jpeg_compression_fastupsample\" and isinstance ( value , bool ): # enable jpeg fastupsample self . __jpeg_compression_fastupsample = value # assign maximum retries in synchronous patterns elif key == \"max_retries\" and isinstance ( value , int ) and pattern < 2 : if value >= 0 : self . __max_retries = value else : logger . warning ( \"Invalid `max_retries` value skipped!\" ) # assign request timeout in synchronous patterns elif key == \"request_timeout\" and isinstance ( value , int ) and pattern < 2 : if value >= 4 : self . __request_timeout = value * 1000 # covert to milliseconds else : logger . warning ( \"Invalid `request_timeout` value skipped!\" ) # handle ZMQ flags elif key == \"flag\" and isinstance ( value , int ): self . __msg_flag = value elif key == \"copy\" and isinstance ( value , bool ): self . __msg_copy = value elif key == \"track\" and isinstance ( value , bool ): self . __msg_track = value else : pass # Handle Secure mode if self . __secure_mode : # activate and log if overwriting is enabled if overwrite_cert : if not receive_mode : self . __logging and logger . warning ( \"Overwriting ZMQ Authentication certificates over previous ones!\" ) else : overwrite_cert = False self . __logging and logger . critical ( \"Overwriting ZMQ Authentication certificates is disabled for Client's end!\" ) # Validate certificate generation paths try : # check if custom certificates path is specified if custom_cert_location : ( auth_cert_dir , self . __auth_secretkeys_dir , self . __auth_publickeys_dir , ) = generate_auth_certificates ( custom_cert_location , overwrite = overwrite_cert , logging = logging ) else : # otherwise auto-generate suitable path ( auth_cert_dir , self . __auth_secretkeys_dir , self . __auth_publickeys_dir , ) = generate_auth_certificates ( os . path . join ( expanduser ( \"~\" ), \".vidgear\" ), overwrite = overwrite_cert , logging = logging , ) # log it self . __logging and logger . debug ( \"` {} ` is the default location for storing ZMQ authentication certificates/keys.\" . format ( auth_cert_dir ) ) except Exception as e : # catch if any error occurred and disable Secure mode logger . exception ( str ( e )) self . __secure_mode = 0 logger . critical ( \"ZMQ Security Mechanism is disabled for this connection due to errors!\" ) # Handle ssh tunneling if enabled if not ( self . __ssh_tunnel_mode is None ): # SSH Tunnel Mode only available for server mode if receive_mode : logger . error ( \"SSH Tunneling cannot be enabled for Client-end!\" ) else : # check if SSH tunneling possible ssh_address = self . __ssh_tunnel_mode ssh_address , ssh_port = ( ssh_address . split ( \":\" ) if \":\" in ssh_address else [ ssh_address , \"22\" ] ) # default to port 22 if \"47\" in ssh_port : self . __ssh_tunnel_mode = self . __ssh_tunnel_mode . replace ( \":47\" , \"\" ) # port-47 is reserved for testing else : # extract ip for validation ssh_user , ssh_ip = ( ssh_address . split ( \"@\" ) if \"@\" in ssh_address else [ \"\" , ssh_address ] ) # validate ip specified port assert check_open_port ( ssh_ip , port = int ( ssh_port ) ), \"[NetGear:ERROR] :: Host ` {} ` is not available for SSH Tunneling at port- {} !\" . format ( ssh_address , ssh_port ) # Handle multiple exclusive modes if enabled if self . __multiclient_mode and self . __multiserver_mode : raise ValueError ( \"[NetGear:ERROR] :: Multi-Client and Multi-Server Mode cannot be enabled simultaneously!\" ) elif self . __multiserver_mode or self . __multiclient_mode : # check if Bidirectional Mode also enabled if self . __bi_mode : # log it self . __logging and logger . debug ( \"Bidirectional Data Transmission is also enabled for this connection!\" ) # check if SSH Tunneling Mode also enabled if self . __ssh_tunnel_mode : # raise error raise ValueError ( \"[NetGear:ERROR] :: SSH Tunneling and {} Mode cannot be enabled simultaneously. Kindly refer docs!\" . format ( \"Multi-Server\" if self . __multiserver_mode else \"Multi-Client\" ) ) elif self . __bi_mode : # log Bidirectional mode activation self . __logging and logger . debug ( \"Bidirectional Data Transmission is enabled for this connection!\" ) elif self . __ssh_tunnel_mode : # log Bidirectional mode activation self . __logging and logger . debug ( \"SSH Tunneling is enabled for host:` {} ` with ` {} ` back-end.\" . format ( self . __ssh_tunnel_mode , \"paramiko\" if self . __paramiko_present else \"pexpect\" , ) ) # define messaging context instance self . __msg_context = zmq . Context . instance () # initialize and assign receive mode to global variable self . __receive_mode = receive_mode # check whether `receive_mode` is enabled if self . __receive_mode : # define connection address if address is None : address = \"*\" # define address # check if multiserver_mode is enabled if self . __multiserver_mode : # check if unique server port address list/tuple is assigned or not in multiserver_mode if port is None or not isinstance ( port , ( tuple , list )): # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Server ports while Multi-Server mode is enabled. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Server Mode at PORTS: {} !\" . format ( port ) ) # create port address buffer for keeping track of connected client's port(s) self . __port_buffer = [] # check if multiclient_mode is enabled elif self . __multiclient_mode : # check if unique server port address is assigned or not in multiclient_mode if port is None : # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Kindly provide a unique & valid port value at Client-end. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Client Mode at PORT: {} on this device!\" . format ( port ) ) # assign value to global variable self . __port = port else : # otherwise assign local port address if None if port is None : port = \"5555\" try : # activate secure_mode threaded authenticator if self . __secure_mode > 0 : # start an authenticator for this context z_auth = ThreadAuthenticator ( self . __msg_context ) z_auth . start () z_auth . allow ( str ( address )) # allow current address # check if `IronHouse` is activated if self . __secure_mode == 2 : # tell authenticator to use the certificate from given valid dir z_auth . configure_curve ( domain = \"*\" , location = self . __auth_publickeys_dir ) else : # otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated z_auth . configure_curve ( domain = \"*\" , location = auth . CURVE_ALLOW_ANY ) # define thread-safe messaging socket self . __msg_socket = self . __msg_context . socket ( msg_pattern [ 1 ]) # define pub-sub flag if self . __pattern == 2 : self . __msg_socket . set_hwm ( 1 ) # enable specified secure mode for the socket if self . __secure_mode > 0 : # load server key server_secret_file = os . path . join ( self . __auth_secretkeys_dir , \"server.key_secret\" ) server_public , server_secret = auth . load_certificate ( server_secret_file ) # load all CURVE keys self . __msg_socket . curve_secretkey = server_secret self . __msg_socket . curve_publickey = server_public # enable CURVE connection for this socket self . __msg_socket . curve_server = True # define exclusive socket options for patterns if self . __pattern == 2 : self . __msg_socket . setsockopt_string ( zmq . SUBSCRIBE , \"\" ) # if multiserver_mode is enabled, then assign port addresses to zmq socket if self . __multiserver_mode : # bind socket to given server protocol, address and ports for pt in port : self . __msg_socket . bind ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : # bind socket to given protocol, address and port normally self . __msg_socket . bind ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) # additional settings if pattern < 2 : if self . __multiserver_mode : self . __connection_address = [] for pt in port : self . __connection_address . append ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : self . __connection_address = ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) self . __msg_pattern = msg_pattern [ 1 ] self . __poll . register ( self . __msg_socket , zmq . POLLIN ) self . __logging and logger . debug ( \"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\" . format ( self . __max_retries , self . __request_timeout / 1000 ) ) except Exception as e : # otherwise log and raise error logger . exception ( str ( e )) if self . __secure_mode : logger . critical ( \"Failed to activate Secure Mode: ` {} ` for this connection!\" . format ( valid_security_mech [ self . __secure_mode ] ) ) if self . __multiserver_mode or self . __multiclient_mode : raise RuntimeError ( \"[NetGear:ERROR] :: Receive Mode failed to activate {} Mode at address: {} with pattern: {} ! Kindly recheck all parameters.\" . format ( \"Multi-Server\" if self . __multiserver_mode else \"Multi-Client\" , ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern , ) ) else : if self . __bi_mode : logger . critical ( \"Failed to activate Bidirectional Mode for this connection!\" ) raise RuntimeError ( \"[NetGear:ERROR] :: Receive Mode failed to bind address: {} and pattern: {} ! Kindly recheck all parameters.\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) # Handle threaded queue mode self . __logging and logger . debug ( \"Threaded Queue Mode is enabled by default for this connection.\" ) # define deque and assign it to global var self . __queue = deque ( maxlen = 96 ) # max len 96 to check overflow # initialize and start threaded recv_handler self . __thread = Thread ( target = self . __recv_handler , name = \"NetGear\" , args = ()) self . __thread . daemon = True self . __thread . start () if self . __logging : # finally log progress logger . debug ( \"Successfully Binded to address: {} with pattern: {} .\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) if self . __jpeg_compression : logger . debug ( \"JPEG Frame-Compression is activated for this connection with Colorspace:` {} `, Quality:` {} `%, Fastdct:` {} `, and Fastupsample:` {} `.\" . format ( self . __jpeg_compression_colorspace , self . __jpeg_compression_quality , \"enabled\" if self . __jpeg_compression_fastdct else \"disabled\" , \"enabled\" if self . __jpeg_compression_fastupsample else \"disabled\" , ) ) if self . __secure_mode : logger . debug ( \"Successfully enabled ZMQ Security Mechanism: ` {} ` for this connection.\" . format ( valid_security_mech [ self . __secure_mode ] ) ) logger . debug ( \"Multi-threaded Receive Mode is successfully enabled.\" ) logger . debug ( \"Unique System ID is {} .\" . format ( self . __id )) logger . debug ( \"Receive Mode is now activated.\" ) else : # otherwise default to `Send Mode` # define connection address if address is None : address = \"localhost\" # check if multiserver_mode is enabled if self . __multiserver_mode : # check if unique server port address is assigned or not in multiserver_mode if port is None : # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Kindly provide a unique & valid port value at Server-end. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Server Mode at PORT: {} on this device!\" . format ( port ) ) # assign value to global variable self . __port = port # check if multiclient_mode is enabled elif self . __multiclient_mode : # check if unique client port address list/tuple is assigned or not in multiclient_mode if port is None or not isinstance ( port , ( tuple , list )): # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Client ports while Multi-Client mode is enabled. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Client Mode at PORTS: {} !\" . format ( port ) ) # create port address buffer for keeping track of connected client ports self . __port_buffer = [] else : # otherwise assign local port address if None if port is None : port = \"5555\" try : # activate secure_mode threaded authenticator if self . __secure_mode > 0 : # start an authenticator for this context z_auth = ThreadAuthenticator ( self . __msg_context ) z_auth . start () z_auth . allow ( str ( address )) # allow current address # check if `IronHouse` is activated if self . __secure_mode == 2 : # tell authenticator to use the certificate from given valid dir z_auth . configure_curve ( domain = \"*\" , location = self . __auth_publickeys_dir ) else : # otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated z_auth . configure_curve ( domain = \"*\" , location = auth . CURVE_ALLOW_ANY ) # define thread-safe messaging socket self . __msg_socket = self . __msg_context . socket ( msg_pattern [ 0 ]) # if req/rep pattern, define additional flags if self . __pattern == 1 : self . __msg_socket . REQ_RELAXED = True self . __msg_socket . REQ_CORRELATE = True # if pub/sub pattern, define additional optimizer if self . __pattern == 2 : self . __msg_socket . set_hwm ( 1 ) # enable specified secure mode for the socket if self . __secure_mode > 0 : # load client key client_secret_file = os . path . join ( self . __auth_secretkeys_dir , \"client.key_secret\" ) client_public , client_secret = auth . load_certificate ( client_secret_file ) # load all CURVE keys self . __msg_socket . curve_secretkey = client_secret self . __msg_socket . curve_publickey = client_public # load server key server_public_file = os . path . join ( self . __auth_publickeys_dir , \"server.key\" ) server_public , _ = auth . load_certificate ( server_public_file ) # inject public key to make a CURVE connection. self . __msg_socket . curve_serverkey = server_public # check if multi-client_mode is enabled if self . __multiclient_mode : # bind socket to given server protocol, address and ports for pt in port : self . __msg_socket . connect ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : # handle SSH tuneling if enabled if self . __ssh_tunnel_mode : # establish tunnel connection ssh . tunnel_connection ( self . __msg_socket , protocol + \"://\" + str ( address ) + \":\" + str ( port ), self . __ssh_tunnel_mode , keyfile = self . __ssh_tunnel_keyfile , password = self . __ssh_tunnel_pwd , paramiko = self . __paramiko_present , ) else : # connect socket to given protocol, address and port self . __msg_socket . connect ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) # additional settings if pattern < 2 : if self . __multiclient_mode : self . __connection_address = [] for pt in port : self . __connection_address . append ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : self . __connection_address = ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) self . __msg_pattern = msg_pattern [ 0 ] self . __poll . register ( self . __msg_socket , zmq . POLLIN ) self . __logging and logger . debug ( \"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\" . format ( self . __max_retries , self . __request_timeout / 1000 ) ) except Exception as e : # otherwise log and raise error logger . exception ( str ( e )) if self . __secure_mode : logger . critical ( \"Failed to activate Secure Mode: ` {} ` for this connection!\" . format ( valid_security_mech [ self . __secure_mode ] ) ) if self . __multiserver_mode or self . __multiclient_mode : raise RuntimeError ( \"[NetGear:ERROR] :: Send Mode failed to activate {} Mode at address: {} with pattern: {} ! Kindly recheck all parameters.\" . format ( \"Multi-Server\" if self . __multiserver_mode else \"Multi-Client\" , ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern , ) ) else : if self . __bi_mode : logger . critical ( \"Failed to activate Bidirectional Mode for this connection!\" ) if self . __ssh_tunnel_mode : logger . critical ( \"Failed to initiate SSH Tunneling Mode for this server with ` {} ` back-end!\" . format ( \"paramiko\" if self . __paramiko_present else \"pexpect\" ) ) raise RuntimeError ( \"[NetGear:ERROR] :: Send Mode failed to connect address: {} and pattern: {} ! Kindly recheck all parameters.\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) if self . __logging : # finally log progress logger . debug ( \"Successfully connected to address: {} with pattern: {} .\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) if self . __jpeg_compression : logger . debug ( \"JPEG Frame-Compression is activated for this connection with Colorspace:` {} `, Quality:` {} `%, Fastdct:` {} `, and Fastupsample:` {} `.\" . format ( self . __jpeg_compression_colorspace , self . __jpeg_compression_quality , \"enabled\" if self . __jpeg_compression_fastdct else \"disabled\" , \"enabled\" if self . __jpeg_compression_fastupsample else \"disabled\" , ) ) if self . __secure_mode : logger . debug ( \"Enabled ZMQ Security Mechanism: ` {} ` for this connection.\" . format ( valid_security_mech [ self . __secure_mode ] ) ) logger . debug ( \"Unique System ID is {} .\" . format ( self . __id )) logger . debug ( \"Send Mode is successfully activated and ready to send data.\" ) def __recv_handler ( self ): \"\"\" A threaded receiver handler, that keep iterating data from ZMQ socket to a internally monitored deque, until the thread is terminated, or socket disconnects. \"\"\" # initialize frame variable frame = None # keep looping infinitely until the thread is terminated while not self . __terminate : # check queue buffer for overflow if len ( self . __queue ) >= 96 : # stop iterating if overflowing occurs time . sleep ( 0.000001 ) continue if self . __pattern < 2 : socks = dict ( self . __poll . poll ( self . __request_timeout * 3 )) if socks . get ( self . __msg_socket ) == zmq . POLLIN : msg_json = self . __msg_socket . recv_json ( flags = self . __msg_flag | zmq . DONTWAIT ) else : logger . critical ( \"No response from Server(s), Reconnecting again...\" ) self . __msg_socket . close ( linger = 0 ) self . __poll . unregister ( self . __msg_socket ) self . __max_retries -= 1 if not ( self . __max_retries ): if self . __multiserver_mode : logger . error ( \"All Servers seems to be offline, Abandoning!\" ) else : logger . error ( \"Server seems to be offline, Abandoning!\" ) self . __terminate = True continue # Create new connection try : self . __msg_socket = self . __msg_context . socket ( self . __msg_pattern ) if isinstance ( self . __connection_address , list ): for _connection in self . __connection_address : self . __msg_socket . bind ( _connection ) else : self . __msg_socket . bind ( self . __connection_address ) except Exception as e : logger . exception ( str ( e )) self . __terminate = True raise RuntimeError ( \"API failed to restart the Client-end!\" ) self . __poll . register ( self . __msg_socket , zmq . POLLIN ) continue else : msg_json = self . __msg_socket . recv_json ( flags = self . __msg_flag ) # check if terminate_flag` received if msg_json [ \"terminate_flag\" ]: # if multiserver_mode is enabled if self . __multiserver_mode : # check and remove from which ports signal is received if msg_json [ \"port\" ] in self . __port_buffer : # if pattern is 1, then send back server the info about termination if self . __pattern == 1 : self . __msg_socket . send_string ( \"Termination signal successfully received at client!\" ) self . __port_buffer . remove ( msg_json [ \"port\" ]) self . __logging and logger . warning ( \"Termination signal received from Server at port: {} !\" . format ( msg_json [ \"port\" ] ) ) # if termination signal received from all servers then exit client. if not self . __port_buffer : logger . critical ( \"Termination signal received from all Servers!!!\" ) self . __terminate = True # termination else : # if pattern is 1, then send back server the info about termination if self . __pattern == 1 : self . __msg_socket . send_string ( \"Termination signal successfully received at Client's end!\" ) # termination self . __terminate = True # notify client self . __logging and logger . critical ( \"Termination signal received from server!\" ) continue msg_data = self . __msg_socket . recv ( flags = self . __msg_flag | zmq . DONTWAIT , copy = self . __msg_copy , track = self . __msg_track , ) # handle data transfer in synchronous modes. if self . __pattern < 2 : if self . __bi_mode or self . __multiclient_mode : # check if we are returning `ndarray` frames if not ( self . __return_data is None ) and isinstance ( self . __return_data , np . ndarray ): # handle return data for compression return_data = np . copy ( self . __return_data ) # check whether exit_flag is False if not ( return_data . flags [ \"C_CONTIGUOUS\" ]): # check whether the incoming frame is contiguous return_data = np . ascontiguousarray ( return_data , dtype = return_data . dtype ) # handle jpeg-compression encoding if self . __jpeg_compression : if self . __jpeg_compression_colorspace == \"GRAY\" : if return_data . ndim == 2 : # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11 return_data = return_data [:, :, np . newaxis ] return_data = simplejpeg . encode_jpeg ( return_data , quality = self . __jpeg_compression_quality , colorspace = self . __jpeg_compression_colorspace , fastdct = self . __jpeg_compression_fastdct , ) else : return_data = simplejpeg . encode_jpeg ( return_data , quality = self . __jpeg_compression_quality , colorspace = self . __jpeg_compression_colorspace , colorsubsampling = \"422\" , fastdct = self . __jpeg_compression_fastdct , ) return_dict = ( dict ( port = self . __port ) if self . __multiclient_mode else dict () ) return_dict . update ( dict ( return_type = ( type ( self . __return_data ) . __name__ ), compression = { \"dct\" : self . __jpeg_compression_fastdct , \"ups\" : self . __jpeg_compression_fastupsample , \"colorspace\" : self . __jpeg_compression_colorspace , } if self . __jpeg_compression else False , array_dtype = str ( self . __return_data . dtype ) if not ( self . __jpeg_compression ) else \"\" , array_shape = self . __return_data . shape if not ( self . __jpeg_compression ) else \"\" , data = None , ) ) # send the json dict self . __msg_socket . send_json ( return_dict , self . __msg_flag | zmq . SNDMORE ) # send the array with correct flags self . __msg_socket . send ( return_data , flags = self . __msg_flag , copy = self . __msg_copy , track = self . __msg_track , ) else : return_dict = ( dict ( port = self . __port ) if self . __multiclient_mode else dict () ) return_dict . update ( dict ( return_type = ( type ( self . __return_data ) . __name__ ), data = self . __return_data , ) ) self . __msg_socket . send_json ( return_dict , self . __msg_flag ) else : # send confirmation message to server self . __msg_socket . send_string ( \"Data received on device: {} !\" . format ( self . __id ) ) else : # else raise warning if self . __return_data : logger . warning ( \"`return_data` is disabled for this pattern!\" ) # check if encoding was enabled if msg_json [ \"compression\" ]: # decode JPEG frame frame = simplejpeg . decode_jpeg ( msg_data , colorspace = msg_json [ \"compression\" ][ \"colorspace\" ], fastdct = self . __jpeg_compression_fastdct or msg_json [ \"compression\" ][ \"dct\" ], fastupsample = self . __jpeg_compression_fastupsample or msg_json [ \"compression\" ][ \"ups\" ], ) # check if valid frame returned if frame is None : self . __terminate = True # otherwise raise error and exit raise RuntimeError ( \"[NetGear:ERROR] :: Received compressed JPEG frame decoding failed\" ) if msg_json [ \"compression\" ][ \"colorspace\" ] == \"GRAY\" and frame . ndim == 3 : # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11 frame = np . squeeze ( frame , axis = 2 ) else : # recover and reshape frame from buffer frame_buffer = np . frombuffer ( msg_data , dtype = msg_json [ \"dtype\" ]) frame = frame_buffer . reshape ( msg_json [ \"shape\" ]) # check if multiserver_mode if self . __multiserver_mode : # save the unique port addresses if not msg_json [ \"port\" ] in self . __port_buffer : self . __port_buffer . append ( msg_json [ \"port\" ]) # extract if any message from server and display it if msg_json [ \"message\" ]: self . __queue . append (( msg_json [ \"port\" ], msg_json [ \"message\" ], frame )) else : # append recovered unique port and frame to queue self . __queue . append (( msg_json [ \"port\" ], frame )) # extract if any message from server if Bidirectional Mode is enabled elif self . __bi_mode : if msg_json [ \"message\" ]: # append grouped frame and data to queue self . __queue . append (( msg_json [ \"message\" ], frame )) else : self . __queue . append (( None , frame )) else : # otherwise append recovered frame to queue self . __queue . append ( frame ) def recv ( self , return_data = None ): \"\"\" A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Parameters: return_data (any): inputs return data _(of any datatype)_, for sending back to Server. **Returns:** A n-dimensional numpy array. \"\"\" # check whether `receive mode` is activated if not ( self . __receive_mode ): # raise value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `recv()` function cannot be used while receive_mode is disabled. Kindly refer vidgear docs!\" ) # handle Bidirectional return data if ( self . __bi_mode or self . __multiclient_mode ) and not ( return_data is None ): self . __return_data = return_data # check whether or not termination flag is enabled while not self . __terminate : try : # check if queue is empty if len ( self . __queue ) > 0 : return self . __queue . popleft () else : time . sleep ( 0.00001 ) continue except KeyboardInterrupt : self . __terminate = True break # otherwise return NoneType return None def send ( self , frame , message = None ): \"\"\" A Server end method, that sends the data and frames over the network to Client(s). Parameters: frame (numpy.ndarray): inputs numpy array(frame). message (any): input for sending additional data _(of any datatype except `numpy.ndarray`)_ to Client(s). **Returns:** Data _(of any datatype)_ in selected exclusive modes, otherwise None-type. \"\"\" # check whether `receive_mode` is disabled if self . __receive_mode : # raise value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `send()` function cannot be used while receive_mode is enabled. Kindly refer vidgear docs!\" ) if not ( message is None ) and isinstance ( message , np . ndarray ): logger . warning ( \"Skipped unsupported `message` of datatype: {} !\" . format ( type ( message ) . __name__ ) ) message = None # define exit_flag and assign value exit_flag = True if ( frame is None or self . __terminate ) else False # check whether exit_flag is False if not ( exit_flag ) and not ( frame . flags [ \"C_CONTIGUOUS\" ]): # check whether the incoming frame is contiguous frame = np . ascontiguousarray ( frame , dtype = frame . dtype ) # handle JPEG compression encoding if self . __jpeg_compression : if self . __jpeg_compression_colorspace == \"GRAY\" : if frame . ndim == 2 : # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11 frame = np . expand_dims ( frame , axis = 2 ) frame = simplejpeg . encode_jpeg ( frame , quality = self . __jpeg_compression_quality , colorspace = self . __jpeg_compression_colorspace , fastdct = self . __jpeg_compression_fastdct , ) else : frame = simplejpeg . encode_jpeg ( frame , quality = self . __jpeg_compression_quality , colorspace = self . __jpeg_compression_colorspace , colorsubsampling = \"422\" , fastdct = self . __jpeg_compression_fastdct , ) # check if multiserver_mode is activated and assign values with unique port msg_dict = dict ( port = self . __port ) if self . __multiserver_mode else dict () # prepare the exclusive json dict msg_dict . update ( dict ( terminate_flag = exit_flag , compression = { \"dct\" : self . __jpeg_compression_fastdct , \"ups\" : self . __jpeg_compression_fastupsample , \"colorspace\" : self . __jpeg_compression_colorspace , } if self . __jpeg_compression else False , message = message , pattern = str ( self . __pattern ), dtype = str ( frame . dtype ) if not ( self . __jpeg_compression ) else \"\" , shape = frame . shape if not ( self . __jpeg_compression ) else \"\" , ) ) # send the json dict self . __msg_socket . send_json ( msg_dict , self . __msg_flag | zmq . SNDMORE ) # send the frame array with correct flags self . __msg_socket . send ( frame , flags = self . __msg_flag , copy = self . __msg_copy , track = self . __msg_track ) # check if synchronous patterns, then wait for confirmation if self . __pattern < 2 : # check if Bidirectional data transmission is enabled if self . __bi_mode or self . __multiclient_mode : # handles return data recvd_data = None socks = dict ( self . __poll . poll ( self . __request_timeout )) if socks . get ( self . __msg_socket ) == zmq . POLLIN : # handle return data recv_json = self . __msg_socket . recv_json ( flags = self . __msg_flag ) else : logger . critical ( \"No response from Client, Reconnecting again...\" ) # Socket is confused. Close and remove it. self . __msg_socket . setsockopt ( zmq . LINGER , 0 ) self . __msg_socket . close () self . __poll . unregister ( self . __msg_socket ) self . __max_retries -= 1 if not ( self . __max_retries ): if self . __multiclient_mode : logger . error ( \"All Clients failed to respond on multiple attempts.\" ) else : logger . error ( \"Client failed to respond on multiple attempts.\" ) self . __terminate = True raise RuntimeError ( \"[NetGear:ERROR] :: Client(s) seems to be offline, Abandoning.\" ) # Create new connection self . __msg_socket = self . __msg_context . socket ( self . __msg_pattern ) if isinstance ( self . __connection_address , list ): for _connection in self . __connection_address : self . __msg_socket . connect ( _connection ) else : # handle SSH tunneling if enabled if self . __ssh_tunnel_mode : # establish tunnel connection ssh . tunnel_connection ( self . __msg_socket , self . __connection_address , self . __ssh_tunnel_mode , keyfile = self . __ssh_tunnel_keyfile , password = self . __ssh_tunnel_pwd , paramiko = self . __paramiko_present , ) else : # connect normally self . __msg_socket . connect ( self . __connection_address ) self . __poll . register ( self . __msg_socket , zmq . POLLIN ) # return None for mean-time return None # save the unique port addresses if ( self . __multiclient_mode and not recv_json [ \"port\" ] in self . __port_buffer ): self . __port_buffer . append ( recv_json [ \"port\" ]) if recv_json [ \"return_type\" ] == \"ndarray\" : recv_array = self . __msg_socket . recv ( flags = self . __msg_flag , copy = self . __msg_copy , track = self . __msg_track , ) # check if encoding was enabled if recv_json [ \"compression\" ]: # decode JPEG frame recvd_data = simplejpeg . decode_jpeg ( recv_array , colorspace = recv_json [ \"compression\" ][ \"colorspace\" ], fastdct = self . __jpeg_compression_fastdct or recv_json [ \"compression\" ][ \"dct\" ], fastupsample = self . __jpeg_compression_fastupsample or recv_json [ \"compression\" ][ \"ups\" ], ) # check if valid frame returned if recvd_data is None : self . __terminate = True # otherwise raise error and exit raise RuntimeError ( \"[NetGear:ERROR] :: Received compressed frame ` {} ` decoding failed with flag: {} .\" . format ( recv_json [ \"compression\" ], self . __ex_compression_params , ) ) if ( recv_json [ \"compression\" ][ \"colorspace\" ] == \"GRAY\" and recvd_data . ndim == 3 ): # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11 recvd_data = np . squeeze ( recvd_data , axis = 2 ) else : recvd_data = np . frombuffer ( recv_array , dtype = recv_json [ \"array_dtype\" ] ) . reshape ( recv_json [ \"array_shape\" ]) else : recvd_data = recv_json [ \"data\" ] return ( ( recv_json [ \"port\" ], recvd_data ) if self . __multiclient_mode else recvd_data ) else : # otherwise log normally socks = dict ( self . __poll . poll ( self . __request_timeout )) if socks . get ( self . __msg_socket ) == zmq . POLLIN : recv_confirmation = self . __msg_socket . recv () else : logger . critical ( \"No response from Client, Reconnecting again...\" ) # Socket is confused. Close and remove it. self . __msg_socket . setsockopt ( zmq . LINGER , 0 ) self . __msg_socket . close () self . __poll . unregister ( self . __msg_socket ) self . __max_retries -= 1 if not ( self . __max_retries ): logger . error ( \"Client failed to respond on repeated attempts.\" ) self . __terminate = True raise RuntimeError ( \"[NetGear:ERROR] :: Client seems to be offline, Abandoning!\" ) # Create new connection self . __msg_socket = self . __msg_context . socket ( self . __msg_pattern ) # handle SSH tunneling if enabled if self . __ssh_tunnel_mode : # establish tunnel connection ssh . tunnel_connection ( self . __msg_socket , self . __connection_address , self . __ssh_tunnel_mode , keyfile = self . __ssh_tunnel_keyfile , password = self . __ssh_tunnel_pwd , paramiko = self . __paramiko_present , ) else : # connect normally self . __msg_socket . connect ( self . __connection_address ) self . __poll . register ( self . __msg_socket , zmq . POLLIN ) return None # log confirmation self . __logging and logger . debug ( recv_confirmation ) def close ( self ): \"\"\" Safely terminates the threads, and NetGear resources. \"\"\" # log it self . __logging and logger . debug ( \"Terminating various {} Processes.\" . format ( \"Receive Mode\" if self . __receive_mode else \"Send Mode\" ) ) # whether `receive_mode` is enabled or not if self . __receive_mode : # check whether queue mode is empty if not ( self . __queue is None ) and self . __queue : self . __queue . clear () # call immediate termination self . __terminate = True # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : # properly handle thread exit self . __thread . join () self . __thread = None self . __logging and logger . debug ( \"Terminating. Please wait...\" ) # properly close the socket self . __msg_socket . close ( linger = 0 ) self . __logging and logger . debug ( \"Terminated Successfully!\" ) else : # indicate that process should be terminated self . __terminate = True # check if all attempts of reconnecting failed, then skip to closure if ( self . __pattern < 2 and not self . __max_retries ) or ( self . __multiclient_mode and not self . __port_buffer ): try : # properly close the socket self . __msg_socket . setsockopt ( zmq . LINGER , 0 ) self . __msg_socket . close () except ZMQError : pass finally : # exit return if self . __multiserver_mode : # check if multiserver_mode # send termination flag to client with its unique port term_dict = dict ( terminate_flag = True , port = self . __port ) else : # otherwise send termination flag to client term_dict = dict ( terminate_flag = True ) try : if self . __multiclient_mode : for _ in self . __port_buffer : self . __msg_socket . send_json ( term_dict ) else : self . __msg_socket . send_json ( term_dict ) # check for confirmation if available within 1/5 timeout if self . __pattern < 2 : self . __logging and logger . debug ( \"Terminating. Please wait...\" ) if self . __msg_socket . poll ( self . __request_timeout // 5 , zmq . POLLIN ): self . __msg_socket . recv () except Exception as e : if not isinstance ( e , ZMQError ): logger . exception ( str ( e )) finally : # properly close the socket self . __msg_socket . setsockopt ( zmq . LINGER , 0 ) self . __msg_socket . close () self . __logging and logger . debug ( \"Terminated Successfully!\" ) __init__ ( self , address = None , port = None , protocol = None , pattern = 0 , receive_mode = False , logging = False , ** options ) special \u2693 This constructor method initializes the object state and attributes of the NetGear class. Parameters: Name Type Description Default address str sets the valid network address of the Server/Client. None port str sets the valid Network Port of the Server/Client. None protocol str sets the valid messaging protocol between Server/Client. None pattern int sets the supported messaging pattern(flow of communication) between Server/Client 0 receive_mode bool select the Netgear's Mode of operation. False logging bool enables/disables logging. False options dict provides the flexibility to alter various NetGear internal properties. {} Source code in vidgear/gears/netgear.py def __init__ ( self , address = None , port = None , protocol = None , pattern = 0 , receive_mode = False , logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the NetGear class. Parameters: address (str): sets the valid network address of the Server/Client. port (str): sets the valid Network Port of the Server/Client. protocol (str): sets the valid messaging protocol between Server/Client. pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client receive_mode (bool): select the Netgear's Mode of operation. logging (bool): enables/disables logging. options (dict): provides the flexibility to alter various NetGear internal properties. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"zmq\" if zmq is None else \"\" , min_version = \"4.0\" , pkg_name = \"pyzmq\" ) import_dependency_safe ( \"simplejpeg\" if simplejpeg is None else \"\" , error = \"log\" , min_version = \"1.6.1\" ) # enable logging if specified self . __logging = True if logging else False # define valid messaging patterns => `0`: zmq.PAIR, `1`:(zmq.REQ,zmq.REP), and `1`:(zmq.SUB,zmq.PUB) valid_messaging_patterns = { 0 : ( zmq . PAIR , zmq . PAIR ), 1 : ( zmq . REQ , zmq . REP ), 2 : ( zmq . PUB , zmq . SUB ), } # Handle messaging pattern msg_pattern = None # check whether user-defined messaging pattern is valid if isinstance ( pattern , int ) and pattern in valid_messaging_patterns . keys (): # assign value msg_pattern = valid_messaging_patterns [ pattern ] else : # otherwise default to 0:`zmq.PAIR` pattern = 0 msg_pattern = valid_messaging_patterns [ pattern ] self . __logging and logger . warning ( \"Wrong pattern value, Defaulting to `zmq.PAIR`! Kindly refer Docs for more Information.\" ) # assign pattern to global parameter for further use self . __pattern = pattern # Handle messaging protocol if protocol is None or not ( protocol in [ \"tcp\" , \"ipc\" ]): # else default to `tcp` protocol protocol = \"tcp\" # log it self . __logging and logger . warning ( \"Protocol is not supported or not provided. Defaulting to `tcp` protocol!\" ) # Handle connection params self . __msg_flag = 0 # handles connection flags self . __msg_copy = False # handles whether to copy data self . __msg_track = False # handles whether to track packets # Handle NetGear's internal exclusive modes and params # define SSH Tunneling Mode self . __ssh_tunnel_mode = None # handles ssh_tunneling mode state self . __ssh_tunnel_pwd = None self . __ssh_tunnel_keyfile = None self . __paramiko_present = False if paramiko is None else True # define Multi-Server mode self . __multiserver_mode = False # handles multi-server mode state # define Multi-Client mode self . __multiclient_mode = False # handles multi-client mode state # define Bidirectional mode self . __bi_mode = False # handles Bidirectional mode state # define Secure mode valid_security_mech = { 0 : \"Grasslands\" , 1 : \"StoneHouse\" , 2 : \"IronHouse\" } self . __secure_mode = 0 # handles ZMQ security layer status auth_cert_dir = \"\" # handles valid ZMQ certificates dir self . __auth_publickeys_dir = \"\" # handles valid ZMQ public certificates dir self . __auth_secretkeys_dir = \"\" # handles valid ZMQ private certificates dir overwrite_cert = False # checks if certificates overwriting allowed custom_cert_location = \"\" # handles custom ZMQ certificates path # define frame-compression handler self . __jpeg_compression = ( True if not ( simplejpeg is None ) else False ) # enabled by default for all connections if simplejpeg is installed self . __jpeg_compression_quality = 90 # 90% quality self . __jpeg_compression_fastdct = True # fastest DCT on by default self . __jpeg_compression_fastupsample = False # fastupsample off by default self . __jpeg_compression_colorspace = \"BGR\" # use BGR colorspace by default # defines frame compression on return data self . __ex_compression_params = None # define receiver return data handler self . __return_data = None # generate 8-digit random system id self . __id = \"\" . join ( secrets . choice ( string . ascii_uppercase + string . digits ) for i in range ( 8 ) ) # define termination flag self . __terminate = False # additional settings for reliability if pattern < 2 : # define zmq poller for reliable transmission self . __poll = zmq . Poller () # define max retries self . __max_retries = 3 # request timeout self . __request_timeout = 4000 # 4 secs # Handle user-defined options dictionary values # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # loop over dictionary key & values and assign to global variables if valid for key , value in options . items (): # handle multi-server mode if key == \"multiserver_mode\" and isinstance ( value , bool ): # check if valid pattern assigned if pattern > 0 : # activate Multi-server mode self . __multiserver_mode = value else : # otherwise disable it and raise error self . __multiserver_mode = False logger . critical ( \"Multi-Server Mode is disabled!\" ) raise ValueError ( \"[NetGear:ERROR] :: ` {} ` pattern is not valid when Multi-Server Mode is enabled. Kindly refer Docs for more Information.\" . format ( pattern ) ) # handle multi-client mode elif key == \"multiclient_mode\" and isinstance ( value , bool ): # check if valid pattern assigned if pattern > 0 : # activate Multi-client mode self . __multiclient_mode = value else : # otherwise disable it and raise error self . __multiclient_mode = False logger . critical ( \"Multi-Client Mode is disabled!\" ) raise ValueError ( \"[NetGear:ERROR] :: ` {} ` pattern is not valid when Multi-Client Mode is enabled. Kindly refer Docs for more Information.\" . format ( pattern ) ) # handle bidirectional mode elif key == \"bidirectional_mode\" and isinstance ( value , bool ): # check if pattern is valid if pattern < 2 : # activate Bidirectional mode if specified self . __bi_mode = value else : # otherwise disable it and raise error self . __bi_mode = False logger . warning ( \"Bidirectional data transmission is disabled!\" ) raise ValueError ( \"[NetGear:ERROR] :: ` {} ` pattern is not valid when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\" . format ( pattern ) ) # handle secure mode elif ( key == \"secure_mode\" and isinstance ( value , int ) and ( value in valid_security_mech ) ): self . __secure_mode = value elif key == \"custom_cert_location\" and isinstance ( value , str ): # verify custom auth certificates path for secure mode custom_cert_location = os . path . abspath ( value ) assert os . path . isdir ( custom_cert_location ), \"[NetGear:ERROR] :: `custom_cert_location` value must be the path to a valid directory!\" assert check_WriteAccess ( custom_cert_location , is_windows = True if os . name == \"nt\" else False , logging = self . __logging , ), \"[NetGear:ERROR] :: Permission Denied!, cannot write ZMQ authentication certificates to ' {} ' directory!\" . format ( value ) elif key == \"overwrite_cert\" and isinstance ( value , bool ): # enable/disable auth certificate overwriting in secure mode overwrite_cert = value # handle ssh-tunneling mode elif key == \"ssh_tunnel_mode\" and isinstance ( value , str ): # enable SSH Tunneling Mode self . __ssh_tunnel_mode = value . strip () elif key == \"ssh_tunnel_pwd\" and isinstance ( value , str ): # add valid SSH Tunneling password self . __ssh_tunnel_pwd = value elif key == \"ssh_tunnel_keyfile\" and isinstance ( value , str ): # add valid SSH Tunneling key-file self . __ssh_tunnel_keyfile = value if os . path . isfile ( value ) else None if self . __ssh_tunnel_keyfile is None : logger . warning ( \"Discarded invalid or non-existential SSH Tunnel Key-file at {} !\" . format ( value ) ) # handle jpeg compression elif ( key == \"jpeg_compression\" and not ( simplejpeg is None ) and isinstance ( value , ( bool , str )) ): if isinstance ( value , str ) and value . strip () . upper () in [ \"RGB\" , \"BGR\" , \"RGBX\" , \"BGRX\" , \"XBGR\" , \"XRGB\" , \"GRAY\" , \"RGBA\" , \"BGRA\" , \"ABGR\" , \"ARGB\" , \"CMYK\" , ]: # set encoding colorspace self . __jpeg_compression_colorspace = value . strip () . upper () # enable frame-compression encoding value self . __jpeg_compression = True else : # enable frame-compression encoding value self . __jpeg_compression = value elif key == \"jpeg_compression_quality\" and isinstance ( value , ( int , float )): # set valid jpeg quality if value >= 10 and value <= 100 : self . __jpeg_compression_quality = int ( value ) else : logger . warning ( \"Skipped invalid `jpeg_compression_quality` value!\" ) elif key == \"jpeg_compression_fastdct\" and isinstance ( value , bool ): # enable jpeg fastdct self . __jpeg_compression_fastdct = value elif key == \"jpeg_compression_fastupsample\" and isinstance ( value , bool ): # enable jpeg fastupsample self . __jpeg_compression_fastupsample = value # assign maximum retries in synchronous patterns elif key == \"max_retries\" and isinstance ( value , int ) and pattern < 2 : if value >= 0 : self . __max_retries = value else : logger . warning ( \"Invalid `max_retries` value skipped!\" ) # assign request timeout in synchronous patterns elif key == \"request_timeout\" and isinstance ( value , int ) and pattern < 2 : if value >= 4 : self . __request_timeout = value * 1000 # covert to milliseconds else : logger . warning ( \"Invalid `request_timeout` value skipped!\" ) # handle ZMQ flags elif key == \"flag\" and isinstance ( value , int ): self . __msg_flag = value elif key == \"copy\" and isinstance ( value , bool ): self . __msg_copy = value elif key == \"track\" and isinstance ( value , bool ): self . __msg_track = value else : pass # Handle Secure mode if self . __secure_mode : # activate and log if overwriting is enabled if overwrite_cert : if not receive_mode : self . __logging and logger . warning ( \"Overwriting ZMQ Authentication certificates over previous ones!\" ) else : overwrite_cert = False self . __logging and logger . critical ( \"Overwriting ZMQ Authentication certificates is disabled for Client's end!\" ) # Validate certificate generation paths try : # check if custom certificates path is specified if custom_cert_location : ( auth_cert_dir , self . __auth_secretkeys_dir , self . __auth_publickeys_dir , ) = generate_auth_certificates ( custom_cert_location , overwrite = overwrite_cert , logging = logging ) else : # otherwise auto-generate suitable path ( auth_cert_dir , self . __auth_secretkeys_dir , self . __auth_publickeys_dir , ) = generate_auth_certificates ( os . path . join ( expanduser ( \"~\" ), \".vidgear\" ), overwrite = overwrite_cert , logging = logging , ) # log it self . __logging and logger . debug ( \"` {} ` is the default location for storing ZMQ authentication certificates/keys.\" . format ( auth_cert_dir ) ) except Exception as e : # catch if any error occurred and disable Secure mode logger . exception ( str ( e )) self . __secure_mode = 0 logger . critical ( \"ZMQ Security Mechanism is disabled for this connection due to errors!\" ) # Handle ssh tunneling if enabled if not ( self . __ssh_tunnel_mode is None ): # SSH Tunnel Mode only available for server mode if receive_mode : logger . error ( \"SSH Tunneling cannot be enabled for Client-end!\" ) else : # check if SSH tunneling possible ssh_address = self . __ssh_tunnel_mode ssh_address , ssh_port = ( ssh_address . split ( \":\" ) if \":\" in ssh_address else [ ssh_address , \"22\" ] ) # default to port 22 if \"47\" in ssh_port : self . __ssh_tunnel_mode = self . __ssh_tunnel_mode . replace ( \":47\" , \"\" ) # port-47 is reserved for testing else : # extract ip for validation ssh_user , ssh_ip = ( ssh_address . split ( \"@\" ) if \"@\" in ssh_address else [ \"\" , ssh_address ] ) # validate ip specified port assert check_open_port ( ssh_ip , port = int ( ssh_port ) ), \"[NetGear:ERROR] :: Host ` {} ` is not available for SSH Tunneling at port- {} !\" . format ( ssh_address , ssh_port ) # Handle multiple exclusive modes if enabled if self . __multiclient_mode and self . __multiserver_mode : raise ValueError ( \"[NetGear:ERROR] :: Multi-Client and Multi-Server Mode cannot be enabled simultaneously!\" ) elif self . __multiserver_mode or self . __multiclient_mode : # check if Bidirectional Mode also enabled if self . __bi_mode : # log it self . __logging and logger . debug ( \"Bidirectional Data Transmission is also enabled for this connection!\" ) # check if SSH Tunneling Mode also enabled if self . __ssh_tunnel_mode : # raise error raise ValueError ( \"[NetGear:ERROR] :: SSH Tunneling and {} Mode cannot be enabled simultaneously. Kindly refer docs!\" . format ( \"Multi-Server\" if self . __multiserver_mode else \"Multi-Client\" ) ) elif self . __bi_mode : # log Bidirectional mode activation self . __logging and logger . debug ( \"Bidirectional Data Transmission is enabled for this connection!\" ) elif self . __ssh_tunnel_mode : # log Bidirectional mode activation self . __logging and logger . debug ( \"SSH Tunneling is enabled for host:` {} ` with ` {} ` back-end.\" . format ( self . __ssh_tunnel_mode , \"paramiko\" if self . __paramiko_present else \"pexpect\" , ) ) # define messaging context instance self . __msg_context = zmq . Context . instance () # initialize and assign receive mode to global variable self . __receive_mode = receive_mode # check whether `receive_mode` is enabled if self . __receive_mode : # define connection address if address is None : address = \"*\" # define address # check if multiserver_mode is enabled if self . __multiserver_mode : # check if unique server port address list/tuple is assigned or not in multiserver_mode if port is None or not isinstance ( port , ( tuple , list )): # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Server ports while Multi-Server mode is enabled. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Server Mode at PORTS: {} !\" . format ( port ) ) # create port address buffer for keeping track of connected client's port(s) self . __port_buffer = [] # check if multiclient_mode is enabled elif self . __multiclient_mode : # check if unique server port address is assigned or not in multiclient_mode if port is None : # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Kindly provide a unique & valid port value at Client-end. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Client Mode at PORT: {} on this device!\" . format ( port ) ) # assign value to global variable self . __port = port else : # otherwise assign local port address if None if port is None : port = \"5555\" try : # activate secure_mode threaded authenticator if self . __secure_mode > 0 : # start an authenticator for this context z_auth = ThreadAuthenticator ( self . __msg_context ) z_auth . start () z_auth . allow ( str ( address )) # allow current address # check if `IronHouse` is activated if self . __secure_mode == 2 : # tell authenticator to use the certificate from given valid dir z_auth . configure_curve ( domain = \"*\" , location = self . __auth_publickeys_dir ) else : # otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated z_auth . configure_curve ( domain = \"*\" , location = auth . CURVE_ALLOW_ANY ) # define thread-safe messaging socket self . __msg_socket = self . __msg_context . socket ( msg_pattern [ 1 ]) # define pub-sub flag if self . __pattern == 2 : self . __msg_socket . set_hwm ( 1 ) # enable specified secure mode for the socket if self . __secure_mode > 0 : # load server key server_secret_file = os . path . join ( self . __auth_secretkeys_dir , \"server.key_secret\" ) server_public , server_secret = auth . load_certificate ( server_secret_file ) # load all CURVE keys self . __msg_socket . curve_secretkey = server_secret self . __msg_socket . curve_publickey = server_public # enable CURVE connection for this socket self . __msg_socket . curve_server = True # define exclusive socket options for patterns if self . __pattern == 2 : self . __msg_socket . setsockopt_string ( zmq . SUBSCRIBE , \"\" ) # if multiserver_mode is enabled, then assign port addresses to zmq socket if self . __multiserver_mode : # bind socket to given server protocol, address and ports for pt in port : self . __msg_socket . bind ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : # bind socket to given protocol, address and port normally self . __msg_socket . bind ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) # additional settings if pattern < 2 : if self . __multiserver_mode : self . __connection_address = [] for pt in port : self . __connection_address . append ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : self . __connection_address = ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) self . __msg_pattern = msg_pattern [ 1 ] self . __poll . register ( self . __msg_socket , zmq . POLLIN ) self . __logging and logger . debug ( \"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\" . format ( self . __max_retries , self . __request_timeout / 1000 ) ) except Exception as e : # otherwise log and raise error logger . exception ( str ( e )) if self . __secure_mode : logger . critical ( \"Failed to activate Secure Mode: ` {} ` for this connection!\" . format ( valid_security_mech [ self . __secure_mode ] ) ) if self . __multiserver_mode or self . __multiclient_mode : raise RuntimeError ( \"[NetGear:ERROR] :: Receive Mode failed to activate {} Mode at address: {} with pattern: {} ! Kindly recheck all parameters.\" . format ( \"Multi-Server\" if self . __multiserver_mode else \"Multi-Client\" , ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern , ) ) else : if self . __bi_mode : logger . critical ( \"Failed to activate Bidirectional Mode for this connection!\" ) raise RuntimeError ( \"[NetGear:ERROR] :: Receive Mode failed to bind address: {} and pattern: {} ! Kindly recheck all parameters.\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) # Handle threaded queue mode self . __logging and logger . debug ( \"Threaded Queue Mode is enabled by default for this connection.\" ) # define deque and assign it to global var self . __queue = deque ( maxlen = 96 ) # max len 96 to check overflow # initialize and start threaded recv_handler self . __thread = Thread ( target = self . __recv_handler , name = \"NetGear\" , args = ()) self . __thread . daemon = True self . __thread . start () if self . __logging : # finally log progress logger . debug ( \"Successfully Binded to address: {} with pattern: {} .\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) if self . __jpeg_compression : logger . debug ( \"JPEG Frame-Compression is activated for this connection with Colorspace:` {} `, Quality:` {} `%, Fastdct:` {} `, and Fastupsample:` {} `.\" . format ( self . __jpeg_compression_colorspace , self . __jpeg_compression_quality , \"enabled\" if self . __jpeg_compression_fastdct else \"disabled\" , \"enabled\" if self . __jpeg_compression_fastupsample else \"disabled\" , ) ) if self . __secure_mode : logger . debug ( \"Successfully enabled ZMQ Security Mechanism: ` {} ` for this connection.\" . format ( valid_security_mech [ self . __secure_mode ] ) ) logger . debug ( \"Multi-threaded Receive Mode is successfully enabled.\" ) logger . debug ( \"Unique System ID is {} .\" . format ( self . __id )) logger . debug ( \"Receive Mode is now activated.\" ) else : # otherwise default to `Send Mode` # define connection address if address is None : address = \"localhost\" # check if multiserver_mode is enabled if self . __multiserver_mode : # check if unique server port address is assigned or not in multiserver_mode if port is None : # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Kindly provide a unique & valid port value at Server-end. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Server Mode at PORT: {} on this device!\" . format ( port ) ) # assign value to global variable self . __port = port # check if multiclient_mode is enabled elif self . __multiclient_mode : # check if unique client port address list/tuple is assigned or not in multiclient_mode if port is None or not isinstance ( port , ( tuple , list )): # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Client ports while Multi-Client mode is enabled. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Client Mode at PORTS: {} !\" . format ( port ) ) # create port address buffer for keeping track of connected client ports self . __port_buffer = [] else : # otherwise assign local port address if None if port is None : port = \"5555\" try : # activate secure_mode threaded authenticator if self . __secure_mode > 0 : # start an authenticator for this context z_auth = ThreadAuthenticator ( self . __msg_context ) z_auth . start () z_auth . allow ( str ( address )) # allow current address # check if `IronHouse` is activated if self . __secure_mode == 2 : # tell authenticator to use the certificate from given valid dir z_auth . configure_curve ( domain = \"*\" , location = self . __auth_publickeys_dir ) else : # otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated z_auth . configure_curve ( domain = \"*\" , location = auth . CURVE_ALLOW_ANY ) # define thread-safe messaging socket self . __msg_socket = self . __msg_context . socket ( msg_pattern [ 0 ]) # if req/rep pattern, define additional flags if self . __pattern == 1 : self . __msg_socket . REQ_RELAXED = True self . __msg_socket . REQ_CORRELATE = True # if pub/sub pattern, define additional optimizer if self . __pattern == 2 : self . __msg_socket . set_hwm ( 1 ) # enable specified secure mode for the socket if self . __secure_mode > 0 : # load client key client_secret_file = os . path . join ( self . __auth_secretkeys_dir , \"client.key_secret\" ) client_public , client_secret = auth . load_certificate ( client_secret_file ) # load all CURVE keys self . __msg_socket . curve_secretkey = client_secret self . __msg_socket . curve_publickey = client_public # load server key server_public_file = os . path . join ( self . __auth_publickeys_dir , \"server.key\" ) server_public , _ = auth . load_certificate ( server_public_file ) # inject public key to make a CURVE connection. self . __msg_socket . curve_serverkey = server_public # check if multi-client_mode is enabled if self . __multiclient_mode : # bind socket to given server protocol, address and ports for pt in port : self . __msg_socket . connect ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : # handle SSH tuneling if enabled if self . __ssh_tunnel_mode : # establish tunnel connection ssh . tunnel_connection ( self . __msg_socket , protocol + \"://\" + str ( address ) + \":\" + str ( port ), self . __ssh_tunnel_mode , keyfile = self . __ssh_tunnel_keyfile , password = self . __ssh_tunnel_pwd , paramiko = self . __paramiko_present , ) else : # connect socket to given protocol, address and port self . __msg_socket . connect ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) # additional settings if pattern < 2 : if self . __multiclient_mode : self . __connection_address = [] for pt in port : self . __connection_address . append ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : self . __connection_address = ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) self . __msg_pattern = msg_pattern [ 0 ] self . __poll . register ( self . __msg_socket , zmq . POLLIN ) self . __logging and logger . debug ( \"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\" . format ( self . __max_retries , self . __request_timeout / 1000 ) ) except Exception as e : # otherwise log and raise error logger . exception ( str ( e )) if self . __secure_mode : logger . critical ( \"Failed to activate Secure Mode: ` {} ` for this connection!\" . format ( valid_security_mech [ self . __secure_mode ] ) ) if self . __multiserver_mode or self . __multiclient_mode : raise RuntimeError ( \"[NetGear:ERROR] :: Send Mode failed to activate {} Mode at address: {} with pattern: {} ! Kindly recheck all parameters.\" . format ( \"Multi-Server\" if self . __multiserver_mode else \"Multi-Client\" , ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern , ) ) else : if self . __bi_mode : logger . critical ( \"Failed to activate Bidirectional Mode for this connection!\" ) if self . __ssh_tunnel_mode : logger . critical ( \"Failed to initiate SSH Tunneling Mode for this server with ` {} ` back-end!\" . format ( \"paramiko\" if self . __paramiko_present else \"pexpect\" ) ) raise RuntimeError ( \"[NetGear:ERROR] :: Send Mode failed to connect address: {} and pattern: {} ! Kindly recheck all parameters.\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) if self . __logging : # finally log progress logger . debug ( \"Successfully connected to address: {} with pattern: {} .\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) if self . __jpeg_compression : logger . debug ( \"JPEG Frame-Compression is activated for this connection with Colorspace:` {} `, Quality:` {} `%, Fastdct:` {} `, and Fastupsample:` {} `.\" . format ( self . __jpeg_compression_colorspace , self . __jpeg_compression_quality , \"enabled\" if self . __jpeg_compression_fastdct else \"disabled\" , \"enabled\" if self . __jpeg_compression_fastupsample else \"disabled\" , ) ) if self . __secure_mode : logger . debug ( \"Enabled ZMQ Security Mechanism: ` {} ` for this connection.\" . format ( valid_security_mech [ self . __secure_mode ] ) ) logger . debug ( \"Unique System ID is {} .\" . format ( self . __id )) logger . debug ( \"Send Mode is successfully activated and ready to send data.\" ) close ( self ) \u2693 Safely terminates the threads, and NetGear resources. Source code in vidgear/gears/netgear.py def close ( self ): \"\"\" Safely terminates the threads, and NetGear resources. \"\"\" # log it self . __logging and logger . debug ( \"Terminating various {} Processes.\" . format ( \"Receive Mode\" if self . __receive_mode else \"Send Mode\" ) ) # whether `receive_mode` is enabled or not if self . __receive_mode : # check whether queue mode is empty if not ( self . __queue is None ) and self . __queue : self . __queue . clear () # call immediate termination self . __terminate = True # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : # properly handle thread exit self . __thread . join () self . __thread = None self . __logging and logger . debug ( \"Terminating. Please wait...\" ) # properly close the socket self . __msg_socket . close ( linger = 0 ) self . __logging and logger . debug ( \"Terminated Successfully!\" ) else : # indicate that process should be terminated self . __terminate = True # check if all attempts of reconnecting failed, then skip to closure if ( self . __pattern < 2 and not self . __max_retries ) or ( self . __multiclient_mode and not self . __port_buffer ): try : # properly close the socket self . __msg_socket . setsockopt ( zmq . LINGER , 0 ) self . __msg_socket . close () except ZMQError : pass finally : # exit return if self . __multiserver_mode : # check if multiserver_mode # send termination flag to client with its unique port term_dict = dict ( terminate_flag = True , port = self . __port ) else : # otherwise send termination flag to client term_dict = dict ( terminate_flag = True ) try : if self . __multiclient_mode : for _ in self . __port_buffer : self . __msg_socket . send_json ( term_dict ) else : self . __msg_socket . send_json ( term_dict ) # check for confirmation if available within 1/5 timeout if self . __pattern < 2 : self . __logging and logger . debug ( \"Terminating. Please wait...\" ) if self . __msg_socket . poll ( self . __request_timeout // 5 , zmq . POLLIN ): self . __msg_socket . recv () except Exception as e : if not isinstance ( e , ZMQError ): logger . exception ( str ( e )) finally : # properly close the socket self . __msg_socket . setsockopt ( zmq . LINGER , 0 ) self . __msg_socket . close () self . __logging and logger . debug ( \"Terminated Successfully!\" ) recv ( self , return_data = None ) \u2693 A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Parameters: Name Type Description Default return_data any inputs return data (of any datatype) , for sending back to Server. None Returns: A n-dimensional numpy array. Source code in vidgear/gears/netgear.py def recv ( self , return_data = None ): \"\"\" A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Parameters: return_data (any): inputs return data _(of any datatype)_, for sending back to Server. **Returns:** A n-dimensional numpy array. \"\"\" # check whether `receive mode` is activated if not ( self . __receive_mode ): # raise value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `recv()` function cannot be used while receive_mode is disabled. Kindly refer vidgear docs!\" ) # handle Bidirectional return data if ( self . __bi_mode or self . __multiclient_mode ) and not ( return_data is None ): self . __return_data = return_data # check whether or not termination flag is enabled while not self . __terminate : try : # check if queue is empty if len ( self . __queue ) > 0 : return self . __queue . popleft () else : time . sleep ( 0.00001 ) continue except KeyboardInterrupt : self . __terminate = True break # otherwise return NoneType return None send ( self , frame , message = None ) \u2693 A Server end method, that sends the data and frames over the network to Client(s). Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). required message any input for sending additional data (of any datatype except numpy.ndarray ) to Client(s). None Returns: Data (of any datatype) in selected exclusive modes, otherwise None-type. Source code in vidgear/gears/netgear.py def send ( self , frame , message = None ): \"\"\" A Server end method, that sends the data and frames over the network to Client(s). Parameters: frame (numpy.ndarray): inputs numpy array(frame). message (any): input for sending additional data _(of any datatype except `numpy.ndarray`)_ to Client(s). **Returns:** Data _(of any datatype)_ in selected exclusive modes, otherwise None-type. \"\"\" # check whether `receive_mode` is disabled if self . __receive_mode : # raise value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `send()` function cannot be used while receive_mode is enabled. Kindly refer vidgear docs!\" ) if not ( message is None ) and isinstance ( message , np . ndarray ): logger . warning ( \"Skipped unsupported `message` of datatype: {} !\" . format ( type ( message ) . __name__ ) ) message = None # define exit_flag and assign value exit_flag = True if ( frame is None or self . __terminate ) else False # check whether exit_flag is False if not ( exit_flag ) and not ( frame . flags [ \"C_CONTIGUOUS\" ]): # check whether the incoming frame is contiguous frame = np . ascontiguousarray ( frame , dtype = frame . dtype ) # handle JPEG compression encoding if self . __jpeg_compression : if self . __jpeg_compression_colorspace == \"GRAY\" : if frame . ndim == 2 : # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11 frame = np . expand_dims ( frame , axis = 2 ) frame = simplejpeg . encode_jpeg ( frame , quality = self . __jpeg_compression_quality , colorspace = self . __jpeg_compression_colorspace , fastdct = self . __jpeg_compression_fastdct , ) else : frame = simplejpeg . encode_jpeg ( frame , quality = self . __jpeg_compression_quality , colorspace = self . __jpeg_compression_colorspace , colorsubsampling = \"422\" , fastdct = self . __jpeg_compression_fastdct , ) # check if multiserver_mode is activated and assign values with unique port msg_dict = dict ( port = self . __port ) if self . __multiserver_mode else dict () # prepare the exclusive json dict msg_dict . update ( dict ( terminate_flag = exit_flag , compression = { \"dct\" : self . __jpeg_compression_fastdct , \"ups\" : self . __jpeg_compression_fastupsample , \"colorspace\" : self . __jpeg_compression_colorspace , } if self . __jpeg_compression else False , message = message , pattern = str ( self . __pattern ), dtype = str ( frame . dtype ) if not ( self . __jpeg_compression ) else \"\" , shape = frame . shape if not ( self . __jpeg_compression ) else \"\" , ) ) # send the json dict self . __msg_socket . send_json ( msg_dict , self . __msg_flag | zmq . SNDMORE ) # send the frame array with correct flags self . __msg_socket . send ( frame , flags = self . __msg_flag , copy = self . __msg_copy , track = self . __msg_track ) # check if synchronous patterns, then wait for confirmation if self . __pattern < 2 : # check if Bidirectional data transmission is enabled if self . __bi_mode or self . __multiclient_mode : # handles return data recvd_data = None socks = dict ( self . __poll . poll ( self . __request_timeout )) if socks . get ( self . __msg_socket ) == zmq . POLLIN : # handle return data recv_json = self . __msg_socket . recv_json ( flags = self . __msg_flag ) else : logger . critical ( \"No response from Client, Reconnecting again...\" ) # Socket is confused. Close and remove it. self . __msg_socket . setsockopt ( zmq . LINGER , 0 ) self . __msg_socket . close () self . __poll . unregister ( self . __msg_socket ) self . __max_retries -= 1 if not ( self . __max_retries ): if self . __multiclient_mode : logger . error ( \"All Clients failed to respond on multiple attempts.\" ) else : logger . error ( \"Client failed to respond on multiple attempts.\" ) self . __terminate = True raise RuntimeError ( \"[NetGear:ERROR] :: Client(s) seems to be offline, Abandoning.\" ) # Create new connection self . __msg_socket = self . __msg_context . socket ( self . __msg_pattern ) if isinstance ( self . __connection_address , list ): for _connection in self . __connection_address : self . __msg_socket . connect ( _connection ) else : # handle SSH tunneling if enabled if self . __ssh_tunnel_mode : # establish tunnel connection ssh . tunnel_connection ( self . __msg_socket , self . __connection_address , self . __ssh_tunnel_mode , keyfile = self . __ssh_tunnel_keyfile , password = self . __ssh_tunnel_pwd , paramiko = self . __paramiko_present , ) else : # connect normally self . __msg_socket . connect ( self . __connection_address ) self . __poll . register ( self . __msg_socket , zmq . POLLIN ) # return None for mean-time return None # save the unique port addresses if ( self . __multiclient_mode and not recv_json [ \"port\" ] in self . __port_buffer ): self . __port_buffer . append ( recv_json [ \"port\" ]) if recv_json [ \"return_type\" ] == \"ndarray\" : recv_array = self . __msg_socket . recv ( flags = self . __msg_flag , copy = self . __msg_copy , track = self . __msg_track , ) # check if encoding was enabled if recv_json [ \"compression\" ]: # decode JPEG frame recvd_data = simplejpeg . decode_jpeg ( recv_array , colorspace = recv_json [ \"compression\" ][ \"colorspace\" ], fastdct = self . __jpeg_compression_fastdct or recv_json [ \"compression\" ][ \"dct\" ], fastupsample = self . __jpeg_compression_fastupsample or recv_json [ \"compression\" ][ \"ups\" ], ) # check if valid frame returned if recvd_data is None : self . __terminate = True # otherwise raise error and exit raise RuntimeError ( \"[NetGear:ERROR] :: Received compressed frame ` {} ` decoding failed with flag: {} .\" . format ( recv_json [ \"compression\" ], self . __ex_compression_params , ) ) if ( recv_json [ \"compression\" ][ \"colorspace\" ] == \"GRAY\" and recvd_data . ndim == 3 ): # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11 recvd_data = np . squeeze ( recvd_data , axis = 2 ) else : recvd_data = np . frombuffer ( recv_array , dtype = recv_json [ \"array_dtype\" ] ) . reshape ( recv_json [ \"array_shape\" ]) else : recvd_data = recv_json [ \"data\" ] return ( ( recv_json [ \"port\" ], recvd_data ) if self . __multiclient_mode else recvd_data ) else : # otherwise log normally socks = dict ( self . __poll . poll ( self . __request_timeout )) if socks . get ( self . __msg_socket ) == zmq . POLLIN : recv_confirmation = self . __msg_socket . recv () else : logger . critical ( \"No response from Client, Reconnecting again...\" ) # Socket is confused. Close and remove it. self . __msg_socket . setsockopt ( zmq . LINGER , 0 ) self . __msg_socket . close () self . __poll . unregister ( self . __msg_socket ) self . __max_retries -= 1 if not ( self . __max_retries ): logger . error ( \"Client failed to respond on repeated attempts.\" ) self . __terminate = True raise RuntimeError ( \"[NetGear:ERROR] :: Client seems to be offline, Abandoning!\" ) # Create new connection self . __msg_socket = self . __msg_context . socket ( self . __msg_pattern ) # handle SSH tunneling if enabled if self . __ssh_tunnel_mode : # establish tunnel connection ssh . tunnel_connection ( self . __msg_socket , self . __connection_address , self . __ssh_tunnel_mode , keyfile = self . __ssh_tunnel_keyfile , password = self . __ssh_tunnel_pwd , paramiko = self . __paramiko_present , ) else : # connect normally self . __msg_socket . connect ( self . __connection_address ) self . __poll . register ( self . __msg_socket , zmq . POLLIN ) return None # log confirmation self . __logging and logger . debug ( recv_confirmation )","title":"NetGear API"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.__init__","text":"This constructor method initializes the object state and attributes of the NetGear class. Parameters: Name Type Description Default address str sets the valid network address of the Server/Client. None port str sets the valid Network Port of the Server/Client. None protocol str sets the valid messaging protocol between Server/Client. None pattern int sets the supported messaging pattern(flow of communication) between Server/Client 0 receive_mode bool select the Netgear's Mode of operation. False logging bool enables/disables logging. False options dict provides the flexibility to alter various NetGear internal properties. {} Source code in vidgear/gears/netgear.py def __init__ ( self , address = None , port = None , protocol = None , pattern = 0 , receive_mode = False , logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the NetGear class. Parameters: address (str): sets the valid network address of the Server/Client. port (str): sets the valid Network Port of the Server/Client. protocol (str): sets the valid messaging protocol between Server/Client. pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client receive_mode (bool): select the Netgear's Mode of operation. logging (bool): enables/disables logging. options (dict): provides the flexibility to alter various NetGear internal properties. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"zmq\" if zmq is None else \"\" , min_version = \"4.0\" , pkg_name = \"pyzmq\" ) import_dependency_safe ( \"simplejpeg\" if simplejpeg is None else \"\" , error = \"log\" , min_version = \"1.6.1\" ) # enable logging if specified self . __logging = True if logging else False # define valid messaging patterns => `0`: zmq.PAIR, `1`:(zmq.REQ,zmq.REP), and `1`:(zmq.SUB,zmq.PUB) valid_messaging_patterns = { 0 : ( zmq . PAIR , zmq . PAIR ), 1 : ( zmq . REQ , zmq . REP ), 2 : ( zmq . PUB , zmq . SUB ), } # Handle messaging pattern msg_pattern = None # check whether user-defined messaging pattern is valid if isinstance ( pattern , int ) and pattern in valid_messaging_patterns . keys (): # assign value msg_pattern = valid_messaging_patterns [ pattern ] else : # otherwise default to 0:`zmq.PAIR` pattern = 0 msg_pattern = valid_messaging_patterns [ pattern ] self . __logging and logger . warning ( \"Wrong pattern value, Defaulting to `zmq.PAIR`! Kindly refer Docs for more Information.\" ) # assign pattern to global parameter for further use self . __pattern = pattern # Handle messaging protocol if protocol is None or not ( protocol in [ \"tcp\" , \"ipc\" ]): # else default to `tcp` protocol protocol = \"tcp\" # log it self . __logging and logger . warning ( \"Protocol is not supported or not provided. Defaulting to `tcp` protocol!\" ) # Handle connection params self . __msg_flag = 0 # handles connection flags self . __msg_copy = False # handles whether to copy data self . __msg_track = False # handles whether to track packets # Handle NetGear's internal exclusive modes and params # define SSH Tunneling Mode self . __ssh_tunnel_mode = None # handles ssh_tunneling mode state self . __ssh_tunnel_pwd = None self . __ssh_tunnel_keyfile = None self . __paramiko_present = False if paramiko is None else True # define Multi-Server mode self . __multiserver_mode = False # handles multi-server mode state # define Multi-Client mode self . __multiclient_mode = False # handles multi-client mode state # define Bidirectional mode self . __bi_mode = False # handles Bidirectional mode state # define Secure mode valid_security_mech = { 0 : \"Grasslands\" , 1 : \"StoneHouse\" , 2 : \"IronHouse\" } self . __secure_mode = 0 # handles ZMQ security layer status auth_cert_dir = \"\" # handles valid ZMQ certificates dir self . __auth_publickeys_dir = \"\" # handles valid ZMQ public certificates dir self . __auth_secretkeys_dir = \"\" # handles valid ZMQ private certificates dir overwrite_cert = False # checks if certificates overwriting allowed custom_cert_location = \"\" # handles custom ZMQ certificates path # define frame-compression handler self . __jpeg_compression = ( True if not ( simplejpeg is None ) else False ) # enabled by default for all connections if simplejpeg is installed self . __jpeg_compression_quality = 90 # 90% quality self . __jpeg_compression_fastdct = True # fastest DCT on by default self . __jpeg_compression_fastupsample = False # fastupsample off by default self . __jpeg_compression_colorspace = \"BGR\" # use BGR colorspace by default # defines frame compression on return data self . __ex_compression_params = None # define receiver return data handler self . __return_data = None # generate 8-digit random system id self . __id = \"\" . join ( secrets . choice ( string . ascii_uppercase + string . digits ) for i in range ( 8 ) ) # define termination flag self . __terminate = False # additional settings for reliability if pattern < 2 : # define zmq poller for reliable transmission self . __poll = zmq . Poller () # define max retries self . __max_retries = 3 # request timeout self . __request_timeout = 4000 # 4 secs # Handle user-defined options dictionary values # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # loop over dictionary key & values and assign to global variables if valid for key , value in options . items (): # handle multi-server mode if key == \"multiserver_mode\" and isinstance ( value , bool ): # check if valid pattern assigned if pattern > 0 : # activate Multi-server mode self . __multiserver_mode = value else : # otherwise disable it and raise error self . __multiserver_mode = False logger . critical ( \"Multi-Server Mode is disabled!\" ) raise ValueError ( \"[NetGear:ERROR] :: ` {} ` pattern is not valid when Multi-Server Mode is enabled. Kindly refer Docs for more Information.\" . format ( pattern ) ) # handle multi-client mode elif key == \"multiclient_mode\" and isinstance ( value , bool ): # check if valid pattern assigned if pattern > 0 : # activate Multi-client mode self . __multiclient_mode = value else : # otherwise disable it and raise error self . __multiclient_mode = False logger . critical ( \"Multi-Client Mode is disabled!\" ) raise ValueError ( \"[NetGear:ERROR] :: ` {} ` pattern is not valid when Multi-Client Mode is enabled. Kindly refer Docs for more Information.\" . format ( pattern ) ) # handle bidirectional mode elif key == \"bidirectional_mode\" and isinstance ( value , bool ): # check if pattern is valid if pattern < 2 : # activate Bidirectional mode if specified self . __bi_mode = value else : # otherwise disable it and raise error self . __bi_mode = False logger . warning ( \"Bidirectional data transmission is disabled!\" ) raise ValueError ( \"[NetGear:ERROR] :: ` {} ` pattern is not valid when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\" . format ( pattern ) ) # handle secure mode elif ( key == \"secure_mode\" and isinstance ( value , int ) and ( value in valid_security_mech ) ): self . __secure_mode = value elif key == \"custom_cert_location\" and isinstance ( value , str ): # verify custom auth certificates path for secure mode custom_cert_location = os . path . abspath ( value ) assert os . path . isdir ( custom_cert_location ), \"[NetGear:ERROR] :: `custom_cert_location` value must be the path to a valid directory!\" assert check_WriteAccess ( custom_cert_location , is_windows = True if os . name == \"nt\" else False , logging = self . __logging , ), \"[NetGear:ERROR] :: Permission Denied!, cannot write ZMQ authentication certificates to ' {} ' directory!\" . format ( value ) elif key == \"overwrite_cert\" and isinstance ( value , bool ): # enable/disable auth certificate overwriting in secure mode overwrite_cert = value # handle ssh-tunneling mode elif key == \"ssh_tunnel_mode\" and isinstance ( value , str ): # enable SSH Tunneling Mode self . __ssh_tunnel_mode = value . strip () elif key == \"ssh_tunnel_pwd\" and isinstance ( value , str ): # add valid SSH Tunneling password self . __ssh_tunnel_pwd = value elif key == \"ssh_tunnel_keyfile\" and isinstance ( value , str ): # add valid SSH Tunneling key-file self . __ssh_tunnel_keyfile = value if os . path . isfile ( value ) else None if self . __ssh_tunnel_keyfile is None : logger . warning ( \"Discarded invalid or non-existential SSH Tunnel Key-file at {} !\" . format ( value ) ) # handle jpeg compression elif ( key == \"jpeg_compression\" and not ( simplejpeg is None ) and isinstance ( value , ( bool , str )) ): if isinstance ( value , str ) and value . strip () . upper () in [ \"RGB\" , \"BGR\" , \"RGBX\" , \"BGRX\" , \"XBGR\" , \"XRGB\" , \"GRAY\" , \"RGBA\" , \"BGRA\" , \"ABGR\" , \"ARGB\" , \"CMYK\" , ]: # set encoding colorspace self . __jpeg_compression_colorspace = value . strip () . upper () # enable frame-compression encoding value self . __jpeg_compression = True else : # enable frame-compression encoding value self . __jpeg_compression = value elif key == \"jpeg_compression_quality\" and isinstance ( value , ( int , float )): # set valid jpeg quality if value >= 10 and value <= 100 : self . __jpeg_compression_quality = int ( value ) else : logger . warning ( \"Skipped invalid `jpeg_compression_quality` value!\" ) elif key == \"jpeg_compression_fastdct\" and isinstance ( value , bool ): # enable jpeg fastdct self . __jpeg_compression_fastdct = value elif key == \"jpeg_compression_fastupsample\" and isinstance ( value , bool ): # enable jpeg fastupsample self . __jpeg_compression_fastupsample = value # assign maximum retries in synchronous patterns elif key == \"max_retries\" and isinstance ( value , int ) and pattern < 2 : if value >= 0 : self . __max_retries = value else : logger . warning ( \"Invalid `max_retries` value skipped!\" ) # assign request timeout in synchronous patterns elif key == \"request_timeout\" and isinstance ( value , int ) and pattern < 2 : if value >= 4 : self . __request_timeout = value * 1000 # covert to milliseconds else : logger . warning ( \"Invalid `request_timeout` value skipped!\" ) # handle ZMQ flags elif key == \"flag\" and isinstance ( value , int ): self . __msg_flag = value elif key == \"copy\" and isinstance ( value , bool ): self . __msg_copy = value elif key == \"track\" and isinstance ( value , bool ): self . __msg_track = value else : pass # Handle Secure mode if self . __secure_mode : # activate and log if overwriting is enabled if overwrite_cert : if not receive_mode : self . __logging and logger . warning ( \"Overwriting ZMQ Authentication certificates over previous ones!\" ) else : overwrite_cert = False self . __logging and logger . critical ( \"Overwriting ZMQ Authentication certificates is disabled for Client's end!\" ) # Validate certificate generation paths try : # check if custom certificates path is specified if custom_cert_location : ( auth_cert_dir , self . __auth_secretkeys_dir , self . __auth_publickeys_dir , ) = generate_auth_certificates ( custom_cert_location , overwrite = overwrite_cert , logging = logging ) else : # otherwise auto-generate suitable path ( auth_cert_dir , self . __auth_secretkeys_dir , self . __auth_publickeys_dir , ) = generate_auth_certificates ( os . path . join ( expanduser ( \"~\" ), \".vidgear\" ), overwrite = overwrite_cert , logging = logging , ) # log it self . __logging and logger . debug ( \"` {} ` is the default location for storing ZMQ authentication certificates/keys.\" . format ( auth_cert_dir ) ) except Exception as e : # catch if any error occurred and disable Secure mode logger . exception ( str ( e )) self . __secure_mode = 0 logger . critical ( \"ZMQ Security Mechanism is disabled for this connection due to errors!\" ) # Handle ssh tunneling if enabled if not ( self . __ssh_tunnel_mode is None ): # SSH Tunnel Mode only available for server mode if receive_mode : logger . error ( \"SSH Tunneling cannot be enabled for Client-end!\" ) else : # check if SSH tunneling possible ssh_address = self . __ssh_tunnel_mode ssh_address , ssh_port = ( ssh_address . split ( \":\" ) if \":\" in ssh_address else [ ssh_address , \"22\" ] ) # default to port 22 if \"47\" in ssh_port : self . __ssh_tunnel_mode = self . __ssh_tunnel_mode . replace ( \":47\" , \"\" ) # port-47 is reserved for testing else : # extract ip for validation ssh_user , ssh_ip = ( ssh_address . split ( \"@\" ) if \"@\" in ssh_address else [ \"\" , ssh_address ] ) # validate ip specified port assert check_open_port ( ssh_ip , port = int ( ssh_port ) ), \"[NetGear:ERROR] :: Host ` {} ` is not available for SSH Tunneling at port- {} !\" . format ( ssh_address , ssh_port ) # Handle multiple exclusive modes if enabled if self . __multiclient_mode and self . __multiserver_mode : raise ValueError ( \"[NetGear:ERROR] :: Multi-Client and Multi-Server Mode cannot be enabled simultaneously!\" ) elif self . __multiserver_mode or self . __multiclient_mode : # check if Bidirectional Mode also enabled if self . __bi_mode : # log it self . __logging and logger . debug ( \"Bidirectional Data Transmission is also enabled for this connection!\" ) # check if SSH Tunneling Mode also enabled if self . __ssh_tunnel_mode : # raise error raise ValueError ( \"[NetGear:ERROR] :: SSH Tunneling and {} Mode cannot be enabled simultaneously. Kindly refer docs!\" . format ( \"Multi-Server\" if self . __multiserver_mode else \"Multi-Client\" ) ) elif self . __bi_mode : # log Bidirectional mode activation self . __logging and logger . debug ( \"Bidirectional Data Transmission is enabled for this connection!\" ) elif self . __ssh_tunnel_mode : # log Bidirectional mode activation self . __logging and logger . debug ( \"SSH Tunneling is enabled for host:` {} ` with ` {} ` back-end.\" . format ( self . __ssh_tunnel_mode , \"paramiko\" if self . __paramiko_present else \"pexpect\" , ) ) # define messaging context instance self . __msg_context = zmq . Context . instance () # initialize and assign receive mode to global variable self . __receive_mode = receive_mode # check whether `receive_mode` is enabled if self . __receive_mode : # define connection address if address is None : address = \"*\" # define address # check if multiserver_mode is enabled if self . __multiserver_mode : # check if unique server port address list/tuple is assigned or not in multiserver_mode if port is None or not isinstance ( port , ( tuple , list )): # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Server ports while Multi-Server mode is enabled. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Server Mode at PORTS: {} !\" . format ( port ) ) # create port address buffer for keeping track of connected client's port(s) self . __port_buffer = [] # check if multiclient_mode is enabled elif self . __multiclient_mode : # check if unique server port address is assigned or not in multiclient_mode if port is None : # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Kindly provide a unique & valid port value at Client-end. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Client Mode at PORT: {} on this device!\" . format ( port ) ) # assign value to global variable self . __port = port else : # otherwise assign local port address if None if port is None : port = \"5555\" try : # activate secure_mode threaded authenticator if self . __secure_mode > 0 : # start an authenticator for this context z_auth = ThreadAuthenticator ( self . __msg_context ) z_auth . start () z_auth . allow ( str ( address )) # allow current address # check if `IronHouse` is activated if self . __secure_mode == 2 : # tell authenticator to use the certificate from given valid dir z_auth . configure_curve ( domain = \"*\" , location = self . __auth_publickeys_dir ) else : # otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated z_auth . configure_curve ( domain = \"*\" , location = auth . CURVE_ALLOW_ANY ) # define thread-safe messaging socket self . __msg_socket = self . __msg_context . socket ( msg_pattern [ 1 ]) # define pub-sub flag if self . __pattern == 2 : self . __msg_socket . set_hwm ( 1 ) # enable specified secure mode for the socket if self . __secure_mode > 0 : # load server key server_secret_file = os . path . join ( self . __auth_secretkeys_dir , \"server.key_secret\" ) server_public , server_secret = auth . load_certificate ( server_secret_file ) # load all CURVE keys self . __msg_socket . curve_secretkey = server_secret self . __msg_socket . curve_publickey = server_public # enable CURVE connection for this socket self . __msg_socket . curve_server = True # define exclusive socket options for patterns if self . __pattern == 2 : self . __msg_socket . setsockopt_string ( zmq . SUBSCRIBE , \"\" ) # if multiserver_mode is enabled, then assign port addresses to zmq socket if self . __multiserver_mode : # bind socket to given server protocol, address and ports for pt in port : self . __msg_socket . bind ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : # bind socket to given protocol, address and port normally self . __msg_socket . bind ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) # additional settings if pattern < 2 : if self . __multiserver_mode : self . __connection_address = [] for pt in port : self . __connection_address . append ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : self . __connection_address = ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) self . __msg_pattern = msg_pattern [ 1 ] self . __poll . register ( self . __msg_socket , zmq . POLLIN ) self . __logging and logger . debug ( \"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\" . format ( self . __max_retries , self . __request_timeout / 1000 ) ) except Exception as e : # otherwise log and raise error logger . exception ( str ( e )) if self . __secure_mode : logger . critical ( \"Failed to activate Secure Mode: ` {} ` for this connection!\" . format ( valid_security_mech [ self . __secure_mode ] ) ) if self . __multiserver_mode or self . __multiclient_mode : raise RuntimeError ( \"[NetGear:ERROR] :: Receive Mode failed to activate {} Mode at address: {} with pattern: {} ! Kindly recheck all parameters.\" . format ( \"Multi-Server\" if self . __multiserver_mode else \"Multi-Client\" , ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern , ) ) else : if self . __bi_mode : logger . critical ( \"Failed to activate Bidirectional Mode for this connection!\" ) raise RuntimeError ( \"[NetGear:ERROR] :: Receive Mode failed to bind address: {} and pattern: {} ! Kindly recheck all parameters.\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) # Handle threaded queue mode self . __logging and logger . debug ( \"Threaded Queue Mode is enabled by default for this connection.\" ) # define deque and assign it to global var self . __queue = deque ( maxlen = 96 ) # max len 96 to check overflow # initialize and start threaded recv_handler self . __thread = Thread ( target = self . __recv_handler , name = \"NetGear\" , args = ()) self . __thread . daemon = True self . __thread . start () if self . __logging : # finally log progress logger . debug ( \"Successfully Binded to address: {} with pattern: {} .\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) if self . __jpeg_compression : logger . debug ( \"JPEG Frame-Compression is activated for this connection with Colorspace:` {} `, Quality:` {} `%, Fastdct:` {} `, and Fastupsample:` {} `.\" . format ( self . __jpeg_compression_colorspace , self . __jpeg_compression_quality , \"enabled\" if self . __jpeg_compression_fastdct else \"disabled\" , \"enabled\" if self . __jpeg_compression_fastupsample else \"disabled\" , ) ) if self . __secure_mode : logger . debug ( \"Successfully enabled ZMQ Security Mechanism: ` {} ` for this connection.\" . format ( valid_security_mech [ self . __secure_mode ] ) ) logger . debug ( \"Multi-threaded Receive Mode is successfully enabled.\" ) logger . debug ( \"Unique System ID is {} .\" . format ( self . __id )) logger . debug ( \"Receive Mode is now activated.\" ) else : # otherwise default to `Send Mode` # define connection address if address is None : address = \"localhost\" # check if multiserver_mode is enabled if self . __multiserver_mode : # check if unique server port address is assigned or not in multiserver_mode if port is None : # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Kindly provide a unique & valid port value at Server-end. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Server Mode at PORT: {} on this device!\" . format ( port ) ) # assign value to global variable self . __port = port # check if multiclient_mode is enabled elif self . __multiclient_mode : # check if unique client port address list/tuple is assigned or not in multiclient_mode if port is None or not isinstance ( port , ( tuple , list )): # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Client ports while Multi-Client mode is enabled. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Client Mode at PORTS: {} !\" . format ( port ) ) # create port address buffer for keeping track of connected client ports self . __port_buffer = [] else : # otherwise assign local port address if None if port is None : port = \"5555\" try : # activate secure_mode threaded authenticator if self . __secure_mode > 0 : # start an authenticator for this context z_auth = ThreadAuthenticator ( self . __msg_context ) z_auth . start () z_auth . allow ( str ( address )) # allow current address # check if `IronHouse` is activated if self . __secure_mode == 2 : # tell authenticator to use the certificate from given valid dir z_auth . configure_curve ( domain = \"*\" , location = self . __auth_publickeys_dir ) else : # otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated z_auth . configure_curve ( domain = \"*\" , location = auth . CURVE_ALLOW_ANY ) # define thread-safe messaging socket self . __msg_socket = self . __msg_context . socket ( msg_pattern [ 0 ]) # if req/rep pattern, define additional flags if self . __pattern == 1 : self . __msg_socket . REQ_RELAXED = True self . __msg_socket . REQ_CORRELATE = True # if pub/sub pattern, define additional optimizer if self . __pattern == 2 : self . __msg_socket . set_hwm ( 1 ) # enable specified secure mode for the socket if self . __secure_mode > 0 : # load client key client_secret_file = os . path . join ( self . __auth_secretkeys_dir , \"client.key_secret\" ) client_public , client_secret = auth . load_certificate ( client_secret_file ) # load all CURVE keys self . __msg_socket . curve_secretkey = client_secret self . __msg_socket . curve_publickey = client_public # load server key server_public_file = os . path . join ( self . __auth_publickeys_dir , \"server.key\" ) server_public , _ = auth . load_certificate ( server_public_file ) # inject public key to make a CURVE connection. self . __msg_socket . curve_serverkey = server_public # check if multi-client_mode is enabled if self . __multiclient_mode : # bind socket to given server protocol, address and ports for pt in port : self . __msg_socket . connect ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : # handle SSH tuneling if enabled if self . __ssh_tunnel_mode : # establish tunnel connection ssh . tunnel_connection ( self . __msg_socket , protocol + \"://\" + str ( address ) + \":\" + str ( port ), self . __ssh_tunnel_mode , keyfile = self . __ssh_tunnel_keyfile , password = self . __ssh_tunnel_pwd , paramiko = self . __paramiko_present , ) else : # connect socket to given protocol, address and port self . __msg_socket . connect ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) # additional settings if pattern < 2 : if self . __multiclient_mode : self . __connection_address = [] for pt in port : self . __connection_address . append ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : self . __connection_address = ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) self . __msg_pattern = msg_pattern [ 0 ] self . __poll . register ( self . __msg_socket , zmq . POLLIN ) self . __logging and logger . debug ( \"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\" . format ( self . __max_retries , self . __request_timeout / 1000 ) ) except Exception as e : # otherwise log and raise error logger . exception ( str ( e )) if self . __secure_mode : logger . critical ( \"Failed to activate Secure Mode: ` {} ` for this connection!\" . format ( valid_security_mech [ self . __secure_mode ] ) ) if self . __multiserver_mode or self . __multiclient_mode : raise RuntimeError ( \"[NetGear:ERROR] :: Send Mode failed to activate {} Mode at address: {} with pattern: {} ! Kindly recheck all parameters.\" . format ( \"Multi-Server\" if self . __multiserver_mode else \"Multi-Client\" , ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern , ) ) else : if self . __bi_mode : logger . critical ( \"Failed to activate Bidirectional Mode for this connection!\" ) if self . __ssh_tunnel_mode : logger . critical ( \"Failed to initiate SSH Tunneling Mode for this server with ` {} ` back-end!\" . format ( \"paramiko\" if self . __paramiko_present else \"pexpect\" ) ) raise RuntimeError ( \"[NetGear:ERROR] :: Send Mode failed to connect address: {} and pattern: {} ! Kindly recheck all parameters.\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) if self . __logging : # finally log progress logger . debug ( \"Successfully connected to address: {} with pattern: {} .\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) if self . __jpeg_compression : logger . debug ( \"JPEG Frame-Compression is activated for this connection with Colorspace:` {} `, Quality:` {} `%, Fastdct:` {} `, and Fastupsample:` {} `.\" . format ( self . __jpeg_compression_colorspace , self . __jpeg_compression_quality , \"enabled\" if self . __jpeg_compression_fastdct else \"disabled\" , \"enabled\" if self . __jpeg_compression_fastupsample else \"disabled\" , ) ) if self . __secure_mode : logger . debug ( \"Enabled ZMQ Security Mechanism: ` {} ` for this connection.\" . format ( valid_security_mech [ self . __secure_mode ] ) ) logger . debug ( \"Unique System ID is {} .\" . format ( self . __id )) logger . debug ( \"Send Mode is successfully activated and ready to send data.\" )","title":"__init__()"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.close","text":"Safely terminates the threads, and NetGear resources. Source code in vidgear/gears/netgear.py def close ( self ): \"\"\" Safely terminates the threads, and NetGear resources. \"\"\" # log it self . __logging and logger . debug ( \"Terminating various {} Processes.\" . format ( \"Receive Mode\" if self . __receive_mode else \"Send Mode\" ) ) # whether `receive_mode` is enabled or not if self . __receive_mode : # check whether queue mode is empty if not ( self . __queue is None ) and self . __queue : self . __queue . clear () # call immediate termination self . __terminate = True # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : # properly handle thread exit self . __thread . join () self . __thread = None self . __logging and logger . debug ( \"Terminating. Please wait...\" ) # properly close the socket self . __msg_socket . close ( linger = 0 ) self . __logging and logger . debug ( \"Terminated Successfully!\" ) else : # indicate that process should be terminated self . __terminate = True # check if all attempts of reconnecting failed, then skip to closure if ( self . __pattern < 2 and not self . __max_retries ) or ( self . __multiclient_mode and not self . __port_buffer ): try : # properly close the socket self . __msg_socket . setsockopt ( zmq . LINGER , 0 ) self . __msg_socket . close () except ZMQError : pass finally : # exit return if self . __multiserver_mode : # check if multiserver_mode # send termination flag to client with its unique port term_dict = dict ( terminate_flag = True , port = self . __port ) else : # otherwise send termination flag to client term_dict = dict ( terminate_flag = True ) try : if self . __multiclient_mode : for _ in self . __port_buffer : self . __msg_socket . send_json ( term_dict ) else : self . __msg_socket . send_json ( term_dict ) # check for confirmation if available within 1/5 timeout if self . __pattern < 2 : self . __logging and logger . debug ( \"Terminating. Please wait...\" ) if self . __msg_socket . poll ( self . __request_timeout // 5 , zmq . POLLIN ): self . __msg_socket . recv () except Exception as e : if not isinstance ( e , ZMQError ): logger . exception ( str ( e )) finally : # properly close the socket self . __msg_socket . setsockopt ( zmq . LINGER , 0 ) self . __msg_socket . close () self . __logging and logger . debug ( \"Terminated Successfully!\" )","title":"close()"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.recv","text":"A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Parameters: Name Type Description Default return_data any inputs return data (of any datatype) , for sending back to Server. None Returns: A n-dimensional numpy array. Source code in vidgear/gears/netgear.py def recv ( self , return_data = None ): \"\"\" A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Parameters: return_data (any): inputs return data _(of any datatype)_, for sending back to Server. **Returns:** A n-dimensional numpy array. \"\"\" # check whether `receive mode` is activated if not ( self . __receive_mode ): # raise value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `recv()` function cannot be used while receive_mode is disabled. Kindly refer vidgear docs!\" ) # handle Bidirectional return data if ( self . __bi_mode or self . __multiclient_mode ) and not ( return_data is None ): self . __return_data = return_data # check whether or not termination flag is enabled while not self . __terminate : try : # check if queue is empty if len ( self . __queue ) > 0 : return self . __queue . popleft () else : time . sleep ( 0.00001 ) continue except KeyboardInterrupt : self . __terminate = True break # otherwise return NoneType return None","title":"recv()"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.send","text":"A Server end method, that sends the data and frames over the network to Client(s). Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). required message any input for sending additional data (of any datatype except numpy.ndarray ) to Client(s). None Returns: Data (of any datatype) in selected exclusive modes, otherwise None-type. Source code in vidgear/gears/netgear.py def send ( self , frame , message = None ): \"\"\" A Server end method, that sends the data and frames over the network to Client(s). Parameters: frame (numpy.ndarray): inputs numpy array(frame). message (any): input for sending additional data _(of any datatype except `numpy.ndarray`)_ to Client(s). **Returns:** Data _(of any datatype)_ in selected exclusive modes, otherwise None-type. \"\"\" # check whether `receive_mode` is disabled if self . __receive_mode : # raise value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `send()` function cannot be used while receive_mode is enabled. Kindly refer vidgear docs!\" ) if not ( message is None ) and isinstance ( message , np . ndarray ): logger . warning ( \"Skipped unsupported `message` of datatype: {} !\" . format ( type ( message ) . __name__ ) ) message = None # define exit_flag and assign value exit_flag = True if ( frame is None or self . __terminate ) else False # check whether exit_flag is False if not ( exit_flag ) and not ( frame . flags [ \"C_CONTIGUOUS\" ]): # check whether the incoming frame is contiguous frame = np . ascontiguousarray ( frame , dtype = frame . dtype ) # handle JPEG compression encoding if self . __jpeg_compression : if self . __jpeg_compression_colorspace == \"GRAY\" : if frame . ndim == 2 : # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11 frame = np . expand_dims ( frame , axis = 2 ) frame = simplejpeg . encode_jpeg ( frame , quality = self . __jpeg_compression_quality , colorspace = self . __jpeg_compression_colorspace , fastdct = self . __jpeg_compression_fastdct , ) else : frame = simplejpeg . encode_jpeg ( frame , quality = self . __jpeg_compression_quality , colorspace = self . __jpeg_compression_colorspace , colorsubsampling = \"422\" , fastdct = self . __jpeg_compression_fastdct , ) # check if multiserver_mode is activated and assign values with unique port msg_dict = dict ( port = self . __port ) if self . __multiserver_mode else dict () # prepare the exclusive json dict msg_dict . update ( dict ( terminate_flag = exit_flag , compression = { \"dct\" : self . __jpeg_compression_fastdct , \"ups\" : self . __jpeg_compression_fastupsample , \"colorspace\" : self . __jpeg_compression_colorspace , } if self . __jpeg_compression else False , message = message , pattern = str ( self . __pattern ), dtype = str ( frame . dtype ) if not ( self . __jpeg_compression ) else \"\" , shape = frame . shape if not ( self . __jpeg_compression ) else \"\" , ) ) # send the json dict self . __msg_socket . send_json ( msg_dict , self . __msg_flag | zmq . SNDMORE ) # send the frame array with correct flags self . __msg_socket . send ( frame , flags = self . __msg_flag , copy = self . __msg_copy , track = self . __msg_track ) # check if synchronous patterns, then wait for confirmation if self . __pattern < 2 : # check if Bidirectional data transmission is enabled if self . __bi_mode or self . __multiclient_mode : # handles return data recvd_data = None socks = dict ( self . __poll . poll ( self . __request_timeout )) if socks . get ( self . __msg_socket ) == zmq . POLLIN : # handle return data recv_json = self . __msg_socket . recv_json ( flags = self . __msg_flag ) else : logger . critical ( \"No response from Client, Reconnecting again...\" ) # Socket is confused. Close and remove it. self . __msg_socket . setsockopt ( zmq . LINGER , 0 ) self . __msg_socket . close () self . __poll . unregister ( self . __msg_socket ) self . __max_retries -= 1 if not ( self . __max_retries ): if self . __multiclient_mode : logger . error ( \"All Clients failed to respond on multiple attempts.\" ) else : logger . error ( \"Client failed to respond on multiple attempts.\" ) self . __terminate = True raise RuntimeError ( \"[NetGear:ERROR] :: Client(s) seems to be offline, Abandoning.\" ) # Create new connection self . __msg_socket = self . __msg_context . socket ( self . __msg_pattern ) if isinstance ( self . __connection_address , list ): for _connection in self . __connection_address : self . __msg_socket . connect ( _connection ) else : # handle SSH tunneling if enabled if self . __ssh_tunnel_mode : # establish tunnel connection ssh . tunnel_connection ( self . __msg_socket , self . __connection_address , self . __ssh_tunnel_mode , keyfile = self . __ssh_tunnel_keyfile , password = self . __ssh_tunnel_pwd , paramiko = self . __paramiko_present , ) else : # connect normally self . __msg_socket . connect ( self . __connection_address ) self . __poll . register ( self . __msg_socket , zmq . POLLIN ) # return None for mean-time return None # save the unique port addresses if ( self . __multiclient_mode and not recv_json [ \"port\" ] in self . __port_buffer ): self . __port_buffer . append ( recv_json [ \"port\" ]) if recv_json [ \"return_type\" ] == \"ndarray\" : recv_array = self . __msg_socket . recv ( flags = self . __msg_flag , copy = self . __msg_copy , track = self . __msg_track , ) # check if encoding was enabled if recv_json [ \"compression\" ]: # decode JPEG frame recvd_data = simplejpeg . decode_jpeg ( recv_array , colorspace = recv_json [ \"compression\" ][ \"colorspace\" ], fastdct = self . __jpeg_compression_fastdct or recv_json [ \"compression\" ][ \"dct\" ], fastupsample = self . __jpeg_compression_fastupsample or recv_json [ \"compression\" ][ \"ups\" ], ) # check if valid frame returned if recvd_data is None : self . __terminate = True # otherwise raise error and exit raise RuntimeError ( \"[NetGear:ERROR] :: Received compressed frame ` {} ` decoding failed with flag: {} .\" . format ( recv_json [ \"compression\" ], self . __ex_compression_params , ) ) if ( recv_json [ \"compression\" ][ \"colorspace\" ] == \"GRAY\" and recvd_data . ndim == 3 ): # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11 recvd_data = np . squeeze ( recvd_data , axis = 2 ) else : recvd_data = np . frombuffer ( recv_array , dtype = recv_json [ \"array_dtype\" ] ) . reshape ( recv_json [ \"array_shape\" ]) else : recvd_data = recv_json [ \"data\" ] return ( ( recv_json [ \"port\" ], recvd_data ) if self . __multiclient_mode else recvd_data ) else : # otherwise log normally socks = dict ( self . __poll . poll ( self . __request_timeout )) if socks . get ( self . __msg_socket ) == zmq . POLLIN : recv_confirmation = self . __msg_socket . recv () else : logger . critical ( \"No response from Client, Reconnecting again...\" ) # Socket is confused. Close and remove it. self . __msg_socket . setsockopt ( zmq . LINGER , 0 ) self . __msg_socket . close () self . __poll . unregister ( self . __msg_socket ) self . __max_retries -= 1 if not ( self . __max_retries ): logger . error ( \"Client failed to respond on repeated attempts.\" ) self . __terminate = True raise RuntimeError ( \"[NetGear:ERROR] :: Client seems to be offline, Abandoning!\" ) # Create new connection self . __msg_socket = self . __msg_context . socket ( self . __msg_pattern ) # handle SSH tunneling if enabled if self . __ssh_tunnel_mode : # establish tunnel connection ssh . tunnel_connection ( self . __msg_socket , self . __connection_address , self . __ssh_tunnel_mode , keyfile = self . __ssh_tunnel_keyfile , password = self . __ssh_tunnel_pwd , paramiko = self . __paramiko_present , ) else : # connect normally self . __msg_socket . connect ( self . __connection_address ) self . __poll . register ( self . __msg_socket , zmq . POLLIN ) return None # log confirmation self . __logging and logger . debug ( recv_confirmation )","title":"send()"},{"location":"bonus/reference/netgear_async/","text":"NetGear_Async API usage examples can be found here \u27b6 NetGear_Async API parameters are explained here \u27b6 NetGear_Async can generate the same performance as NetGear API at about one-third the memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but lacks in term of flexibility as it supports only a few NetGear's Exclusive Modes. NetGear_Async is built on zmq.asyncio , and powered by a high-performance asyncio event loop called uvloop to achieve unwatchable high-speed and lag-free video streaming over the network with minimal resource constraints. NetGear_Async can transfer thousands of frames in just a few seconds without causing any significant load on your system. NetGear_Async provides complete server-client handling and options to use variable protocols/patterns similar to NetGear API. Furthermore, NetGear_Async allows us to define our custom Server as source to transform frames easily before sending them across the network. NetGear_Async now supports additional bidirectional data transmission between receiver(client) and sender(server) while transferring frames. Users can easily build complex applications such as like Real-Time Video Chat in just few lines of code. In addition to all this, NetGear_Async API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network. NetGear_Async as of now supports four ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) zmq.PUSH/zmq.PULL (ZMQ Push/Pull Pattern) Whereas supported protocol are: tcp and ipc . Source code in vidgear/gears/asyncio/netgear_async.py class NetGear_Async : \"\"\" NetGear_Async can generate the same performance as NetGear API at about one-third the memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but lacks in term of flexibility as it supports only a few NetGear's Exclusive Modes. NetGear_Async is built on `zmq.asyncio`, and powered by a high-performance asyncio event loop called uvloop to achieve unwatchable high-speed and lag-free video streaming over the network with minimal resource constraints. NetGear_Async can transfer thousands of frames in just a few seconds without causing any significant load on your system. NetGear_Async provides complete server-client handling and options to use variable protocols/patterns similar to NetGear API. Furthermore, NetGear_Async allows us to define our custom Server as source to transform frames easily before sending them across the network. NetGear_Async now supports additional **bidirectional data transmission** between receiver(client) and sender(server) while transferring frames. Users can easily build complex applications such as like _Real-Time Video Chat_ in just few lines of code. In addition to all this, NetGear_Async API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network. NetGear_Async as of now supports four ZeroMQ messaging patterns: - `zmq.PAIR` _(ZMQ Pair Pattern)_ - `zmq.REQ/zmq.REP` _(ZMQ Request/Reply Pattern)_ - `zmq.PUB/zmq.SUB` _(ZMQ Publish/Subscribe Pattern)_ - `zmq.PUSH/zmq.PULL` _(ZMQ Push/Pull Pattern)_ Whereas supported protocol are: `tcp` and `ipc`. \"\"\" def __init__ ( self , # NetGear_Async parameters address = None , port = None , protocol = \"tcp\" , pattern = 0 , receive_mode = False , timeout = 0.0 , # Videogear parameters enablePiCamera = False , stabilize = False , source = None , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , time_delay = 0 , # common parameters logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the NetGear_Async class. Parameters: address (str): sets the valid network address of the Server/Client. port (str): sets the valid Network Port of the Server/Client. protocol (str): sets the valid messaging protocol between Server/Client. pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client receive_mode (bool): select the NetGear_Async's Mode of operation. timeout (int/float): controls the maximum waiting time(in sec) after which Client throws `TimeoutError`. enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of NetGear_Async, CamGear, PiGear & Stabilizer. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"zmq\" if zmq is None else \"\" , min_version = \"4.0\" , pkg_name = \"pyzmq\" ) import_dependency_safe ( \"msgpack\" if msgpack is None else \"\" ) import_dependency_safe ( \"msgpack_numpy\" if m is None else \"\" ) # enable logging if specified self . __logging = logging # define valid messaging patterns => `0`: PAIR, `1`:(REQ, REP), `2`:(SUB, PUB), `3`:(PUSH, PULL) valid_messaging_patterns = { 0 : ( zmq . PAIR , zmq . PAIR ), 1 : ( zmq . REQ , zmq . REP ), 2 : ( zmq . PUB , zmq . SUB ), 3 : ( zmq . PUSH , zmq . PULL ), } # check whether user-defined messaging pattern is valid if isinstance ( pattern , int ) and pattern in valid_messaging_patterns : # assign value self . __msg_pattern = pattern self . __pattern = valid_messaging_patterns [ pattern ] else : # otherwise default to 0:`zmq.PAIR` self . __msg_pattern = 0 self . __pattern = valid_messaging_patterns [ self . __msg_pattern ] if self . __logging : logger . warning ( \"Invalid pattern {pattern} . Defaulting to `zmq.PAIR`!\" . format ( pattern = pattern ) ) # check whether user-defined messaging protocol is valid if isinstance ( protocol , str ) and protocol in [ \"tcp\" , \"ipc\" ]: # assign value self . __protocol = protocol else : # else default to `tcp` protocol self . __protocol = \"tcp\" if self . __logging : logger . warning ( \"Invalid protocol. Defaulting to `tcp`!\" ) # initialize Termination flag self . __terminate = False # initialize and assign `Receive Mode` self . __receive_mode = receive_mode # initialize stream handler self . __stream = None # initialize Messaging Socket self . __msg_socket = None # initialize NetGear_Async's configuration dictionary self . config = {} # asyncio queue handler self . __queue = None # define Bidirectional mode self . __bi_mode = False # handles Bidirectional mode state # assign timeout for Receiver end if timeout and isinstance ( timeout , ( int , float )): self . __timeout = float ( timeout ) else : self . __timeout = 15.0 # generate 8-digit random system id self . __id = \"\" . join ( secrets . choice ( string . ascii_uppercase + string . digits ) for i in range ( 8 ) ) # Handle user-defined options dictionary values # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # handle bidirectional mode if \"bidirectional_mode\" in options : value = options [ \"bidirectional_mode\" ] # also check if pattern and source is valid if isinstance ( value , bool ) and pattern < 2 and source is None : # activate Bidirectional mode if specified self . __bi_mode = value else : # otherwise disable it self . __bi_mode = False logger . warning ( \"Bidirectional data transmission is disabled!\" ) # handle errors and logging if pattern >= 2 : # raise error raise ValueError ( \"[NetGear_Async:ERROR] :: ` {} ` pattern is not valid when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\" . format ( pattern ) ) elif not ( source is None ): raise ValueError ( \"[NetGear_Async:ERROR] :: Custom source must be used when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\" . format ( pattern ) ) elif isinstance ( value , bool ) and self . __logging : # log Bidirectional mode activation logger . debug ( \"Bidirectional Data Transmission is {} for this connection!\" . format ( \"enabled\" if value else \"disabled\" ) ) else : logger . error ( \"`bidirectional_mode` value is invalid!\" ) # clean del options [ \"bidirectional_mode\" ] # define messaging asynchronous Context self . __msg_context = zmq . asyncio . Context () # check whether `Receive Mode` is enabled if receive_mode : # assign local IP address if None if address is None : self . __address = \"*\" # define address else : self . __address = address # assign default port address if None if port is None : self . __port = \"5555\" else : self . __port = port else : # Handle video source if source is None : self . config = { \"generator\" : None } if self . __logging : logger . warning ( \"Given source is of NoneType!\" ) else : # define stream with necessary params self . __stream = VideoGear ( enablePiCamera = enablePiCamera , stabilize = stabilize , source = source , camera_num = camera_num , stream_mode = stream_mode , backend = backend , colorspace = colorspace , resolution = resolution , framerate = framerate , logging = logging , time_delay = time_delay , ** options ) # define default frame generator in configuration self . config = { \"generator\" : self . __frame_generator ()} # assign local ip address if None if address is None : self . __address = \"localhost\" else : self . __address = address # assign default port address if None if port is None : self . __port = \"5555\" else : self . __port = port # add server task handler self . task = None # Setup and assign event loop policy if platform . system () == \"Windows\" : # On Windows, VidGear requires the ``WindowsSelectorEventLoop``, and this is # the default in Python 3.7 and older, but new Python 3.8, defaults to an # event loop that is not compatible with it. Thereby, we had to set it manually. if sys . version_info [: 2 ] >= ( 3 , 8 ): asyncio . set_event_loop_policy ( asyncio . WindowsSelectorEventLoopPolicy ()) else : if not ( uvloop is None ): # Latest uvloop eventloop is only available for UNIX machines. asyncio . set_event_loop_policy ( uvloop . EventLoopPolicy ()) else : # log if not present import_dependency_safe ( \"uvloop\" , error = \"log\" ) # Retrieve event loop and assign it self . loop = asyncio . get_event_loop () # create asyncio queue if bidirectional mode activated self . __queue = asyncio . Queue () if self . __bi_mode else None # log eventloop for debugging if self . __logging : # debugging logger . info ( \"Using ` {} ` event loop for this process.\" . format ( self . loop . __class__ . __name__ ) ) def launch ( self ): \"\"\" Launches an asynchronous generators and loop executors for respective task. \"\"\" # check if receive mode enabled if self . __receive_mode : if self . __logging : logger . debug ( \"Launching NetGear_Async asynchronous generator!\" ) # run loop executor for Receiver asynchronous generator self . loop . run_in_executor ( None , self . recv_generator ) else : # Otherwise launch Server handler if self . __logging : logger . debug ( \"Creating NetGear_Async asynchronous server handler!\" ) # create task for Server Handler self . task = asyncio . ensure_future ( self . __server_handler ()) # return instance return self async def __server_handler ( self ): \"\"\" Handles various Server-end processes/tasks. \"\"\" # validate assigned frame generator in NetGear_Async configuration if isinstance ( self . config , dict ) and \"generator\" in self . config : # check if its assigned value is a asynchronous generator if self . config [ \"generator\" ] is None or not inspect . isasyncgen ( self . config [ \"generator\" ] ): # otherwise raise error raise ValueError ( \"[NetGear_Async:ERROR] :: Invalid configuration. Assigned generator must be a asynchronous generator function/method only!\" ) else : # raise error if validation fails raise RuntimeError ( \"[NetGear_Async:ERROR] :: Assigned NetGear_Async configuration is invalid!\" ) # define our messaging socket self . __msg_socket = self . __msg_context . socket ( self . __pattern [ 0 ]) # if req/rep pattern, define additional flags if self . __msg_pattern == 1 : self . __msg_socket . REQ_RELAXED = True self . __msg_socket . REQ_CORRELATE = True # if pub/sub pattern, define additional optimizer if self . __msg_pattern == 2 : self . __msg_socket . set_hwm ( 1 ) # try connecting socket to assigned protocol, address and port try : self . __msg_socket . connect ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ) # finally log if successful if self . __logging : logger . debug ( \"Successfully connected to address: {} with pattern: {} .\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , ) ) logger . critical ( \"Send Mode is successfully activated and ready to send data!\" ) except Exception as e : # log ad raise error if failed logger . exception ( str ( e )) if self . __bi_mode : logger . error ( \"Failed to activate Bidirectional Mode for this connection!\" ) raise ValueError ( \"[NetGear_Async:ERROR] :: Failed to connect address: {} and pattern: {} !\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , ) ) # loop over our Asynchronous frame generator async for dataframe in self . config [ \"generator\" ]: # extract data if bidirectional mode if self . __bi_mode and len ( dataframe ) == 2 : ( data , frame ) = dataframe if not ( data is None ) and isinstance ( data , np . ndarray ): logger . warning ( \"Skipped unsupported `data` of datatype: {} !\" . format ( type ( data ) . __name__ ) ) data = None assert isinstance ( frame , np . ndarray ), \"[NetGear_Async:ERROR] :: Invalid data received from server end!\" elif self . __bi_mode : # raise error for invalid data raise ValueError ( \"[NetGear_Async:ERROR] :: Send Mode only accepts tuple(data, frame) as input in Bidirectional Mode. \\ Kindly refer vidgear docs!\" ) else : # otherwise just make a copy of frame frame = np . copy ( dataframe ) data = None # check if retrieved frame is `CONTIGUOUS` if not ( frame . flags [ \"C_CONTIGUOUS\" ]): # otherwise make it frame = np . ascontiguousarray ( frame , dtype = frame . dtype ) # create data dict data_dict = dict ( terminate = False , bi_mode = self . __bi_mode , data = data if not ( data is None ) else \"\" , ) # encode it data_enc = msgpack . packb ( data_dict ) # send the encoded data with correct flags await self . __msg_socket . send ( data_enc , flags = zmq . SNDMORE ) # encode frame frame_enc = msgpack . packb ( frame , default = m . encode ) # send the encoded frame await self . __msg_socket . send_multipart ([ frame_enc ]) # check if bidirectional patterns used if self . __msg_pattern < 2 : # handle bidirectional data transfer if enabled if self . __bi_mode : # get receiver encoded message withing timeout limit recvdmsg_encoded = await asyncio . wait_for ( self . __msg_socket . recv (), timeout = self . __timeout ) # retrieve receiver data from encoded message recvd_data = msgpack . unpackb ( recvdmsg_encoded , use_list = False ) # check message type if recvd_data [ \"return_type\" ] == \"ndarray\" : # numpy.ndarray # get encoded frame from receiver recvdframe_encoded = await asyncio . wait_for ( self . __msg_socket . recv_multipart (), timeout = self . __timeout ) # retrieve frame and put in queue await self . __queue . put ( msgpack . unpackb ( recvdframe_encoded [ 0 ], use_list = False , object_hook = m . decode , ) ) else : # otherwise put data directly in queue await self . __queue . put ( recvd_data [ \"return_data\" ] if recvd_data [ \"return_data\" ] else None ) else : # otherwise log received confirmation recv_confirmation = await asyncio . wait_for ( self . __msg_socket . recv (), timeout = self . __timeout ) if self . __logging : logger . debug ( recv_confirmation ) async def recv_generator ( self ): \"\"\" A default Asynchronous Frame Generator for NetGear_Async's Receiver-end. \"\"\" # check whether `receive mode` is activated if not ( self . __receive_mode ): # raise Value error and exit self . __terminate = True raise ValueError ( \"[NetGear_Async:ERROR] :: `recv_generator()` function cannot be accessed while `receive_mode` is disabled. Kindly refer vidgear docs!\" ) # initialize and define messaging socket self . __msg_socket = self . __msg_context . socket ( self . __pattern [ 1 ]) # define exclusive socket options for patterns if self . __msg_pattern == 2 : self . __msg_socket . set_hwm ( 1 ) self . __msg_socket . setsockopt ( zmq . SUBSCRIBE , b \"\" ) try : # bind socket to the assigned protocol, address and port self . __msg_socket . bind ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ) # finally log progress if self . __logging : logger . debug ( \"Successfully binded to address: {} with pattern: {} .\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , ) ) logger . critical ( \"Receive Mode is activated successfully!\" ) except Exception as e : logger . exception ( str ( e )) raise RuntimeError ( \"[NetGear_Async:ERROR] :: Failed to bind address: {} and pattern: {}{} !\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , \" and Bidirectional Mode enabled\" if self . __bi_mode else \"\" , ) ) # loop until terminated while not self . __terminate : # get encoded data message from server withing timeout limit datamsg_encoded = await asyncio . wait_for ( self . __msg_socket . recv (), timeout = self . __timeout ) # retrieve data from message data = msgpack . unpackb ( datamsg_encoded , use_list = False ) # terminate if exit` flag received from server if data [ \"terminate\" ]: # send confirmation message to server if bidirectional patterns if self . __msg_pattern < 2 : # create termination confirmation message return_dict = dict ( terminated = \"Client-` {} ` successfully terminated!\" . format ( self . __id ), ) # encode message retdata_enc = msgpack . packb ( return_dict ) # send message back to server await self . __msg_socket . send ( retdata_enc ) if self . __logging : logger . info ( \"Termination signal received from server!\" ) # break loop and terminate self . __terminate = True break # get encoded frame message from server withing timeout limit framemsg_encoded = await asyncio . wait_for ( self . __msg_socket . recv_multipart (), timeout = self . __timeout ) # retrieve frame from message frame = msgpack . unpackb ( framemsg_encoded [ 0 ], use_list = False , object_hook = m . decode ) # check if bidirectional patterns if self . __msg_pattern < 2 : # handle bidirectional data transfer if enabled if self . __bi_mode and data [ \"bi_mode\" ]: # handle empty queue if not self . __queue . empty (): return_data = await self . __queue . get () self . __queue . task_done () else : return_data = None # check if we are returning `ndarray` frames if not ( return_data is None ) and isinstance ( return_data , np . ndarray ): # check whether the incoming frame is contiguous if not ( return_data . flags [ \"C_CONTIGUOUS\" ]): return_data = np . ascontiguousarray ( return_data , dtype = return_data . dtype ) # create return type dict without data rettype_dict = dict ( return_type = ( type ( return_data ) . __name__ ), return_data = None , ) # encode it rettype_enc = msgpack . packb ( rettype_dict ) # send it to server with correct flags await self . __msg_socket . send ( rettype_enc , flags = zmq . SNDMORE ) # encode return ndarray data retframe_enc = msgpack . packb ( return_data , default = m . encode ) # send it over network to server await self . __msg_socket . send_multipart ([ retframe_enc ]) else : # otherwise create type and data dict return_dict = dict ( return_type = ( type ( return_data ) . __name__ ), return_data = return_data if not ( return_data is None ) else \"\" , ) # encode it retdata_enc = msgpack . packb ( return_dict ) # send it over network to server await self . __msg_socket . send ( retdata_enc ) elif self . __bi_mode or data [ \"bi_mode\" ]: # raise error if bidirectional mode is disabled at server or client but not both raise RuntimeError ( \"[NetGear_Async:ERROR] :: Invalid configuration! Bidirectional Mode is not activate on {} end.\" . format ( \"client\" if self . __bi_mode else \"server\" ) ) else : # otherwise just send confirmation message to server await self . __msg_socket . send ( bytes ( \"Data received on client: {} !\" . format ( self . __id ), \"utf-8\" ) ) # yield received tuple(data-frame) if bidirectional mode or else just frame if self . __bi_mode : yield ( data [ \"data\" ], frame ) if data [ \"data\" ] else ( None , frame ) else : yield frame # sleep for sometime await asyncio . sleep ( 0 ) async def __frame_generator ( self ): \"\"\" Returns a default frame-generator for NetGear_Async's Server Handler. \"\"\" # start stream self . __stream . start () # loop over stream until its terminated while not self . __terminate : # read frames frame = self . __stream . read () # break if NoneType if frame is None : break # yield frame yield frame # sleep for sometime await asyncio . sleep ( 0 ) async def transceive_data ( self , data = None ): \"\"\" Bidirectional Mode exclusive method to Transmit data _(in Receive mode)_ and Receive data _(in Send mode)_. Parameters: data (any): inputs data _(of any datatype)_ for sending back to Server. \"\"\" recvd_data = None if not self . __terminate : if self . __bi_mode : if self . __receive_mode : await self . __queue . put ( data ) else : if not self . __queue . empty (): recvd_data = await self . __queue . get () self . __queue . task_done () else : logger . error ( \"`transceive_data()` function cannot be used when Bidirectional Mode is disabled.\" ) return recvd_data async def __terminate_connection ( self , disable_confirmation = False ): \"\"\" Internal asyncio method to safely terminate ZMQ connection and queues Parameters: disable_confirmation (boolean): Force disable termination confirmation from client in bidirectional patterns. \"\"\" # log termination if self . __logging : logger . debug ( \"Terminating various {} Processes. Please wait.\" . format ( \"Receive Mode\" if self . __receive_mode else \"Send Mode\" ) ) # check whether `receive_mode` is enabled or not if self . __receive_mode : # indicate that process should be terminated self . __terminate = True else : # indicate that process should be terminated self . __terminate = True # terminate stream if not ( self . __stream is None ): self . __stream . stop () # signal `exit` flag for termination! data_dict = dict ( terminate = True ) data_enc = msgpack . packb ( data_dict ) await self . __msg_socket . send ( data_enc ) # check if bidirectional patterns if self . __msg_pattern < 2 and not disable_confirmation : # then receive and log confirmation recv_confirmation = await self . __msg_socket . recv () recvd_conf = msgpack . unpackb ( recv_confirmation , use_list = False ) if self . __logging and \"terminated\" in recvd_conf : logger . debug ( recvd_conf [ \"terminated\" ]) # close socket self . __msg_socket . setsockopt ( zmq . LINGER , 0 ) self . __msg_socket . close () # handle asyncio queues in bidirectional mode if self . __bi_mode : # empty queue if not while not self . __queue . empty (): try : self . __queue . get_nowait () except asyncio . QueueEmpty : continue self . __queue . task_done () # join queues await self . __queue . join () logger . critical ( \" {} successfully terminated!\" . format ( \"Receive Mode\" if self . __receive_mode else \"Send Mode\" ) ) def close ( self , skip_loop = False ): \"\"\" Terminates all NetGear_Async Asynchronous processes gracefully. Parameters: skip_loop (Boolean): (optional)used only if don't want to close eventloop(required in pytest). \"\"\" # close event loop if specified if not ( skip_loop ): # close connection gracefully self . loop . run_until_complete ( self . __terminate_connection ()) self . loop . close () else : # otherwise create a task asyncio . ensure_future ( self . __terminate_connection ( disable_confirmation = True ) ) __init__ ( self , address = None , port = None , protocol = 'tcp' , pattern = 0 , receive_mode = False , timeout = 0.0 , enablePiCamera = False , stabilize = False , source = None , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , time_delay = 0 , logging = False , ** options ) special \u2693 This constructor method initializes the object state and attributes of the NetGear_Async class. Parameters: Name Type Description Default address str sets the valid network address of the Server/Client. None port str sets the valid Network Port of the Server/Client. None protocol str sets the valid messaging protocol between Server/Client. 'tcp' pattern int sets the supported messaging pattern(flow of communication) between Server/Client 0 receive_mode bool select the NetGear_Async's Mode of operation. False timeout int/float controls the maximum waiting time(in sec) after which Client throws TimeoutError . 0.0 enablePiCamera bool provide access to PiGear(if True) or CamGear(if False) APIs respectively. False stabilize bool enable access to Stabilizer Class for stabilizing frames. False camera_num int selects the camera module index which will be used as Rpi source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the Rpi source. (640, 480) framerate int/float sets the framerate of the Rpi source. 25 source based on input defines the source for the input stream. None stream_mode bool controls the exclusive YouTube Mode. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Tweak Parameters of NetGear_Async, CamGear, PiGear & Stabilizer. {} Source code in vidgear/gears/asyncio/netgear_async.py def __init__ ( self , # NetGear_Async parameters address = None , port = None , protocol = \"tcp\" , pattern = 0 , receive_mode = False , timeout = 0.0 , # Videogear parameters enablePiCamera = False , stabilize = False , source = None , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , time_delay = 0 , # common parameters logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the NetGear_Async class. Parameters: address (str): sets the valid network address of the Server/Client. port (str): sets the valid Network Port of the Server/Client. protocol (str): sets the valid messaging protocol between Server/Client. pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client receive_mode (bool): select the NetGear_Async's Mode of operation. timeout (int/float): controls the maximum waiting time(in sec) after which Client throws `TimeoutError`. enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of NetGear_Async, CamGear, PiGear & Stabilizer. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"zmq\" if zmq is None else \"\" , min_version = \"4.0\" , pkg_name = \"pyzmq\" ) import_dependency_safe ( \"msgpack\" if msgpack is None else \"\" ) import_dependency_safe ( \"msgpack_numpy\" if m is None else \"\" ) # enable logging if specified self . __logging = logging # define valid messaging patterns => `0`: PAIR, `1`:(REQ, REP), `2`:(SUB, PUB), `3`:(PUSH, PULL) valid_messaging_patterns = { 0 : ( zmq . PAIR , zmq . PAIR ), 1 : ( zmq . REQ , zmq . REP ), 2 : ( zmq . PUB , zmq . SUB ), 3 : ( zmq . PUSH , zmq . PULL ), } # check whether user-defined messaging pattern is valid if isinstance ( pattern , int ) and pattern in valid_messaging_patterns : # assign value self . __msg_pattern = pattern self . __pattern = valid_messaging_patterns [ pattern ] else : # otherwise default to 0:`zmq.PAIR` self . __msg_pattern = 0 self . __pattern = valid_messaging_patterns [ self . __msg_pattern ] if self . __logging : logger . warning ( \"Invalid pattern {pattern} . Defaulting to `zmq.PAIR`!\" . format ( pattern = pattern ) ) # check whether user-defined messaging protocol is valid if isinstance ( protocol , str ) and protocol in [ \"tcp\" , \"ipc\" ]: # assign value self . __protocol = protocol else : # else default to `tcp` protocol self . __protocol = \"tcp\" if self . __logging : logger . warning ( \"Invalid protocol. Defaulting to `tcp`!\" ) # initialize Termination flag self . __terminate = False # initialize and assign `Receive Mode` self . __receive_mode = receive_mode # initialize stream handler self . __stream = None # initialize Messaging Socket self . __msg_socket = None # initialize NetGear_Async's configuration dictionary self . config = {} # asyncio queue handler self . __queue = None # define Bidirectional mode self . __bi_mode = False # handles Bidirectional mode state # assign timeout for Receiver end if timeout and isinstance ( timeout , ( int , float )): self . __timeout = float ( timeout ) else : self . __timeout = 15.0 # generate 8-digit random system id self . __id = \"\" . join ( secrets . choice ( string . ascii_uppercase + string . digits ) for i in range ( 8 ) ) # Handle user-defined options dictionary values # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # handle bidirectional mode if \"bidirectional_mode\" in options : value = options [ \"bidirectional_mode\" ] # also check if pattern and source is valid if isinstance ( value , bool ) and pattern < 2 and source is None : # activate Bidirectional mode if specified self . __bi_mode = value else : # otherwise disable it self . __bi_mode = False logger . warning ( \"Bidirectional data transmission is disabled!\" ) # handle errors and logging if pattern >= 2 : # raise error raise ValueError ( \"[NetGear_Async:ERROR] :: ` {} ` pattern is not valid when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\" . format ( pattern ) ) elif not ( source is None ): raise ValueError ( \"[NetGear_Async:ERROR] :: Custom source must be used when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\" . format ( pattern ) ) elif isinstance ( value , bool ) and self . __logging : # log Bidirectional mode activation logger . debug ( \"Bidirectional Data Transmission is {} for this connection!\" . format ( \"enabled\" if value else \"disabled\" ) ) else : logger . error ( \"`bidirectional_mode` value is invalid!\" ) # clean del options [ \"bidirectional_mode\" ] # define messaging asynchronous Context self . __msg_context = zmq . asyncio . Context () # check whether `Receive Mode` is enabled if receive_mode : # assign local IP address if None if address is None : self . __address = \"*\" # define address else : self . __address = address # assign default port address if None if port is None : self . __port = \"5555\" else : self . __port = port else : # Handle video source if source is None : self . config = { \"generator\" : None } if self . __logging : logger . warning ( \"Given source is of NoneType!\" ) else : # define stream with necessary params self . __stream = VideoGear ( enablePiCamera = enablePiCamera , stabilize = stabilize , source = source , camera_num = camera_num , stream_mode = stream_mode , backend = backend , colorspace = colorspace , resolution = resolution , framerate = framerate , logging = logging , time_delay = time_delay , ** options ) # define default frame generator in configuration self . config = { \"generator\" : self . __frame_generator ()} # assign local ip address if None if address is None : self . __address = \"localhost\" else : self . __address = address # assign default port address if None if port is None : self . __port = \"5555\" else : self . __port = port # add server task handler self . task = None # Setup and assign event loop policy if platform . system () == \"Windows\" : # On Windows, VidGear requires the ``WindowsSelectorEventLoop``, and this is # the default in Python 3.7 and older, but new Python 3.8, defaults to an # event loop that is not compatible with it. Thereby, we had to set it manually. if sys . version_info [: 2 ] >= ( 3 , 8 ): asyncio . set_event_loop_policy ( asyncio . WindowsSelectorEventLoopPolicy ()) else : if not ( uvloop is None ): # Latest uvloop eventloop is only available for UNIX machines. asyncio . set_event_loop_policy ( uvloop . EventLoopPolicy ()) else : # log if not present import_dependency_safe ( \"uvloop\" , error = \"log\" ) # Retrieve event loop and assign it self . loop = asyncio . get_event_loop () # create asyncio queue if bidirectional mode activated self . __queue = asyncio . Queue () if self . __bi_mode else None # log eventloop for debugging if self . __logging : # debugging logger . info ( \"Using ` {} ` event loop for this process.\" . format ( self . loop . __class__ . __name__ ) ) close ( self , skip_loop = False ) \u2693 Terminates all NetGear_Async Asynchronous processes gracefully. Parameters: Name Type Description Default skip_loop Boolean (optional)used only if don't want to close eventloop(required in pytest). False Source code in vidgear/gears/asyncio/netgear_async.py def close ( self , skip_loop = False ): \"\"\" Terminates all NetGear_Async Asynchronous processes gracefully. Parameters: skip_loop (Boolean): (optional)used only if don't want to close eventloop(required in pytest). \"\"\" # close event loop if specified if not ( skip_loop ): # close connection gracefully self . loop . run_until_complete ( self . __terminate_connection ()) self . loop . close () else : # otherwise create a task asyncio . ensure_future ( self . __terminate_connection ( disable_confirmation = True ) ) launch ( self ) \u2693 Launches an asynchronous generators and loop executors for respective task. Source code in vidgear/gears/asyncio/netgear_async.py def launch ( self ): \"\"\" Launches an asynchronous generators and loop executors for respective task. \"\"\" # check if receive mode enabled if self . __receive_mode : if self . __logging : logger . debug ( \"Launching NetGear_Async asynchronous generator!\" ) # run loop executor for Receiver asynchronous generator self . loop . run_in_executor ( None , self . recv_generator ) else : # Otherwise launch Server handler if self . __logging : logger . debug ( \"Creating NetGear_Async asynchronous server handler!\" ) # create task for Server Handler self . task = asyncio . ensure_future ( self . __server_handler ()) # return instance return self recv_generator ( self ) \u2693 A default Asynchronous Frame Generator for NetGear_Async's Receiver-end. Source code in vidgear/gears/asyncio/netgear_async.py async def recv_generator ( self ): \"\"\" A default Asynchronous Frame Generator for NetGear_Async's Receiver-end. \"\"\" # check whether `receive mode` is activated if not ( self . __receive_mode ): # raise Value error and exit self . __terminate = True raise ValueError ( \"[NetGear_Async:ERROR] :: `recv_generator()` function cannot be accessed while `receive_mode` is disabled. Kindly refer vidgear docs!\" ) # initialize and define messaging socket self . __msg_socket = self . __msg_context . socket ( self . __pattern [ 1 ]) # define exclusive socket options for patterns if self . __msg_pattern == 2 : self . __msg_socket . set_hwm ( 1 ) self . __msg_socket . setsockopt ( zmq . SUBSCRIBE , b \"\" ) try : # bind socket to the assigned protocol, address and port self . __msg_socket . bind ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ) # finally log progress if self . __logging : logger . debug ( \"Successfully binded to address: {} with pattern: {} .\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , ) ) logger . critical ( \"Receive Mode is activated successfully!\" ) except Exception as e : logger . exception ( str ( e )) raise RuntimeError ( \"[NetGear_Async:ERROR] :: Failed to bind address: {} and pattern: {}{} !\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , \" and Bidirectional Mode enabled\" if self . __bi_mode else \"\" , ) ) # loop until terminated while not self . __terminate : # get encoded data message from server withing timeout limit datamsg_encoded = await asyncio . wait_for ( self . __msg_socket . recv (), timeout = self . __timeout ) # retrieve data from message data = msgpack . unpackb ( datamsg_encoded , use_list = False ) # terminate if exit` flag received from server if data [ \"terminate\" ]: # send confirmation message to server if bidirectional patterns if self . __msg_pattern < 2 : # create termination confirmation message return_dict = dict ( terminated = \"Client-` {} ` successfully terminated!\" . format ( self . __id ), ) # encode message retdata_enc = msgpack . packb ( return_dict ) # send message back to server await self . __msg_socket . send ( retdata_enc ) if self . __logging : logger . info ( \"Termination signal received from server!\" ) # break loop and terminate self . __terminate = True break # get encoded frame message from server withing timeout limit framemsg_encoded = await asyncio . wait_for ( self . __msg_socket . recv_multipart (), timeout = self . __timeout ) # retrieve frame from message frame = msgpack . unpackb ( framemsg_encoded [ 0 ], use_list = False , object_hook = m . decode ) # check if bidirectional patterns if self . __msg_pattern < 2 : # handle bidirectional data transfer if enabled if self . __bi_mode and data [ \"bi_mode\" ]: # handle empty queue if not self . __queue . empty (): return_data = await self . __queue . get () self . __queue . task_done () else : return_data = None # check if we are returning `ndarray` frames if not ( return_data is None ) and isinstance ( return_data , np . ndarray ): # check whether the incoming frame is contiguous if not ( return_data . flags [ \"C_CONTIGUOUS\" ]): return_data = np . ascontiguousarray ( return_data , dtype = return_data . dtype ) # create return type dict without data rettype_dict = dict ( return_type = ( type ( return_data ) . __name__ ), return_data = None , ) # encode it rettype_enc = msgpack . packb ( rettype_dict ) # send it to server with correct flags await self . __msg_socket . send ( rettype_enc , flags = zmq . SNDMORE ) # encode return ndarray data retframe_enc = msgpack . packb ( return_data , default = m . encode ) # send it over network to server await self . __msg_socket . send_multipart ([ retframe_enc ]) else : # otherwise create type and data dict return_dict = dict ( return_type = ( type ( return_data ) . __name__ ), return_data = return_data if not ( return_data is None ) else \"\" , ) # encode it retdata_enc = msgpack . packb ( return_dict ) # send it over network to server await self . __msg_socket . send ( retdata_enc ) elif self . __bi_mode or data [ \"bi_mode\" ]: # raise error if bidirectional mode is disabled at server or client but not both raise RuntimeError ( \"[NetGear_Async:ERROR] :: Invalid configuration! Bidirectional Mode is not activate on {} end.\" . format ( \"client\" if self . __bi_mode else \"server\" ) ) else : # otherwise just send confirmation message to server await self . __msg_socket . send ( bytes ( \"Data received on client: {} !\" . format ( self . __id ), \"utf-8\" ) ) # yield received tuple(data-frame) if bidirectional mode or else just frame if self . __bi_mode : yield ( data [ \"data\" ], frame ) if data [ \"data\" ] else ( None , frame ) else : yield frame # sleep for sometime await asyncio . sleep ( 0 ) transceive_data ( self , data = None ) async \u2693 Bidirectional Mode exclusive method to Transmit data (in Receive mode) and Receive data (in Send mode) . Parameters: Name Type Description Default data any inputs data (of any datatype) for sending back to Server. None Source code in vidgear/gears/asyncio/netgear_async.py async def transceive_data ( self , data = None ): \"\"\" Bidirectional Mode exclusive method to Transmit data _(in Receive mode)_ and Receive data _(in Send mode)_. Parameters: data (any): inputs data _(of any datatype)_ for sending back to Server. \"\"\" recvd_data = None if not self . __terminate : if self . __bi_mode : if self . __receive_mode : await self . __queue . put ( data ) else : if not self . __queue . empty (): recvd_data = await self . __queue . get () self . __queue . task_done () else : logger . error ( \"`transceive_data()` function cannot be used when Bidirectional Mode is disabled.\" ) return recvd_data","title":"NetGear_Async API"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.__init__","text":"This constructor method initializes the object state and attributes of the NetGear_Async class. Parameters: Name Type Description Default address str sets the valid network address of the Server/Client. None port str sets the valid Network Port of the Server/Client. None protocol str sets the valid messaging protocol between Server/Client. 'tcp' pattern int sets the supported messaging pattern(flow of communication) between Server/Client 0 receive_mode bool select the NetGear_Async's Mode of operation. False timeout int/float controls the maximum waiting time(in sec) after which Client throws TimeoutError . 0.0 enablePiCamera bool provide access to PiGear(if True) or CamGear(if False) APIs respectively. False stabilize bool enable access to Stabilizer Class for stabilizing frames. False camera_num int selects the camera module index which will be used as Rpi source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the Rpi source. (640, 480) framerate int/float sets the framerate of the Rpi source. 25 source based on input defines the source for the input stream. None stream_mode bool controls the exclusive YouTube Mode. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Tweak Parameters of NetGear_Async, CamGear, PiGear & Stabilizer. {} Source code in vidgear/gears/asyncio/netgear_async.py def __init__ ( self , # NetGear_Async parameters address = None , port = None , protocol = \"tcp\" , pattern = 0 , receive_mode = False , timeout = 0.0 , # Videogear parameters enablePiCamera = False , stabilize = False , source = None , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , time_delay = 0 , # common parameters logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the NetGear_Async class. Parameters: address (str): sets the valid network address of the Server/Client. port (str): sets the valid Network Port of the Server/Client. protocol (str): sets the valid messaging protocol between Server/Client. pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client receive_mode (bool): select the NetGear_Async's Mode of operation. timeout (int/float): controls the maximum waiting time(in sec) after which Client throws `TimeoutError`. enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of NetGear_Async, CamGear, PiGear & Stabilizer. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"zmq\" if zmq is None else \"\" , min_version = \"4.0\" , pkg_name = \"pyzmq\" ) import_dependency_safe ( \"msgpack\" if msgpack is None else \"\" ) import_dependency_safe ( \"msgpack_numpy\" if m is None else \"\" ) # enable logging if specified self . __logging = logging # define valid messaging patterns => `0`: PAIR, `1`:(REQ, REP), `2`:(SUB, PUB), `3`:(PUSH, PULL) valid_messaging_patterns = { 0 : ( zmq . PAIR , zmq . PAIR ), 1 : ( zmq . REQ , zmq . REP ), 2 : ( zmq . PUB , zmq . SUB ), 3 : ( zmq . PUSH , zmq . PULL ), } # check whether user-defined messaging pattern is valid if isinstance ( pattern , int ) and pattern in valid_messaging_patterns : # assign value self . __msg_pattern = pattern self . __pattern = valid_messaging_patterns [ pattern ] else : # otherwise default to 0:`zmq.PAIR` self . __msg_pattern = 0 self . __pattern = valid_messaging_patterns [ self . __msg_pattern ] if self . __logging : logger . warning ( \"Invalid pattern {pattern} . Defaulting to `zmq.PAIR`!\" . format ( pattern = pattern ) ) # check whether user-defined messaging protocol is valid if isinstance ( protocol , str ) and protocol in [ \"tcp\" , \"ipc\" ]: # assign value self . __protocol = protocol else : # else default to `tcp` protocol self . __protocol = \"tcp\" if self . __logging : logger . warning ( \"Invalid protocol. Defaulting to `tcp`!\" ) # initialize Termination flag self . __terminate = False # initialize and assign `Receive Mode` self . __receive_mode = receive_mode # initialize stream handler self . __stream = None # initialize Messaging Socket self . __msg_socket = None # initialize NetGear_Async's configuration dictionary self . config = {} # asyncio queue handler self . __queue = None # define Bidirectional mode self . __bi_mode = False # handles Bidirectional mode state # assign timeout for Receiver end if timeout and isinstance ( timeout , ( int , float )): self . __timeout = float ( timeout ) else : self . __timeout = 15.0 # generate 8-digit random system id self . __id = \"\" . join ( secrets . choice ( string . ascii_uppercase + string . digits ) for i in range ( 8 ) ) # Handle user-defined options dictionary values # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # handle bidirectional mode if \"bidirectional_mode\" in options : value = options [ \"bidirectional_mode\" ] # also check if pattern and source is valid if isinstance ( value , bool ) and pattern < 2 and source is None : # activate Bidirectional mode if specified self . __bi_mode = value else : # otherwise disable it self . __bi_mode = False logger . warning ( \"Bidirectional data transmission is disabled!\" ) # handle errors and logging if pattern >= 2 : # raise error raise ValueError ( \"[NetGear_Async:ERROR] :: ` {} ` pattern is not valid when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\" . format ( pattern ) ) elif not ( source is None ): raise ValueError ( \"[NetGear_Async:ERROR] :: Custom source must be used when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\" . format ( pattern ) ) elif isinstance ( value , bool ) and self . __logging : # log Bidirectional mode activation logger . debug ( \"Bidirectional Data Transmission is {} for this connection!\" . format ( \"enabled\" if value else \"disabled\" ) ) else : logger . error ( \"`bidirectional_mode` value is invalid!\" ) # clean del options [ \"bidirectional_mode\" ] # define messaging asynchronous Context self . __msg_context = zmq . asyncio . Context () # check whether `Receive Mode` is enabled if receive_mode : # assign local IP address if None if address is None : self . __address = \"*\" # define address else : self . __address = address # assign default port address if None if port is None : self . __port = \"5555\" else : self . __port = port else : # Handle video source if source is None : self . config = { \"generator\" : None } if self . __logging : logger . warning ( \"Given source is of NoneType!\" ) else : # define stream with necessary params self . __stream = VideoGear ( enablePiCamera = enablePiCamera , stabilize = stabilize , source = source , camera_num = camera_num , stream_mode = stream_mode , backend = backend , colorspace = colorspace , resolution = resolution , framerate = framerate , logging = logging , time_delay = time_delay , ** options ) # define default frame generator in configuration self . config = { \"generator\" : self . __frame_generator ()} # assign local ip address if None if address is None : self . __address = \"localhost\" else : self . __address = address # assign default port address if None if port is None : self . __port = \"5555\" else : self . __port = port # add server task handler self . task = None # Setup and assign event loop policy if platform . system () == \"Windows\" : # On Windows, VidGear requires the ``WindowsSelectorEventLoop``, and this is # the default in Python 3.7 and older, but new Python 3.8, defaults to an # event loop that is not compatible with it. Thereby, we had to set it manually. if sys . version_info [: 2 ] >= ( 3 , 8 ): asyncio . set_event_loop_policy ( asyncio . WindowsSelectorEventLoopPolicy ()) else : if not ( uvloop is None ): # Latest uvloop eventloop is only available for UNIX machines. asyncio . set_event_loop_policy ( uvloop . EventLoopPolicy ()) else : # log if not present import_dependency_safe ( \"uvloop\" , error = \"log\" ) # Retrieve event loop and assign it self . loop = asyncio . get_event_loop () # create asyncio queue if bidirectional mode activated self . __queue = asyncio . Queue () if self . __bi_mode else None # log eventloop for debugging if self . __logging : # debugging logger . info ( \"Using ` {} ` event loop for this process.\" . format ( self . loop . __class__ . __name__ ) )","title":"__init__()"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.close","text":"Terminates all NetGear_Async Asynchronous processes gracefully. Parameters: Name Type Description Default skip_loop Boolean (optional)used only if don't want to close eventloop(required in pytest). False Source code in vidgear/gears/asyncio/netgear_async.py def close ( self , skip_loop = False ): \"\"\" Terminates all NetGear_Async Asynchronous processes gracefully. Parameters: skip_loop (Boolean): (optional)used only if don't want to close eventloop(required in pytest). \"\"\" # close event loop if specified if not ( skip_loop ): # close connection gracefully self . loop . run_until_complete ( self . __terminate_connection ()) self . loop . close () else : # otherwise create a task asyncio . ensure_future ( self . __terminate_connection ( disable_confirmation = True ) )","title":"close()"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.launch","text":"Launches an asynchronous generators and loop executors for respective task. Source code in vidgear/gears/asyncio/netgear_async.py def launch ( self ): \"\"\" Launches an asynchronous generators and loop executors for respective task. \"\"\" # check if receive mode enabled if self . __receive_mode : if self . __logging : logger . debug ( \"Launching NetGear_Async asynchronous generator!\" ) # run loop executor for Receiver asynchronous generator self . loop . run_in_executor ( None , self . recv_generator ) else : # Otherwise launch Server handler if self . __logging : logger . debug ( \"Creating NetGear_Async asynchronous server handler!\" ) # create task for Server Handler self . task = asyncio . ensure_future ( self . __server_handler ()) # return instance return self","title":"launch()"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.recv_generator","text":"A default Asynchronous Frame Generator for NetGear_Async's Receiver-end. Source code in vidgear/gears/asyncio/netgear_async.py async def recv_generator ( self ): \"\"\" A default Asynchronous Frame Generator for NetGear_Async's Receiver-end. \"\"\" # check whether `receive mode` is activated if not ( self . __receive_mode ): # raise Value error and exit self . __terminate = True raise ValueError ( \"[NetGear_Async:ERROR] :: `recv_generator()` function cannot be accessed while `receive_mode` is disabled. Kindly refer vidgear docs!\" ) # initialize and define messaging socket self . __msg_socket = self . __msg_context . socket ( self . __pattern [ 1 ]) # define exclusive socket options for patterns if self . __msg_pattern == 2 : self . __msg_socket . set_hwm ( 1 ) self . __msg_socket . setsockopt ( zmq . SUBSCRIBE , b \"\" ) try : # bind socket to the assigned protocol, address and port self . __msg_socket . bind ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ) # finally log progress if self . __logging : logger . debug ( \"Successfully binded to address: {} with pattern: {} .\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , ) ) logger . critical ( \"Receive Mode is activated successfully!\" ) except Exception as e : logger . exception ( str ( e )) raise RuntimeError ( \"[NetGear_Async:ERROR] :: Failed to bind address: {} and pattern: {}{} !\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , \" and Bidirectional Mode enabled\" if self . __bi_mode else \"\" , ) ) # loop until terminated while not self . __terminate : # get encoded data message from server withing timeout limit datamsg_encoded = await asyncio . wait_for ( self . __msg_socket . recv (), timeout = self . __timeout ) # retrieve data from message data = msgpack . unpackb ( datamsg_encoded , use_list = False ) # terminate if exit` flag received from server if data [ \"terminate\" ]: # send confirmation message to server if bidirectional patterns if self . __msg_pattern < 2 : # create termination confirmation message return_dict = dict ( terminated = \"Client-` {} ` successfully terminated!\" . format ( self . __id ), ) # encode message retdata_enc = msgpack . packb ( return_dict ) # send message back to server await self . __msg_socket . send ( retdata_enc ) if self . __logging : logger . info ( \"Termination signal received from server!\" ) # break loop and terminate self . __terminate = True break # get encoded frame message from server withing timeout limit framemsg_encoded = await asyncio . wait_for ( self . __msg_socket . recv_multipart (), timeout = self . __timeout ) # retrieve frame from message frame = msgpack . unpackb ( framemsg_encoded [ 0 ], use_list = False , object_hook = m . decode ) # check if bidirectional patterns if self . __msg_pattern < 2 : # handle bidirectional data transfer if enabled if self . __bi_mode and data [ \"bi_mode\" ]: # handle empty queue if not self . __queue . empty (): return_data = await self . __queue . get () self . __queue . task_done () else : return_data = None # check if we are returning `ndarray` frames if not ( return_data is None ) and isinstance ( return_data , np . ndarray ): # check whether the incoming frame is contiguous if not ( return_data . flags [ \"C_CONTIGUOUS\" ]): return_data = np . ascontiguousarray ( return_data , dtype = return_data . dtype ) # create return type dict without data rettype_dict = dict ( return_type = ( type ( return_data ) . __name__ ), return_data = None , ) # encode it rettype_enc = msgpack . packb ( rettype_dict ) # send it to server with correct flags await self . __msg_socket . send ( rettype_enc , flags = zmq . SNDMORE ) # encode return ndarray data retframe_enc = msgpack . packb ( return_data , default = m . encode ) # send it over network to server await self . __msg_socket . send_multipart ([ retframe_enc ]) else : # otherwise create type and data dict return_dict = dict ( return_type = ( type ( return_data ) . __name__ ), return_data = return_data if not ( return_data is None ) else \"\" , ) # encode it retdata_enc = msgpack . packb ( return_dict ) # send it over network to server await self . __msg_socket . send ( retdata_enc ) elif self . __bi_mode or data [ \"bi_mode\" ]: # raise error if bidirectional mode is disabled at server or client but not both raise RuntimeError ( \"[NetGear_Async:ERROR] :: Invalid configuration! Bidirectional Mode is not activate on {} end.\" . format ( \"client\" if self . __bi_mode else \"server\" ) ) else : # otherwise just send confirmation message to server await self . __msg_socket . send ( bytes ( \"Data received on client: {} !\" . format ( self . __id ), \"utf-8\" ) ) # yield received tuple(data-frame) if bidirectional mode or else just frame if self . __bi_mode : yield ( data [ \"data\" ], frame ) if data [ \"data\" ] else ( None , frame ) else : yield frame # sleep for sometime await asyncio . sleep ( 0 )","title":"recv_generator()"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.transceive_data","text":"Bidirectional Mode exclusive method to Transmit data (in Receive mode) and Receive data (in Send mode) . Parameters: Name Type Description Default data any inputs data (of any datatype) for sending back to Server. None Source code in vidgear/gears/asyncio/netgear_async.py async def transceive_data ( self , data = None ): \"\"\" Bidirectional Mode exclusive method to Transmit data _(in Receive mode)_ and Receive data _(in Send mode)_. Parameters: data (any): inputs data _(of any datatype)_ for sending back to Server. \"\"\" recvd_data = None if not self . __terminate : if self . __bi_mode : if self . __receive_mode : await self . __queue . put ( data ) else : if not self . __queue . empty (): recvd_data = await self . __queue . get () self . __queue . task_done () else : logger . error ( \"`transceive_data()` function cannot be used when Bidirectional Mode is disabled.\" ) return recvd_data","title":"transceive_data()"},{"location":"bonus/reference/pigear/","text":"PiGear API usage examples can be found here \u27b6 PiGear API parameters are explained here \u27b6 PiGear is similar to CamGear API but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module). PiGear provides a flexible multi-threaded framework around complete picamera python library, and provide us the ability to exploit almost all of its parameters like brightness, saturation, sensor_mode, iso, exposure, etc. effortlessly. Furthermore, PiGear also supports multiple camera modules, such as in the case of Raspberry-Pi Compute Module IO boards. Best of all, PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur. That means that if you're running PiGear API in your script and someone accidentally pulls the Camera-Module cable out, instead of going into possible kernel panic, API will exit safely to save resources. Make sure to enable Raspberry Pi hardware-specific settings prior using this API, otherwise nothing will work. Source code in vidgear/gears/pigear.py class PiGear : \"\"\" PiGear is similar to CamGear API but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module). PiGear provides a flexible multi-threaded framework around complete picamera python library, and provide us the ability to exploit almost all of its parameters like brightness, saturation, sensor_mode, iso, exposure, etc. effortlessly. Furthermore, PiGear also supports multiple camera modules, such as in the case of Raspberry-Pi Compute Module IO boards. Best of all, PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur. That means that if you're running PiGear API in your script and someone accidentally pulls the Camera-Module cable out, instead of going into possible kernel panic, API will exit safely to save resources. !!! warning \"Make sure to enable [Raspberry Pi hardware-specific settings](https://picamera.readthedocs.io/en/release-1.13/quickstart.html) prior using this API, otherwise nothing will work.\" \"\"\" def __init__ ( self , camera_num = 0 , resolution = ( 640 , 480 ), framerate = 30 , colorspace = None , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the PiGear class. Parameters: camera_num (int): selects the camera module index which will be used as source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the source.. framerate (int/float): sets the framerate of the source. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Source Tweak Parameters. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"picamera\" if picamera is None else \"\" , ) # enable logging if specified self . __logging = False if logging : self . __logging = logging assert ( isinstance ( framerate , ( int , float )) and framerate > 5.0 ), \"[PiGear:ERROR] :: Input framerate value ` {} ` is a Invalid! Kindly read docs.\" . format ( framerate ) assert ( isinstance ( resolution , ( tuple , list )) and len ( resolution ) == 2 ), \"[PiGear:ERROR] :: Input resolution value ` {} ` is a Invalid! Kindly read docs.\" . format ( resolution ) if not ( isinstance ( camera_num , int ) and camera_num >= 0 ): camera_num = 0 logger . warning ( \"Input camera_num value ` {} ` is invalid, Defaulting to index 0!\" ) # initialize the picamera stream at given index self . __camera = PiCamera ( camera_num = camera_num ) self . __camera . resolution = tuple ( resolution ) self . __camera . framerate = framerate self . __logging and logger . debug ( \"Activating Pi camera at index: {} with resolution: {} & framerate: {} \" . format ( camera_num , resolution , framerate ) ) # initialize framerate variable self . framerate = framerate # initializing colorspace variable self . color_space = None # reformat dict options = { str ( k ) . strip (): v for k , v in options . items ()} # define timeout variable default value(handles hardware failures) self . __failure_timeout = options . pop ( \"HWFAILURE_TIMEOUT\" , 2.0 ) if isinstance ( self . __failure_timeout , ( int , float )): if not ( 10.0 > self . __failure_timeout > 1.0 ): raise ValueError ( \"[PiGear:ERROR] :: `HWFAILURE_TIMEOUT` value can only be between 1.0 ~ 10.0\" ) self . __logging and logger . debug ( \"Setting HW Failure Timeout: {} seconds\" . format ( self . __failure_timeout ) ) else : # reset improper values self . __failure_timeout = 2.0 try : # apply attributes to source if specified for key , value in options . items (): self . __logging and logger . debug ( \"Setting Parameter: {} = ' {} '\" . format ( key , value ) ) setattr ( self . __camera , key , value ) except Exception as e : # Catch if any error occurred logger . exception ( str ( e )) # separately handle colorspace value to int conversion if not ( colorspace is None ): self . color_space = capPropId ( colorspace . strip ()) if self . __logging and not ( self . color_space is None ): logger . debug ( \"Enabling ` {} ` colorspace for this video stream!\" . format ( colorspace . strip () ) ) # enable rgb capture array thread and capture stream self . __rawCapture = PiRGBArray ( self . __camera , size = resolution ) self . stream = self . __camera . capture_continuous ( self . __rawCapture , format = \"bgr\" , use_video_port = True ) # frame variable initialization self . frame = None try : stream = next ( self . stream ) self . frame = stream . array self . __rawCapture . seek ( 0 ) self . __rawCapture . truncate () # render colorspace if defined if not ( self . frame is None ) and not ( self . color_space is None ): self . frame = cv2 . cvtColor ( self . frame , self . color_space ) except Exception as e : logger . exception ( str ( e )) raise RuntimeError ( \"[PiGear:ERROR] :: Camera Module failed to initialize!\" ) # applying time delay to warm-up picamera only if specified if time_delay and isinstance ( time_delay , ( int , float )): time . sleep ( time_delay ) # thread initialization self . __thread = None # timer thread initialization(Keeps check on frozen thread) self . __timer = None self . __t_elasped = 0.0 # records time taken by thread # catching thread exceptions self . __exceptions = None # initialize termination flag self . __terminate = False def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the CamGear class object. \"\"\" # Start frame producer thread self . __thread = Thread ( target = self . __update , name = \"PiGear\" , args = ()) self . __thread . daemon = True self . __thread . start () # Start internal timer thread self . __timer = Thread ( target = self . __timeit , name = \"PiTimer\" , args = ()) self . __timer . daemon = True self . __timer . start () return self def __timeit ( self ): \"\"\" Threaded Internal Timer that keep checks on thread excecution timing \"\"\" # assign current time self . __t_elasped = time . time () # loop until termainated while not ( self . __terminate ): # check for frozen thread if time . time () - self . __t_elasped > self . __failure_timeout : # log failure self . __logging and logger . critical ( \"Camera Module Disconnected!\" ) # prepare for clean exit self . __exceptions = True self . __terminate = True # self-terminate def __update ( self ): \"\"\" A **Threaded Frames Extractor**, that keep iterating frames from PiCamera API to a internal monitored deque, until the thread is terminated, or frames runs out. \"\"\" # keep looping infinitely until the thread is terminated while not ( self . __terminate ): try : # Try to iterate next frame from generator stream = next ( self . stream ) except Exception : # catch and save any exceptions self . __exceptions = sys . exc_info () break # exit # __update timer self . __t_elasped = time . time () # grab the frame from the stream and clear the stream in # preparation for the next frame frame = stream . array self . __rawCapture . seek ( 0 ) self . __rawCapture . truncate () # apply colorspace if specified if not ( self . color_space is None ): # apply colorspace to frames color_frame = None try : if isinstance ( self . color_space , int ): color_frame = cv2 . cvtColor ( frame , self . color_space ) else : self . __logging and logger . warning ( \"Global color_space parameter value ` {} ` is not a valid!\" . format ( self . color_space ) ) self . color_space = None except Exception as e : # Catch if any error occurred self . color_space = None if self . __logging : logger . exception ( str ( e )) logger . warning ( \"Input colorspace is not a valid colorspace!\" ) if not ( color_frame is None ): self . frame = color_frame else : self . frame = frame else : self . frame = frame # terminate processes if not ( self . __terminate ): self . __terminate = True # release picamera resources self . __rawCapture . close () self . __camera . close () def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" # check if there are any thread exceptions if not ( self . __exceptions is None ): if isinstance ( self . __exceptions , bool ): # clear frame self . frame = None # notify user about hardware failure raise SystemError ( \"[PiGear:ERROR] :: Hardware failure occurred, Kindly reconnect Camera Module and restart your Pi!\" ) else : # clear frame self . frame = None # re-raise error for debugging error_msg = ( \"[PiGear:ERROR] :: Camera Module API failure occured: {} \" . format ( self . __exceptions [ 1 ] ) ) raise RuntimeError ( error_msg ) . with_traceback ( self . __exceptions [ 2 ]) # return the frame return self . frame def stop ( self ): \"\"\" Safely terminates the thread, and release the VideoStream resources. \"\"\" self . __logging and logger . debug ( \"Terminating PiGear Processes.\" ) # make sure that the threads should be terminated self . __terminate = True # stop timer thread if not ( self . __timer is None ): self . __timer . join () self . __timer = None # handle camera thread if not ( self . __thread is None ): # check if hardware failure occured if not ( self . __exceptions is None ) and isinstance ( self . __exceptions , bool ): # force release picamera resources self . __rawCapture . close () self . __camera . close () # properly handle thread exit self . __thread . join () # wait if still process is still processing some information # remove any threads self . __thread = None __init__ ( self , camera_num = 0 , resolution = ( 640 , 480 ), framerate = 30 , colorspace = None , logging = False , time_delay = 0 , ** options ) special \u2693 This constructor method initializes the object state and attributes of the PiGear class. Parameters: Name Type Description Default camera_num int selects the camera module index which will be used as source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the source.. (640, 480) framerate int/float sets the framerate of the source. 30 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Source Tweak Parameters. {} Source code in vidgear/gears/pigear.py def __init__ ( self , camera_num = 0 , resolution = ( 640 , 480 ), framerate = 30 , colorspace = None , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the PiGear class. Parameters: camera_num (int): selects the camera module index which will be used as source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the source.. framerate (int/float): sets the framerate of the source. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Source Tweak Parameters. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"picamera\" if picamera is None else \"\" , ) # enable logging if specified self . __logging = False if logging : self . __logging = logging assert ( isinstance ( framerate , ( int , float )) and framerate > 5.0 ), \"[PiGear:ERROR] :: Input framerate value ` {} ` is a Invalid! Kindly read docs.\" . format ( framerate ) assert ( isinstance ( resolution , ( tuple , list )) and len ( resolution ) == 2 ), \"[PiGear:ERROR] :: Input resolution value ` {} ` is a Invalid! Kindly read docs.\" . format ( resolution ) if not ( isinstance ( camera_num , int ) and camera_num >= 0 ): camera_num = 0 logger . warning ( \"Input camera_num value ` {} ` is invalid, Defaulting to index 0!\" ) # initialize the picamera stream at given index self . __camera = PiCamera ( camera_num = camera_num ) self . __camera . resolution = tuple ( resolution ) self . __camera . framerate = framerate self . __logging and logger . debug ( \"Activating Pi camera at index: {} with resolution: {} & framerate: {} \" . format ( camera_num , resolution , framerate ) ) # initialize framerate variable self . framerate = framerate # initializing colorspace variable self . color_space = None # reformat dict options = { str ( k ) . strip (): v for k , v in options . items ()} # define timeout variable default value(handles hardware failures) self . __failure_timeout = options . pop ( \"HWFAILURE_TIMEOUT\" , 2.0 ) if isinstance ( self . __failure_timeout , ( int , float )): if not ( 10.0 > self . __failure_timeout > 1.0 ): raise ValueError ( \"[PiGear:ERROR] :: `HWFAILURE_TIMEOUT` value can only be between 1.0 ~ 10.0\" ) self . __logging and logger . debug ( \"Setting HW Failure Timeout: {} seconds\" . format ( self . __failure_timeout ) ) else : # reset improper values self . __failure_timeout = 2.0 try : # apply attributes to source if specified for key , value in options . items (): self . __logging and logger . debug ( \"Setting Parameter: {} = ' {} '\" . format ( key , value ) ) setattr ( self . __camera , key , value ) except Exception as e : # Catch if any error occurred logger . exception ( str ( e )) # separately handle colorspace value to int conversion if not ( colorspace is None ): self . color_space = capPropId ( colorspace . strip ()) if self . __logging and not ( self . color_space is None ): logger . debug ( \"Enabling ` {} ` colorspace for this video stream!\" . format ( colorspace . strip () ) ) # enable rgb capture array thread and capture stream self . __rawCapture = PiRGBArray ( self . __camera , size = resolution ) self . stream = self . __camera . capture_continuous ( self . __rawCapture , format = \"bgr\" , use_video_port = True ) # frame variable initialization self . frame = None try : stream = next ( self . stream ) self . frame = stream . array self . __rawCapture . seek ( 0 ) self . __rawCapture . truncate () # render colorspace if defined if not ( self . frame is None ) and not ( self . color_space is None ): self . frame = cv2 . cvtColor ( self . frame , self . color_space ) except Exception as e : logger . exception ( str ( e )) raise RuntimeError ( \"[PiGear:ERROR] :: Camera Module failed to initialize!\" ) # applying time delay to warm-up picamera only if specified if time_delay and isinstance ( time_delay , ( int , float )): time . sleep ( time_delay ) # thread initialization self . __thread = None # timer thread initialization(Keeps check on frozen thread) self . __timer = None self . __t_elasped = 0.0 # records time taken by thread # catching thread exceptions self . __exceptions = None # initialize termination flag self . __terminate = False read ( self ) \u2693 Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/pigear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" # check if there are any thread exceptions if not ( self . __exceptions is None ): if isinstance ( self . __exceptions , bool ): # clear frame self . frame = None # notify user about hardware failure raise SystemError ( \"[PiGear:ERROR] :: Hardware failure occurred, Kindly reconnect Camera Module and restart your Pi!\" ) else : # clear frame self . frame = None # re-raise error for debugging error_msg = ( \"[PiGear:ERROR] :: Camera Module API failure occured: {} \" . format ( self . __exceptions [ 1 ] ) ) raise RuntimeError ( error_msg ) . with_traceback ( self . __exceptions [ 2 ]) # return the frame return self . frame start ( self ) \u2693 Launches the internal Threaded Frames Extractor daemon Returns: A reference to the CamGear class object. Source code in vidgear/gears/pigear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the CamGear class object. \"\"\" # Start frame producer thread self . __thread = Thread ( target = self . __update , name = \"PiGear\" , args = ()) self . __thread . daemon = True self . __thread . start () # Start internal timer thread self . __timer = Thread ( target = self . __timeit , name = \"PiTimer\" , args = ()) self . __timer . daemon = True self . __timer . start () return self stop ( self ) \u2693 Safely terminates the thread, and release the VideoStream resources. Source code in vidgear/gears/pigear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the VideoStream resources. \"\"\" self . __logging and logger . debug ( \"Terminating PiGear Processes.\" ) # make sure that the threads should be terminated self . __terminate = True # stop timer thread if not ( self . __timer is None ): self . __timer . join () self . __timer = None # handle camera thread if not ( self . __thread is None ): # check if hardware failure occured if not ( self . __exceptions is None ) and isinstance ( self . __exceptions , bool ): # force release picamera resources self . __rawCapture . close () self . __camera . close () # properly handle thread exit self . __thread . join () # wait if still process is still processing some information # remove any threads self . __thread = None","title":"PiGear API"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.__init__","text":"This constructor method initializes the object state and attributes of the PiGear class. Parameters: Name Type Description Default camera_num int selects the camera module index which will be used as source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the source.. (640, 480) framerate int/float sets the framerate of the source. 30 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Source Tweak Parameters. {} Source code in vidgear/gears/pigear.py def __init__ ( self , camera_num = 0 , resolution = ( 640 , 480 ), framerate = 30 , colorspace = None , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the PiGear class. Parameters: camera_num (int): selects the camera module index which will be used as source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the source.. framerate (int/float): sets the framerate of the source. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Source Tweak Parameters. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"picamera\" if picamera is None else \"\" , ) # enable logging if specified self . __logging = False if logging : self . __logging = logging assert ( isinstance ( framerate , ( int , float )) and framerate > 5.0 ), \"[PiGear:ERROR] :: Input framerate value ` {} ` is a Invalid! Kindly read docs.\" . format ( framerate ) assert ( isinstance ( resolution , ( tuple , list )) and len ( resolution ) == 2 ), \"[PiGear:ERROR] :: Input resolution value ` {} ` is a Invalid! Kindly read docs.\" . format ( resolution ) if not ( isinstance ( camera_num , int ) and camera_num >= 0 ): camera_num = 0 logger . warning ( \"Input camera_num value ` {} ` is invalid, Defaulting to index 0!\" ) # initialize the picamera stream at given index self . __camera = PiCamera ( camera_num = camera_num ) self . __camera . resolution = tuple ( resolution ) self . __camera . framerate = framerate self . __logging and logger . debug ( \"Activating Pi camera at index: {} with resolution: {} & framerate: {} \" . format ( camera_num , resolution , framerate ) ) # initialize framerate variable self . framerate = framerate # initializing colorspace variable self . color_space = None # reformat dict options = { str ( k ) . strip (): v for k , v in options . items ()} # define timeout variable default value(handles hardware failures) self . __failure_timeout = options . pop ( \"HWFAILURE_TIMEOUT\" , 2.0 ) if isinstance ( self . __failure_timeout , ( int , float )): if not ( 10.0 > self . __failure_timeout > 1.0 ): raise ValueError ( \"[PiGear:ERROR] :: `HWFAILURE_TIMEOUT` value can only be between 1.0 ~ 10.0\" ) self . __logging and logger . debug ( \"Setting HW Failure Timeout: {} seconds\" . format ( self . __failure_timeout ) ) else : # reset improper values self . __failure_timeout = 2.0 try : # apply attributes to source if specified for key , value in options . items (): self . __logging and logger . debug ( \"Setting Parameter: {} = ' {} '\" . format ( key , value ) ) setattr ( self . __camera , key , value ) except Exception as e : # Catch if any error occurred logger . exception ( str ( e )) # separately handle colorspace value to int conversion if not ( colorspace is None ): self . color_space = capPropId ( colorspace . strip ()) if self . __logging and not ( self . color_space is None ): logger . debug ( \"Enabling ` {} ` colorspace for this video stream!\" . format ( colorspace . strip () ) ) # enable rgb capture array thread and capture stream self . __rawCapture = PiRGBArray ( self . __camera , size = resolution ) self . stream = self . __camera . capture_continuous ( self . __rawCapture , format = \"bgr\" , use_video_port = True ) # frame variable initialization self . frame = None try : stream = next ( self . stream ) self . frame = stream . array self . __rawCapture . seek ( 0 ) self . __rawCapture . truncate () # render colorspace if defined if not ( self . frame is None ) and not ( self . color_space is None ): self . frame = cv2 . cvtColor ( self . frame , self . color_space ) except Exception as e : logger . exception ( str ( e )) raise RuntimeError ( \"[PiGear:ERROR] :: Camera Module failed to initialize!\" ) # applying time delay to warm-up picamera only if specified if time_delay and isinstance ( time_delay , ( int , float )): time . sleep ( time_delay ) # thread initialization self . __thread = None # timer thread initialization(Keeps check on frozen thread) self . __timer = None self . __t_elasped = 0.0 # records time taken by thread # catching thread exceptions self . __exceptions = None # initialize termination flag self . __terminate = False","title":"__init__()"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.read","text":"Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/pigear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" # check if there are any thread exceptions if not ( self . __exceptions is None ): if isinstance ( self . __exceptions , bool ): # clear frame self . frame = None # notify user about hardware failure raise SystemError ( \"[PiGear:ERROR] :: Hardware failure occurred, Kindly reconnect Camera Module and restart your Pi!\" ) else : # clear frame self . frame = None # re-raise error for debugging error_msg = ( \"[PiGear:ERROR] :: Camera Module API failure occured: {} \" . format ( self . __exceptions [ 1 ] ) ) raise RuntimeError ( error_msg ) . with_traceback ( self . __exceptions [ 2 ]) # return the frame return self . frame","title":"read()"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.start","text":"Launches the internal Threaded Frames Extractor daemon Returns: A reference to the CamGear class object. Source code in vidgear/gears/pigear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the CamGear class object. \"\"\" # Start frame producer thread self . __thread = Thread ( target = self . __update , name = \"PiGear\" , args = ()) self . __thread . daemon = True self . __thread . start () # Start internal timer thread self . __timer = Thread ( target = self . __timeit , name = \"PiTimer\" , args = ()) self . __timer . daemon = True self . __timer . start () return self","title":"start()"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.stop","text":"Safely terminates the thread, and release the VideoStream resources. Source code in vidgear/gears/pigear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the VideoStream resources. \"\"\" self . __logging and logger . debug ( \"Terminating PiGear Processes.\" ) # make sure that the threads should be terminated self . __terminate = True # stop timer thread if not ( self . __timer is None ): self . __timer . join () self . __timer = None # handle camera thread if not ( self . __thread is None ): # check if hardware failure occured if not ( self . __exceptions is None ) and isinstance ( self . __exceptions , bool ): # force release picamera resources self . __rawCapture . close () self . __camera . close () # properly handle thread exit self . __thread . join () # wait if still process is still processing some information # remove any threads self . __thread = None","title":"stop()"},{"location":"bonus/reference/screengear/","text":"ScreenGear API usage examples can be found here \u27b6 ScreenGear API parameters are explained here \u27b6 ScreenGear is designed exclusively for ultra-fast Screencasting, which means it can grab frames from your monitor in real-time, either by defining an area on the computer screen or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends. ScreenGear API implements a multi-threaded wrapper around pyscreenshot & python-mss python library, and also flexibly supports its internal parameter. Source code in vidgear/gears/screengear.py class ScreenGear : \"\"\" ScreenGear is designed exclusively for ultra-fast Screencasting, which means it can grab frames from your monitor in real-time, either by defining an area on the computer screen or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends. ScreenGear API implements a multi-threaded wrapper around pyscreenshot & python-mss python library, and also flexibly supports its internal parameter. \"\"\" def __init__ ( self , monitor = None , backend = \"\" , colorspace = None , logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the ScreenGear class. Parameters: monitor (int): enables `mss` backend and sets the index of the monitor screen. backend (str): enables `pyscreenshot` and select suitable backend for extracting frames. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. options (dict): provides the flexibility to manually set the dimensions of capture screen area. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"from mss import mss\" if mss is None else \"\" , pkg_name = \"mss\" ) import_dependency_safe ( \"pyscreenshot\" if pysct is None else \"\" ) # enable logging if specified: self . __logging = logging if isinstance ( logging , bool ) else False # create monitor instance for the user-defined monitor self . __monitor_instance = None self . __backend = \"\" if monitor is None : self . __capture_object = pysct self . __backend = backend . lower () . strip () else : self . __capture_object = mss () if backend . strip (): logger . warning ( \"Backends are disabled for Monitor Indexing(monitor>=0)!\" ) try : self . __monitor_instance = self . __capture_object . monitors [ monitor ] except Exception as e : logger . exception ( str ( e )) self . __monitor_instance = None # assigns special parameter to global variable and clear # Thread Timeout self . __thread_timeout = options . pop ( \"THREAD_TIMEOUT\" , None ) if self . __thread_timeout and isinstance ( self . __thread_timeout , ( int , float )): # set values self . __thread_timeout = float ( self . __thread_timeout ) else : # defaults to 5mins timeout self . __thread_timeout = None # define deque and assign it to global var self . __queue = queue . Queue ( maxsize = 96 ) # max bufferlen 96 to check overflow # log it if logging : logger . debug ( \"Enabling Threaded Queue Mode by default for ScreenGear!\" ) if self . __thread_timeout : logger . debug ( \"Setting Video-Thread Timeout to {} s.\" . format ( self . __thread_timeout ) ) # intiate screen dimension handler screen_dims = {} # reformat proper mss dict and assign to screen dimension handler screen_dims = { k . strip (): v for k , v in options . items () if k . strip () in [ \"top\" , \"left\" , \"width\" , \"height\" ] } # check whether user-defined dimensions are provided if screen_dims and len ( screen_dims ) == 4 : key_order = ( \"top\" , \"left\" , \"width\" , \"height\" ) screen_dims = OrderedDict (( k , screen_dims [ k ]) for k in key_order ) if logging : logger . debug ( \"Setting Capture-Area dimensions: {} !\" . format ( screen_dims )) else : screen_dims . clear () # separately handle colorspace value to int conversion if colorspace : self . color_space = capPropId ( colorspace . strip ()) if logging and not ( self . color_space is None ): logger . debug ( \"Enabling ` {} ` colorspace for this video stream!\" . format ( colorspace . strip () ) ) else : self . color_space = None # intialize mss capture instance self . __mss_capture_instance = \"\" try : if self . __monitor_instance is None : if screen_dims : self . __mss_capture_instance = tuple ( screen_dims . values ()) # extract global frame from instance self . frame = np . asanyarray ( self . __capture_object . grab ( bbox = self . __mss_capture_instance , childprocess = False , backend = self . __backend , ) ) else : if screen_dims : self . __mss_capture_instance = { \"top\" : self . __monitor_instance [ \"top\" ] + screen_dims [ \"top\" ], \"left\" : self . __monitor_instance [ \"left\" ] + screen_dims [ \"left\" ], \"width\" : screen_dims [ \"width\" ], \"height\" : screen_dims [ \"height\" ], \"mon\" : monitor , } else : self . __mss_capture_instance = ( self . __monitor_instance # otherwise create instance from monitor ) # extract global frame from instance self . frame = np . asanyarray ( self . __capture_object . grab ( self . __mss_capture_instance ) ) # initialize and append to queue self . __queue . put ( self . frame ) except Exception as e : if isinstance ( e , ScreenShotError ): # otherwise catch and log errors if logging : logger . exception ( self . __capture_object . get_error_details ()) raise ValueError ( \"[ScreenGear:ERROR] :: ScreenShotError caught, Wrong dimensions passed to python-mss, Kindly Refer Docs!\" ) elif isinstance ( e , KeyError ): raise ValueError ( \"[ScreenGear:ERROR] :: ScreenShotError caught, Invalid backend: ` {} `, Kindly Refer Docs!\" . format ( backend ) ) else : raise SystemError ( \"[ScreenGear:ERROR] :: Unable to grab any instance on this system, Are you running headless?\" ) # thread initialization self . __thread = None # initialize termination flag self . __terminate = Event () def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the ScreenGear class object. \"\"\" self . __thread = Thread ( target = self . __update , name = \"ScreenGear\" , args = ()) self . __thread . daemon = True self . __thread . start () return self def __update ( self ): \"\"\" A **Threaded Frames Extractor**, that keep iterating frames from `mss` API to a internal monitored deque, until the thread is terminated, or frames runs out. \"\"\" # intialize frame variable frame = None # keep looping infinitely until the thread is terminated while True : # if the thread indicator variable is set, stop the thread if self . __terminate . is_set (): break try : if self . __monitor_instance : frame = np . asanyarray ( self . __capture_object . grab ( self . __mss_capture_instance ) ) else : frame = np . asanyarray ( self . __capture_object . grab ( bbox = self . __mss_capture_instance , childprocess = False , backend = self . __backend , ) ) if not self . __backend or self . __backend == \"pil\" : frame = frame [:, :, :: - 1 ] assert not ( frame is None or np . shape ( frame ) == () ), \"[ScreenGear:ERROR] :: Failed to retreive any valid frames!\" except Exception as e : if isinstance ( e , ScreenShotError ): raise RuntimeError ( self . __capture_object . get_error_details ()) else : logger . exception ( str ( e )) self . __terminate . set () continue if not ( self . color_space is None ): # apply colorspace to frames color_frame = None try : if isinstance ( self . color_space , int ): color_frame = cv2 . cvtColor ( frame , self . color_space ) else : self . __logging and logger . warning ( \"Global color_space parameter value ` {} ` is not a valid!\" . format ( self . color_space ) ) self . color_space = None except Exception as e : # Catch if any error occurred self . color_space = None if self . __logging : logger . exception ( str ( e )) logger . warning ( \"Input colorspace is not a valid colorspace!\" ) if not ( color_frame is None ): self . frame = color_frame else : self . frame = frame else : self . frame = frame # append to queue self . __queue . put ( self . frame ) # finally release mss resources if self . __monitor_instance : self . __capture_object . close () def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" # check whether or not termination flag is enabled while not self . __terminate . is_set (): return self . __queue . get ( timeout = self . __thread_timeout ) # otherwise return NoneType return None def stop ( self ): \"\"\" Safely terminates the thread, and release the resources. \"\"\" self . __logging and logger . debug ( \"Terminating ScreenGear Processes.\" ) # indicate that the thread should be terminate self . __terminate . set () # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : if not ( self . __queue is None ): while not self . __queue . empty (): try : self . __queue . get_nowait () except queue . Empty : continue self . __queue . task_done () self . __thread . join () __init__ ( self , monitor = None , backend = '' , colorspace = None , logging = False , ** options ) special \u2693 This constructor method initializes the object state and attributes of the ScreenGear class. Parameters: Name Type Description Default monitor int enables mss backend and sets the index of the monitor screen. None backend str enables pyscreenshot and select suitable backend for extracting frames. '' colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False options dict provides the flexibility to manually set the dimensions of capture screen area. {} Source code in vidgear/gears/screengear.py def __init__ ( self , monitor = None , backend = \"\" , colorspace = None , logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the ScreenGear class. Parameters: monitor (int): enables `mss` backend and sets the index of the monitor screen. backend (str): enables `pyscreenshot` and select suitable backend for extracting frames. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. options (dict): provides the flexibility to manually set the dimensions of capture screen area. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"from mss import mss\" if mss is None else \"\" , pkg_name = \"mss\" ) import_dependency_safe ( \"pyscreenshot\" if pysct is None else \"\" ) # enable logging if specified: self . __logging = logging if isinstance ( logging , bool ) else False # create monitor instance for the user-defined monitor self . __monitor_instance = None self . __backend = \"\" if monitor is None : self . __capture_object = pysct self . __backend = backend . lower () . strip () else : self . __capture_object = mss () if backend . strip (): logger . warning ( \"Backends are disabled for Monitor Indexing(monitor>=0)!\" ) try : self . __monitor_instance = self . __capture_object . monitors [ monitor ] except Exception as e : logger . exception ( str ( e )) self . __monitor_instance = None # assigns special parameter to global variable and clear # Thread Timeout self . __thread_timeout = options . pop ( \"THREAD_TIMEOUT\" , None ) if self . __thread_timeout and isinstance ( self . __thread_timeout , ( int , float )): # set values self . __thread_timeout = float ( self . __thread_timeout ) else : # defaults to 5mins timeout self . __thread_timeout = None # define deque and assign it to global var self . __queue = queue . Queue ( maxsize = 96 ) # max bufferlen 96 to check overflow # log it if logging : logger . debug ( \"Enabling Threaded Queue Mode by default for ScreenGear!\" ) if self . __thread_timeout : logger . debug ( \"Setting Video-Thread Timeout to {} s.\" . format ( self . __thread_timeout ) ) # intiate screen dimension handler screen_dims = {} # reformat proper mss dict and assign to screen dimension handler screen_dims = { k . strip (): v for k , v in options . items () if k . strip () in [ \"top\" , \"left\" , \"width\" , \"height\" ] } # check whether user-defined dimensions are provided if screen_dims and len ( screen_dims ) == 4 : key_order = ( \"top\" , \"left\" , \"width\" , \"height\" ) screen_dims = OrderedDict (( k , screen_dims [ k ]) for k in key_order ) if logging : logger . debug ( \"Setting Capture-Area dimensions: {} !\" . format ( screen_dims )) else : screen_dims . clear () # separately handle colorspace value to int conversion if colorspace : self . color_space = capPropId ( colorspace . strip ()) if logging and not ( self . color_space is None ): logger . debug ( \"Enabling ` {} ` colorspace for this video stream!\" . format ( colorspace . strip () ) ) else : self . color_space = None # intialize mss capture instance self . __mss_capture_instance = \"\" try : if self . __monitor_instance is None : if screen_dims : self . __mss_capture_instance = tuple ( screen_dims . values ()) # extract global frame from instance self . frame = np . asanyarray ( self . __capture_object . grab ( bbox = self . __mss_capture_instance , childprocess = False , backend = self . __backend , ) ) else : if screen_dims : self . __mss_capture_instance = { \"top\" : self . __monitor_instance [ \"top\" ] + screen_dims [ \"top\" ], \"left\" : self . __monitor_instance [ \"left\" ] + screen_dims [ \"left\" ], \"width\" : screen_dims [ \"width\" ], \"height\" : screen_dims [ \"height\" ], \"mon\" : monitor , } else : self . __mss_capture_instance = ( self . __monitor_instance # otherwise create instance from monitor ) # extract global frame from instance self . frame = np . asanyarray ( self . __capture_object . grab ( self . __mss_capture_instance ) ) # initialize and append to queue self . __queue . put ( self . frame ) except Exception as e : if isinstance ( e , ScreenShotError ): # otherwise catch and log errors if logging : logger . exception ( self . __capture_object . get_error_details ()) raise ValueError ( \"[ScreenGear:ERROR] :: ScreenShotError caught, Wrong dimensions passed to python-mss, Kindly Refer Docs!\" ) elif isinstance ( e , KeyError ): raise ValueError ( \"[ScreenGear:ERROR] :: ScreenShotError caught, Invalid backend: ` {} `, Kindly Refer Docs!\" . format ( backend ) ) else : raise SystemError ( \"[ScreenGear:ERROR] :: Unable to grab any instance on this system, Are you running headless?\" ) # thread initialization self . __thread = None # initialize termination flag self . __terminate = Event () read ( self ) \u2693 Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/screengear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" # check whether or not termination flag is enabled while not self . __terminate . is_set (): return self . __queue . get ( timeout = self . __thread_timeout ) # otherwise return NoneType return None start ( self ) \u2693 Launches the internal Threaded Frames Extractor daemon Returns: A reference to the ScreenGear class object. Source code in vidgear/gears/screengear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the ScreenGear class object. \"\"\" self . __thread = Thread ( target = self . __update , name = \"ScreenGear\" , args = ()) self . __thread . daemon = True self . __thread . start () return self stop ( self ) \u2693 Safely terminates the thread, and release the resources. Source code in vidgear/gears/screengear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the resources. \"\"\" self . __logging and logger . debug ( \"Terminating ScreenGear Processes.\" ) # indicate that the thread should be terminate self . __terminate . set () # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : if not ( self . __queue is None ): while not self . __queue . empty (): try : self . __queue . get_nowait () except queue . Empty : continue self . __queue . task_done () self . __thread . join ()","title":"ScreenGear API"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.__init__","text":"This constructor method initializes the object state and attributes of the ScreenGear class. Parameters: Name Type Description Default monitor int enables mss backend and sets the index of the monitor screen. None backend str enables pyscreenshot and select suitable backend for extracting frames. '' colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False options dict provides the flexibility to manually set the dimensions of capture screen area. {} Source code in vidgear/gears/screengear.py def __init__ ( self , monitor = None , backend = \"\" , colorspace = None , logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the ScreenGear class. Parameters: monitor (int): enables `mss` backend and sets the index of the monitor screen. backend (str): enables `pyscreenshot` and select suitable backend for extracting frames. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. options (dict): provides the flexibility to manually set the dimensions of capture screen area. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"from mss import mss\" if mss is None else \"\" , pkg_name = \"mss\" ) import_dependency_safe ( \"pyscreenshot\" if pysct is None else \"\" ) # enable logging if specified: self . __logging = logging if isinstance ( logging , bool ) else False # create monitor instance for the user-defined monitor self . __monitor_instance = None self . __backend = \"\" if monitor is None : self . __capture_object = pysct self . __backend = backend . lower () . strip () else : self . __capture_object = mss () if backend . strip (): logger . warning ( \"Backends are disabled for Monitor Indexing(monitor>=0)!\" ) try : self . __monitor_instance = self . __capture_object . monitors [ monitor ] except Exception as e : logger . exception ( str ( e )) self . __monitor_instance = None # assigns special parameter to global variable and clear # Thread Timeout self . __thread_timeout = options . pop ( \"THREAD_TIMEOUT\" , None ) if self . __thread_timeout and isinstance ( self . __thread_timeout , ( int , float )): # set values self . __thread_timeout = float ( self . __thread_timeout ) else : # defaults to 5mins timeout self . __thread_timeout = None # define deque and assign it to global var self . __queue = queue . Queue ( maxsize = 96 ) # max bufferlen 96 to check overflow # log it if logging : logger . debug ( \"Enabling Threaded Queue Mode by default for ScreenGear!\" ) if self . __thread_timeout : logger . debug ( \"Setting Video-Thread Timeout to {} s.\" . format ( self . __thread_timeout ) ) # intiate screen dimension handler screen_dims = {} # reformat proper mss dict and assign to screen dimension handler screen_dims = { k . strip (): v for k , v in options . items () if k . strip () in [ \"top\" , \"left\" , \"width\" , \"height\" ] } # check whether user-defined dimensions are provided if screen_dims and len ( screen_dims ) == 4 : key_order = ( \"top\" , \"left\" , \"width\" , \"height\" ) screen_dims = OrderedDict (( k , screen_dims [ k ]) for k in key_order ) if logging : logger . debug ( \"Setting Capture-Area dimensions: {} !\" . format ( screen_dims )) else : screen_dims . clear () # separately handle colorspace value to int conversion if colorspace : self . color_space = capPropId ( colorspace . strip ()) if logging and not ( self . color_space is None ): logger . debug ( \"Enabling ` {} ` colorspace for this video stream!\" . format ( colorspace . strip () ) ) else : self . color_space = None # intialize mss capture instance self . __mss_capture_instance = \"\" try : if self . __monitor_instance is None : if screen_dims : self . __mss_capture_instance = tuple ( screen_dims . values ()) # extract global frame from instance self . frame = np . asanyarray ( self . __capture_object . grab ( bbox = self . __mss_capture_instance , childprocess = False , backend = self . __backend , ) ) else : if screen_dims : self . __mss_capture_instance = { \"top\" : self . __monitor_instance [ \"top\" ] + screen_dims [ \"top\" ], \"left\" : self . __monitor_instance [ \"left\" ] + screen_dims [ \"left\" ], \"width\" : screen_dims [ \"width\" ], \"height\" : screen_dims [ \"height\" ], \"mon\" : monitor , } else : self . __mss_capture_instance = ( self . __monitor_instance # otherwise create instance from monitor ) # extract global frame from instance self . frame = np . asanyarray ( self . __capture_object . grab ( self . __mss_capture_instance ) ) # initialize and append to queue self . __queue . put ( self . frame ) except Exception as e : if isinstance ( e , ScreenShotError ): # otherwise catch and log errors if logging : logger . exception ( self . __capture_object . get_error_details ()) raise ValueError ( \"[ScreenGear:ERROR] :: ScreenShotError caught, Wrong dimensions passed to python-mss, Kindly Refer Docs!\" ) elif isinstance ( e , KeyError ): raise ValueError ( \"[ScreenGear:ERROR] :: ScreenShotError caught, Invalid backend: ` {} `, Kindly Refer Docs!\" . format ( backend ) ) else : raise SystemError ( \"[ScreenGear:ERROR] :: Unable to grab any instance on this system, Are you running headless?\" ) # thread initialization self . __thread = None # initialize termination flag self . __terminate = Event ()","title":"__init__()"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.read","text":"Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/screengear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" # check whether or not termination flag is enabled while not self . __terminate . is_set (): return self . __queue . get ( timeout = self . __thread_timeout ) # otherwise return NoneType return None","title":"read()"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.start","text":"Launches the internal Threaded Frames Extractor daemon Returns: A reference to the ScreenGear class object. Source code in vidgear/gears/screengear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the ScreenGear class object. \"\"\" self . __thread = Thread ( target = self . __update , name = \"ScreenGear\" , args = ()) self . __thread . daemon = True self . __thread . start () return self","title":"start()"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.stop","text":"Safely terminates the thread, and release the resources. Source code in vidgear/gears/screengear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the resources. \"\"\" self . __logging and logger . debug ( \"Terminating ScreenGear Processes.\" ) # indicate that the thread should be terminate self . __terminate . set () # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : if not ( self . __queue is None ): while not self . __queue . empty (): try : self . __queue . get_nowait () except queue . Empty : continue self . __queue . task_done () self . __thread . join ()","title":"stop()"},{"location":"bonus/reference/stabilizer/","text":"Stabilizer API usage examples can be found here \u27b6 Stabilizer API parameters are explained here \u27b6 This is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies heavily on Threaded Queue mode for error-free & ultra-fast frame handling. Source code in vidgear/gears/stabilizer.py class Stabilizer : \"\"\" This is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies heavily on **Threaded Queue mode** for error-free & ultra-fast frame handling. \"\"\" def __init__ ( self , smoothing_radius = 25 , border_type = \"black\" , border_size = 0 , crop_n_zoom = False , logging = False , ): \"\"\" This constructor method initializes the object state and attributes of the Stabilizer class. Parameters: smoothing_radius (int): alter averaging window size. border_type (str): changes the extended border type. border_size (int): enables and set the value for extended border size to reduce the black borders. crop_n_zoom (bool): enables croping and zooming of frames(to original size) to reduce the black borders. logging (bool): enables/disables logging. \"\"\" # initialize deques for handling input frames and its indexes self . __frame_queue = deque ( maxlen = smoothing_radius ) self . __frame_queue_indexes = deque ( maxlen = smoothing_radius ) # enable logging if specified self . __logging = False if logging : self . __logging = logging # define and create Adaptive histogram equalization (AHE) object for optimizations self . __clahe = cv2 . createCLAHE ( clipLimit = 2.0 , tileGridSize = ( 8 , 8 )) # initialize global vars self . __smoothing_radius = smoothing_radius # averaging window, handles the quality of stabilization at expense of latency and sudden panning self . __smoothed_path = None # handles the smoothed path with box filter self . __path = None # handles path i.e cumulative sum of pevious_2_current transformations along a axis self . __transforms = [] # handles pevious_2_current transformations [dx,dy,da] self . __frame_transforms_smoothed = None # handles smoothed array of pevious_2_current transformations w.r.t to frames self . __previous_gray = None # handles previous gray frame self . __previous_keypoints = ( None # handles previous detect_GFTTed keypoints w.r.t previous gray frame ) self . __frame_height , self . frame_width = ( 0 , 0 , ) # handles width and height of input frames self . __crop_n_zoom = 0 # handles cropping and zooms frames to reduce the black borders from stabilization being too noticeable. # if check if crop_n_zoom defined if crop_n_zoom and border_size : self . __crop_n_zoom = border_size # crops and zoom frame to original size self . __border_size = 0 # zero out border size self . __frame_size = None # handles frame size for zooming if logging : logger . debug ( \"Setting Cropping margin {} pixels\" . format ( border_size )) else : # Add output borders to frame self . __border_size = border_size if self . __logging and border_size : logger . debug ( \"Setting Border size {} pixels\" . format ( border_size )) # define valid border modes border_modes = { \"black\" : cv2 . BORDER_CONSTANT , \"reflect\" : cv2 . BORDER_REFLECT , \"reflect_101\" : cv2 . BORDER_REFLECT_101 , \"replicate\" : cv2 . BORDER_REPLICATE , \"wrap\" : cv2 . BORDER_WRAP , } # choose valid border_mode from border_type if border_type in [ \"black\" , \"reflect\" , \"reflect_101\" , \"replicate\" , \"wrap\" ]: if not crop_n_zoom : # initialize global border mode variable self . __border_mode = border_modes [ border_type ] if self . __logging and border_type != \"black\" : logger . debug ( \"Setting Border type: {} \" . format ( border_type )) else : # log and reset to default if self . __logging and border_type != \"black\" : logger . debug ( \"Setting border type is disabled if cropping is enabled!\" ) self . __border_mode = border_modes [ \"black\" ] else : # otherwise log if not if logging : logger . debug ( \"Invalid input border type!\" ) self . __border_mode = border_modes [ \"black\" ] # reset to default mode # define OpenCV version self . __cv2_version = check_CV_version () # retrieve best interpolation self . __interpolation = retrieve_best_interpolation ( [ \"INTER_LINEAR_EXACT\" , \"INTER_LINEAR\" , \"INTER_AREA\" ] ) # define normalized box filter self . __box_filter = np . ones ( smoothing_radius ) / smoothing_radius def stabilize ( self , frame ): \"\"\" This method takes an unstabilized video frame, and returns a stabilized one. Parameters: frame (numpy.ndarray): inputs unstabilized video frames. \"\"\" # check if frame is None if frame is None : # return if it does return # save frame size for zooming if self . __crop_n_zoom and self . __frame_size == None : self . __frame_size = frame . shape [: 2 ] # initiate transformations capturing if not self . __frame_queue : # for first frame previous_gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # convert to gray previous_gray = self . __clahe . apply ( previous_gray ) # optimize gray frame self . __previous_keypoints = cv2 . goodFeaturesToTrack ( previous_gray , maxCorners = 200 , qualityLevel = 0.05 , minDistance = 30.0 , blockSize = 3 , mask = None , useHarrisDetector = False , k = 0.04 , ) # track features using GFTT self . __frame_height , self . frame_width = frame . shape [ : 2 ] # save input frame height and width self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( 0 ) # save frame index to deque self . __previous_gray = previous_gray [ : ] # save gray frame clone for further processing elif self . __frame_queue_indexes [ - 1 ] <= self . __smoothing_radius - 1 : # for rest of frames self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( self . __frame_queue_indexes [ - 1 ] + 1 ) # save frame index self . __generate_transformations () # generate transformations if self . __frame_queue_indexes [ - 1 ] == self . __smoothing_radius - 1 : # calculate smooth path once transformation capturing is completed for i in range ( 3 ): # apply normalized box filter to the path self . __smoothed_path [:, i ] = self . __box_filter_convolve ( ( self . __path [:, i ]), window_size = self . __smoothing_radius ) # calculate deviation of path from smoothed path deviation = self . __smoothed_path - self . __path # save smoothed transformation self . __frame_transforms_smoothed = self . frame_transform + deviation else : # start applying transformations self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( self . __frame_queue_indexes [ - 1 ] + 1 ) # save frame index self . __generate_transformations () # generate transformations # calculate smooth path once transformation capturing is completed for i in range ( 3 ): # apply normalized box filter to the path self . __smoothed_path [:, i ] = self . __box_filter_convolve ( ( self . __path [:, i ]), window_size = self . __smoothing_radius ) # calculate deviation of path from smoothed path deviation = self . __smoothed_path - self . __path # save smoothed transformation self . __frame_transforms_smoothed = self . frame_transform + deviation # return transformation applied stabilized frame return self . __apply_transformations () def __generate_transformations ( self ): \"\"\" An internal method that generate previous-to-current transformations [dx,dy,da]. \"\"\" frame_gray = cv2 . cvtColor ( self . __frame_queue [ - 1 ], cv2 . COLOR_BGR2GRAY ) # retrieve current frame and convert to gray frame_gray = self . __clahe . apply ( frame_gray ) # optimize it transformation = None try : # calculate optical flow using Lucas-Kanade differential method curr_kps , status , error = cv2 . calcOpticalFlowPyrLK ( self . __previous_gray , frame_gray , self . __previous_keypoints , None ) # select only valid key-points valid_curr_kps = curr_kps [ status == 1 ] # current valid_previous_keypoints = self . __previous_keypoints [ status == 1 ] # previous # calculate optimal affine transformation between pevious_2_current key-points if self . __cv2_version == 3 : # backward compatibility with OpenCV3 transformation = cv2 . estimateRigidTransform ( valid_previous_keypoints , valid_curr_kps , False ) else : transformation = cv2 . estimateAffinePartial2D ( valid_previous_keypoints , valid_curr_kps )[ 0 ] except cv2 . error as e : # catch any OpenCV assertion errors and warn user logger . warning ( \"Video-Frame is too dark to generate any transformations!\" ) transformation = None # check if transformation is not None if not ( transformation is None ): # pevious_2_current translation in x direction dx = transformation [ 0 , 2 ] # pevious_2_current translation in y direction dy = transformation [ 1 , 2 ] # pevious_2_current rotation in angle da = np . arctan2 ( transformation [ 1 , 0 ], transformation [ 0 , 0 ]) else : # otherwise zero it dx = dy = da = 0 # save this transformation self . __transforms . append ([ dx , dy , da ]) # calculate path from cumulative transformations sum self . frame_transform = np . array ( self . __transforms , dtype = \"float32\" ) self . __path = np . cumsum ( self . frame_transform , axis = 0 ) # create smoothed path from a copy of path self . __smoothed_path = np . copy ( self . __path ) # re-calculate and save GFTT key-points for current gray frame self . __previous_keypoints = cv2 . goodFeaturesToTrack ( frame_gray , maxCorners = 200 , qualityLevel = 0.05 , minDistance = 30.0 , blockSize = 3 , mask = None , useHarrisDetector = False , k = 0.04 , ) # save this gray frame for further processing self . __previous_gray = frame_gray [:] def __box_filter_convolve ( self , path , window_size ): \"\"\" An internal method that applies *normalized linear box filter* to path w.r.t averaging window Parameters: * path (numpy.ndarray): a cumulative sum of transformations * window_size (int): averaging window size \"\"\" # pad path to size of averaging window path_padded = np . pad ( path , ( window_size , window_size ), \"median\" ) # apply linear box filter to path path_smoothed = np . convolve ( path_padded , self . __box_filter , mode = \"same\" ) # crop the smoothed path to original path path_smoothed = path_smoothed [ window_size : - window_size ] # assert if cropping is completed assert path . shape == path_smoothed . shape # return smoothed path return path_smoothed def __apply_transformations ( self ): \"\"\" An internal method that applies affine transformation to the given frame from previously calculated transformations \"\"\" # extract frame and its index from deque queue_frame = self . __frame_queue . popleft () queue_frame_index = self . __frame_queue_indexes . popleft () # create border around extracted frame w.r.t border_size bordered_frame = cv2 . copyMakeBorder ( queue_frame , top = self . __border_size , bottom = self . __border_size , left = self . __border_size , right = self . __border_size , borderType = self . __border_mode , value = [ 0 , 0 , 0 ], ) alpha_bordered_frame = cv2 . cvtColor ( bordered_frame , cv2 . COLOR_BGR2BGRA ) # create alpha channel # extract alpha channel alpha_bordered_frame [:, :, 3 ] = 0 alpha_bordered_frame [ self . __border_size : self . __border_size + self . __frame_height , self . __border_size : self . __border_size + self . frame_width , 3 , ] = 255 # extracting Transformations w.r.t frame index dx = self . __frame_transforms_smoothed [ queue_frame_index , 0 ] # x-axis dy = self . __frame_transforms_smoothed [ queue_frame_index , 1 ] # y-axis da = self . __frame_transforms_smoothed [ queue_frame_index , 2 ] # angle # building 2x3 transformation matrix from extracted transformations queue_frame_transform = np . zeros (( 2 , 3 ), np . float32 ) queue_frame_transform [ 0 , 0 ] = np . cos ( da ) queue_frame_transform [ 0 , 1 ] = - np . sin ( da ) queue_frame_transform [ 1 , 0 ] = np . sin ( da ) queue_frame_transform [ 1 , 1 ] = np . cos ( da ) queue_frame_transform [ 0 , 2 ] = dx queue_frame_transform [ 1 , 2 ] = dy # Applying an affine transformation to the frame frame_wrapped = cv2 . warpAffine ( alpha_bordered_frame , queue_frame_transform , alpha_bordered_frame . shape [: 2 ][:: - 1 ], borderMode = self . __border_mode , ) # drop alpha channel frame_stabilized = frame_wrapped [:, :, : 3 ] # crop and zoom if self . __crop_n_zoom : # crop stabilized frame frame_cropped = frame_stabilized [ self . __crop_n_zoom : - self . __crop_n_zoom , self . __crop_n_zoom : - self . __crop_n_zoom , ] # zoom stabilized frame frame_stabilized = cv2 . resize ( frame_cropped , self . __frame_size [:: - 1 ], interpolation = self . __interpolation , ) # finally return stabilized frame return frame_stabilized def clean ( self ): \"\"\" Cleans Stabilizer resources \"\"\" # check if deque present if self . __frame_queue : # clear frame deque self . __frame_queue . clear () # clear frame indexes deque self . __frame_queue_indexes . clear () __init__ ( self , smoothing_radius = 25 , border_type = 'black' , border_size = 0 , crop_n_zoom = False , logging = False ) special \u2693 This constructor method initializes the object state and attributes of the Stabilizer class. Parameters: Name Type Description Default smoothing_radius int alter averaging window size. 25 border_type str changes the extended border type. 'black' border_size int enables and set the value for extended border size to reduce the black borders. 0 crop_n_zoom bool enables croping and zooming of frames(to original size) to reduce the black borders. False logging bool enables/disables logging. False Source code in vidgear/gears/stabilizer.py def __init__ ( self , smoothing_radius = 25 , border_type = \"black\" , border_size = 0 , crop_n_zoom = False , logging = False , ): \"\"\" This constructor method initializes the object state and attributes of the Stabilizer class. Parameters: smoothing_radius (int): alter averaging window size. border_type (str): changes the extended border type. border_size (int): enables and set the value for extended border size to reduce the black borders. crop_n_zoom (bool): enables croping and zooming of frames(to original size) to reduce the black borders. logging (bool): enables/disables logging. \"\"\" # initialize deques for handling input frames and its indexes self . __frame_queue = deque ( maxlen = smoothing_radius ) self . __frame_queue_indexes = deque ( maxlen = smoothing_radius ) # enable logging if specified self . __logging = False if logging : self . __logging = logging # define and create Adaptive histogram equalization (AHE) object for optimizations self . __clahe = cv2 . createCLAHE ( clipLimit = 2.0 , tileGridSize = ( 8 , 8 )) # initialize global vars self . __smoothing_radius = smoothing_radius # averaging window, handles the quality of stabilization at expense of latency and sudden panning self . __smoothed_path = None # handles the smoothed path with box filter self . __path = None # handles path i.e cumulative sum of pevious_2_current transformations along a axis self . __transforms = [] # handles pevious_2_current transformations [dx,dy,da] self . __frame_transforms_smoothed = None # handles smoothed array of pevious_2_current transformations w.r.t to frames self . __previous_gray = None # handles previous gray frame self . __previous_keypoints = ( None # handles previous detect_GFTTed keypoints w.r.t previous gray frame ) self . __frame_height , self . frame_width = ( 0 , 0 , ) # handles width and height of input frames self . __crop_n_zoom = 0 # handles cropping and zooms frames to reduce the black borders from stabilization being too noticeable. # if check if crop_n_zoom defined if crop_n_zoom and border_size : self . __crop_n_zoom = border_size # crops and zoom frame to original size self . __border_size = 0 # zero out border size self . __frame_size = None # handles frame size for zooming if logging : logger . debug ( \"Setting Cropping margin {} pixels\" . format ( border_size )) else : # Add output borders to frame self . __border_size = border_size if self . __logging and border_size : logger . debug ( \"Setting Border size {} pixels\" . format ( border_size )) # define valid border modes border_modes = { \"black\" : cv2 . BORDER_CONSTANT , \"reflect\" : cv2 . BORDER_REFLECT , \"reflect_101\" : cv2 . BORDER_REFLECT_101 , \"replicate\" : cv2 . BORDER_REPLICATE , \"wrap\" : cv2 . BORDER_WRAP , } # choose valid border_mode from border_type if border_type in [ \"black\" , \"reflect\" , \"reflect_101\" , \"replicate\" , \"wrap\" ]: if not crop_n_zoom : # initialize global border mode variable self . __border_mode = border_modes [ border_type ] if self . __logging and border_type != \"black\" : logger . debug ( \"Setting Border type: {} \" . format ( border_type )) else : # log and reset to default if self . __logging and border_type != \"black\" : logger . debug ( \"Setting border type is disabled if cropping is enabled!\" ) self . __border_mode = border_modes [ \"black\" ] else : # otherwise log if not if logging : logger . debug ( \"Invalid input border type!\" ) self . __border_mode = border_modes [ \"black\" ] # reset to default mode # define OpenCV version self . __cv2_version = check_CV_version () # retrieve best interpolation self . __interpolation = retrieve_best_interpolation ( [ \"INTER_LINEAR_EXACT\" , \"INTER_LINEAR\" , \"INTER_AREA\" ] ) # define normalized box filter self . __box_filter = np . ones ( smoothing_radius ) / smoothing_radius clean ( self ) \u2693 Cleans Stabilizer resources Source code in vidgear/gears/stabilizer.py def clean ( self ): \"\"\" Cleans Stabilizer resources \"\"\" # check if deque present if self . __frame_queue : # clear frame deque self . __frame_queue . clear () # clear frame indexes deque self . __frame_queue_indexes . clear () stabilize ( self , frame ) \u2693 This method takes an unstabilized video frame, and returns a stabilized one. Parameters: Name Type Description Default frame numpy.ndarray inputs unstabilized video frames. required Source code in vidgear/gears/stabilizer.py def stabilize ( self , frame ): \"\"\" This method takes an unstabilized video frame, and returns a stabilized one. Parameters: frame (numpy.ndarray): inputs unstabilized video frames. \"\"\" # check if frame is None if frame is None : # return if it does return # save frame size for zooming if self . __crop_n_zoom and self . __frame_size == None : self . __frame_size = frame . shape [: 2 ] # initiate transformations capturing if not self . __frame_queue : # for first frame previous_gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # convert to gray previous_gray = self . __clahe . apply ( previous_gray ) # optimize gray frame self . __previous_keypoints = cv2 . goodFeaturesToTrack ( previous_gray , maxCorners = 200 , qualityLevel = 0.05 , minDistance = 30.0 , blockSize = 3 , mask = None , useHarrisDetector = False , k = 0.04 , ) # track features using GFTT self . __frame_height , self . frame_width = frame . shape [ : 2 ] # save input frame height and width self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( 0 ) # save frame index to deque self . __previous_gray = previous_gray [ : ] # save gray frame clone for further processing elif self . __frame_queue_indexes [ - 1 ] <= self . __smoothing_radius - 1 : # for rest of frames self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( self . __frame_queue_indexes [ - 1 ] + 1 ) # save frame index self . __generate_transformations () # generate transformations if self . __frame_queue_indexes [ - 1 ] == self . __smoothing_radius - 1 : # calculate smooth path once transformation capturing is completed for i in range ( 3 ): # apply normalized box filter to the path self . __smoothed_path [:, i ] = self . __box_filter_convolve ( ( self . __path [:, i ]), window_size = self . __smoothing_radius ) # calculate deviation of path from smoothed path deviation = self . __smoothed_path - self . __path # save smoothed transformation self . __frame_transforms_smoothed = self . frame_transform + deviation else : # start applying transformations self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( self . __frame_queue_indexes [ - 1 ] + 1 ) # save frame index self . __generate_transformations () # generate transformations # calculate smooth path once transformation capturing is completed for i in range ( 3 ): # apply normalized box filter to the path self . __smoothed_path [:, i ] = self . __box_filter_convolve ( ( self . __path [:, i ]), window_size = self . __smoothing_radius ) # calculate deviation of path from smoothed path deviation = self . __smoothed_path - self . __path # save smoothed transformation self . __frame_transforms_smoothed = self . frame_transform + deviation # return transformation applied stabilized frame return self . __apply_transformations ()","title":"Stabilizer Class"},{"location":"bonus/reference/stabilizer/#vidgear.gears.stabilizer.Stabilizer.__init__","text":"This constructor method initializes the object state and attributes of the Stabilizer class. Parameters: Name Type Description Default smoothing_radius int alter averaging window size. 25 border_type str changes the extended border type. 'black' border_size int enables and set the value for extended border size to reduce the black borders. 0 crop_n_zoom bool enables croping and zooming of frames(to original size) to reduce the black borders. False logging bool enables/disables logging. False Source code in vidgear/gears/stabilizer.py def __init__ ( self , smoothing_radius = 25 , border_type = \"black\" , border_size = 0 , crop_n_zoom = False , logging = False , ): \"\"\" This constructor method initializes the object state and attributes of the Stabilizer class. Parameters: smoothing_radius (int): alter averaging window size. border_type (str): changes the extended border type. border_size (int): enables and set the value for extended border size to reduce the black borders. crop_n_zoom (bool): enables croping and zooming of frames(to original size) to reduce the black borders. logging (bool): enables/disables logging. \"\"\" # initialize deques for handling input frames and its indexes self . __frame_queue = deque ( maxlen = smoothing_radius ) self . __frame_queue_indexes = deque ( maxlen = smoothing_radius ) # enable logging if specified self . __logging = False if logging : self . __logging = logging # define and create Adaptive histogram equalization (AHE) object for optimizations self . __clahe = cv2 . createCLAHE ( clipLimit = 2.0 , tileGridSize = ( 8 , 8 )) # initialize global vars self . __smoothing_radius = smoothing_radius # averaging window, handles the quality of stabilization at expense of latency and sudden panning self . __smoothed_path = None # handles the smoothed path with box filter self . __path = None # handles path i.e cumulative sum of pevious_2_current transformations along a axis self . __transforms = [] # handles pevious_2_current transformations [dx,dy,da] self . __frame_transforms_smoothed = None # handles smoothed array of pevious_2_current transformations w.r.t to frames self . __previous_gray = None # handles previous gray frame self . __previous_keypoints = ( None # handles previous detect_GFTTed keypoints w.r.t previous gray frame ) self . __frame_height , self . frame_width = ( 0 , 0 , ) # handles width and height of input frames self . __crop_n_zoom = 0 # handles cropping and zooms frames to reduce the black borders from stabilization being too noticeable. # if check if crop_n_zoom defined if crop_n_zoom and border_size : self . __crop_n_zoom = border_size # crops and zoom frame to original size self . __border_size = 0 # zero out border size self . __frame_size = None # handles frame size for zooming if logging : logger . debug ( \"Setting Cropping margin {} pixels\" . format ( border_size )) else : # Add output borders to frame self . __border_size = border_size if self . __logging and border_size : logger . debug ( \"Setting Border size {} pixels\" . format ( border_size )) # define valid border modes border_modes = { \"black\" : cv2 . BORDER_CONSTANT , \"reflect\" : cv2 . BORDER_REFLECT , \"reflect_101\" : cv2 . BORDER_REFLECT_101 , \"replicate\" : cv2 . BORDER_REPLICATE , \"wrap\" : cv2 . BORDER_WRAP , } # choose valid border_mode from border_type if border_type in [ \"black\" , \"reflect\" , \"reflect_101\" , \"replicate\" , \"wrap\" ]: if not crop_n_zoom : # initialize global border mode variable self . __border_mode = border_modes [ border_type ] if self . __logging and border_type != \"black\" : logger . debug ( \"Setting Border type: {} \" . format ( border_type )) else : # log and reset to default if self . __logging and border_type != \"black\" : logger . debug ( \"Setting border type is disabled if cropping is enabled!\" ) self . __border_mode = border_modes [ \"black\" ] else : # otherwise log if not if logging : logger . debug ( \"Invalid input border type!\" ) self . __border_mode = border_modes [ \"black\" ] # reset to default mode # define OpenCV version self . __cv2_version = check_CV_version () # retrieve best interpolation self . __interpolation = retrieve_best_interpolation ( [ \"INTER_LINEAR_EXACT\" , \"INTER_LINEAR\" , \"INTER_AREA\" ] ) # define normalized box filter self . __box_filter = np . ones ( smoothing_radius ) / smoothing_radius","title":"__init__()"},{"location":"bonus/reference/stabilizer/#vidgear.gears.stabilizer.Stabilizer.clean","text":"Cleans Stabilizer resources Source code in vidgear/gears/stabilizer.py def clean ( self ): \"\"\" Cleans Stabilizer resources \"\"\" # check if deque present if self . __frame_queue : # clear frame deque self . __frame_queue . clear () # clear frame indexes deque self . __frame_queue_indexes . clear ()","title":"clean()"},{"location":"bonus/reference/stabilizer/#vidgear.gears.stabilizer.Stabilizer.stabilize","text":"This method takes an unstabilized video frame, and returns a stabilized one. Parameters: Name Type Description Default frame numpy.ndarray inputs unstabilized video frames. required Source code in vidgear/gears/stabilizer.py def stabilize ( self , frame ): \"\"\" This method takes an unstabilized video frame, and returns a stabilized one. Parameters: frame (numpy.ndarray): inputs unstabilized video frames. \"\"\" # check if frame is None if frame is None : # return if it does return # save frame size for zooming if self . __crop_n_zoom and self . __frame_size == None : self . __frame_size = frame . shape [: 2 ] # initiate transformations capturing if not self . __frame_queue : # for first frame previous_gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # convert to gray previous_gray = self . __clahe . apply ( previous_gray ) # optimize gray frame self . __previous_keypoints = cv2 . goodFeaturesToTrack ( previous_gray , maxCorners = 200 , qualityLevel = 0.05 , minDistance = 30.0 , blockSize = 3 , mask = None , useHarrisDetector = False , k = 0.04 , ) # track features using GFTT self . __frame_height , self . frame_width = frame . shape [ : 2 ] # save input frame height and width self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( 0 ) # save frame index to deque self . __previous_gray = previous_gray [ : ] # save gray frame clone for further processing elif self . __frame_queue_indexes [ - 1 ] <= self . __smoothing_radius - 1 : # for rest of frames self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( self . __frame_queue_indexes [ - 1 ] + 1 ) # save frame index self . __generate_transformations () # generate transformations if self . __frame_queue_indexes [ - 1 ] == self . __smoothing_radius - 1 : # calculate smooth path once transformation capturing is completed for i in range ( 3 ): # apply normalized box filter to the path self . __smoothed_path [:, i ] = self . __box_filter_convolve ( ( self . __path [:, i ]), window_size = self . __smoothing_radius ) # calculate deviation of path from smoothed path deviation = self . __smoothed_path - self . __path # save smoothed transformation self . __frame_transforms_smoothed = self . frame_transform + deviation else : # start applying transformations self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( self . __frame_queue_indexes [ - 1 ] + 1 ) # save frame index self . __generate_transformations () # generate transformations # calculate smooth path once transformation capturing is completed for i in range ( 3 ): # apply normalized box filter to the path self . __smoothed_path [:, i ] = self . __box_filter_convolve ( ( self . __path [:, i ]), window_size = self . __smoothing_radius ) # calculate deviation of path from smoothed path deviation = self . __smoothed_path - self . __path # save smoothed transformation self . __frame_transforms_smoothed = self . frame_transform + deviation # return transformation applied stabilized frame return self . __apply_transformations ()","title":"stabilize()"},{"location":"bonus/reference/streamgear/","text":"StreamGear API usage examples for: Single-Source Mode \u27b6 and Real-time Frames Mode \u27b6 StreamGear API parameters are explained here \u27b6 StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats (such as MPEG-DASH and HLS) in just few lines of python code. StreamGear provides a standalone, highly extensible, and flexible wrapper around FFmpeg multimedia framework for generating chunked-encoded media segments of the content. SteamGear easily transcodes source videos/audio files & real-time video-frames and breaks them into a sequence of multiple smaller chunks/segments of suitable length. These segments make it possible to stream videos at different quality levels (different bitrates or spatial resolutions) and can be switched in the middle of a video from one quality level to another \u2013 if bandwidth permits \u2013 on a per-segment basis. A user can serve these segments on a web server that makes it easier to download them through HTTP standard-compliant GET requests. SteamGear also creates a Manifest/Playlist file (such as MPD in-case of DASH and M3U8 in-case of HLS) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and bit rates) and is provided to the client before the streaming session. SteamGear currently supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) and Apple HLS (HTTP live streaming). Source code in vidgear/gears/streamgear.py class StreamGear : \"\"\" StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats (such as MPEG-DASH and HLS) in just few lines of python code. StreamGear provides a standalone, highly extensible, and flexible wrapper around FFmpeg multimedia framework for generating chunked-encoded media segments of the content. SteamGear easily transcodes source videos/audio files & real-time video-frames and breaks them into a sequence of multiple smaller chunks/segments of suitable length. These segments make it possible to stream videos at different quality levels (different bitrates or spatial resolutions) and can be switched in the middle of a video from one quality level to another \u2013 if bandwidth permits \u2013 on a per-segment basis. A user can serve these segments on a web server that makes it easier to download them through HTTP standard-compliant GET requests. SteamGear also creates a Manifest/Playlist file (such as MPD in-case of DASH and M3U8 in-case of HLS) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and bit rates) and is provided to the client before the streaming session. SteamGear currently supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) and Apple HLS (HTTP live streaming). \"\"\" def __init__ ( self , output = \"\" , format = \"dash\" , custom_ffmpeg = \"\" , logging = False , ** stream_params ): \"\"\" This constructor method initializes the object state and attributes of the StreamGear class. Parameters: output (str): sets the valid filename/path for storing the StreamGear assets. format (str): select the adaptive HTTP streaming format(DASH and HLS). custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables. logging (bool): enables/disables logging. stream_params (dict): provides the flexibility to control supported internal parameters and FFmpeg properities. \"\"\" # checks if machine in-use is running windows os or not self . __os_windows = True if os . name == \"nt\" else False # enable logging if specified self . __logging = logging if ( logging and isinstance ( logging , bool )) else False # initialize various class variables # handles user-defined parameters self . __params = {} # handle input video/frame resolution and channels self . __inputheight = None self . __inputwidth = None self . __inputchannels = None self . __sourceframerate = None # handle process to be frames written self . __process = None # handle valid FFmpeg assets location self . __ffmpeg = \"\" # handle one time process for valid process initialization self . __initiate_stream = True # cleans and reformat user-defined parameters self . __params = { str ( k ) . strip (): str ( v ) . strip () if not isinstance ( v , ( dict , list , int , float )) else v for k , v in stream_params . items () } # handle where to save the downloaded FFmpeg Static assets on Windows(if specified) __ffmpeg_download_path = self . __params . pop ( \"-ffmpeg_download_path\" , \"\" ) if not isinstance ( __ffmpeg_download_path , ( str )): # reset improper values __ffmpeg_download_path = \"\" # validate the FFmpeg assets and return location (also downloads static assets on windows) self . __ffmpeg = get_valid_ffmpeg_path ( str ( custom_ffmpeg ), self . __os_windows , ffmpeg_download_path = __ffmpeg_download_path , logging = self . __logging , ) # check if valid FFmpeg path returned if self . __ffmpeg : self . __logging and logger . debug ( \"Found valid FFmpeg executables: ` {} `.\" . format ( self . __ffmpeg ) ) else : # else raise error raise RuntimeError ( \"[StreamGear:ERROR] :: Failed to find FFmpeg assets on this system. Kindly compile/install FFmpeg or provide a valid custom FFmpeg binary path!\" ) # handle Audio-Input audio = self . __params . pop ( \"-audio\" , \"\" ) if audio and isinstance ( audio , str ): if os . path . isfile ( audio ): self . __audio = os . path . abspath ( audio ) elif is_valid_url ( self . __ffmpeg , url = audio , logging = self . __logging ): self . __audio = audio else : self . __audio = \"\" elif audio and isinstance ( audio , list ): self . __audio = audio else : self . __audio = \"\" if self . __audio and self . __logging : logger . debug ( \"External audio source detected!\" ) # handle Video-Source input source = self . __params . pop ( \"-video_source\" , \"\" ) # Check if input is valid string if source and isinstance ( source , str ) and len ( source ) > 1 : # Differentiate input if os . path . isfile ( source ): self . __video_source = os . path . abspath ( source ) elif is_valid_url ( self . __ffmpeg , url = source , logging = self . __logging ): self . __video_source = source else : # discard the value otherwise self . __video_source = \"\" # Validate input if self . __video_source : validation_results = validate_video ( self . __ffmpeg , video_path = self . __video_source ) assert not ( validation_results is None ), \"[StreamGear:ERROR] :: Given ` {} ` video_source is Invalid, Check Again!\" . format ( self . __video_source ) self . __aspect_source = validation_results [ \"resolution\" ] self . __fps_source = validation_results [ \"framerate\" ] # log it self . __logging and logger . debug ( \"Given video_source is valid and has {} x {} resolution, and a framerate of {} fps.\" . format ( self . __aspect_source [ 0 ], self . __aspect_source [ 1 ], self . __fps_source , ) ) else : logger . warning ( \"No valid video_source provided.\" ) else : # discard the value otherwise self . __video_source = \"\" # handle user-defined framerate self . __inputframerate = self . __params . pop ( \"-input_framerate\" , 0.0 ) if isinstance ( self . __inputframerate , ( float , int )): # must be float self . __inputframerate = float ( self . __inputframerate ) else : # reset improper values self . __inputframerate = 0.0 # handle old assests self . __clear_assets = self . __params . pop ( \"-clear_prev_assets\" , False ) if not isinstance ( self . __clear_assets , bool ): # reset improper values self . __clear_assets = False # handle whether to livestream? self . __livestreaming = self . __params . pop ( \"-livestream\" , False ) if not isinstance ( self . __livestreaming , bool ): # reset improper values self . __livestreaming = False # handle Streaming formats supported_formats = [ \"dash\" , \"hls\" ] # will be extended in future # Validate if not ( format is None ) and format and isinstance ( format , str ): _format = format . strip () . lower () if _format in supported_formats : self . __format = _format logger . info ( \"StreamGear will generate files for {} HTTP streaming format.\" . format ( self . __format . upper () ) ) elif difflib . get_close_matches ( _format , supported_formats ): raise ValueError ( \"[StreamGear:ERROR] :: Incorrect format! Did you mean ` {} `?\" . format ( difflib . get_close_matches ( _format , supported_formats )[ 0 ] ) ) else : raise ValueError ( \"[StreamGear:ERROR] :: format value ` {} ` not valid/supported!\" . format ( format ) ) else : raise ValueError ( \"[StreamGear:ERROR] :: format value is Missing/Incorrect. Check vidgear docs!\" ) # handles output name if not output : raise ValueError ( \"[StreamGear:ERROR] :: Kindly provide a valid `output` value. Refer Docs for more information.\" ) else : # validate this class has the access rights to specified directory or not abs_path = os . path . abspath ( output ) if check_WriteAccess ( os . path . dirname ( abs_path ), is_windows = self . __os_windows , logging = self . __logging , ): # check if given path is directory valid_extension = \"mpd\" if self . __format == \"dash\" else \"m3u8\" # get all assets extensions assets_exts = [ ( \"chunk-stream\" , \".m4s\" ), # filename prefix, extension ( \"chunk-stream\" , \".ts\" ), # filename prefix, extension \". {} \" . format ( valid_extension ), ] # add source file extension too if self . __video_source : assets_exts . append ( ( \"chunk-stream\" , os . path . splitext ( self . __video_source )[ 1 ], ) # filename prefix, extension ) if os . path . isdir ( abs_path ): if self . __clear_assets : delete_ext_safe ( abs_path , assets_exts , logging = self . __logging ) abs_path = os . path . join ( abs_path , \" {} - {} . {} \" . format ( self . __format , time . strftime ( \"%Y%m %d -%H%M%S\" ), valid_extension , ), ) # auto-assign valid name and adds it to path elif self . __clear_assets and os . path . isfile ( abs_path ): delete_ext_safe ( os . path . dirname ( abs_path ), assets_exts , logging = self . __logging , ) # check if path has valid file extension assert abs_path . endswith ( valid_extension ), \"Given ` {} ` path has invalid file-extension w.r.t selected format: ` {} `!\" . format ( output , self . __format . upper () ) self . __logging and logger . debug ( \"Path:` {} ` is sucessfully configured for streaming.\" . format ( abs_path ) ) # assign it self . __out_file = abs_path . replace ( \" \\\\ \" , \"/\" ) # workaround for Windows platform only, others will not be affected elif ( platform . system () == \"Linux\" and pathlib . Path ( output ) . is_char_device () ): # check if linux video device path (such as `/dev/video0`) self . __logging and logger . debug ( \"Path:` {} ` is a valid Linux Video Device path.\" . format ( output ) ) self . __out_file = output # check if given output is a valid URL elif is_valid_url ( self . __ffmpeg , url = output , logging = self . __logging ): self . __logging and logger . debug ( \"URL:` {} ` is valid and sucessfully configured for streaming.\" . format ( output ) ) self . __out_file = output else : raise ValueError ( \"[StreamGear:ERROR] :: Output value:` {} ` is not valid/supported!\" . format ( output ) ) # log Mode of operation logger . info ( \"StreamGear has been successfully configured for {} Mode.\" . format ( \"Single-Source\" if self . __video_source else \"Real-time Frames\" ) ) def stream ( self , frame , rgb_mode = False ): \"\"\" Pipelines `ndarray` frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets. Parameters: frame (ndarray): a valid numpy frame rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format instead of default BGR)_. \"\"\" # check if function is called in correct context if self . __video_source : raise RuntimeError ( \"[StreamGear:ERROR] :: `stream()` function cannot be used when streaming from a `-video_source` input file. Kindly refer vidgear docs!\" ) # None-Type frames will be skipped if frame is None : return # extract height, width and number of channels of frame height , width = frame . shape [: 2 ] channels = frame . shape [ - 1 ] if frame . ndim == 3 else 1 # assign values to class variables on first run if self . __initiate_stream : self . __inputheight = height self . __inputwidth = width self . __inputchannels = channels self . __sourceframerate = ( 25.0 if not ( self . __inputframerate ) else self . __inputframerate ) self . __logging and logger . debug ( \"InputFrame => Height: {} Width: {} Channels: {} \" . format ( self . __inputheight , self . __inputwidth , self . __inputchannels ) ) # validate size of frame if height != self . __inputheight or width != self . __inputwidth : raise ValueError ( \"[StreamGear:ERROR] :: All frames must have same size!\" ) # validate number of channels if channels != self . __inputchannels : raise ValueError ( \"[StreamGear:ERROR] :: All frames must have same number of channels!\" ) # initiate FFmpeg process on first run if self . __initiate_stream : # launch pre-processing self . __PreProcess ( channels = channels , rgb = rgb_mode ) # Check status of the process assert self . __process is not None # write the frame to pipeline try : self . __process . stdin . write ( frame . tobytes ()) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only def transcode_source ( self ): \"\"\" Transcodes entire Video Source _(with audio)_ into multi-bitrate streamable assets \"\"\" # check if function is called in correct context if not ( self . __video_source ): raise RuntimeError ( \"[StreamGear:ERROR] :: `transcode_source()` function cannot be used without a valid `-video_source` input. Kindly refer vidgear docs!\" ) # assign height, width and framerate self . __inputheight = int ( self . __aspect_source [ 1 ]) self . __inputwidth = int ( self . __aspect_source [ 0 ]) self . __sourceframerate = float ( self . __fps_source ) # launch pre-processing self . __PreProcess () def __PreProcess ( self , channels = 0 , rgb = False ): \"\"\" Internal method that pre-processes default FFmpeg parameters before beginning pipelining. Parameters: channels (int): Number of channels rgb_mode (boolean): activates RGB mode _(if enabled)_. \"\"\" # turn off initiate flag self . __initiate_stream = False # initialize parameters input_parameters = OrderedDict () output_parameters = OrderedDict () # pre-assign default codec parameters (if not assigned by user). default_codec = \"libx264rgb\" if rgb else \"libx264\" output_parameters [ \"-vcodec\" ] = self . __params . pop ( \"-vcodec\" , default_codec ) # enable optimizations and enforce compatibility output_parameters [ \"-vf\" ] = self . __params . pop ( \"-vf\" , \"format=yuv420p\" ) aspect_ratio = Fraction ( self . __inputwidth / self . __inputheight ) . limit_denominator ( 10 ) output_parameters [ \"-aspect\" ] = \":\" . join ( str ( aspect_ratio ) . split ( \"/\" )) # w.r.t selected codec if output_parameters [ \"-vcodec\" ] in [ \"libx264\" , \"libx264rgb\" , \"libx265\" , \"libvpx-vp9\" , ]: output_parameters [ \"-crf\" ] = self . __params . pop ( \"-crf\" , \"20\" ) if output_parameters [ \"-vcodec\" ] in [ \"libx264\" , \"libx264rgb\" ]: if not ( self . __video_source ): output_parameters [ \"-profile:v\" ] = self . __params . pop ( \"-profile:v\" , \"high\" ) output_parameters [ \"-tune\" ] = self . __params . pop ( \"-tune\" , \"zerolatency\" ) output_parameters [ \"-preset\" ] = self . __params . pop ( \"-preset\" , \"veryfast\" ) if output_parameters [ \"-vcodec\" ] == \"libx265\" : output_parameters [ \"-x265-params\" ] = self . __params . pop ( \"-x265-params\" , \"lossless=1\" ) # enable audio (if present) if self . __audio : # validate audio source bitrate = validate_audio ( self . __ffmpeg , source = self . __audio ) if bitrate : logger . info ( \"Detected External Audio Source is valid, and will be used for streams.\" ) # assign audio source output_parameters [ \" {} \" . format ( \"-core_asource\" if isinstance ( self . __audio , list ) else \"-i\" ) ] = self . __audio # assign audio codec output_parameters [ \"-acodec\" ] = self . __params . pop ( \"-acodec\" , \"aac\" if isinstance ( self . __audio , list ) else \"copy\" ) output_parameters [ \"a_bitrate\" ] = bitrate # temporary handler output_parameters [ \"-core_audio\" ] = ( [ \"-map\" , \"1:a:0\" ] if self . __format == \"dash\" else [] ) else : logger . warning ( \"Audio source ` {} ` is not valid, Skipped!\" . format ( self . __audio ) ) elif self . __video_source : # validate audio source bitrate = validate_audio ( self . __ffmpeg , source = self . __video_source ) if bitrate : logger . info ( \"Source Audio will be used for streams.\" ) # assign audio codec output_parameters [ \"-acodec\" ] = ( \"aac\" if self . __format == \"hls\" else \"copy\" ) output_parameters [ \"a_bitrate\" ] = bitrate # temporary handler else : logger . warning ( \"No valid audio_source available. Disabling audio for streams!\" ) else : logger . warning ( \"No valid audio_source provided. Disabling audio for streams!\" ) # enable audio optimizations based on audio codec if \"-acodec\" in output_parameters and output_parameters [ \"-acodec\" ] == \"aac\" : output_parameters [ \"-movflags\" ] = \"+faststart\" # set input framerate if self . __sourceframerate > 0 and not ( self . __video_source ): # set input framerate self . __logging and logger . debug ( \"Setting Input framerate: {} \" . format ( self . __sourceframerate ) ) input_parameters [ \"-framerate\" ] = str ( self . __sourceframerate ) # handle input resolution and pixel format if not ( self . __video_source ): dimensions = \" {} x {} \" . format ( self . __inputwidth , self . __inputheight ) input_parameters [ \"-video_size\" ] = str ( dimensions ) # handles pix_fmt based on channels(HACK) if channels == 1 : input_parameters [ \"-pix_fmt\" ] = \"gray\" elif channels == 2 : input_parameters [ \"-pix_fmt\" ] = \"ya8\" elif channels == 3 : input_parameters [ \"-pix_fmt\" ] = \"rgb24\" if rgb else \"bgr24\" elif channels == 4 : input_parameters [ \"-pix_fmt\" ] = \"rgba\" if rgb else \"bgra\" else : raise ValueError ( \"[StreamGear:ERROR] :: Frames with channels outside range 1-to-4 are not supported!\" ) # process assigned format parameters process_params = self . __handle_streams ( input_params = input_parameters , output_params = output_parameters ) # check if processing completed successfully assert not ( process_params is None ), \"[StreamGear:ERROR] :: {} stream cannot be initiated!\" . format ( self . __format . upper () ) # Finally start FFmpef pipline and process everything self . __Build_n_Execute ( process_params [ 0 ], process_params [ 1 ]) def __handle_streams ( self , input_params , output_params ): \"\"\" An internal function that parses various streams and its parameters. Parameters: input_params (dict): Input FFmpeg parameters output_params (dict): Output FFmpeg parameters \"\"\" # handle bit-per-pixels bpp = self . __params . pop ( \"-bpp\" , 0.1000 ) if isinstance ( bpp , ( float , int )) and bpp > 0.0 : bpp = float ( bpp ) if ( bpp > 0.001 ) else 0.1000 else : # reset to defaut if invalid bpp = 0.1000 # log it self . __logging and logger . debug ( \"Setting bit-per-pixels: {} for this stream.\" . format ( bpp ) ) # handle gop gop = self . __params . pop ( \"-gop\" , 0 ) if isinstance ( gop , ( int , float )) and gop > 0 : gop = int ( gop ) else : # reset to some recommended value gop = 2 * int ( self . __sourceframerate ) # log it self . __logging and logger . debug ( \"Setting GOP: {} for this stream.\" . format ( gop )) # define and map default stream if self . __format != \"hls\" : output_params [ \"-map\" ] = 0 else : output_params [ \"-corev0\" ] = [ \"-map\" , \"0:v\" ] if \"-acodec\" in output_params : output_params [ \"-corea0\" ] = [ \"-map\" , \" {} :a\" . format ( 1 if \"-core_audio\" in output_params else 0 ), ] # assign resolution if \"-s:v:0\" in self . __params : # prevent duplicates del self . __params [ \"-s:v:0\" ] output_params [ \"-s:v:0\" ] = \" {} x {} \" . format ( self . __inputwidth , self . __inputheight ) # assign video-bitrate if \"-b:v:0\" in self . __params : # prevent duplicates del self . __params [ \"-b:v:0\" ] output_params [ \"-b:v:0\" ] = ( str ( get_video_bitrate ( int ( self . __inputwidth ), int ( self . __inputheight ), self . __sourceframerate , bpp , ) ) + \"k\" ) # assign audio-bitrate if \"-b:a:0\" in self . __params : # prevent duplicates del self . __params [ \"-b:a:0\" ] # extract audio-bitrate from temporary handler a_bitrate = output_params . pop ( \"a_bitrate\" , \"\" ) if \"-acodec\" in output_params and a_bitrate : output_params [ \"-b:a:0\" ] = a_bitrate # handle user-defined streams streams = self . __params . pop ( \"-streams\" , {}) output_params = self . __evaluate_streams ( streams , output_params , bpp ) # define additional stream optimization parameters if output_params [ \"-vcodec\" ] in [ \"libx264\" , \"libx264rgb\" ]: if not \"-bf\" in self . __params : output_params [ \"-bf\" ] = 1 if not \"-sc_threshold\" in self . __params : output_params [ \"-sc_threshold\" ] = 0 if not \"-keyint_min\" in self . __params : output_params [ \"-keyint_min\" ] = gop if output_params [ \"-vcodec\" ] in [ \"libx264\" , \"libx264rgb\" , \"libvpx-vp9\" ]: if not \"-g\" in self . __params : output_params [ \"-g\" ] = gop if output_params [ \"-vcodec\" ] == \"libx265\" : output_params [ \"-core_x265\" ] = [ \"-x265-params\" , \"keyint= {} :min-keyint= {} \" . format ( gop , gop ), ] # process given dash/hls stream processed_params = None if self . __format == \"dash\" : processed_params = self . __generate_dash_stream ( input_params = input_params , output_params = output_params , ) else : processed_params = self . __generate_hls_stream ( input_params = input_params , output_params = output_params , ) return processed_params def __evaluate_streams ( self , streams , output_params , bpp ): \"\"\" Internal function that Extracts, Evaluates & Validates user-defined streams Parameters: streams (dict): Indivisual streams formatted as list of dict. output_params (dict): Output FFmpeg parameters \"\"\" # temporary streams count variable output_params [ \"stream_count\" ] = 1 # default is 1 # check if streams are empty if not streams : logger . warning ( \"No `-streams` are provided!\" ) return output_params # check if streams are valid if isinstance ( streams , list ) and all ( isinstance ( x , dict ) for x in streams ): stream_count = 1 # keep track of streams # calculate source aspect-ratio source_aspect_ratio = self . __inputwidth / self . __inputheight # log the process self . __logging and logger . debug ( \"Processing {} streams.\" . format ( len ( streams )) ) # iterate over given streams for stream in streams : stream_copy = stream . copy () # make copy intermediate_dict = {} # handles intermediate stream data as dictionary # define and map stream to intermediate dict if self . __format != \"hls\" : intermediate_dict [ \"-core {} \" . format ( stream_count )] = [ \"-map\" , \"0\" ] else : intermediate_dict [ \"-corev {} \" . format ( stream_count )] = [ \"-map\" , \"0:v\" ] if \"-acodec\" in output_params : intermediate_dict [ \"-corea {} \" . format ( stream_count )] = [ \"-map\" , \" {} :a\" . format ( 1 if \"-core_audio\" in output_params else 0 ), ] # extract resolution & indivisual dimension of stream resolution = stream . pop ( \"-resolution\" , \"\" ) dimensions = ( resolution . lower () . split ( \"x\" ) if ( resolution and isinstance ( resolution , str )) else [] ) # validate resolution if ( len ( dimensions ) == 2 and dimensions [ 0 ] . isnumeric () and dimensions [ 1 ] . isnumeric () ): # verify resolution is w.r.t source aspect-ratio expected_width = math . floor ( int ( dimensions [ 1 ]) * source_aspect_ratio ) if int ( dimensions [ 0 ]) != expected_width : logger . warning ( \"Given stream resolution ` {} ` is not in accordance with the Source Aspect-Ratio. Stream Output may appear Distorted!\" . format ( resolution ) ) # assign stream resolution to intermediate dict intermediate_dict [ \"-s:v: {} \" . format ( stream_count )] = resolution else : # otherwise log error and skip stream logger . error ( \"Missing `-resolution` value, Stream ` {} ` Skipped!\" . format ( stream_copy ) ) continue # verify given stream video-bitrate video_bitrate = stream . pop ( \"-video_bitrate\" , \"\" ) if ( video_bitrate and isinstance ( video_bitrate , str ) and video_bitrate . endswith (( \"k\" , \"M\" )) ): # assign it intermediate_dict [ \"-b:v: {} \" . format ( stream_count )] = video_bitrate else : # otherwise calculate video-bitrate fps = stream . pop ( \"-framerate\" , 0.0 ) if dimensions and isinstance ( fps , ( float , int )) and fps > 0 : intermediate_dict [ \"-b:v: {} \" . format ( stream_count ) ] = \" {} k\" . format ( get_video_bitrate ( int ( dimensions [ 0 ]), int ( dimensions [ 1 ]), fps , bpp ) ) else : # If everything fails, log and skip the stream! logger . error ( \"Unable to determine Video-Bitrate for the stream ` {} `, Skipped!\" . format ( stream_copy ) ) continue # verify given stream audio-bitrate audio_bitrate = stream . pop ( \"-audio_bitrate\" , \"\" ) if \"-acodec\" in output_params : if audio_bitrate and audio_bitrate . endswith (( \"k\" , \"M\" )): intermediate_dict [ \"-b:a: {} \" . format ( stream_count ) ] = audio_bitrate else : # otherwise calculate audio-bitrate if dimensions : aspect_width = int ( dimensions [ 0 ]) intermediate_dict [ \"-b:a: {} \" . format ( stream_count ) ] = \" {} k\" . format ( 128 if ( aspect_width > 800 ) else 96 ) # update output parameters output_params . update ( intermediate_dict ) # clear intermediate dict intermediate_dict . clear () # clear stream copy stream_copy . clear () # increment to next stream stream_count += 1 output_params [ \"stream_count\" ] = stream_count self . __logging and logger . debug ( \"All streams processed successfully!\" ) else : logger . warning ( \"Invalid type `-streams` skipped!\" ) return output_params def __generate_hls_stream ( self , input_params , output_params ): \"\"\" An internal function that parses user-defined parameters and generates suitable FFmpeg Terminal Command for transcoding input into HLS Stream. Parameters: input_params (dict): Input FFmpeg parameters output_params (dict): Output FFmpeg parameters \"\"\" # Check if live-streaming or not? # validate `hls_segment_type` default_hls_segment_type = self . __params . pop ( \"-hls_segment_type\" , \"mpegts\" ) if isinstance ( default_hls_segment_type , str ) and default_hls_segment_type . strip () in [ \"fmp4\" , \"mpegts\" ]: output_params [ \"-hls_segment_type\" ] = default_hls_segment_type . strip () else : output_params [ \"-hls_segment_type\" ] = \"mpegts\" # gather required parameters if self . __livestreaming : # `hls_list_size` must be greater than 0 default_hls_list_size = self . __params . pop ( \"-hls_list_size\" , 6 ) if isinstance ( default_hls_list_size , int ) and default_hls_list_size > 0 : output_params [ \"-hls_list_size\" ] = default_hls_list_size else : # otherwise reset to default output_params [ \"-hls_list_size\" ] = 6 # default behaviour output_params [ \"-hls_init_time\" ] = self . __params . pop ( \"-hls_init_time\" , 4 ) output_params [ \"-hls_time\" ] = self . __params . pop ( \"-hls_time\" , 6 ) output_params [ \"-hls_flags\" ] = self . __params . pop ( \"-hls_flags\" , \"delete_segments+discont_start+split_by_time\" ) # clean everything at exit? output_params [ \"-remove_at_exit\" ] = self . __params . pop ( \"-remove_at_exit\" , 0 ) else : # enforce \"contain all the segments\" output_params [ \"-hls_list_size\" ] = 0 output_params [ \"-hls_playlist_type\" ] = \"vod\" # handle base URL for absolute paths output_params [ \"-hls_base_url\" ] = self . __params . pop ( \"-hls_base_url\" , \"\" ) # Finally, some hardcoded HLS parameters (Refer FFmpeg docs for more info.) output_params [ \"-allowed_extensions\" ] = \"ALL\" # Handling <hls_segment_filename> # Here filenname will be based on `stream_count` dict parameter that # would be used to check whether stream is multivariant(>1) or single(0-1) segment_template = ( \" {} -stream%v- %03d . {} \" if output_params [ \"stream_count\" ] > 1 else \" {} -stream- %03d . {} \" ) output_params [ \"-hls_segment_filename\" ] = segment_template . format ( os . path . join ( os . path . dirname ( self . __out_file ), \"chunk\" ), \"m4s\" if output_params [ \"-hls_segment_type\" ] == \"fmp4\" else \"ts\" , ) output_params [ \"-hls_allow_cache\" ] = 0 # enable hls formatting output_params [ \"-f\" ] = \"hls\" return ( input_params , output_params ) def __generate_dash_stream ( self , input_params , output_params ): \"\"\" An internal function that parses user-defined parameters and generates suitable FFmpeg Terminal Command for transcoding input into MPEG-dash Stream. Parameters: input_params (dict): Input FFmpeg parameters output_params (dict): Output FFmpeg parameters \"\"\" # Check if live-streaming or not? if self . __livestreaming : output_params [ \"-window_size\" ] = self . __params . pop ( \"-window_size\" , 5 ) output_params [ \"-extra_window_size\" ] = self . __params . pop ( \"-extra_window_size\" , 5 ) # clean everything at exit? output_params [ \"-remove_at_exit\" ] = self . __params . pop ( \"-remove_at_exit\" , 0 ) # default behaviour output_params [ \"-seg_duration\" ] = self . __params . pop ( \"-seg_duration\" , 20 ) # Disable (0) the use of a SegmentTimline inside a SegmentTemplate. output_params [ \"-use_timeline\" ] = 0 else : # default behaviour output_params [ \"-seg_duration\" ] = self . __params . pop ( \"-seg_duration\" , 5 ) # Enable (1) the use of a SegmentTimline inside a SegmentTemplate. output_params [ \"-use_timeline\" ] = 1 # Finally, some hardcoded DASH parameters (Refer FFmpeg docs for more info.) output_params [ \"-use_template\" ] = 1 output_params [ \"-adaptation_sets\" ] = \"id=0,streams=v {} \" . format ( \"id=1,streams=a\" if ( \"-acodec\" in output_params ) else \"\" ) # enable dash formatting output_params [ \"-f\" ] = \"dash\" return ( input_params , output_params ) def __Build_n_Execute ( self , input_params , output_params ): \"\"\" An Internal function that launches FFmpeg subprocess and pipelines commands. Parameters: input_params (dict): Input FFmpeg parameters output_params (dict): Output FFmpeg parameters \"\"\" # handle audio source if present if \"-core_asource\" in output_params : output_params . move_to_end ( \"-core_asource\" , last = False ) # finally handle `-i` if \"-i\" in output_params : output_params . move_to_end ( \"-i\" , last = False ) # copy streams count stream_count = output_params . pop ( \"stream_count\" , 1 ) # convert input parameters to list input_commands = dict2Args ( input_params ) # convert output parameters to list output_commands = dict2Args ( output_params ) # convert any additional parameters to list stream_commands = dict2Args ( self . __params ) # create exclusive HLS params hls_commands = [] # handle HLS multi-variant streams if self . __format == \"hls\" and stream_count > 1 : stream_map = \"\" for count in range ( 0 , stream_count ): stream_map += \"v: {}{} \" . format ( count , \",a: {} \" . format ( count ) if \"-acodec\" in output_params else \",\" ) hls_commands += [ \"-master_pl_name\" , os . path . basename ( self . __out_file ), \"-var_stream_map\" , stream_map . strip (), os . path . join ( os . path . dirname ( self . __out_file ), \"stream_%v.m3u8\" ), ] # log it if enabled if self . __logging : logger . debug ( \"User-Defined Output parameters: ` {} `\" . format ( \" \" . join ( output_commands ) if output_commands else None ) ) logger . debug ( \"Additional parameters: ` {} `\" . format ( \" \" . join ( stream_commands ) if stream_commands else None ) ) # build FFmpeg command from parameters ffmpeg_cmd = None hide_banner = ( [] if self . __logging else [ \"-hide_banner\" ] ) # ensuring less cluterring if specified # format commands if self . __video_source : ffmpeg_cmd = ( [ self . __ffmpeg , \"-y\" ] + ([ \"-re\" ] if self . __livestreaming else []) # pseudo live-streaming + hide_banner + [ \"-i\" , self . __video_source ] + input_commands + output_commands + stream_commands ) else : ffmpeg_cmd = ( [ self . __ffmpeg , \"-y\" ] + hide_banner + [ \"-f\" , \"rawvideo\" , \"-vcodec\" , \"rawvideo\" ] + input_commands + [ \"-i\" , \"-\" ] + output_commands + stream_commands ) # format outputs ffmpeg_cmd . extend ([ self . __out_file ] if not ( hls_commands ) else hls_commands ) # Launch the FFmpeg pipeline with built command logger . critical ( \"Transcoding streaming chunks. Please wait...\" ) # log it self . __process = sp . Popen ( ffmpeg_cmd , stdin = sp . PIPE , stdout = sp . DEVNULL if ( not self . __video_source and not self . __logging ) else sp . PIPE , stderr = None if self . __logging else sp . STDOUT , ) # post handle progress bar and runtime errors in case of video_source if self . __video_source : return_code = 0 pbar = None sec_prev = 0 if not self . __logging : # iterate until stdout runs out while True : # read and process data data = self . __process . stdout . readline () if data : data = data . decode ( \"utf-8\" ) # extract duration and time-left if pbar is None : if \"Duration:\" in data : sec_duration = extract_time ( data ) # initate progress bar pbar = tqdm ( total = sec_duration , desc = \"Processing Frames\" , unit = \"frame\" , ) else : if \"time=\" in data : sec_current = extract_time ( data ) # update progress bar if sec_current : pbar . update ( sec_current - sec_prev ) sec_prev = sec_current else : # poll if no data if self . __process . poll () is not None : break return_code = self . __process . poll () else : self . __process . communicate () return_code = self . __process . returncode # close progress bar if pbar : pbar . close () # handle return_code if return_code : # log and raise error if return_code is `1` logger . error ( \"StreamGear failed to initiate stream for this video source!\" ) error = sp . CalledProcessError ( return_code , ffmpeg_cmd ) raise error else : # log if successful logger . critical ( \"Transcoding Ended. {} Streaming assets are successfully generated at specified path.\" . format ( self . __format . upper () ) ) def terminate ( self ): \"\"\" Safely terminates StreamGear. \"\"\" # return if no process was initiated at first place if self . __process is None or not ( self . __process . poll () is None ): return # close `stdin` output if self . __process . stdin : self . __process . stdin . close () # force terminate if external audio source if isinstance ( self . __audio , list ): self . __process . terminate () # wait if still process is still processing some information self . __process . wait () self . __process = None # log it logger . critical ( \"Transcoding Ended. {} Streaming assets are successfully generated at specified path.\" . format ( self . __format . upper () ) ) __init__ ( self , output = '' , format = 'dash' , custom_ffmpeg = '' , logging = False , ** stream_params ) special \u2693 This constructor method initializes the object state and attributes of the StreamGear class. Parameters: Name Type Description Default output str sets the valid filename/path for storing the StreamGear assets. '' format str select the adaptive HTTP streaming format(DASH and HLS). 'dash' custom_ffmpeg str assigns the location of custom path/directory for custom FFmpeg executables. '' logging bool enables/disables logging. False stream_params dict provides the flexibility to control supported internal parameters and FFmpeg properities. {} Source code in vidgear/gears/streamgear.py def __init__ ( self , output = \"\" , format = \"dash\" , custom_ffmpeg = \"\" , logging = False , ** stream_params ): \"\"\" This constructor method initializes the object state and attributes of the StreamGear class. Parameters: output (str): sets the valid filename/path for storing the StreamGear assets. format (str): select the adaptive HTTP streaming format(DASH and HLS). custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables. logging (bool): enables/disables logging. stream_params (dict): provides the flexibility to control supported internal parameters and FFmpeg properities. \"\"\" # checks if machine in-use is running windows os or not self . __os_windows = True if os . name == \"nt\" else False # enable logging if specified self . __logging = logging if ( logging and isinstance ( logging , bool )) else False # initialize various class variables # handles user-defined parameters self . __params = {} # handle input video/frame resolution and channels self . __inputheight = None self . __inputwidth = None self . __inputchannels = None self . __sourceframerate = None # handle process to be frames written self . __process = None # handle valid FFmpeg assets location self . __ffmpeg = \"\" # handle one time process for valid process initialization self . __initiate_stream = True # cleans and reformat user-defined parameters self . __params = { str ( k ) . strip (): str ( v ) . strip () if not isinstance ( v , ( dict , list , int , float )) else v for k , v in stream_params . items () } # handle where to save the downloaded FFmpeg Static assets on Windows(if specified) __ffmpeg_download_path = self . __params . pop ( \"-ffmpeg_download_path\" , \"\" ) if not isinstance ( __ffmpeg_download_path , ( str )): # reset improper values __ffmpeg_download_path = \"\" # validate the FFmpeg assets and return location (also downloads static assets on windows) self . __ffmpeg = get_valid_ffmpeg_path ( str ( custom_ffmpeg ), self . __os_windows , ffmpeg_download_path = __ffmpeg_download_path , logging = self . __logging , ) # check if valid FFmpeg path returned if self . __ffmpeg : self . __logging and logger . debug ( \"Found valid FFmpeg executables: ` {} `.\" . format ( self . __ffmpeg ) ) else : # else raise error raise RuntimeError ( \"[StreamGear:ERROR] :: Failed to find FFmpeg assets on this system. Kindly compile/install FFmpeg or provide a valid custom FFmpeg binary path!\" ) # handle Audio-Input audio = self . __params . pop ( \"-audio\" , \"\" ) if audio and isinstance ( audio , str ): if os . path . isfile ( audio ): self . __audio = os . path . abspath ( audio ) elif is_valid_url ( self . __ffmpeg , url = audio , logging = self . __logging ): self . __audio = audio else : self . __audio = \"\" elif audio and isinstance ( audio , list ): self . __audio = audio else : self . __audio = \"\" if self . __audio and self . __logging : logger . debug ( \"External audio source detected!\" ) # handle Video-Source input source = self . __params . pop ( \"-video_source\" , \"\" ) # Check if input is valid string if source and isinstance ( source , str ) and len ( source ) > 1 : # Differentiate input if os . path . isfile ( source ): self . __video_source = os . path . abspath ( source ) elif is_valid_url ( self . __ffmpeg , url = source , logging = self . __logging ): self . __video_source = source else : # discard the value otherwise self . __video_source = \"\" # Validate input if self . __video_source : validation_results = validate_video ( self . __ffmpeg , video_path = self . __video_source ) assert not ( validation_results is None ), \"[StreamGear:ERROR] :: Given ` {} ` video_source is Invalid, Check Again!\" . format ( self . __video_source ) self . __aspect_source = validation_results [ \"resolution\" ] self . __fps_source = validation_results [ \"framerate\" ] # log it self . __logging and logger . debug ( \"Given video_source is valid and has {} x {} resolution, and a framerate of {} fps.\" . format ( self . __aspect_source [ 0 ], self . __aspect_source [ 1 ], self . __fps_source , ) ) else : logger . warning ( \"No valid video_source provided.\" ) else : # discard the value otherwise self . __video_source = \"\" # handle user-defined framerate self . __inputframerate = self . __params . pop ( \"-input_framerate\" , 0.0 ) if isinstance ( self . __inputframerate , ( float , int )): # must be float self . __inputframerate = float ( self . __inputframerate ) else : # reset improper values self . __inputframerate = 0.0 # handle old assests self . __clear_assets = self . __params . pop ( \"-clear_prev_assets\" , False ) if not isinstance ( self . __clear_assets , bool ): # reset improper values self . __clear_assets = False # handle whether to livestream? self . __livestreaming = self . __params . pop ( \"-livestream\" , False ) if not isinstance ( self . __livestreaming , bool ): # reset improper values self . __livestreaming = False # handle Streaming formats supported_formats = [ \"dash\" , \"hls\" ] # will be extended in future # Validate if not ( format is None ) and format and isinstance ( format , str ): _format = format . strip () . lower () if _format in supported_formats : self . __format = _format logger . info ( \"StreamGear will generate files for {} HTTP streaming format.\" . format ( self . __format . upper () ) ) elif difflib . get_close_matches ( _format , supported_formats ): raise ValueError ( \"[StreamGear:ERROR] :: Incorrect format! Did you mean ` {} `?\" . format ( difflib . get_close_matches ( _format , supported_formats )[ 0 ] ) ) else : raise ValueError ( \"[StreamGear:ERROR] :: format value ` {} ` not valid/supported!\" . format ( format ) ) else : raise ValueError ( \"[StreamGear:ERROR] :: format value is Missing/Incorrect. Check vidgear docs!\" ) # handles output name if not output : raise ValueError ( \"[StreamGear:ERROR] :: Kindly provide a valid `output` value. Refer Docs for more information.\" ) else : # validate this class has the access rights to specified directory or not abs_path = os . path . abspath ( output ) if check_WriteAccess ( os . path . dirname ( abs_path ), is_windows = self . __os_windows , logging = self . __logging , ): # check if given path is directory valid_extension = \"mpd\" if self . __format == \"dash\" else \"m3u8\" # get all assets extensions assets_exts = [ ( \"chunk-stream\" , \".m4s\" ), # filename prefix, extension ( \"chunk-stream\" , \".ts\" ), # filename prefix, extension \". {} \" . format ( valid_extension ), ] # add source file extension too if self . __video_source : assets_exts . append ( ( \"chunk-stream\" , os . path . splitext ( self . __video_source )[ 1 ], ) # filename prefix, extension ) if os . path . isdir ( abs_path ): if self . __clear_assets : delete_ext_safe ( abs_path , assets_exts , logging = self . __logging ) abs_path = os . path . join ( abs_path , \" {} - {} . {} \" . format ( self . __format , time . strftime ( \"%Y%m %d -%H%M%S\" ), valid_extension , ), ) # auto-assign valid name and adds it to path elif self . __clear_assets and os . path . isfile ( abs_path ): delete_ext_safe ( os . path . dirname ( abs_path ), assets_exts , logging = self . __logging , ) # check if path has valid file extension assert abs_path . endswith ( valid_extension ), \"Given ` {} ` path has invalid file-extension w.r.t selected format: ` {} `!\" . format ( output , self . __format . upper () ) self . __logging and logger . debug ( \"Path:` {} ` is sucessfully configured for streaming.\" . format ( abs_path ) ) # assign it self . __out_file = abs_path . replace ( \" \\\\ \" , \"/\" ) # workaround for Windows platform only, others will not be affected elif ( platform . system () == \"Linux\" and pathlib . Path ( output ) . is_char_device () ): # check if linux video device path (such as `/dev/video0`) self . __logging and logger . debug ( \"Path:` {} ` is a valid Linux Video Device path.\" . format ( output ) ) self . __out_file = output # check if given output is a valid URL elif is_valid_url ( self . __ffmpeg , url = output , logging = self . __logging ): self . __logging and logger . debug ( \"URL:` {} ` is valid and sucessfully configured for streaming.\" . format ( output ) ) self . __out_file = output else : raise ValueError ( \"[StreamGear:ERROR] :: Output value:` {} ` is not valid/supported!\" . format ( output ) ) # log Mode of operation logger . info ( \"StreamGear has been successfully configured for {} Mode.\" . format ( \"Single-Source\" if self . __video_source else \"Real-time Frames\" ) ) stream ( self , frame , rgb_mode = False ) \u2693 Pipelines ndarray frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets. Parameters: Name Type Description Default frame ndarray a valid numpy frame required rgb_mode boolean enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format instead of default BGR) . False Source code in vidgear/gears/streamgear.py def stream ( self , frame , rgb_mode = False ): \"\"\" Pipelines `ndarray` frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets. Parameters: frame (ndarray): a valid numpy frame rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format instead of default BGR)_. \"\"\" # check if function is called in correct context if self . __video_source : raise RuntimeError ( \"[StreamGear:ERROR] :: `stream()` function cannot be used when streaming from a `-video_source` input file. Kindly refer vidgear docs!\" ) # None-Type frames will be skipped if frame is None : return # extract height, width and number of channels of frame height , width = frame . shape [: 2 ] channels = frame . shape [ - 1 ] if frame . ndim == 3 else 1 # assign values to class variables on first run if self . __initiate_stream : self . __inputheight = height self . __inputwidth = width self . __inputchannels = channels self . __sourceframerate = ( 25.0 if not ( self . __inputframerate ) else self . __inputframerate ) self . __logging and logger . debug ( \"InputFrame => Height: {} Width: {} Channels: {} \" . format ( self . __inputheight , self . __inputwidth , self . __inputchannels ) ) # validate size of frame if height != self . __inputheight or width != self . __inputwidth : raise ValueError ( \"[StreamGear:ERROR] :: All frames must have same size!\" ) # validate number of channels if channels != self . __inputchannels : raise ValueError ( \"[StreamGear:ERROR] :: All frames must have same number of channels!\" ) # initiate FFmpeg process on first run if self . __initiate_stream : # launch pre-processing self . __PreProcess ( channels = channels , rgb = rgb_mode ) # Check status of the process assert self . __process is not None # write the frame to pipeline try : self . __process . stdin . write ( frame . tobytes ()) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only terminate ( self ) \u2693 Safely terminates StreamGear. Source code in vidgear/gears/streamgear.py def terminate ( self ): \"\"\" Safely terminates StreamGear. \"\"\" # return if no process was initiated at first place if self . __process is None or not ( self . __process . poll () is None ): return # close `stdin` output if self . __process . stdin : self . __process . stdin . close () # force terminate if external audio source if isinstance ( self . __audio , list ): self . __process . terminate () # wait if still process is still processing some information self . __process . wait () self . __process = None # log it logger . critical ( \"Transcoding Ended. {} Streaming assets are successfully generated at specified path.\" . format ( self . __format . upper () ) ) transcode_source ( self ) \u2693 Transcodes entire Video Source (with audio) into multi-bitrate streamable assets Source code in vidgear/gears/streamgear.py def transcode_source ( self ): \"\"\" Transcodes entire Video Source _(with audio)_ into multi-bitrate streamable assets \"\"\" # check if function is called in correct context if not ( self . __video_source ): raise RuntimeError ( \"[StreamGear:ERROR] :: `transcode_source()` function cannot be used without a valid `-video_source` input. Kindly refer vidgear docs!\" ) # assign height, width and framerate self . __inputheight = int ( self . __aspect_source [ 1 ]) self . __inputwidth = int ( self . __aspect_source [ 0 ]) self . __sourceframerate = float ( self . __fps_source ) # launch pre-processing self . __PreProcess ()","title":"StreamGear API"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.__init__","text":"This constructor method initializes the object state and attributes of the StreamGear class. Parameters: Name Type Description Default output str sets the valid filename/path for storing the StreamGear assets. '' format str select the adaptive HTTP streaming format(DASH and HLS). 'dash' custom_ffmpeg str assigns the location of custom path/directory for custom FFmpeg executables. '' logging bool enables/disables logging. False stream_params dict provides the flexibility to control supported internal parameters and FFmpeg properities. {} Source code in vidgear/gears/streamgear.py def __init__ ( self , output = \"\" , format = \"dash\" , custom_ffmpeg = \"\" , logging = False , ** stream_params ): \"\"\" This constructor method initializes the object state and attributes of the StreamGear class. Parameters: output (str): sets the valid filename/path for storing the StreamGear assets. format (str): select the adaptive HTTP streaming format(DASH and HLS). custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables. logging (bool): enables/disables logging. stream_params (dict): provides the flexibility to control supported internal parameters and FFmpeg properities. \"\"\" # checks if machine in-use is running windows os or not self . __os_windows = True if os . name == \"nt\" else False # enable logging if specified self . __logging = logging if ( logging and isinstance ( logging , bool )) else False # initialize various class variables # handles user-defined parameters self . __params = {} # handle input video/frame resolution and channels self . __inputheight = None self . __inputwidth = None self . __inputchannels = None self . __sourceframerate = None # handle process to be frames written self . __process = None # handle valid FFmpeg assets location self . __ffmpeg = \"\" # handle one time process for valid process initialization self . __initiate_stream = True # cleans and reformat user-defined parameters self . __params = { str ( k ) . strip (): str ( v ) . strip () if not isinstance ( v , ( dict , list , int , float )) else v for k , v in stream_params . items () } # handle where to save the downloaded FFmpeg Static assets on Windows(if specified) __ffmpeg_download_path = self . __params . pop ( \"-ffmpeg_download_path\" , \"\" ) if not isinstance ( __ffmpeg_download_path , ( str )): # reset improper values __ffmpeg_download_path = \"\" # validate the FFmpeg assets and return location (also downloads static assets on windows) self . __ffmpeg = get_valid_ffmpeg_path ( str ( custom_ffmpeg ), self . __os_windows , ffmpeg_download_path = __ffmpeg_download_path , logging = self . __logging , ) # check if valid FFmpeg path returned if self . __ffmpeg : self . __logging and logger . debug ( \"Found valid FFmpeg executables: ` {} `.\" . format ( self . __ffmpeg ) ) else : # else raise error raise RuntimeError ( \"[StreamGear:ERROR] :: Failed to find FFmpeg assets on this system. Kindly compile/install FFmpeg or provide a valid custom FFmpeg binary path!\" ) # handle Audio-Input audio = self . __params . pop ( \"-audio\" , \"\" ) if audio and isinstance ( audio , str ): if os . path . isfile ( audio ): self . __audio = os . path . abspath ( audio ) elif is_valid_url ( self . __ffmpeg , url = audio , logging = self . __logging ): self . __audio = audio else : self . __audio = \"\" elif audio and isinstance ( audio , list ): self . __audio = audio else : self . __audio = \"\" if self . __audio and self . __logging : logger . debug ( \"External audio source detected!\" ) # handle Video-Source input source = self . __params . pop ( \"-video_source\" , \"\" ) # Check if input is valid string if source and isinstance ( source , str ) and len ( source ) > 1 : # Differentiate input if os . path . isfile ( source ): self . __video_source = os . path . abspath ( source ) elif is_valid_url ( self . __ffmpeg , url = source , logging = self . __logging ): self . __video_source = source else : # discard the value otherwise self . __video_source = \"\" # Validate input if self . __video_source : validation_results = validate_video ( self . __ffmpeg , video_path = self . __video_source ) assert not ( validation_results is None ), \"[StreamGear:ERROR] :: Given ` {} ` video_source is Invalid, Check Again!\" . format ( self . __video_source ) self . __aspect_source = validation_results [ \"resolution\" ] self . __fps_source = validation_results [ \"framerate\" ] # log it self . __logging and logger . debug ( \"Given video_source is valid and has {} x {} resolution, and a framerate of {} fps.\" . format ( self . __aspect_source [ 0 ], self . __aspect_source [ 1 ], self . __fps_source , ) ) else : logger . warning ( \"No valid video_source provided.\" ) else : # discard the value otherwise self . __video_source = \"\" # handle user-defined framerate self . __inputframerate = self . __params . pop ( \"-input_framerate\" , 0.0 ) if isinstance ( self . __inputframerate , ( float , int )): # must be float self . __inputframerate = float ( self . __inputframerate ) else : # reset improper values self . __inputframerate = 0.0 # handle old assests self . __clear_assets = self . __params . pop ( \"-clear_prev_assets\" , False ) if not isinstance ( self . __clear_assets , bool ): # reset improper values self . __clear_assets = False # handle whether to livestream? self . __livestreaming = self . __params . pop ( \"-livestream\" , False ) if not isinstance ( self . __livestreaming , bool ): # reset improper values self . __livestreaming = False # handle Streaming formats supported_formats = [ \"dash\" , \"hls\" ] # will be extended in future # Validate if not ( format is None ) and format and isinstance ( format , str ): _format = format . strip () . lower () if _format in supported_formats : self . __format = _format logger . info ( \"StreamGear will generate files for {} HTTP streaming format.\" . format ( self . __format . upper () ) ) elif difflib . get_close_matches ( _format , supported_formats ): raise ValueError ( \"[StreamGear:ERROR] :: Incorrect format! Did you mean ` {} `?\" . format ( difflib . get_close_matches ( _format , supported_formats )[ 0 ] ) ) else : raise ValueError ( \"[StreamGear:ERROR] :: format value ` {} ` not valid/supported!\" . format ( format ) ) else : raise ValueError ( \"[StreamGear:ERROR] :: format value is Missing/Incorrect. Check vidgear docs!\" ) # handles output name if not output : raise ValueError ( \"[StreamGear:ERROR] :: Kindly provide a valid `output` value. Refer Docs for more information.\" ) else : # validate this class has the access rights to specified directory or not abs_path = os . path . abspath ( output ) if check_WriteAccess ( os . path . dirname ( abs_path ), is_windows = self . __os_windows , logging = self . __logging , ): # check if given path is directory valid_extension = \"mpd\" if self . __format == \"dash\" else \"m3u8\" # get all assets extensions assets_exts = [ ( \"chunk-stream\" , \".m4s\" ), # filename prefix, extension ( \"chunk-stream\" , \".ts\" ), # filename prefix, extension \". {} \" . format ( valid_extension ), ] # add source file extension too if self . __video_source : assets_exts . append ( ( \"chunk-stream\" , os . path . splitext ( self . __video_source )[ 1 ], ) # filename prefix, extension ) if os . path . isdir ( abs_path ): if self . __clear_assets : delete_ext_safe ( abs_path , assets_exts , logging = self . __logging ) abs_path = os . path . join ( abs_path , \" {} - {} . {} \" . format ( self . __format , time . strftime ( \"%Y%m %d -%H%M%S\" ), valid_extension , ), ) # auto-assign valid name and adds it to path elif self . __clear_assets and os . path . isfile ( abs_path ): delete_ext_safe ( os . path . dirname ( abs_path ), assets_exts , logging = self . __logging , ) # check if path has valid file extension assert abs_path . endswith ( valid_extension ), \"Given ` {} ` path has invalid file-extension w.r.t selected format: ` {} `!\" . format ( output , self . __format . upper () ) self . __logging and logger . debug ( \"Path:` {} ` is sucessfully configured for streaming.\" . format ( abs_path ) ) # assign it self . __out_file = abs_path . replace ( \" \\\\ \" , \"/\" ) # workaround for Windows platform only, others will not be affected elif ( platform . system () == \"Linux\" and pathlib . Path ( output ) . is_char_device () ): # check if linux video device path (such as `/dev/video0`) self . __logging and logger . debug ( \"Path:` {} ` is a valid Linux Video Device path.\" . format ( output ) ) self . __out_file = output # check if given output is a valid URL elif is_valid_url ( self . __ffmpeg , url = output , logging = self . __logging ): self . __logging and logger . debug ( \"URL:` {} ` is valid and sucessfully configured for streaming.\" . format ( output ) ) self . __out_file = output else : raise ValueError ( \"[StreamGear:ERROR] :: Output value:` {} ` is not valid/supported!\" . format ( output ) ) # log Mode of operation logger . info ( \"StreamGear has been successfully configured for {} Mode.\" . format ( \"Single-Source\" if self . __video_source else \"Real-time Frames\" ) )","title":"__init__()"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.stream","text":"Pipelines ndarray frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets. Parameters: Name Type Description Default frame ndarray a valid numpy frame required rgb_mode boolean enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format instead of default BGR) . False Source code in vidgear/gears/streamgear.py def stream ( self , frame , rgb_mode = False ): \"\"\" Pipelines `ndarray` frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets. Parameters: frame (ndarray): a valid numpy frame rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format instead of default BGR)_. \"\"\" # check if function is called in correct context if self . __video_source : raise RuntimeError ( \"[StreamGear:ERROR] :: `stream()` function cannot be used when streaming from a `-video_source` input file. Kindly refer vidgear docs!\" ) # None-Type frames will be skipped if frame is None : return # extract height, width and number of channels of frame height , width = frame . shape [: 2 ] channels = frame . shape [ - 1 ] if frame . ndim == 3 else 1 # assign values to class variables on first run if self . __initiate_stream : self . __inputheight = height self . __inputwidth = width self . __inputchannels = channels self . __sourceframerate = ( 25.0 if not ( self . __inputframerate ) else self . __inputframerate ) self . __logging and logger . debug ( \"InputFrame => Height: {} Width: {} Channels: {} \" . format ( self . __inputheight , self . __inputwidth , self . __inputchannels ) ) # validate size of frame if height != self . __inputheight or width != self . __inputwidth : raise ValueError ( \"[StreamGear:ERROR] :: All frames must have same size!\" ) # validate number of channels if channels != self . __inputchannels : raise ValueError ( \"[StreamGear:ERROR] :: All frames must have same number of channels!\" ) # initiate FFmpeg process on first run if self . __initiate_stream : # launch pre-processing self . __PreProcess ( channels = channels , rgb = rgb_mode ) # Check status of the process assert self . __process is not None # write the frame to pipeline try : self . __process . stdin . write ( frame . tobytes ()) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only","title":"stream()"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.terminate","text":"Safely terminates StreamGear. Source code in vidgear/gears/streamgear.py def terminate ( self ): \"\"\" Safely terminates StreamGear. \"\"\" # return if no process was initiated at first place if self . __process is None or not ( self . __process . poll () is None ): return # close `stdin` output if self . __process . stdin : self . __process . stdin . close () # force terminate if external audio source if isinstance ( self . __audio , list ): self . __process . terminate () # wait if still process is still processing some information self . __process . wait () self . __process = None # log it logger . critical ( \"Transcoding Ended. {} Streaming assets are successfully generated at specified path.\" . format ( self . __format . upper () ) )","title":"terminate()"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.transcode_source","text":"Transcodes entire Video Source (with audio) into multi-bitrate streamable assets Source code in vidgear/gears/streamgear.py def transcode_source ( self ): \"\"\" Transcodes entire Video Source _(with audio)_ into multi-bitrate streamable assets \"\"\" # check if function is called in correct context if not ( self . __video_source ): raise RuntimeError ( \"[StreamGear:ERROR] :: `transcode_source()` function cannot be used without a valid `-video_source` input. Kindly refer vidgear docs!\" ) # assign height, width and framerate self . __inputheight = int ( self . __aspect_source [ 1 ]) self . __inputwidth = int ( self . __aspect_source [ 0 ]) self . __sourceframerate = float ( self . __fps_source ) # launch pre-processing self . __PreProcess ()","title":"transcode_source()"},{"location":"bonus/reference/videogear/","text":"VideoGear API usage examples can be found here \u27b6 VideoGear API parameters are explained here \u27b6 VideoGear API provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. VideoGear also acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and their parameters with an exclusive enablePiCamera boolean flag. VideoGear is ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and writing way fewer lines of code. Source code in vidgear/gears/videogear.py class VideoGear : \"\"\" VideoGear API provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. VideoGear also acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and their parameters with an exclusive enablePiCamera boolean flag. VideoGear is ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and writing way fewer lines of code. \"\"\" def __init__ ( self , # VideoGear parameters enablePiCamera = False , stabilize = False , # PiGear parameters camera_num = 0 , resolution = ( 640 , 480 ), framerate = 30 , # CamGear parameters source = 0 , stream_mode = False , backend = 0 , # common parameters time_delay = 0 , colorspace = None , logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the VideoGear class. Parameters: enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of CamGear, PiGear & Stabilizer. \"\"\" # initialize stabilizer self . __stablization_mode = stabilize # enable logging if specified self . __logging = False if logging : self . __logging = logging # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} if self . __stablization_mode : from .stabilizer import Stabilizer s_radius = options . pop ( \"SMOOTHING_RADIUS\" , 25 ) if not isinstance ( s_radius , int ): s_radius = 25 border_size = options . pop ( \"BORDER_SIZE\" , 0 ) if not isinstance ( border_size , int ): border_size = 0 border_type = options . pop ( \"BORDER_TYPE\" , \"black\" ) if not isinstance ( border_type , str ): border_type = \"black\" crop_n_zoom = options . pop ( \"CROP_N_ZOOM\" , False ) if not isinstance ( crop_n_zoom , bool ): crop_n_zoom = False self . __stabilizer_obj = Stabilizer ( smoothing_radius = s_radius , border_type = border_type , border_size = border_size , crop_n_zoom = crop_n_zoom , logging = logging , ) self . __logging and logger . debug ( \"Enabling Stablization Mode for the current video source!\" ) # log info if enablePiCamera : # only import the pigear module only if required from .pigear import PiGear # initialize the picamera stream by enabling PiGear API self . stream = PiGear ( camera_num = camera_num , resolution = resolution , framerate = framerate , colorspace = colorspace , logging = logging , time_delay = time_delay , ** options ) else : # otherwise, we are using OpenCV so initialize the webcam # stream by activating CamGear API self . stream = CamGear ( source = source , stream_mode = stream_mode , backend = backend , colorspace = colorspace , logging = logging , time_delay = time_delay , ** options ) # initialize framerate variable self . framerate = self . stream . framerate def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon of API in use. **Returns:** A reference to the selected class object. \"\"\" self . stream . start () return self def read ( self ): \"\"\" Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" while self . __stablization_mode : frame = self . stream . read () if frame is None : break frame_stab = self . __stabilizer_obj . stabilize ( frame ) if not ( frame_stab is None ): return frame_stab return self . stream . read () def stop ( self ): \"\"\" Safely terminates the thread, and release the respective VideoStream resources. \"\"\" self . stream . stop () # logged self . __logging and logger . debug ( \"Terminating VideoGear.\" ) # clean queue if self . __stablization_mode : self . __stabilizer_obj . clean () __init__ ( self , enablePiCamera = False , stabilize = False , camera_num = 0 , resolution = ( 640 , 480 ), framerate = 30 , source = 0 , stream_mode = False , backend = 0 , time_delay = 0 , colorspace = None , logging = False , ** options ) special \u2693 This constructor method initializes the object state and attributes of the VideoGear class. Parameters: Name Type Description Default enablePiCamera bool provide access to PiGear(if True) or CamGear(if False) APIs respectively. False stabilize bool enable access to Stabilizer Class for stabilizing frames. False camera_num int selects the camera module index which will be used as Rpi source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the Rpi source. (640, 480) framerate int/float sets the framerate of the Rpi source. 30 source based on input defines the source for the input stream. 0 stream_mode bool controls the exclusive YouTube Mode. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Tweak Parameters of CamGear, PiGear & Stabilizer. {} Source code in vidgear/gears/videogear.py def __init__ ( self , # VideoGear parameters enablePiCamera = False , stabilize = False , # PiGear parameters camera_num = 0 , resolution = ( 640 , 480 ), framerate = 30 , # CamGear parameters source = 0 , stream_mode = False , backend = 0 , # common parameters time_delay = 0 , colorspace = None , logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the VideoGear class. Parameters: enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of CamGear, PiGear & Stabilizer. \"\"\" # initialize stabilizer self . __stablization_mode = stabilize # enable logging if specified self . __logging = False if logging : self . __logging = logging # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} if self . __stablization_mode : from .stabilizer import Stabilizer s_radius = options . pop ( \"SMOOTHING_RADIUS\" , 25 ) if not isinstance ( s_radius , int ): s_radius = 25 border_size = options . pop ( \"BORDER_SIZE\" , 0 ) if not isinstance ( border_size , int ): border_size = 0 border_type = options . pop ( \"BORDER_TYPE\" , \"black\" ) if not isinstance ( border_type , str ): border_type = \"black\" crop_n_zoom = options . pop ( \"CROP_N_ZOOM\" , False ) if not isinstance ( crop_n_zoom , bool ): crop_n_zoom = False self . __stabilizer_obj = Stabilizer ( smoothing_radius = s_radius , border_type = border_type , border_size = border_size , crop_n_zoom = crop_n_zoom , logging = logging , ) self . __logging and logger . debug ( \"Enabling Stablization Mode for the current video source!\" ) # log info if enablePiCamera : # only import the pigear module only if required from .pigear import PiGear # initialize the picamera stream by enabling PiGear API self . stream = PiGear ( camera_num = camera_num , resolution = resolution , framerate = framerate , colorspace = colorspace , logging = logging , time_delay = time_delay , ** options ) else : # otherwise, we are using OpenCV so initialize the webcam # stream by activating CamGear API self . stream = CamGear ( source = source , stream_mode = stream_mode , backend = backend , colorspace = colorspace , logging = logging , time_delay = time_delay , ** options ) # initialize framerate variable self . framerate = self . stream . framerate read ( self ) \u2693 Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/videogear.py def read ( self ): \"\"\" Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" while self . __stablization_mode : frame = self . stream . read () if frame is None : break frame_stab = self . __stabilizer_obj . stabilize ( frame ) if not ( frame_stab is None ): return frame_stab return self . stream . read () start ( self ) \u2693 Launches the internal Threaded Frames Extractor daemon of API in use. Returns: A reference to the selected class object. Source code in vidgear/gears/videogear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon of API in use. **Returns:** A reference to the selected class object. \"\"\" self . stream . start () return self stop ( self ) \u2693 Safely terminates the thread, and release the respective VideoStream resources. Source code in vidgear/gears/videogear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the respective VideoStream resources. \"\"\" self . stream . stop () # logged self . __logging and logger . debug ( \"Terminating VideoGear.\" ) # clean queue if self . __stablization_mode : self . __stabilizer_obj . clean ()","title":"VideoGear API"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.__init__","text":"This constructor method initializes the object state and attributes of the VideoGear class. Parameters: Name Type Description Default enablePiCamera bool provide access to PiGear(if True) or CamGear(if False) APIs respectively. False stabilize bool enable access to Stabilizer Class for stabilizing frames. False camera_num int selects the camera module index which will be used as Rpi source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the Rpi source. (640, 480) framerate int/float sets the framerate of the Rpi source. 30 source based on input defines the source for the input stream. 0 stream_mode bool controls the exclusive YouTube Mode. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Tweak Parameters of CamGear, PiGear & Stabilizer. {} Source code in vidgear/gears/videogear.py def __init__ ( self , # VideoGear parameters enablePiCamera = False , stabilize = False , # PiGear parameters camera_num = 0 , resolution = ( 640 , 480 ), framerate = 30 , # CamGear parameters source = 0 , stream_mode = False , backend = 0 , # common parameters time_delay = 0 , colorspace = None , logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the VideoGear class. Parameters: enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of CamGear, PiGear & Stabilizer. \"\"\" # initialize stabilizer self . __stablization_mode = stabilize # enable logging if specified self . __logging = False if logging : self . __logging = logging # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} if self . __stablization_mode : from .stabilizer import Stabilizer s_radius = options . pop ( \"SMOOTHING_RADIUS\" , 25 ) if not isinstance ( s_radius , int ): s_radius = 25 border_size = options . pop ( \"BORDER_SIZE\" , 0 ) if not isinstance ( border_size , int ): border_size = 0 border_type = options . pop ( \"BORDER_TYPE\" , \"black\" ) if not isinstance ( border_type , str ): border_type = \"black\" crop_n_zoom = options . pop ( \"CROP_N_ZOOM\" , False ) if not isinstance ( crop_n_zoom , bool ): crop_n_zoom = False self . __stabilizer_obj = Stabilizer ( smoothing_radius = s_radius , border_type = border_type , border_size = border_size , crop_n_zoom = crop_n_zoom , logging = logging , ) self . __logging and logger . debug ( \"Enabling Stablization Mode for the current video source!\" ) # log info if enablePiCamera : # only import the pigear module only if required from .pigear import PiGear # initialize the picamera stream by enabling PiGear API self . stream = PiGear ( camera_num = camera_num , resolution = resolution , framerate = framerate , colorspace = colorspace , logging = logging , time_delay = time_delay , ** options ) else : # otherwise, we are using OpenCV so initialize the webcam # stream by activating CamGear API self . stream = CamGear ( source = source , stream_mode = stream_mode , backend = backend , colorspace = colorspace , logging = logging , time_delay = time_delay , ** options ) # initialize framerate variable self . framerate = self . stream . framerate","title":"__init__()"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.read","text":"Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/videogear.py def read ( self ): \"\"\" Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" while self . __stablization_mode : frame = self . stream . read () if frame is None : break frame_stab = self . __stabilizer_obj . stabilize ( frame ) if not ( frame_stab is None ): return frame_stab return self . stream . read ()","title":"read()"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.start","text":"Launches the internal Threaded Frames Extractor daemon of API in use. Returns: A reference to the selected class object. Source code in vidgear/gears/videogear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon of API in use. **Returns:** A reference to the selected class object. \"\"\" self . stream . start () return self","title":"start()"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.stop","text":"Safely terminates the thread, and release the respective VideoStream resources. Source code in vidgear/gears/videogear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the respective VideoStream resources. \"\"\" self . stream . stop () # logged self . __logging and logger . debug ( \"Terminating VideoGear.\" ) # clean queue if self . __stablization_mode : self . __stabilizer_obj . clean ()","title":"stop()"},{"location":"bonus/reference/webgear/","text":"WebGear API usage examples can be found here \u27b6 WebGear API parameters are explained here \u27b6 WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting Motion-JPEG-frames from a single source to multiple recipients via the browser. WebGear API works on Starlette's ASGI application and provides a highly extensible and flexible async wrapper around its complete framework. WebGear can flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc. WebGear API uses an intraframe-only compression scheme under the hood where the sequence of video-frames are first encoded as JPEG-DIB (JPEG with Device-Independent Bit compression) and then streamed over HTTP using Starlette's Multipart Streaming Response and a Uvicorn ASGI Server. This method imposes lower processing and memory requirements, but the quality is not the best, since JPEG compression is not very efficient for motion video. In layman's terms, WebGear acts as a powerful Video Broadcaster that transmits live video-frames to any web-browser in the network. Additionally, WebGear API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network. Source code in vidgear/gears/asyncio/webgear.py class WebGear : \"\"\" WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting Motion-JPEG-frames from a single source to multiple recipients via the browser. WebGear API works on Starlette's ASGI application and provides a highly extensible and flexible async wrapper around its complete framework. WebGear can flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc. WebGear API uses an intraframe-only compression scheme under the hood where the sequence of video-frames are first encoded as JPEG-DIB (JPEG with Device-Independent Bit compression) and then streamed over HTTP using Starlette's Multipart Streaming Response and a Uvicorn ASGI Server. This method imposes lower processing and memory requirements, but the quality is not the best, since JPEG compression is not very efficient for motion video. In layman's terms, WebGear acts as a powerful Video Broadcaster that transmits live video-frames to any web-browser in the network. Additionally, WebGear API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network. \"\"\" def __init__ ( self , enablePiCamera = False , stabilize = False , source = None , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the WebGear class. Parameters: enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of WebGear, CamGear, PiGear & Stabilizer. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"starlette\" if starlette is None else \"\" ) import_dependency_safe ( \"simplejpeg\" if simplejpeg is None else \"\" , min_version = \"1.6.1\" ) # initialize global params # define frame-compression handler self . __jpeg_compression_quality = 90 # 90% quality self . __jpeg_compression_fastdct = True # fastest DCT on by default self . __jpeg_compression_fastupsample = False # fastupsample off by default self . __jpeg_compression_colorspace = \"BGR\" # use BGR colorspace by default self . __logging = logging self . __frame_size_reduction = 25 # use 25% reduction # retrieve interpolation for reduction self . __interpolation = retrieve_best_interpolation ( [ \"INTER_LINEAR_EXACT\" , \"INTER_LINEAR\" , \"INTER_AREA\" ] ) custom_data_location = \"\" # path to save data-files to custom location data_path = \"\" # path to WebGear data-files overwrite_default = False self . __enable_inf = False # continue frames even when video ends. # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # assign values to global variables if specified and valid if options : if \"jpeg_compression_colorspace\" in options : value = options [ \"jpeg_compression_colorspace\" ] if isinstance ( value , str ) and value . strip () . upper () in [ \"RGB\" , \"BGR\" , \"RGBX\" , \"BGRX\" , \"XBGR\" , \"XRGB\" , \"GRAY\" , \"RGBA\" , \"BGRA\" , \"ABGR\" , \"ARGB\" , \"CMYK\" , ]: # set encoding colorspace self . __jpeg_compression_colorspace = value . strip () . upper () else : logger . warning ( \"Skipped invalid `jpeg_compression_colorspace` value!\" ) del options [ \"jpeg_compression_colorspace\" ] # clean if \"jpeg_compression_quality\" in options : value = options [ \"jpeg_compression_quality\" ] # set valid jpeg quality if isinstance ( value , ( int , float )) and value >= 10 and value <= 100 : self . __jpeg_compression_quality = int ( value ) else : logger . warning ( \"Skipped invalid `jpeg_compression_quality` value!\" ) del options [ \"jpeg_compression_quality\" ] # clean if \"jpeg_compression_fastdct\" in options : value = options [ \"jpeg_compression_fastdct\" ] # enable jpeg fastdct if isinstance ( value , bool ): self . __jpeg_compression_fastdct = value else : logger . warning ( \"Skipped invalid `jpeg_compression_fastdct` value!\" ) del options [ \"jpeg_compression_fastdct\" ] # clean if \"jpeg_compression_fastupsample\" in options : value = options [ \"jpeg_compression_fastupsample\" ] # enable jpeg fastupsample if isinstance ( value , bool ): self . __jpeg_compression_fastupsample = value else : logger . warning ( \"Skipped invalid `jpeg_compression_fastupsample` value!\" ) del options [ \"jpeg_compression_fastupsample\" ] # clean if \"frame_size_reduction\" in options : value = options [ \"frame_size_reduction\" ] if isinstance ( value , ( int , float )) and value >= 0 and value <= 90 : self . __frame_size_reduction = value else : logger . warning ( \"Skipped invalid `frame_size_reduction` value!\" ) del options [ \"frame_size_reduction\" ] # clean if \"custom_data_location\" in options : value = options [ \"custom_data_location\" ] if isinstance ( value , str ): assert os . access ( value , os . W_OK ), \"[WebGear:ERROR] :: Permission Denied!, cannot write WebGear data-files to ' {} ' directory!\" . format ( value ) assert os . path . isdir ( os . path . abspath ( value ) ), \"[WebGear:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\" custom_data_location = os . path . abspath ( value ) else : logger . warning ( \"Skipped invalid `custom_data_location` value!\" ) del options [ \"custom_data_location\" ] # clean if \"overwrite_default_files\" in options : value = options [ \"overwrite_default_files\" ] if isinstance ( value , bool ): overwrite_default = value else : logger . warning ( \"Skipped invalid `overwrite_default_files` value!\" ) del options [ \"overwrite_default_files\" ] # clean if \"enable_infinite_frames\" in options : value = options [ \"enable_infinite_frames\" ] if isinstance ( value , bool ): self . __enable_inf = value else : logger . warning ( \"Skipped invalid `enable_infinite_frames` value!\" ) del options [ \"enable_infinite_frames\" ] # clean # check if custom certificates path is specified if custom_data_location : data_path = generate_webdata ( custom_data_location , c_name = \"webgear\" , overwrite_default = overwrite_default , logging = logging , ) else : # otherwise generate suitable path data_path = generate_webdata ( os . path . join ( expanduser ( \"~\" ), \".vidgear\" ), c_name = \"webgear\" , overwrite_default = overwrite_default , logging = logging , ) # log it self . __logging and logger . debug ( \"` {} ` is the default location for saving WebGear data-files.\" . format ( data_path ) ) # define Jinja2 templates handler self . __templates = Jinja2Templates ( directory = \" {} /templates\" . format ( data_path )) # define custom exception handlers self . __exception_handlers = { 404 : self . __not_found , 500 : self . __server_error } # define routing tables self . routes = [ Route ( \"/\" , endpoint = self . __homepage ), Route ( \"/video\" , endpoint = self . __video ), Mount ( \"/static\" , app = StaticFiles ( directory = \" {} /static\" . format ( data_path )), name = \"static\" , ), ] # define middleware support self . middleware = [] # Handle video source if source is None : self . config = { \"generator\" : None } self . __stream = None else : # define stream with necessary params self . __stream = VideoGear ( enablePiCamera = enablePiCamera , stabilize = stabilize , source = source , camera_num = camera_num , stream_mode = stream_mode , backend = backend , colorspace = colorspace , resolution = resolution , framerate = framerate , logging = logging , time_delay = time_delay , ** options ) # define default frame generator in configuration self . config = { \"generator\" : self . __producer } # log if specified if self . __logging : if source is None : logger . warning ( \"Given source is of NoneType. Therefore, JPEG Frame-Compression is disabled!\" ) else : logger . debug ( \"Enabling JPEG Frame-Compression with Colorspace:` {} `, Quality:` {} `%, Fastdct:` {} `, and Fastupsample:` {} `.\" . format ( self . __jpeg_compression_colorspace , self . __jpeg_compression_quality , \"enabled\" if self . __jpeg_compression_fastdct else \"disabled\" , \"enabled\" if self . __jpeg_compression_fastupsample else \"disabled\" , ) ) # copying original routing tables for further validation self . __rt_org_copy = self . routes [:] # initialize blank frame self . blank_frame = None # keeps check if producer loop should be running self . __isrunning = True def __call__ ( self ): \"\"\" Implements a custom Callable method for WebGear application. \"\"\" # validate routing tables assert not ( self . routes is None ), \"Routing tables are NoneType!\" if not isinstance ( self . routes , list ) or not all ( x in self . routes for x in self . __rt_org_copy ): raise RuntimeError ( \"[WebGear:ERROR] :: Routing tables are not valid!\" ) # validate middlewares assert not ( self . middleware is None ), \"Middlewares are NoneType!\" if self . middleware and ( not isinstance ( self . middleware , list ) or not all ( isinstance ( x , Middleware ) for x in self . middleware ) ): raise RuntimeError ( \"[WebGear:ERROR] :: Middlewares are not valid!\" ) # validate assigned frame generator in WebGear configuration if isinstance ( self . config , dict ) and \"generator\" in self . config : # check if its assigned value is a asynchronous generator if self . config [ \"generator\" ] is None or not inspect . isasyncgen ( self . config [ \"generator\" ]() ): # otherwise raise error raise ValueError ( \"[WebGear:ERROR] :: Invalid configuration. Assigned generator must be a asynchronous generator function/method only!\" ) else : # raise error if validation fails raise RuntimeError ( \"[WebGear:ERROR] :: Assigned configuration is invalid!\" ) # initiate stream self . __logging and logger . debug ( \"Initiating Video Streaming.\" ) if not ( self . __stream is None ): self . __stream . start () # return Starlette application self . __logging and logger . debug ( \"Running Starlette application.\" ) return Starlette ( debug = ( True if self . __logging else False ), routes = self . routes , middleware = self . middleware , exception_handlers = self . __exception_handlers , on_shutdown = [ self . shutdown ], ) async def __producer ( self ): \"\"\" WebGear's default asynchronous frame producer/generator. \"\"\" # loop over frames while self . __isrunning : # read frame frame = self . __stream . read () # display blank if NoneType if frame is None : frame = ( self . blank_frame if self . blank_frame is None else self . blank_frame [:] ) if not self . __enable_inf : self . __isrunning = False else : # create blank if self . blank_frame is None : self . blank_frame = create_blank_frame ( frame = frame , text = \"No Input\" if self . __enable_inf else \"The End\" , logging = self . __logging , ) # reducer frames size if specified if self . __frame_size_reduction : frame = await reducer ( frame , percentage = self . __frame_size_reduction , interpolation = self . __interpolation , ) # handle JPEG encoding if self . __jpeg_compression_colorspace == \"GRAY\" : if frame . ndim == 2 : # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11 frame = np . expand_dims ( frame , axis = 2 ) encodedImage = simplejpeg . encode_jpeg ( frame , quality = self . __jpeg_compression_quality , colorspace = self . __jpeg_compression_colorspace , fastdct = self . __jpeg_compression_fastdct , ) else : encodedImage = simplejpeg . encode_jpeg ( frame , quality = self . __jpeg_compression_quality , colorspace = self . __jpeg_compression_colorspace , colorsubsampling = \"422\" , fastdct = self . __jpeg_compression_fastdct , ) # yield frame in byte format yield ( b \"--frame \\r\\n Content-Type:image/jpeg \\r\\n\\r\\n \" + encodedImage + b \" \\r\\n \" ) # sleep for sometime. await asyncio . sleep ( 0 ) async def __video ( self , scope ): \"\"\" Return a async video streaming response. \"\"\" assert scope [ \"type\" ] in [ \"http\" , \"https\" ] return StreamingResponse ( self . config [ \"generator\" ](), media_type = \"multipart/x-mixed-replace; boundary=frame\" , ) async def __homepage ( self , request ): \"\"\" Return an HTML index page. \"\"\" return self . __templates . TemplateResponse ( \"index.html\" , { \"request\" : request }) async def __not_found ( self , request , exc ): \"\"\" Return an HTML 404 page. \"\"\" return self . __templates . TemplateResponse ( \"404.html\" , { \"request\" : request }, status_code = 404 ) async def __server_error ( self , request , exc ): \"\"\" Return an HTML 500 page. \"\"\" return self . __templates . TemplateResponse ( \"500.html\" , { \"request\" : request }, status_code = 500 ) def shutdown ( self ): \"\"\" Implements a Callable to be run on application shutdown \"\"\" if not ( self . __stream is None ): self . __logging and logger . debug ( \"Closing Video Streaming.\" ) # stops producer self . __isrunning = False # stops VideoGear stream self . __stream . stop () # prevent any re-iteration self . __stream = None __call__ ( self ) special \u2693 Implements a custom Callable method for WebGear application. Source code in vidgear/gears/asyncio/webgear.py def __call__ ( self ): \"\"\" Implements a custom Callable method for WebGear application. \"\"\" # validate routing tables assert not ( self . routes is None ), \"Routing tables are NoneType!\" if not isinstance ( self . routes , list ) or not all ( x in self . routes for x in self . __rt_org_copy ): raise RuntimeError ( \"[WebGear:ERROR] :: Routing tables are not valid!\" ) # validate middlewares assert not ( self . middleware is None ), \"Middlewares are NoneType!\" if self . middleware and ( not isinstance ( self . middleware , list ) or not all ( isinstance ( x , Middleware ) for x in self . middleware ) ): raise RuntimeError ( \"[WebGear:ERROR] :: Middlewares are not valid!\" ) # validate assigned frame generator in WebGear configuration if isinstance ( self . config , dict ) and \"generator\" in self . config : # check if its assigned value is a asynchronous generator if self . config [ \"generator\" ] is None or not inspect . isasyncgen ( self . config [ \"generator\" ]() ): # otherwise raise error raise ValueError ( \"[WebGear:ERROR] :: Invalid configuration. Assigned generator must be a asynchronous generator function/method only!\" ) else : # raise error if validation fails raise RuntimeError ( \"[WebGear:ERROR] :: Assigned configuration is invalid!\" ) # initiate stream self . __logging and logger . debug ( \"Initiating Video Streaming.\" ) if not ( self . __stream is None ): self . __stream . start () # return Starlette application self . __logging and logger . debug ( \"Running Starlette application.\" ) return Starlette ( debug = ( True if self . __logging else False ), routes = self . routes , middleware = self . middleware , exception_handlers = self . __exception_handlers , on_shutdown = [ self . shutdown ], ) __init__ ( self , enablePiCamera = False , stabilize = False , source = None , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , logging = False , time_delay = 0 , ** options ) special \u2693 This constructor method initializes the object state and attributes of the WebGear class. Parameters: Name Type Description Default enablePiCamera bool provide access to PiGear(if True) or CamGear(if False) APIs respectively. False stabilize bool enable access to Stabilizer Class for stabilizing frames. False camera_num int selects the camera module index which will be used as Rpi source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the Rpi source. (640, 480) framerate int/float sets the framerate of the Rpi source. 25 source based on input defines the source for the input stream. None stream_mode bool controls the exclusive YouTube Mode. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Tweak Parameters of WebGear, CamGear, PiGear & Stabilizer. {} Source code in vidgear/gears/asyncio/webgear.py def __init__ ( self , enablePiCamera = False , stabilize = False , source = None , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the WebGear class. Parameters: enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of WebGear, CamGear, PiGear & Stabilizer. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"starlette\" if starlette is None else \"\" ) import_dependency_safe ( \"simplejpeg\" if simplejpeg is None else \"\" , min_version = \"1.6.1\" ) # initialize global params # define frame-compression handler self . __jpeg_compression_quality = 90 # 90% quality self . __jpeg_compression_fastdct = True # fastest DCT on by default self . __jpeg_compression_fastupsample = False # fastupsample off by default self . __jpeg_compression_colorspace = \"BGR\" # use BGR colorspace by default self . __logging = logging self . __frame_size_reduction = 25 # use 25% reduction # retrieve interpolation for reduction self . __interpolation = retrieve_best_interpolation ( [ \"INTER_LINEAR_EXACT\" , \"INTER_LINEAR\" , \"INTER_AREA\" ] ) custom_data_location = \"\" # path to save data-files to custom location data_path = \"\" # path to WebGear data-files overwrite_default = False self . __enable_inf = False # continue frames even when video ends. # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # assign values to global variables if specified and valid if options : if \"jpeg_compression_colorspace\" in options : value = options [ \"jpeg_compression_colorspace\" ] if isinstance ( value , str ) and value . strip () . upper () in [ \"RGB\" , \"BGR\" , \"RGBX\" , \"BGRX\" , \"XBGR\" , \"XRGB\" , \"GRAY\" , \"RGBA\" , \"BGRA\" , \"ABGR\" , \"ARGB\" , \"CMYK\" , ]: # set encoding colorspace self . __jpeg_compression_colorspace = value . strip () . upper () else : logger . warning ( \"Skipped invalid `jpeg_compression_colorspace` value!\" ) del options [ \"jpeg_compression_colorspace\" ] # clean if \"jpeg_compression_quality\" in options : value = options [ \"jpeg_compression_quality\" ] # set valid jpeg quality if isinstance ( value , ( int , float )) and value >= 10 and value <= 100 : self . __jpeg_compression_quality = int ( value ) else : logger . warning ( \"Skipped invalid `jpeg_compression_quality` value!\" ) del options [ \"jpeg_compression_quality\" ] # clean if \"jpeg_compression_fastdct\" in options : value = options [ \"jpeg_compression_fastdct\" ] # enable jpeg fastdct if isinstance ( value , bool ): self . __jpeg_compression_fastdct = value else : logger . warning ( \"Skipped invalid `jpeg_compression_fastdct` value!\" ) del options [ \"jpeg_compression_fastdct\" ] # clean if \"jpeg_compression_fastupsample\" in options : value = options [ \"jpeg_compression_fastupsample\" ] # enable jpeg fastupsample if isinstance ( value , bool ): self . __jpeg_compression_fastupsample = value else : logger . warning ( \"Skipped invalid `jpeg_compression_fastupsample` value!\" ) del options [ \"jpeg_compression_fastupsample\" ] # clean if \"frame_size_reduction\" in options : value = options [ \"frame_size_reduction\" ] if isinstance ( value , ( int , float )) and value >= 0 and value <= 90 : self . __frame_size_reduction = value else : logger . warning ( \"Skipped invalid `frame_size_reduction` value!\" ) del options [ \"frame_size_reduction\" ] # clean if \"custom_data_location\" in options : value = options [ \"custom_data_location\" ] if isinstance ( value , str ): assert os . access ( value , os . W_OK ), \"[WebGear:ERROR] :: Permission Denied!, cannot write WebGear data-files to ' {} ' directory!\" . format ( value ) assert os . path . isdir ( os . path . abspath ( value ) ), \"[WebGear:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\" custom_data_location = os . path . abspath ( value ) else : logger . warning ( \"Skipped invalid `custom_data_location` value!\" ) del options [ \"custom_data_location\" ] # clean if \"overwrite_default_files\" in options : value = options [ \"overwrite_default_files\" ] if isinstance ( value , bool ): overwrite_default = value else : logger . warning ( \"Skipped invalid `overwrite_default_files` value!\" ) del options [ \"overwrite_default_files\" ] # clean if \"enable_infinite_frames\" in options : value = options [ \"enable_infinite_frames\" ] if isinstance ( value , bool ): self . __enable_inf = value else : logger . warning ( \"Skipped invalid `enable_infinite_frames` value!\" ) del options [ \"enable_infinite_frames\" ] # clean # check if custom certificates path is specified if custom_data_location : data_path = generate_webdata ( custom_data_location , c_name = \"webgear\" , overwrite_default = overwrite_default , logging = logging , ) else : # otherwise generate suitable path data_path = generate_webdata ( os . path . join ( expanduser ( \"~\" ), \".vidgear\" ), c_name = \"webgear\" , overwrite_default = overwrite_default , logging = logging , ) # log it self . __logging and logger . debug ( \"` {} ` is the default location for saving WebGear data-files.\" . format ( data_path ) ) # define Jinja2 templates handler self . __templates = Jinja2Templates ( directory = \" {} /templates\" . format ( data_path )) # define custom exception handlers self . __exception_handlers = { 404 : self . __not_found , 500 : self . __server_error } # define routing tables self . routes = [ Route ( \"/\" , endpoint = self . __homepage ), Route ( \"/video\" , endpoint = self . __video ), Mount ( \"/static\" , app = StaticFiles ( directory = \" {} /static\" . format ( data_path )), name = \"static\" , ), ] # define middleware support self . middleware = [] # Handle video source if source is None : self . config = { \"generator\" : None } self . __stream = None else : # define stream with necessary params self . __stream = VideoGear ( enablePiCamera = enablePiCamera , stabilize = stabilize , source = source , camera_num = camera_num , stream_mode = stream_mode , backend = backend , colorspace = colorspace , resolution = resolution , framerate = framerate , logging = logging , time_delay = time_delay , ** options ) # define default frame generator in configuration self . config = { \"generator\" : self . __producer } # log if specified if self . __logging : if source is None : logger . warning ( \"Given source is of NoneType. Therefore, JPEG Frame-Compression is disabled!\" ) else : logger . debug ( \"Enabling JPEG Frame-Compression with Colorspace:` {} `, Quality:` {} `%, Fastdct:` {} `, and Fastupsample:` {} `.\" . format ( self . __jpeg_compression_colorspace , self . __jpeg_compression_quality , \"enabled\" if self . __jpeg_compression_fastdct else \"disabled\" , \"enabled\" if self . __jpeg_compression_fastupsample else \"disabled\" , ) ) # copying original routing tables for further validation self . __rt_org_copy = self . routes [:] # initialize blank frame self . blank_frame = None # keeps check if producer loop should be running self . __isrunning = True shutdown ( self ) \u2693 Implements a Callable to be run on application shutdown Source code in vidgear/gears/asyncio/webgear.py def shutdown ( self ): \"\"\" Implements a Callable to be run on application shutdown \"\"\" if not ( self . __stream is None ): self . __logging and logger . debug ( \"Closing Video Streaming.\" ) # stops producer self . __isrunning = False # stops VideoGear stream self . __stream . stop () # prevent any re-iteration self . __stream = None","title":"WebGear API"},{"location":"bonus/reference/webgear/#vidgear.gears.asyncio.webgear.WebGear.__call__","text":"Implements a custom Callable method for WebGear application. Source code in vidgear/gears/asyncio/webgear.py def __call__ ( self ): \"\"\" Implements a custom Callable method for WebGear application. \"\"\" # validate routing tables assert not ( self . routes is None ), \"Routing tables are NoneType!\" if not isinstance ( self . routes , list ) or not all ( x in self . routes for x in self . __rt_org_copy ): raise RuntimeError ( \"[WebGear:ERROR] :: Routing tables are not valid!\" ) # validate middlewares assert not ( self . middleware is None ), \"Middlewares are NoneType!\" if self . middleware and ( not isinstance ( self . middleware , list ) or not all ( isinstance ( x , Middleware ) for x in self . middleware ) ): raise RuntimeError ( \"[WebGear:ERROR] :: Middlewares are not valid!\" ) # validate assigned frame generator in WebGear configuration if isinstance ( self . config , dict ) and \"generator\" in self . config : # check if its assigned value is a asynchronous generator if self . config [ \"generator\" ] is None or not inspect . isasyncgen ( self . config [ \"generator\" ]() ): # otherwise raise error raise ValueError ( \"[WebGear:ERROR] :: Invalid configuration. Assigned generator must be a asynchronous generator function/method only!\" ) else : # raise error if validation fails raise RuntimeError ( \"[WebGear:ERROR] :: Assigned configuration is invalid!\" ) # initiate stream self . __logging and logger . debug ( \"Initiating Video Streaming.\" ) if not ( self . __stream is None ): self . __stream . start () # return Starlette application self . __logging and logger . debug ( \"Running Starlette application.\" ) return Starlette ( debug = ( True if self . __logging else False ), routes = self . routes , middleware = self . middleware , exception_handlers = self . __exception_handlers , on_shutdown = [ self . shutdown ], )","title":"__call__()"},{"location":"bonus/reference/webgear/#vidgear.gears.asyncio.webgear.WebGear.__init__","text":"This constructor method initializes the object state and attributes of the WebGear class. Parameters: Name Type Description Default enablePiCamera bool provide access to PiGear(if True) or CamGear(if False) APIs respectively. False stabilize bool enable access to Stabilizer Class for stabilizing frames. False camera_num int selects the camera module index which will be used as Rpi source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the Rpi source. (640, 480) framerate int/float sets the framerate of the Rpi source. 25 source based on input defines the source for the input stream. None stream_mode bool controls the exclusive YouTube Mode. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Tweak Parameters of WebGear, CamGear, PiGear & Stabilizer. {} Source code in vidgear/gears/asyncio/webgear.py def __init__ ( self , enablePiCamera = False , stabilize = False , source = None , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the WebGear class. Parameters: enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of WebGear, CamGear, PiGear & Stabilizer. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"starlette\" if starlette is None else \"\" ) import_dependency_safe ( \"simplejpeg\" if simplejpeg is None else \"\" , min_version = \"1.6.1\" ) # initialize global params # define frame-compression handler self . __jpeg_compression_quality = 90 # 90% quality self . __jpeg_compression_fastdct = True # fastest DCT on by default self . __jpeg_compression_fastupsample = False # fastupsample off by default self . __jpeg_compression_colorspace = \"BGR\" # use BGR colorspace by default self . __logging = logging self . __frame_size_reduction = 25 # use 25% reduction # retrieve interpolation for reduction self . __interpolation = retrieve_best_interpolation ( [ \"INTER_LINEAR_EXACT\" , \"INTER_LINEAR\" , \"INTER_AREA\" ] ) custom_data_location = \"\" # path to save data-files to custom location data_path = \"\" # path to WebGear data-files overwrite_default = False self . __enable_inf = False # continue frames even when video ends. # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # assign values to global variables if specified and valid if options : if \"jpeg_compression_colorspace\" in options : value = options [ \"jpeg_compression_colorspace\" ] if isinstance ( value , str ) and value . strip () . upper () in [ \"RGB\" , \"BGR\" , \"RGBX\" , \"BGRX\" , \"XBGR\" , \"XRGB\" , \"GRAY\" , \"RGBA\" , \"BGRA\" , \"ABGR\" , \"ARGB\" , \"CMYK\" , ]: # set encoding colorspace self . __jpeg_compression_colorspace = value . strip () . upper () else : logger . warning ( \"Skipped invalid `jpeg_compression_colorspace` value!\" ) del options [ \"jpeg_compression_colorspace\" ] # clean if \"jpeg_compression_quality\" in options : value = options [ \"jpeg_compression_quality\" ] # set valid jpeg quality if isinstance ( value , ( int , float )) and value >= 10 and value <= 100 : self . __jpeg_compression_quality = int ( value ) else : logger . warning ( \"Skipped invalid `jpeg_compression_quality` value!\" ) del options [ \"jpeg_compression_quality\" ] # clean if \"jpeg_compression_fastdct\" in options : value = options [ \"jpeg_compression_fastdct\" ] # enable jpeg fastdct if isinstance ( value , bool ): self . __jpeg_compression_fastdct = value else : logger . warning ( \"Skipped invalid `jpeg_compression_fastdct` value!\" ) del options [ \"jpeg_compression_fastdct\" ] # clean if \"jpeg_compression_fastupsample\" in options : value = options [ \"jpeg_compression_fastupsample\" ] # enable jpeg fastupsample if isinstance ( value , bool ): self . __jpeg_compression_fastupsample = value else : logger . warning ( \"Skipped invalid `jpeg_compression_fastupsample` value!\" ) del options [ \"jpeg_compression_fastupsample\" ] # clean if \"frame_size_reduction\" in options : value = options [ \"frame_size_reduction\" ] if isinstance ( value , ( int , float )) and value >= 0 and value <= 90 : self . __frame_size_reduction = value else : logger . warning ( \"Skipped invalid `frame_size_reduction` value!\" ) del options [ \"frame_size_reduction\" ] # clean if \"custom_data_location\" in options : value = options [ \"custom_data_location\" ] if isinstance ( value , str ): assert os . access ( value , os . W_OK ), \"[WebGear:ERROR] :: Permission Denied!, cannot write WebGear data-files to ' {} ' directory!\" . format ( value ) assert os . path . isdir ( os . path . abspath ( value ) ), \"[WebGear:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\" custom_data_location = os . path . abspath ( value ) else : logger . warning ( \"Skipped invalid `custom_data_location` value!\" ) del options [ \"custom_data_location\" ] # clean if \"overwrite_default_files\" in options : value = options [ \"overwrite_default_files\" ] if isinstance ( value , bool ): overwrite_default = value else : logger . warning ( \"Skipped invalid `overwrite_default_files` value!\" ) del options [ \"overwrite_default_files\" ] # clean if \"enable_infinite_frames\" in options : value = options [ \"enable_infinite_frames\" ] if isinstance ( value , bool ): self . __enable_inf = value else : logger . warning ( \"Skipped invalid `enable_infinite_frames` value!\" ) del options [ \"enable_infinite_frames\" ] # clean # check if custom certificates path is specified if custom_data_location : data_path = generate_webdata ( custom_data_location , c_name = \"webgear\" , overwrite_default = overwrite_default , logging = logging , ) else : # otherwise generate suitable path data_path = generate_webdata ( os . path . join ( expanduser ( \"~\" ), \".vidgear\" ), c_name = \"webgear\" , overwrite_default = overwrite_default , logging = logging , ) # log it self . __logging and logger . debug ( \"` {} ` is the default location for saving WebGear data-files.\" . format ( data_path ) ) # define Jinja2 templates handler self . __templates = Jinja2Templates ( directory = \" {} /templates\" . format ( data_path )) # define custom exception handlers self . __exception_handlers = { 404 : self . __not_found , 500 : self . __server_error } # define routing tables self . routes = [ Route ( \"/\" , endpoint = self . __homepage ), Route ( \"/video\" , endpoint = self . __video ), Mount ( \"/static\" , app = StaticFiles ( directory = \" {} /static\" . format ( data_path )), name = \"static\" , ), ] # define middleware support self . middleware = [] # Handle video source if source is None : self . config = { \"generator\" : None } self . __stream = None else : # define stream with necessary params self . __stream = VideoGear ( enablePiCamera = enablePiCamera , stabilize = stabilize , source = source , camera_num = camera_num , stream_mode = stream_mode , backend = backend , colorspace = colorspace , resolution = resolution , framerate = framerate , logging = logging , time_delay = time_delay , ** options ) # define default frame generator in configuration self . config = { \"generator\" : self . __producer } # log if specified if self . __logging : if source is None : logger . warning ( \"Given source is of NoneType. Therefore, JPEG Frame-Compression is disabled!\" ) else : logger . debug ( \"Enabling JPEG Frame-Compression with Colorspace:` {} `, Quality:` {} `%, Fastdct:` {} `, and Fastupsample:` {} `.\" . format ( self . __jpeg_compression_colorspace , self . __jpeg_compression_quality , \"enabled\" if self . __jpeg_compression_fastdct else \"disabled\" , \"enabled\" if self . __jpeg_compression_fastupsample else \"disabled\" , ) ) # copying original routing tables for further validation self . __rt_org_copy = self . routes [:] # initialize blank frame self . blank_frame = None # keeps check if producer loop should be running self . __isrunning = True","title":"__init__()"},{"location":"bonus/reference/webgear/#vidgear.gears.asyncio.webgear.WebGear.shutdown","text":"Implements a Callable to be run on application shutdown Source code in vidgear/gears/asyncio/webgear.py def shutdown ( self ): \"\"\" Implements a Callable to be run on application shutdown \"\"\" if not ( self . __stream is None ): self . __logging and logger . debug ( \"Closing Video Streaming.\" ) # stops producer self . __isrunning = False # stops VideoGear stream self . __stream . stop () # prevent any re-iteration self . __stream = None","title":"shutdown()"},{"location":"bonus/reference/webgear_rtc/","text":"WebGear_RTC API usage examples can be found here \u27b6 WebGear_RTC API parameters are explained here \u27b6 WebGear_RTC is similar to WeGear API in many aspects but utilizes WebRTC technology under the hood instead of Motion JPEG, which makes it suitable for building powerful video-streaming solutions for all modern browsers as well as native clients available on all major platforms. WebGear_RTC is implemented with the help of aiortc library which is built on top of asynchronous I/O framework for Web Real-Time Communication (WebRTC) and Object Real-Time Communication (ORTC) and supports many features like SDP generation/parsing, Interactive Connectivity Establishment with half-trickle and mDNS support, DTLS key and certificate generation, DTLS handshake, etc. WebGear_RTC can handle multiple consumers seamlessly and provides native support for ICE (Interactive Connectivity Establishment) protocol, STUN (Session Traversal Utilities for NAT), and TURN (Traversal Using Relays around NAT) servers that help us to easily establish direct media connection with the remote peers for uninterrupted data flow. It also allows us to define our custom Server as a source to transform frames easily before sending them across the network(see this doc example). WebGear_RTC API works in conjunction with Starlette ASGI application and can also flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc. Additionally, WebGear_RTC API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs. Source code in vidgear/gears/asyncio/webgear_rtc.py class WebGear_RTC : \"\"\" WebGear_RTC is similar to WeGear API in many aspects but utilizes WebRTC technology under the hood instead of Motion JPEG, which makes it suitable for building powerful video-streaming solutions for all modern browsers as well as native clients available on all major platforms. WebGear_RTC is implemented with the help of aiortc library which is built on top of asynchronous I/O framework for Web Real-Time Communication (WebRTC) and Object Real-Time Communication (ORTC) and supports many features like SDP generation/parsing, Interactive Connectivity Establishment with half-trickle and mDNS support, DTLS key and certificate generation, DTLS handshake, etc. WebGear_RTC can handle multiple consumers seamlessly and provides native support for ICE (Interactive Connectivity Establishment) protocol, STUN (Session Traversal Utilities for NAT), and TURN (Traversal Using Relays around NAT) servers that help us to easily establish direct media connection with the remote peers for uninterrupted data flow. It also allows us to define our custom Server as a source to transform frames easily before sending them across the network(see this doc example). WebGear_RTC API works in conjunction with Starlette ASGI application and can also flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc. Additionally, WebGear_RTC API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs. \"\"\" def __init__ ( self , enablePiCamera = False , stabilize = False , source = None , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the WebGear_RTC class. Parameters: enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of WebGear_RTC, CamGear, PiGear & Stabilizer. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"starlette\" if starlette is None else \"\" ) import_dependency_safe ( \"aiortc\" if aiortc is None else \"\" ) # initialize global params self . __logging = logging custom_data_location = \"\" # path to save data-files to custom location data_path = \"\" # path to WebGear_RTC data-files overwrite_default = False self . __relay = None # act as broadcaster # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # assign values to global variables if specified and valid if options : if \"custom_data_location\" in options : value = options [ \"custom_data_location\" ] if isinstance ( value , str ): assert os . access ( value , os . W_OK ), \"[WebGear_RTC:ERROR] :: Permission Denied!, cannot write WebGear_RTC data-files to ' {} ' directory!\" . format ( value ) assert os . path . isdir ( os . path . abspath ( value ) ), \"[WebGear_RTC:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\" custom_data_location = os . path . abspath ( value ) else : logger . warning ( \"Skipped invalid `custom_data_location` value!\" ) del options [ \"custom_data_location\" ] # clean if \"overwrite_default_files\" in options : value = options [ \"overwrite_default_files\" ] if isinstance ( value , bool ): overwrite_default = value else : logger . warning ( \"Skipped invalid `overwrite_default_files` value!\" ) del options [ \"overwrite_default_files\" ] # clean if \"enable_live_broadcast\" in options : value = options [ \"enable_live_broadcast\" ] if isinstance ( value , bool ): if value : self . __relay = MediaRelay () options [ \"enable_infinite_frames\" ] = True # enforce infinite frames logger . critical ( \"Enabled live broadcasting for Peer connection(s).\" ) else : None else : logger . warning ( \"Skipped invalid `enable_live_broadcast` value!\" ) del options [ \"enable_live_broadcast\" ] # clean # check if custom certificates path is specified if custom_data_location : data_path = generate_webdata ( custom_data_location , c_name = \"webgear_rtc\" , overwrite_default = overwrite_default , logging = logging , ) else : # otherwise generate suitable path data_path = generate_webdata ( os . path . join ( expanduser ( \"~\" ), \".vidgear\" ), c_name = \"webgear_rtc\" , overwrite_default = overwrite_default , logging = logging , ) # log it self . __logging and logger . debug ( \"` {} ` is the default location for saving WebGear_RTC data-files.\" . format ( data_path ) ) # define Jinja2 templates handler self . __templates = Jinja2Templates ( directory = \" {} /templates\" . format ( data_path )) # define custom exception handlers self . __exception_handlers = { 404 : self . __not_found , 500 : self . __server_error } # define routing tables self . routes = [ Route ( \"/\" , endpoint = self . __homepage ), Route ( \"/offer\" , self . __offer , methods = [ \"GET\" , \"POST\" ]), Mount ( \"/static\" , app = StaticFiles ( directory = \" {} /static\" . format ( data_path )), name = \"static\" , ), ] # define middleware support self . middleware = [] # Handle RTC video server if \"custom_stream\" in options or not ( source is None ): # Handle video source self . __default_rtc_server = RTC_VideoServer ( enablePiCamera = enablePiCamera , stabilize = stabilize , source = source , camera_num = camera_num , stream_mode = stream_mode , backend = backend , colorspace = colorspace , resolution = resolution , framerate = framerate , logging = logging , time_delay = time_delay , ** options ) # add exclusive reset connection node self . routes . append ( Route ( \"/close_connection\" , self . __reset_connections , methods = [ \"POST\" ]) ) else : raise ValueError ( \"[WebGear_RTC:ERROR] :: Source cannot be NoneType without Custom Stream(`custom_stream`) defined!\" ) # copying original routing tables for further validation self . __rt_org_copy = self . routes [:] # collects peer RTC connections self . __pcs = set () def __call__ ( self ): \"\"\" Implements a custom Callable method for WebGear_RTC application. \"\"\" # validate routing tables assert not ( self . routes is None ), \"Routing tables are NoneType!\" if not isinstance ( self . routes , list ) or not all ( x in self . routes for x in self . __rt_org_copy ): raise RuntimeError ( \"[WebGear_RTC:ERROR] :: Routing tables are not valid!\" ) # validate middlewares assert not ( self . middleware is None ), \"Middlewares are NoneType!\" if self . middleware and ( not isinstance ( self . middleware , list ) or not all ( isinstance ( x , Middleware ) for x in self . middleware ) ): raise RuntimeError ( \"[WebGear_RTC:ERROR] :: Middlewares are not valid!\" ) # return Starlette application self . __logging and logger . debug ( \"Running Starlette application.\" ) return Starlette ( debug = ( True if self . __logging else False ), routes = self . routes , middleware = self . middleware , exception_handlers = self . __exception_handlers , on_shutdown = [ self . __on_shutdown ], ) async def __offer ( self , request ): \"\"\" Generates JSON Response with a WebRTC Peer Connection of Video Server. \"\"\" # get offer from params params = await request . json () offer = RTCSessionDescription ( sdp = params [ \"sdp\" ], type = params [ \"type\" ]) # initiate stream if not ( self . __default_rtc_server is None ) and not ( self . __default_rtc_server . is_launched ): self . __logging and logger . debug ( \"Initiating Video Streaming.\" ) self . __default_rtc_server . launch () # setup RTC peer connection - interface represents a WebRTC connection # between the local computer and a remote peer. pc = RTCPeerConnection () self . __pcs . add ( pc ) self . __logging and logger . info ( \"Created WebRTC Peer Connection.\" ) # track ICE connection state changes @pc . on ( \"iceconnectionstatechange\" ) async def on_iceconnectionstatechange (): logger . debug ( \"ICE connection state is %s \" % pc . iceConnectionState ) if pc . iceConnectionState == \"failed\" : logger . error ( \"ICE connection state failed.\" ) # check if Live Broadcasting is enabled if self . __relay is None : # if not, close connection. await pc . close () self . __pcs . discard ( pc ) # Change the remote description associated with the connection. await pc . setRemoteDescription ( offer ) # retrieve list of RTCRtpTransceiver objects that are currently attached to the connection for t in pc . getTransceivers (): # Increments performance significantly, IDK why this works as H265 codec is not even supported :D capabilities = RTCRtpSender . getCapabilities ( \"video\" ) preferences = list ( filter ( lambda x : x . name == \"H265\" , capabilities . codecs )) t . setCodecPreferences ( preferences ) # add video server to peer track if t . kind == \"video\" : pc . addTrack ( self . __relay . subscribe ( self . __default_rtc_server ) if not ( self . __relay is None ) else self . __default_rtc_server ) # Create an SDP answer to an offer received from a remote peer answer = await pc . createAnswer () # Change the local description for the answer await pc . setLocalDescription ( answer ) # return Starlette json response return JSONResponse ( { \"sdp\" : pc . localDescription . sdp , \"type\" : pc . localDescription . type } ) async def __homepage ( self , request ): \"\"\" Return an HTML index page. \"\"\" return self . __templates . TemplateResponse ( \"index.html\" , { \"request\" : request }) async def __not_found ( self , request , exc ): \"\"\" Return an HTML 404 page. \"\"\" return self . __templates . TemplateResponse ( \"404.html\" , { \"request\" : request }, status_code = 404 ) async def __server_error ( self , request , exc ): \"\"\" Return an HTML 500 page. \"\"\" return self . __templates . TemplateResponse ( \"500.html\" , { \"request\" : request }, status_code = 500 ) async def __reset_connections ( self , request ): \"\"\" Resets all connections and recreates VideoServer timestamps \"\"\" # get additional parameter parameter = await request . json () # check if Live Broadcasting is enabled if ( self . __relay is None and not ( self . __default_rtc_server is None ) and ( self . __default_rtc_server . is_running ) ): logger . critical ( \"Resetting Server\" ) # close old peer connections if parameter != 0 : # disable if specified explicitly coros = [ pc . close () for pc in self . __pcs ] await asyncio . gather ( * coros ) self . __pcs . clear () await self . __default_rtc_server . reset () return PlainTextResponse ( \"OK\" ) else : # if does, then do nothing return PlainTextResponse ( \"DISABLED\" ) async def __on_shutdown ( self ): \"\"\" Implements a Callable to be run on application shutdown \"\"\" # close Video Server self . shutdown () # collects peer RTC connections coros = [ pc . close () for pc in self . __pcs ] await asyncio . gather ( * coros ) self . __pcs . clear () def shutdown ( self ): \"\"\" Gracefully shutdown video-server \"\"\" if not ( self . __default_rtc_server is None ): self . __logging and logger . debug ( \"Closing Video Server.\" ) self . __default_rtc_server . terminate () self . __default_rtc_server = None # terminate internal server aswell. self . __default_rtc_server = None __call__ ( self ) special \u2693 Implements a custom Callable method for WebGear_RTC application. Source code in vidgear/gears/asyncio/webgear_rtc.py def __call__ ( self ): \"\"\" Implements a custom Callable method for WebGear_RTC application. \"\"\" # validate routing tables assert not ( self . routes is None ), \"Routing tables are NoneType!\" if not isinstance ( self . routes , list ) or not all ( x in self . routes for x in self . __rt_org_copy ): raise RuntimeError ( \"[WebGear_RTC:ERROR] :: Routing tables are not valid!\" ) # validate middlewares assert not ( self . middleware is None ), \"Middlewares are NoneType!\" if self . middleware and ( not isinstance ( self . middleware , list ) or not all ( isinstance ( x , Middleware ) for x in self . middleware ) ): raise RuntimeError ( \"[WebGear_RTC:ERROR] :: Middlewares are not valid!\" ) # return Starlette application self . __logging and logger . debug ( \"Running Starlette application.\" ) return Starlette ( debug = ( True if self . __logging else False ), routes = self . routes , middleware = self . middleware , exception_handlers = self . __exception_handlers , on_shutdown = [ self . __on_shutdown ], ) __init__ ( self , enablePiCamera = False , stabilize = False , source = None , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , logging = False , time_delay = 0 , ** options ) special \u2693 This constructor method initializes the object state and attributes of the WebGear_RTC class. Parameters: Name Type Description Default enablePiCamera bool provide access to PiGear(if True) or CamGear(if False) APIs respectively. False stabilize bool enable access to Stabilizer Class for stabilizing frames. False camera_num int selects the camera module index which will be used as Rpi source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the Rpi source. (640, 480) framerate int/float sets the framerate of the Rpi source. 25 source based on input defines the source for the input stream. None stream_mode bool controls the exclusive YouTube Mode. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Tweak Parameters of WebGear_RTC, CamGear, PiGear & Stabilizer. {} Source code in vidgear/gears/asyncio/webgear_rtc.py def __init__ ( self , enablePiCamera = False , stabilize = False , source = None , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the WebGear_RTC class. Parameters: enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of WebGear_RTC, CamGear, PiGear & Stabilizer. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"starlette\" if starlette is None else \"\" ) import_dependency_safe ( \"aiortc\" if aiortc is None else \"\" ) # initialize global params self . __logging = logging custom_data_location = \"\" # path to save data-files to custom location data_path = \"\" # path to WebGear_RTC data-files overwrite_default = False self . __relay = None # act as broadcaster # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # assign values to global variables if specified and valid if options : if \"custom_data_location\" in options : value = options [ \"custom_data_location\" ] if isinstance ( value , str ): assert os . access ( value , os . W_OK ), \"[WebGear_RTC:ERROR] :: Permission Denied!, cannot write WebGear_RTC data-files to ' {} ' directory!\" . format ( value ) assert os . path . isdir ( os . path . abspath ( value ) ), \"[WebGear_RTC:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\" custom_data_location = os . path . abspath ( value ) else : logger . warning ( \"Skipped invalid `custom_data_location` value!\" ) del options [ \"custom_data_location\" ] # clean if \"overwrite_default_files\" in options : value = options [ \"overwrite_default_files\" ] if isinstance ( value , bool ): overwrite_default = value else : logger . warning ( \"Skipped invalid `overwrite_default_files` value!\" ) del options [ \"overwrite_default_files\" ] # clean if \"enable_live_broadcast\" in options : value = options [ \"enable_live_broadcast\" ] if isinstance ( value , bool ): if value : self . __relay = MediaRelay () options [ \"enable_infinite_frames\" ] = True # enforce infinite frames logger . critical ( \"Enabled live broadcasting for Peer connection(s).\" ) else : None else : logger . warning ( \"Skipped invalid `enable_live_broadcast` value!\" ) del options [ \"enable_live_broadcast\" ] # clean # check if custom certificates path is specified if custom_data_location : data_path = generate_webdata ( custom_data_location , c_name = \"webgear_rtc\" , overwrite_default = overwrite_default , logging = logging , ) else : # otherwise generate suitable path data_path = generate_webdata ( os . path . join ( expanduser ( \"~\" ), \".vidgear\" ), c_name = \"webgear_rtc\" , overwrite_default = overwrite_default , logging = logging , ) # log it self . __logging and logger . debug ( \"` {} ` is the default location for saving WebGear_RTC data-files.\" . format ( data_path ) ) # define Jinja2 templates handler self . __templates = Jinja2Templates ( directory = \" {} /templates\" . format ( data_path )) # define custom exception handlers self . __exception_handlers = { 404 : self . __not_found , 500 : self . __server_error } # define routing tables self . routes = [ Route ( \"/\" , endpoint = self . __homepage ), Route ( \"/offer\" , self . __offer , methods = [ \"GET\" , \"POST\" ]), Mount ( \"/static\" , app = StaticFiles ( directory = \" {} /static\" . format ( data_path )), name = \"static\" , ), ] # define middleware support self . middleware = [] # Handle RTC video server if \"custom_stream\" in options or not ( source is None ): # Handle video source self . __default_rtc_server = RTC_VideoServer ( enablePiCamera = enablePiCamera , stabilize = stabilize , source = source , camera_num = camera_num , stream_mode = stream_mode , backend = backend , colorspace = colorspace , resolution = resolution , framerate = framerate , logging = logging , time_delay = time_delay , ** options ) # add exclusive reset connection node self . routes . append ( Route ( \"/close_connection\" , self . __reset_connections , methods = [ \"POST\" ]) ) else : raise ValueError ( \"[WebGear_RTC:ERROR] :: Source cannot be NoneType without Custom Stream(`custom_stream`) defined!\" ) # copying original routing tables for further validation self . __rt_org_copy = self . routes [:] # collects peer RTC connections self . __pcs = set () shutdown ( self ) \u2693 Gracefully shutdown video-server Source code in vidgear/gears/asyncio/webgear_rtc.py def shutdown ( self ): \"\"\" Gracefully shutdown video-server \"\"\" if not ( self . __default_rtc_server is None ): self . __logging and logger . debug ( \"Closing Video Server.\" ) self . __default_rtc_server . terminate () self . __default_rtc_server = None # terminate internal server aswell. self . __default_rtc_server = None","title":"WebGear_RTC API"},{"location":"bonus/reference/webgear_rtc/#vidgear.gears.asyncio.webgear_rtc.WebGear_RTC.__call__","text":"Implements a custom Callable method for WebGear_RTC application. Source code in vidgear/gears/asyncio/webgear_rtc.py def __call__ ( self ): \"\"\" Implements a custom Callable method for WebGear_RTC application. \"\"\" # validate routing tables assert not ( self . routes is None ), \"Routing tables are NoneType!\" if not isinstance ( self . routes , list ) or not all ( x in self . routes for x in self . __rt_org_copy ): raise RuntimeError ( \"[WebGear_RTC:ERROR] :: Routing tables are not valid!\" ) # validate middlewares assert not ( self . middleware is None ), \"Middlewares are NoneType!\" if self . middleware and ( not isinstance ( self . middleware , list ) or not all ( isinstance ( x , Middleware ) for x in self . middleware ) ): raise RuntimeError ( \"[WebGear_RTC:ERROR] :: Middlewares are not valid!\" ) # return Starlette application self . __logging and logger . debug ( \"Running Starlette application.\" ) return Starlette ( debug = ( True if self . __logging else False ), routes = self . routes , middleware = self . middleware , exception_handlers = self . __exception_handlers , on_shutdown = [ self . __on_shutdown ], )","title":"__call__()"},{"location":"bonus/reference/webgear_rtc/#vidgear.gears.asyncio.webgear_rtc.WebGear_RTC.__init__","text":"This constructor method initializes the object state and attributes of the WebGear_RTC class. Parameters: Name Type Description Default enablePiCamera bool provide access to PiGear(if True) or CamGear(if False) APIs respectively. False stabilize bool enable access to Stabilizer Class for stabilizing frames. False camera_num int selects the camera module index which will be used as Rpi source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the Rpi source. (640, 480) framerate int/float sets the framerate of the Rpi source. 25 source based on input defines the source for the input stream. None stream_mode bool controls the exclusive YouTube Mode. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Tweak Parameters of WebGear_RTC, CamGear, PiGear & Stabilizer. {} Source code in vidgear/gears/asyncio/webgear_rtc.py def __init__ ( self , enablePiCamera = False , stabilize = False , source = None , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the WebGear_RTC class. Parameters: enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of WebGear_RTC, CamGear, PiGear & Stabilizer. \"\"\" # raise error(s) for critical Class imports import_dependency_safe ( \"starlette\" if starlette is None else \"\" ) import_dependency_safe ( \"aiortc\" if aiortc is None else \"\" ) # initialize global params self . __logging = logging custom_data_location = \"\" # path to save data-files to custom location data_path = \"\" # path to WebGear_RTC data-files overwrite_default = False self . __relay = None # act as broadcaster # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # assign values to global variables if specified and valid if options : if \"custom_data_location\" in options : value = options [ \"custom_data_location\" ] if isinstance ( value , str ): assert os . access ( value , os . W_OK ), \"[WebGear_RTC:ERROR] :: Permission Denied!, cannot write WebGear_RTC data-files to ' {} ' directory!\" . format ( value ) assert os . path . isdir ( os . path . abspath ( value ) ), \"[WebGear_RTC:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\" custom_data_location = os . path . abspath ( value ) else : logger . warning ( \"Skipped invalid `custom_data_location` value!\" ) del options [ \"custom_data_location\" ] # clean if \"overwrite_default_files\" in options : value = options [ \"overwrite_default_files\" ] if isinstance ( value , bool ): overwrite_default = value else : logger . warning ( \"Skipped invalid `overwrite_default_files` value!\" ) del options [ \"overwrite_default_files\" ] # clean if \"enable_live_broadcast\" in options : value = options [ \"enable_live_broadcast\" ] if isinstance ( value , bool ): if value : self . __relay = MediaRelay () options [ \"enable_infinite_frames\" ] = True # enforce infinite frames logger . critical ( \"Enabled live broadcasting for Peer connection(s).\" ) else : None else : logger . warning ( \"Skipped invalid `enable_live_broadcast` value!\" ) del options [ \"enable_live_broadcast\" ] # clean # check if custom certificates path is specified if custom_data_location : data_path = generate_webdata ( custom_data_location , c_name = \"webgear_rtc\" , overwrite_default = overwrite_default , logging = logging , ) else : # otherwise generate suitable path data_path = generate_webdata ( os . path . join ( expanduser ( \"~\" ), \".vidgear\" ), c_name = \"webgear_rtc\" , overwrite_default = overwrite_default , logging = logging , ) # log it self . __logging and logger . debug ( \"` {} ` is the default location for saving WebGear_RTC data-files.\" . format ( data_path ) ) # define Jinja2 templates handler self . __templates = Jinja2Templates ( directory = \" {} /templates\" . format ( data_path )) # define custom exception handlers self . __exception_handlers = { 404 : self . __not_found , 500 : self . __server_error } # define routing tables self . routes = [ Route ( \"/\" , endpoint = self . __homepage ), Route ( \"/offer\" , self . __offer , methods = [ \"GET\" , \"POST\" ]), Mount ( \"/static\" , app = StaticFiles ( directory = \" {} /static\" . format ( data_path )), name = \"static\" , ), ] # define middleware support self . middleware = [] # Handle RTC video server if \"custom_stream\" in options or not ( source is None ): # Handle video source self . __default_rtc_server = RTC_VideoServer ( enablePiCamera = enablePiCamera , stabilize = stabilize , source = source , camera_num = camera_num , stream_mode = stream_mode , backend = backend , colorspace = colorspace , resolution = resolution , framerate = framerate , logging = logging , time_delay = time_delay , ** options ) # add exclusive reset connection node self . routes . append ( Route ( \"/close_connection\" , self . __reset_connections , methods = [ \"POST\" ]) ) else : raise ValueError ( \"[WebGear_RTC:ERROR] :: Source cannot be NoneType without Custom Stream(`custom_stream`) defined!\" ) # copying original routing tables for further validation self . __rt_org_copy = self . routes [:] # collects peer RTC connections self . __pcs = set ()","title":"__init__()"},{"location":"bonus/reference/webgear_rtc/#vidgear.gears.asyncio.webgear_rtc.WebGear_RTC.shutdown","text":"Gracefully shutdown video-server Source code in vidgear/gears/asyncio/webgear_rtc.py def shutdown ( self ): \"\"\" Gracefully shutdown video-server \"\"\" if not ( self . __default_rtc_server is None ): self . __logging and logger . debug ( \"Closing Video Server.\" ) self . __default_rtc_server . terminate () self . __default_rtc_server = None # terminate internal server aswell. self . __default_rtc_server = None","title":"shutdown()"},{"location":"bonus/reference/writegear/","text":"WriteGear API usage examples for: Compression Mode \u27b6 and Non-Compression Mode \u27b6 WriteGear API parameters are explained for: Compression Mode \u27b6 and Non-Compression Mode \u27b6 WriteGear handles various powerful Video-Writer Tools that provide us the freedom to do almost anything imaginable with multimedia data. WriteGear API provides a complete, flexible, and robust wrapper around FFmpeg, a leading multimedia framework. WriteGear can process real-time frames into a lossless compressed video-file with any suitable specification (such asbitrate, codec, framerate, resolution, subtitles, etc.). It is powerful enough to perform complex tasks such as Live-Streaming (such as for Twitch) and Multiplexing Video-Audio with real-time frames in way fewer lines of code. Best of all, WriteGear grants users the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function without relying on any third-party API. In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API tools for video-frames encoding without compression. Modes of Operation WriteGear primarily operates in following modes: Compression Mode : In this mode, WriteGear utilizes powerful FFmpeg inbuilt encoders to encode lossless multimedia files. This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly, and while doing that it robustly handles all errors/warnings quietly. Non-Compression Mode : In this mode, WriteGear utilizes basic OpenCV's inbuilt VideoWriter API tools. This mode also supports all parameters manipulation available within VideoWriter API, but it lacks the ability to manipulate encoding parameters and other important features like video compression, audio encoding, etc. Source code in vidgear/gears/writegear.py class WriteGear : \"\"\" WriteGear handles various powerful Video-Writer Tools that provide us the freedom to do almost anything imaginable with multimedia data. WriteGear API provides a complete, flexible, and robust wrapper around FFmpeg, a leading multimedia framework. WriteGear can process real-time frames into a lossless compressed video-file with any suitable specification (such asbitrate, codec, framerate, resolution, subtitles, etc.). It is powerful enough to perform complex tasks such as Live-Streaming (such as for Twitch) and Multiplexing Video-Audio with real-time frames in way fewer lines of code. Best of all, WriteGear grants users the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function without relying on any third-party API. In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API tools for video-frames encoding without compression. ??? tip \"Modes of Operation\" WriteGear primarily operates in following modes: * **Compression Mode**: In this mode, WriteGear utilizes powerful **FFmpeg** inbuilt encoders to encode lossless multimedia files. This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly, and while doing that it robustly handles all errors/warnings quietly. * **Non-Compression Mode**: In this mode, WriteGear utilizes basic **OpenCV's inbuilt VideoWriter API** tools. This mode also supports all parameters manipulation available within VideoWriter API, but it lacks the ability to manipulate encoding parameters and other important features like video compression, audio encoding, etc. \"\"\" def __init__ ( self , output_filename = \"\" , compression_mode = True , custom_ffmpeg = \"\" , logging = False , ** output_params ): \"\"\" This constructor method initializes the object state and attributes of the WriteGear class. Parameters: output_filename (str): sets the valid filename/path/URL for the video output. compression_mode (bool): selects the WriteGear's Primary Mode of Operation. custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables. logging (bool): enables/disables logging. output_params (dict): provides the flexibility to control supported internal parameters and FFmpeg properities. \"\"\" # assign parameter values to class variables self . __compression = compression_mode self . __os_windows = ( True if os . name == \"nt\" else False ) # checks if machine in-use is running windows os or not # enable logging if specified self . __logging = False if logging : self . __logging = logging # initialize various important class variables self . __output_parameters = {} self . __inputheight = None self . __inputwidth = None self . __inputchannels = None self . __process = None # handle process to be frames written self . __cmd = \"\" # handle FFmpeg Pipe command self . __ffmpeg = \"\" # handle valid FFmpeg binaries location self . __initiate = ( True # initiate one time process for valid process initialization ) self . __out_file = None # handles output filename gstpipeline_support = False # handles GStreamer Pipeline Mode # handles output file name (if not given) if not output_filename : raise ValueError ( \"[WriteGear:ERROR] :: Kindly provide a valid `output_filename` value. Refer Docs for more information.\" ) else : # validate this class has the access rights to specified directory or not abs_path = os . path . abspath ( output_filename ) if check_WriteAccess ( os . path . dirname ( abs_path ), is_windows = self . __os_windows , logging = self . __logging , ): if os . path . isdir ( abs_path ): # check if given path is directory abs_path = os . path . join ( abs_path , \"VidGear- {} .mp4\" . format ( time . strftime ( \"%Y%m %d -%H%M%S\" )), ) # auto-assign valid name and adds it to path # assign output file absolute path to class variable self . __out_file = abs_path else : # log warning if logger . warning ( \"` {} ` isn't a valid system path or directory. Skipped!\" . format ( output_filename ) ) # cleans and reformat output parameters self . __output_parameters = { str ( k ) . strip (): str ( v ) . strip () if not isinstance ( v , ( list , tuple , int , float )) else v for k , v in output_params . items () } # handles FFmpeg binaries validity tests if self . __compression : if self . __logging : logger . debug ( \"Compression Mode is enabled therefore checking for valid FFmpeg executable.\" ) logger . debug ( \"Output Parameters: {} \" . format ( self . __output_parameters )) # handles where to save the downloaded FFmpeg Static Binaries on Windows(if specified) __ffmpeg_download_path = self . __output_parameters . pop ( \"-ffmpeg_download_path\" , \"\" ) if not isinstance ( __ffmpeg_download_path , ( str )): # reset improper values __ffmpeg_download_path = \"\" # handle user defined output dimensions(must be a tuple or list) self . __output_dimensions = self . __output_parameters . pop ( \"-output_dimensions\" , None ) if not isinstance ( self . __output_dimensions , ( list , tuple )): # reset improper values self . __output_dimensions = None # handle user defined framerate self . __inputframerate = self . __output_parameters . pop ( \"-input_framerate\" , 0.0 ) if not isinstance ( self . __inputframerate , ( float , int )): # reset improper values self . __inputframerate = 0.0 else : # must be float self . __inputframerate = float ( self . __inputframerate ) # handle user defined ffmpeg cmd preheaders(must be a list) self . __ffmpeg_preheaders = self . __output_parameters . pop ( \"-ffpreheaders\" , []) if not isinstance ( self . __ffmpeg_preheaders , list ): # reset improper values self . __ffmpeg_preheaders = [] # handle special-case force-termination in compression mode disable_force_termination = self . __output_parameters . pop ( \"-disable_force_termination\" , False if ( \"-i\" in self . __output_parameters ) else True , ) if isinstance ( disable_force_termination , bool ): self . __force_termination = not ( disable_force_termination ) else : # handle improper values self . __force_termination = ( True if ( \"-i\" in self . __output_parameters ) else False ) # validate the FFmpeg path/binaries and returns valid FFmpeg file # executable location (also downloads static binaries on windows) self . __ffmpeg = get_valid_ffmpeg_path ( custom_ffmpeg , self . __os_windows , ffmpeg_download_path = __ffmpeg_download_path , logging = self . __logging , ) # check if valid path returned if self . __ffmpeg : self . __logging and logger . debug ( \"Found valid FFmpeg executable: ` {} `.\" . format ( self . __ffmpeg ) ) else : # otherwise disable Compression Mode logger . warning ( \"Disabling Compression Mode since no valid FFmpeg executable found on this machine!\" ) if self . __logging and not self . __os_windows : logger . debug ( \"Kindly install working FFmpeg or provide a valid custom FFmpeg binary path. See docs for more info.\" ) self . __compression = False # compression mode disabled else : # handle GStreamer Pipeline Mode for non-compression mode if \"-gst_pipeline_mode\" in self . __output_parameters : if isinstance ( self . __output_parameters [ \"-gst_pipeline_mode\" ], bool ): gstpipeline_support = self . __output_parameters [ \"-gst_pipeline_mode\" ] and check_gstreamer_support ( logging = logging ) self . __logging and logger . debug ( \"GStreamer Pipeline Mode successfully activated!\" ) else : # reset improper values gstpipeline_support = False self . __logging and logger . warning ( \"GStreamer Pipeline Mode failed to activate!\" ) # display confirmation if logging is enabled/disabled if self . __compression and self . __ffmpeg : if self . __out_file is None : if ( platform . system () == \"Linux\" and pathlib . Path ( output_filename ) . is_char_device () ): # check if linux video device path (such as `/dev/video0`) self . __logging and logger . debug ( \"Path:` {} ` is a valid Linux Video Device path.\" . format ( output_filename ) ) self . __out_file = output_filename elif is_valid_url ( self . __ffmpeg , url = output_filename , logging = self . __logging ): # check whether url is valid instead self . __logging and logger . debug ( \"URL:` {} ` is valid and successfully configured for streaming.\" . format ( output_filename ) ) self . __out_file = output_filename else : raise ValueError ( \"[WriteGear:ERROR] :: output_filename value:` {} ` is not supported in Compression Mode.\" . format ( output_filename ) ) self . __force_termination and logger . debug ( \"Forced termination is enabled for this FFmpeg process.\" ) self . __logging and logger . debug ( \"Compression Mode with FFmpeg backend is configured properly.\" ) else : if self . __out_file is None : if gstpipeline_support : # enforce GStreamer backend self . __output_parameters [ \"-backend\" ] = \"CAP_GSTREAMER\" # assign original value self . __out_file = output_filename # log it self . __logging and logger . debug ( \"Non-Compression Mode is successfully configured in GStreamer Pipeline Mode.\" ) else : raise ValueError ( \"[WriteGear:ERROR] :: output_filename value:` {} ` is not supported in Non-Compression Mode.\" . format ( output_filename ) ) logger . critical ( \"Compression Mode is disabled, Activating OpenCV built-in Writer!\" ) def write ( self , frame , rgb_mode = False ): \"\"\" Pipelines `ndarray` frames to respective API _(FFmpeg in Compression Mode & OpenCV VideoWriter API in Non-Compression Mode)_. Parameters: frame (ndarray): a valid numpy frame rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format(instead of default BGR)_. \"\"\" if frame is None : # None-Type frames will be skipped return # get height, width and number of channels of current frame height , width = frame . shape [: 2 ] channels = frame . shape [ - 1 ] if frame . ndim == 3 else 1 # assign values to class variables on first run if self . __initiate : self . __inputheight = height self . __inputwidth = width self . __inputchannels = channels self . __logging and logger . debug ( \"InputFrame => Height: {} Width: {} Channels: {} \" . format ( self . __inputheight , self . __inputwidth , self . __inputchannels ) ) # validate size of frame if height != self . __inputheight or width != self . __inputwidth : raise ValueError ( \"[WriteGear:ERROR] :: All video-frames must have same size!\" ) # validate number of channels if channels != self . __inputchannels : raise ValueError ( \"[WriteGear:ERROR] :: All video-frames must have same number of channels!\" ) if self . __compression : # checks if compression mode is enabled # initiate FFmpeg process on first run if self . __initiate : # start pre-processing and initiate process self . __Preprocess ( channels , rgb = rgb_mode ) # Check status of the process assert self . __process is not None # write the frame try : self . __process . stdin . write ( frame . tobytes ()) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only else : # otherwise initiate OpenCV's VideoWriter Class if self . __initiate : # start VideoWriter Class process self . __startCV_Process () # Check status of the process assert self . __process is not None # log OpenCV warning self . __logging and logger . info ( \"RGBA and 16-bit grayscale video frames are not supported by OpenCV yet, switch to `compression_mode` to use them!\" ) # write the frame self . __process . write ( frame ) def __Preprocess ( self , channels , rgb = False ): \"\"\" Internal method that pre-processes FFmpeg Parameters before beginning pipelining. Parameters: channels (int): Number of channels rgb_mode (boolean): activates RGB mode _(if enabled)_. \"\"\" # turn off initiate flag self . __initiate = False # initialize input parameters input_parameters = {} # handle dimensions dimensions = \"\" if self . __output_dimensions is None : # check if dimensions are given dimensions += \" {} x {} \" . format ( self . __inputwidth , self . __inputheight ) # auto derive from frame else : dimensions += \" {} x {} \" . format ( self . __output_dimensions [ 0 ], self . __output_dimensions [ 1 ] ) # apply if defined input_parameters [ \"-s\" ] = str ( dimensions ) # handles pix_fmt based on channels(HACK) if channels == 1 : input_parameters [ \"-pix_fmt\" ] = \"gray\" elif channels == 2 : input_parameters [ \"-pix_fmt\" ] = \"ya8\" elif channels == 3 : input_parameters [ \"-pix_fmt\" ] = \"rgb24\" if rgb else \"bgr24\" elif channels == 4 : input_parameters [ \"-pix_fmt\" ] = \"rgba\" if rgb else \"bgra\" else : raise ValueError ( \"[WriteGear:ERROR] :: Frames with channels outside range 1-to-4 are not supported!\" ) if self . __inputframerate > 0 : # set input framerate self . __logging and logger . debug ( \"Setting Input framerate: {} \" . format ( self . __inputframerate ) ) input_parameters [ \"-framerate\" ] = str ( self . __inputframerate ) # initiate FFmpeg process self . __startFFmpeg_Process ( input_params = input_parameters , output_params = self . __output_parameters ) def __startFFmpeg_Process ( self , input_params , output_params ): \"\"\" An Internal method that launches FFmpeg subprocess, that pipelines frames to stdin, in Compression Mode. Parameters: input_params (dict): Input FFmpeg parameters output_params (dict): Output FFmpeg parameters \"\"\" # convert input parameters to list input_parameters = dict2Args ( input_params ) # dynamically pre-assign a default video-encoder (if not assigned by user). supported_vcodecs = get_supported_vencoders ( self . __ffmpeg ) default_vcodec = [ vcodec for vcodec in [ \"libx264\" , \"libx265\" , \"libxvid\" , \"mpeg4\" ] if vcodec in supported_vcodecs ][ 0 ] or \"unknown\" if \"-c:v\" in output_params : output_params [ \"-vcodec\" ] = output_params . pop ( \"-c:v\" , default_vcodec ) if not \"-vcodec\" in output_params : output_params [ \"-vcodec\" ] = default_vcodec if ( default_vcodec != \"unknown\" and not output_params [ \"-vcodec\" ] in supported_vcodecs ): logger . critical ( \"Provided FFmpeg does not support ` {} ` video-encoder. Switching to default supported ` {} ` encoder!\" . format ( output_params [ \"-vcodec\" ], default_vcodec ) ) output_params [ \"-vcodec\" ] = default_vcodec # assign optimizations if output_params [ \"-vcodec\" ] in supported_vcodecs : if output_params [ \"-vcodec\" ] in [ \"libx265\" , \"libx264\" ]: if not \"-crf\" in output_params : output_params [ \"-crf\" ] = \"18\" if not \"-preset\" in output_params : output_params [ \"-preset\" ] = \"fast\" if output_params [ \"-vcodec\" ] in [ \"libxvid\" , \"mpeg4\" ]: if not \"-qscale:v\" in output_params : output_params [ \"-qscale:v\" ] = \"3\" else : raise RuntimeError ( \"[WriteGear:ERROR] :: Provided FFmpeg does not support any suitable/usable video-encoders for compression.\" \" Kindly disable compression mode or switch to another FFmpeg binaries(if available).\" ) # convert output parameters to list output_parameters = dict2Args ( output_params ) # format command cmd = ( [ self . __ffmpeg , \"-y\" ] + self . __ffmpeg_preheaders + [ \"-f\" , \"rawvideo\" , \"-vcodec\" , \"rawvideo\" ] + input_parameters + [ \"-i\" , \"-\" ] + output_parameters + [ self . __out_file ] ) # assign value to class variable self . __cmd += \" \" . join ( cmd ) # Launch the FFmpeg process if self . __logging : logger . debug ( \"Executing FFmpeg command: ` {} `\" . format ( self . __cmd )) # In debugging mode self . __process = sp . Popen ( cmd , stdin = sp . PIPE , stdout = sp . PIPE , stderr = None ) else : # In silent mode self . __process = sp . Popen ( cmd , stdin = sp . PIPE , stdout = sp . DEVNULL , stderr = sp . STDOUT ) def execute_ffmpeg_cmd ( self , cmd = None ): \"\"\" Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only). Parameters: cmd (list): inputs list data-type command. \"\"\" # check if valid command if cmd is None or not ( cmd ): logger . warning ( \"Input FFmpeg command is empty, Nothing to execute!\" ) return else : if not ( isinstance ( cmd , list )): raise ValueError ( \"[WriteGear:ERROR] :: Invalid input FFmpeg command datatype! Kindly read docs.\" ) # check if Compression Mode is enabled if not ( self . __compression ): raise RuntimeError ( \"[WriteGear:ERROR] :: Compression Mode is disabled, Kindly enable it to access this function.\" ) # add configured FFmpeg path cmd = [ self . __ffmpeg ] + cmd try : # write to pipeline if self . __logging : logger . debug ( \"Executing FFmpeg command: ` {} `\" . format ( \" \" . join ( cmd ))) # In debugging mode sp . run ( cmd , stdin = sp . PIPE , stdout = sp . PIPE , stderr = None ) else : sp . run ( cmd , stdin = sp . PIPE , stdout = sp . DEVNULL , stderr = sp . STDOUT ) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong command passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only def __startCV_Process ( self ): \"\"\" An Internal method that launches OpenCV VideoWriter process for given settings, in Non-Compression Mode. \"\"\" # turn off initiate flag self . __initiate = False # initialize essential parameter variables FPS = 0 BACKEND = \"\" FOURCC = 0 COLOR = True # pre-assign default encoder parameters (if not assigned by user). if \"-fourcc\" not in self . __output_parameters : FOURCC = cv2 . VideoWriter_fourcc ( * \"MJPG\" ) if \"-fps\" not in self . __output_parameters : FPS = 25 # auto assign dimensions HEIGHT = self . __inputheight WIDTH = self . __inputwidth # assign parameter dict values to variables try : for key , value in self . __output_parameters . items (): if key == \"-fourcc\" : FOURCC = cv2 . VideoWriter_fourcc ( * ( value . upper ())) elif key == \"-fps\" : FPS = int ( value ) elif key == \"-backend\" : BACKEND = capPropId ( value . upper ()) elif key == \"-color\" : COLOR = bool ( value ) else : pass except Exception as e : # log if something is wrong self . __logging and logger . exception ( str ( e )) raise ValueError ( \"[WriteGear:ERROR] :: Wrong Values passed to OpenCV Writer, Kindly Refer Docs!\" ) if self . __logging : # log values for debugging logger . debug ( \"FILE_PATH: {} , FOURCC = {} , FPS = {} , WIDTH = {} , HEIGHT = {} , BACKEND = {} \" . format ( self . __out_file , FOURCC , FPS , WIDTH , HEIGHT , BACKEND ) ) # start different process for with/without Backend. if BACKEND : self . __process = cv2 . VideoWriter ( self . __out_file , apiPreference = BACKEND , fourcc = FOURCC , fps = FPS , frameSize = ( WIDTH , HEIGHT ), isColor = COLOR , ) else : self . __process = cv2 . VideoWriter ( self . __out_file , fourcc = FOURCC , fps = FPS , frameSize = ( WIDTH , HEIGHT ), isColor = COLOR , ) assert ( self . __process . isOpened () ), \"[WriteGear:ERROR] :: Failed to intialize OpenCV Writer!\" def close ( self ): \"\"\" Safely terminates various WriteGear process. \"\"\" if self . __logging : logger . debug ( \"Terminating WriteGear Processes.\" ) if self . __compression : # if Compression Mode is enabled if self . __process is None or not ( self . __process . poll () is None ): return # no process was initiated at first place if self . __process . stdin : self . __process . stdin . close () # close `stdin` output if self . __force_termination : self . __process . terminate () self . __process . wait () # wait if still process is still processing some information self . __process = None else : # if Compression Mode is disabled if self . __process is None : return # no process was initiated at first place self . __process . release () # close it __init__ ( self , output_filename = '' , compression_mode = True , custom_ffmpeg = '' , logging = False , ** output_params ) special \u2693 This constructor method initializes the object state and attributes of the WriteGear class. Parameters: Name Type Description Default output_filename str sets the valid filename/path/URL for the video output. '' compression_mode bool selects the WriteGear's Primary Mode of Operation. True custom_ffmpeg str assigns the location of custom path/directory for custom FFmpeg executables. '' logging bool enables/disables logging. False output_params dict provides the flexibility to control supported internal parameters and FFmpeg properities. {} Source code in vidgear/gears/writegear.py def __init__ ( self , output_filename = \"\" , compression_mode = True , custom_ffmpeg = \"\" , logging = False , ** output_params ): \"\"\" This constructor method initializes the object state and attributes of the WriteGear class. Parameters: output_filename (str): sets the valid filename/path/URL for the video output. compression_mode (bool): selects the WriteGear's Primary Mode of Operation. custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables. logging (bool): enables/disables logging. output_params (dict): provides the flexibility to control supported internal parameters and FFmpeg properities. \"\"\" # assign parameter values to class variables self . __compression = compression_mode self . __os_windows = ( True if os . name == \"nt\" else False ) # checks if machine in-use is running windows os or not # enable logging if specified self . __logging = False if logging : self . __logging = logging # initialize various important class variables self . __output_parameters = {} self . __inputheight = None self . __inputwidth = None self . __inputchannels = None self . __process = None # handle process to be frames written self . __cmd = \"\" # handle FFmpeg Pipe command self . __ffmpeg = \"\" # handle valid FFmpeg binaries location self . __initiate = ( True # initiate one time process for valid process initialization ) self . __out_file = None # handles output filename gstpipeline_support = False # handles GStreamer Pipeline Mode # handles output file name (if not given) if not output_filename : raise ValueError ( \"[WriteGear:ERROR] :: Kindly provide a valid `output_filename` value. Refer Docs for more information.\" ) else : # validate this class has the access rights to specified directory or not abs_path = os . path . abspath ( output_filename ) if check_WriteAccess ( os . path . dirname ( abs_path ), is_windows = self . __os_windows , logging = self . __logging , ): if os . path . isdir ( abs_path ): # check if given path is directory abs_path = os . path . join ( abs_path , \"VidGear- {} .mp4\" . format ( time . strftime ( \"%Y%m %d -%H%M%S\" )), ) # auto-assign valid name and adds it to path # assign output file absolute path to class variable self . __out_file = abs_path else : # log warning if logger . warning ( \"` {} ` isn't a valid system path or directory. Skipped!\" . format ( output_filename ) ) # cleans and reformat output parameters self . __output_parameters = { str ( k ) . strip (): str ( v ) . strip () if not isinstance ( v , ( list , tuple , int , float )) else v for k , v in output_params . items () } # handles FFmpeg binaries validity tests if self . __compression : if self . __logging : logger . debug ( \"Compression Mode is enabled therefore checking for valid FFmpeg executable.\" ) logger . debug ( \"Output Parameters: {} \" . format ( self . __output_parameters )) # handles where to save the downloaded FFmpeg Static Binaries on Windows(if specified) __ffmpeg_download_path = self . __output_parameters . pop ( \"-ffmpeg_download_path\" , \"\" ) if not isinstance ( __ffmpeg_download_path , ( str )): # reset improper values __ffmpeg_download_path = \"\" # handle user defined output dimensions(must be a tuple or list) self . __output_dimensions = self . __output_parameters . pop ( \"-output_dimensions\" , None ) if not isinstance ( self . __output_dimensions , ( list , tuple )): # reset improper values self . __output_dimensions = None # handle user defined framerate self . __inputframerate = self . __output_parameters . pop ( \"-input_framerate\" , 0.0 ) if not isinstance ( self . __inputframerate , ( float , int )): # reset improper values self . __inputframerate = 0.0 else : # must be float self . __inputframerate = float ( self . __inputframerate ) # handle user defined ffmpeg cmd preheaders(must be a list) self . __ffmpeg_preheaders = self . __output_parameters . pop ( \"-ffpreheaders\" , []) if not isinstance ( self . __ffmpeg_preheaders , list ): # reset improper values self . __ffmpeg_preheaders = [] # handle special-case force-termination in compression mode disable_force_termination = self . __output_parameters . pop ( \"-disable_force_termination\" , False if ( \"-i\" in self . __output_parameters ) else True , ) if isinstance ( disable_force_termination , bool ): self . __force_termination = not ( disable_force_termination ) else : # handle improper values self . __force_termination = ( True if ( \"-i\" in self . __output_parameters ) else False ) # validate the FFmpeg path/binaries and returns valid FFmpeg file # executable location (also downloads static binaries on windows) self . __ffmpeg = get_valid_ffmpeg_path ( custom_ffmpeg , self . __os_windows , ffmpeg_download_path = __ffmpeg_download_path , logging = self . __logging , ) # check if valid path returned if self . __ffmpeg : self . __logging and logger . debug ( \"Found valid FFmpeg executable: ` {} `.\" . format ( self . __ffmpeg ) ) else : # otherwise disable Compression Mode logger . warning ( \"Disabling Compression Mode since no valid FFmpeg executable found on this machine!\" ) if self . __logging and not self . __os_windows : logger . debug ( \"Kindly install working FFmpeg or provide a valid custom FFmpeg binary path. See docs for more info.\" ) self . __compression = False # compression mode disabled else : # handle GStreamer Pipeline Mode for non-compression mode if \"-gst_pipeline_mode\" in self . __output_parameters : if isinstance ( self . __output_parameters [ \"-gst_pipeline_mode\" ], bool ): gstpipeline_support = self . __output_parameters [ \"-gst_pipeline_mode\" ] and check_gstreamer_support ( logging = logging ) self . __logging and logger . debug ( \"GStreamer Pipeline Mode successfully activated!\" ) else : # reset improper values gstpipeline_support = False self . __logging and logger . warning ( \"GStreamer Pipeline Mode failed to activate!\" ) # display confirmation if logging is enabled/disabled if self . __compression and self . __ffmpeg : if self . __out_file is None : if ( platform . system () == \"Linux\" and pathlib . Path ( output_filename ) . is_char_device () ): # check if linux video device path (such as `/dev/video0`) self . __logging and logger . debug ( \"Path:` {} ` is a valid Linux Video Device path.\" . format ( output_filename ) ) self . __out_file = output_filename elif is_valid_url ( self . __ffmpeg , url = output_filename , logging = self . __logging ): # check whether url is valid instead self . __logging and logger . debug ( \"URL:` {} ` is valid and successfully configured for streaming.\" . format ( output_filename ) ) self . __out_file = output_filename else : raise ValueError ( \"[WriteGear:ERROR] :: output_filename value:` {} ` is not supported in Compression Mode.\" . format ( output_filename ) ) self . __force_termination and logger . debug ( \"Forced termination is enabled for this FFmpeg process.\" ) self . __logging and logger . debug ( \"Compression Mode with FFmpeg backend is configured properly.\" ) else : if self . __out_file is None : if gstpipeline_support : # enforce GStreamer backend self . __output_parameters [ \"-backend\" ] = \"CAP_GSTREAMER\" # assign original value self . __out_file = output_filename # log it self . __logging and logger . debug ( \"Non-Compression Mode is successfully configured in GStreamer Pipeline Mode.\" ) else : raise ValueError ( \"[WriteGear:ERROR] :: output_filename value:` {} ` is not supported in Non-Compression Mode.\" . format ( output_filename ) ) logger . critical ( \"Compression Mode is disabled, Activating OpenCV built-in Writer!\" ) close ( self ) \u2693 Safely terminates various WriteGear process. Source code in vidgear/gears/writegear.py def close ( self ): \"\"\" Safely terminates various WriteGear process. \"\"\" if self . __logging : logger . debug ( \"Terminating WriteGear Processes.\" ) if self . __compression : # if Compression Mode is enabled if self . __process is None or not ( self . __process . poll () is None ): return # no process was initiated at first place if self . __process . stdin : self . __process . stdin . close () # close `stdin` output if self . __force_termination : self . __process . terminate () self . __process . wait () # wait if still process is still processing some information self . __process = None else : # if Compression Mode is disabled if self . __process is None : return # no process was initiated at first place self . __process . release () # close it execute_ffmpeg_cmd ( self , cmd = None ) \u2693 Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only). Parameters: Name Type Description Default cmd list inputs list data-type command. None Source code in vidgear/gears/writegear.py def execute_ffmpeg_cmd ( self , cmd = None ): \"\"\" Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only). Parameters: cmd (list): inputs list data-type command. \"\"\" # check if valid command if cmd is None or not ( cmd ): logger . warning ( \"Input FFmpeg command is empty, Nothing to execute!\" ) return else : if not ( isinstance ( cmd , list )): raise ValueError ( \"[WriteGear:ERROR] :: Invalid input FFmpeg command datatype! Kindly read docs.\" ) # check if Compression Mode is enabled if not ( self . __compression ): raise RuntimeError ( \"[WriteGear:ERROR] :: Compression Mode is disabled, Kindly enable it to access this function.\" ) # add configured FFmpeg path cmd = [ self . __ffmpeg ] + cmd try : # write to pipeline if self . __logging : logger . debug ( \"Executing FFmpeg command: ` {} `\" . format ( \" \" . join ( cmd ))) # In debugging mode sp . run ( cmd , stdin = sp . PIPE , stdout = sp . PIPE , stderr = None ) else : sp . run ( cmd , stdin = sp . PIPE , stdout = sp . DEVNULL , stderr = sp . STDOUT ) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong command passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only write ( self , frame , rgb_mode = False ) \u2693 Pipelines ndarray frames to respective API (FFmpeg in Compression Mode & OpenCV VideoWriter API in Non-Compression Mode) . Parameters: Name Type Description Default frame ndarray a valid numpy frame required rgb_mode boolean enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format(instead of default BGR) . False Source code in vidgear/gears/writegear.py def write ( self , frame , rgb_mode = False ): \"\"\" Pipelines `ndarray` frames to respective API _(FFmpeg in Compression Mode & OpenCV VideoWriter API in Non-Compression Mode)_. Parameters: frame (ndarray): a valid numpy frame rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format(instead of default BGR)_. \"\"\" if frame is None : # None-Type frames will be skipped return # get height, width and number of channels of current frame height , width = frame . shape [: 2 ] channels = frame . shape [ - 1 ] if frame . ndim == 3 else 1 # assign values to class variables on first run if self . __initiate : self . __inputheight = height self . __inputwidth = width self . __inputchannels = channels self . __logging and logger . debug ( \"InputFrame => Height: {} Width: {} Channels: {} \" . format ( self . __inputheight , self . __inputwidth , self . __inputchannels ) ) # validate size of frame if height != self . __inputheight or width != self . __inputwidth : raise ValueError ( \"[WriteGear:ERROR] :: All video-frames must have same size!\" ) # validate number of channels if channels != self . __inputchannels : raise ValueError ( \"[WriteGear:ERROR] :: All video-frames must have same number of channels!\" ) if self . __compression : # checks if compression mode is enabled # initiate FFmpeg process on first run if self . __initiate : # start pre-processing and initiate process self . __Preprocess ( channels , rgb = rgb_mode ) # Check status of the process assert self . __process is not None # write the frame try : self . __process . stdin . write ( frame . tobytes ()) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only else : # otherwise initiate OpenCV's VideoWriter Class if self . __initiate : # start VideoWriter Class process self . __startCV_Process () # Check status of the process assert self . __process is not None # log OpenCV warning self . __logging and logger . info ( \"RGBA and 16-bit grayscale video frames are not supported by OpenCV yet, switch to `compression_mode` to use them!\" ) # write the frame self . __process . write ( frame )","title":"WriteGear API"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.__init__","text":"This constructor method initializes the object state and attributes of the WriteGear class. Parameters: Name Type Description Default output_filename str sets the valid filename/path/URL for the video output. '' compression_mode bool selects the WriteGear's Primary Mode of Operation. True custom_ffmpeg str assigns the location of custom path/directory for custom FFmpeg executables. '' logging bool enables/disables logging. False output_params dict provides the flexibility to control supported internal parameters and FFmpeg properities. {} Source code in vidgear/gears/writegear.py def __init__ ( self , output_filename = \"\" , compression_mode = True , custom_ffmpeg = \"\" , logging = False , ** output_params ): \"\"\" This constructor method initializes the object state and attributes of the WriteGear class. Parameters: output_filename (str): sets the valid filename/path/URL for the video output. compression_mode (bool): selects the WriteGear's Primary Mode of Operation. custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables. logging (bool): enables/disables logging. output_params (dict): provides the flexibility to control supported internal parameters and FFmpeg properities. \"\"\" # assign parameter values to class variables self . __compression = compression_mode self . __os_windows = ( True if os . name == \"nt\" else False ) # checks if machine in-use is running windows os or not # enable logging if specified self . __logging = False if logging : self . __logging = logging # initialize various important class variables self . __output_parameters = {} self . __inputheight = None self . __inputwidth = None self . __inputchannels = None self . __process = None # handle process to be frames written self . __cmd = \"\" # handle FFmpeg Pipe command self . __ffmpeg = \"\" # handle valid FFmpeg binaries location self . __initiate = ( True # initiate one time process for valid process initialization ) self . __out_file = None # handles output filename gstpipeline_support = False # handles GStreamer Pipeline Mode # handles output file name (if not given) if not output_filename : raise ValueError ( \"[WriteGear:ERROR] :: Kindly provide a valid `output_filename` value. Refer Docs for more information.\" ) else : # validate this class has the access rights to specified directory or not abs_path = os . path . abspath ( output_filename ) if check_WriteAccess ( os . path . dirname ( abs_path ), is_windows = self . __os_windows , logging = self . __logging , ): if os . path . isdir ( abs_path ): # check if given path is directory abs_path = os . path . join ( abs_path , \"VidGear- {} .mp4\" . format ( time . strftime ( \"%Y%m %d -%H%M%S\" )), ) # auto-assign valid name and adds it to path # assign output file absolute path to class variable self . __out_file = abs_path else : # log warning if logger . warning ( \"` {} ` isn't a valid system path or directory. Skipped!\" . format ( output_filename ) ) # cleans and reformat output parameters self . __output_parameters = { str ( k ) . strip (): str ( v ) . strip () if not isinstance ( v , ( list , tuple , int , float )) else v for k , v in output_params . items () } # handles FFmpeg binaries validity tests if self . __compression : if self . __logging : logger . debug ( \"Compression Mode is enabled therefore checking for valid FFmpeg executable.\" ) logger . debug ( \"Output Parameters: {} \" . format ( self . __output_parameters )) # handles where to save the downloaded FFmpeg Static Binaries on Windows(if specified) __ffmpeg_download_path = self . __output_parameters . pop ( \"-ffmpeg_download_path\" , \"\" ) if not isinstance ( __ffmpeg_download_path , ( str )): # reset improper values __ffmpeg_download_path = \"\" # handle user defined output dimensions(must be a tuple or list) self . __output_dimensions = self . __output_parameters . pop ( \"-output_dimensions\" , None ) if not isinstance ( self . __output_dimensions , ( list , tuple )): # reset improper values self . __output_dimensions = None # handle user defined framerate self . __inputframerate = self . __output_parameters . pop ( \"-input_framerate\" , 0.0 ) if not isinstance ( self . __inputframerate , ( float , int )): # reset improper values self . __inputframerate = 0.0 else : # must be float self . __inputframerate = float ( self . __inputframerate ) # handle user defined ffmpeg cmd preheaders(must be a list) self . __ffmpeg_preheaders = self . __output_parameters . pop ( \"-ffpreheaders\" , []) if not isinstance ( self . __ffmpeg_preheaders , list ): # reset improper values self . __ffmpeg_preheaders = [] # handle special-case force-termination in compression mode disable_force_termination = self . __output_parameters . pop ( \"-disable_force_termination\" , False if ( \"-i\" in self . __output_parameters ) else True , ) if isinstance ( disable_force_termination , bool ): self . __force_termination = not ( disable_force_termination ) else : # handle improper values self . __force_termination = ( True if ( \"-i\" in self . __output_parameters ) else False ) # validate the FFmpeg path/binaries and returns valid FFmpeg file # executable location (also downloads static binaries on windows) self . __ffmpeg = get_valid_ffmpeg_path ( custom_ffmpeg , self . __os_windows , ffmpeg_download_path = __ffmpeg_download_path , logging = self . __logging , ) # check if valid path returned if self . __ffmpeg : self . __logging and logger . debug ( \"Found valid FFmpeg executable: ` {} `.\" . format ( self . __ffmpeg ) ) else : # otherwise disable Compression Mode logger . warning ( \"Disabling Compression Mode since no valid FFmpeg executable found on this machine!\" ) if self . __logging and not self . __os_windows : logger . debug ( \"Kindly install working FFmpeg or provide a valid custom FFmpeg binary path. See docs for more info.\" ) self . __compression = False # compression mode disabled else : # handle GStreamer Pipeline Mode for non-compression mode if \"-gst_pipeline_mode\" in self . __output_parameters : if isinstance ( self . __output_parameters [ \"-gst_pipeline_mode\" ], bool ): gstpipeline_support = self . __output_parameters [ \"-gst_pipeline_mode\" ] and check_gstreamer_support ( logging = logging ) self . __logging and logger . debug ( \"GStreamer Pipeline Mode successfully activated!\" ) else : # reset improper values gstpipeline_support = False self . __logging and logger . warning ( \"GStreamer Pipeline Mode failed to activate!\" ) # display confirmation if logging is enabled/disabled if self . __compression and self . __ffmpeg : if self . __out_file is None : if ( platform . system () == \"Linux\" and pathlib . Path ( output_filename ) . is_char_device () ): # check if linux video device path (such as `/dev/video0`) self . __logging and logger . debug ( \"Path:` {} ` is a valid Linux Video Device path.\" . format ( output_filename ) ) self . __out_file = output_filename elif is_valid_url ( self . __ffmpeg , url = output_filename , logging = self . __logging ): # check whether url is valid instead self . __logging and logger . debug ( \"URL:` {} ` is valid and successfully configured for streaming.\" . format ( output_filename ) ) self . __out_file = output_filename else : raise ValueError ( \"[WriteGear:ERROR] :: output_filename value:` {} ` is not supported in Compression Mode.\" . format ( output_filename ) ) self . __force_termination and logger . debug ( \"Forced termination is enabled for this FFmpeg process.\" ) self . __logging and logger . debug ( \"Compression Mode with FFmpeg backend is configured properly.\" ) else : if self . __out_file is None : if gstpipeline_support : # enforce GStreamer backend self . __output_parameters [ \"-backend\" ] = \"CAP_GSTREAMER\" # assign original value self . __out_file = output_filename # log it self . __logging and logger . debug ( \"Non-Compression Mode is successfully configured in GStreamer Pipeline Mode.\" ) else : raise ValueError ( \"[WriteGear:ERROR] :: output_filename value:` {} ` is not supported in Non-Compression Mode.\" . format ( output_filename ) ) logger . critical ( \"Compression Mode is disabled, Activating OpenCV built-in Writer!\" )","title":"__init__()"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.close","text":"Safely terminates various WriteGear process. Source code in vidgear/gears/writegear.py def close ( self ): \"\"\" Safely terminates various WriteGear process. \"\"\" if self . __logging : logger . debug ( \"Terminating WriteGear Processes.\" ) if self . __compression : # if Compression Mode is enabled if self . __process is None or not ( self . __process . poll () is None ): return # no process was initiated at first place if self . __process . stdin : self . __process . stdin . close () # close `stdin` output if self . __force_termination : self . __process . terminate () self . __process . wait () # wait if still process is still processing some information self . __process = None else : # if Compression Mode is disabled if self . __process is None : return # no process was initiated at first place self . __process . release () # close it","title":"close()"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.execute_ffmpeg_cmd","text":"Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only). Parameters: Name Type Description Default cmd list inputs list data-type command. None Source code in vidgear/gears/writegear.py def execute_ffmpeg_cmd ( self , cmd = None ): \"\"\" Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only). Parameters: cmd (list): inputs list data-type command. \"\"\" # check if valid command if cmd is None or not ( cmd ): logger . warning ( \"Input FFmpeg command is empty, Nothing to execute!\" ) return else : if not ( isinstance ( cmd , list )): raise ValueError ( \"[WriteGear:ERROR] :: Invalid input FFmpeg command datatype! Kindly read docs.\" ) # check if Compression Mode is enabled if not ( self . __compression ): raise RuntimeError ( \"[WriteGear:ERROR] :: Compression Mode is disabled, Kindly enable it to access this function.\" ) # add configured FFmpeg path cmd = [ self . __ffmpeg ] + cmd try : # write to pipeline if self . __logging : logger . debug ( \"Executing FFmpeg command: ` {} `\" . format ( \" \" . join ( cmd ))) # In debugging mode sp . run ( cmd , stdin = sp . PIPE , stdout = sp . PIPE , stderr = None ) else : sp . run ( cmd , stdin = sp . PIPE , stdout = sp . DEVNULL , stderr = sp . STDOUT ) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong command passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only","title":"execute_ffmpeg_cmd()"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.write","text":"Pipelines ndarray frames to respective API (FFmpeg in Compression Mode & OpenCV VideoWriter API in Non-Compression Mode) . Parameters: Name Type Description Default frame ndarray a valid numpy frame required rgb_mode boolean enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format(instead of default BGR) . False Source code in vidgear/gears/writegear.py def write ( self , frame , rgb_mode = False ): \"\"\" Pipelines `ndarray` frames to respective API _(FFmpeg in Compression Mode & OpenCV VideoWriter API in Non-Compression Mode)_. Parameters: frame (ndarray): a valid numpy frame rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format(instead of default BGR)_. \"\"\" if frame is None : # None-Type frames will be skipped return # get height, width and number of channels of current frame height , width = frame . shape [: 2 ] channels = frame . shape [ - 1 ] if frame . ndim == 3 else 1 # assign values to class variables on first run if self . __initiate : self . __inputheight = height self . __inputwidth = width self . __inputchannels = channels self . __logging and logger . debug ( \"InputFrame => Height: {} Width: {} Channels: {} \" . format ( self . __inputheight , self . __inputwidth , self . __inputchannels ) ) # validate size of frame if height != self . __inputheight or width != self . __inputwidth : raise ValueError ( \"[WriteGear:ERROR] :: All video-frames must have same size!\" ) # validate number of channels if channels != self . __inputchannels : raise ValueError ( \"[WriteGear:ERROR] :: All video-frames must have same number of channels!\" ) if self . __compression : # checks if compression mode is enabled # initiate FFmpeg process on first run if self . __initiate : # start pre-processing and initiate process self . __Preprocess ( channels , rgb = rgb_mode ) # Check status of the process assert self . __process is not None # write the frame try : self . __process . stdin . write ( frame . tobytes ()) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only else : # otherwise initiate OpenCV's VideoWriter Class if self . __initiate : # start VideoWriter Class process self . __startCV_Process () # Check status of the process assert self . __process is not None # log OpenCV warning self . __logging and logger . info ( \"RGBA and 16-bit grayscale video frames are not supported by OpenCV yet, switch to `compression_mode` to use them!\" ) # write the frame self . __process . write ( frame )","title":"write()"},{"location":"contribution/PR/","text":"Submitting Pull Request(PR) Guidelines: \u2693 The following guidelines tells you how to submit a valid PR for vidGear: Working on your first Pull Request for VidGear? If you don't know how to contribute to an Open Source Project on GitHub, then You can learn about it from here \u27b6 If you're stuck at something, please join our Gitter community channel . We will help you get started! Kindly follow the EXEMPLARY tag for some finest PR examples. Clone Testing branch \u2693 Base Branch must be testing in your Pull Request Every PR MUST be pushed against VidGear's testing branch only, in order to trigger must needed CI testing workflows. If your's not, then change the base branch to testing \u27b6 Make sure the testing branch of your Forked repository is up-to-date with VidGear, before starting working on Pull Request. You can clone your Forked remote git to local and create your PR working branch as a sub-branch of latest testing branch as follows: Functions of different VidGear's Github Branches Following are the base branches for VidGear's code in its Github Repository: Master/Main Testing Development Branch Features: Most-Stable Includes the latest stable-release. Lacks any latest bug-fixes and changes. Everything CI tested. Cloning: # clone your forked repository and `cd` inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear Branch Features: Stable. Includes latest stable bug-fixes and changes. Used for pushing PR commits. Everything CI tested. Cloning: # clone your forked repository and `cd` inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing Branch Features: Unstable. Includes latest experimental changes. Used for pushing experimental commits. Nothing CI tested. Cloning: # clone your forked repository and `cd` inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest development branch git checkout development Workflow: Typically any feature/improvement/bug-fix code flows as follows: # clone your forked repository(change with your username) and get inside git clone https://github.com/ { YOUR USERNAME } /vidgear.git && cd vidgear # pull any recent updates git pull # checkout the latest testing branch git checkout testing # Now create your new branch with suitable name(such as \"subbranch_of_testing\") git checkout -b subbranch_of_testing Now after working with this newly created branch for your Pull Request, you can commit and push or merge it locally or remotely as usual. PR Submission Checklist \u2693 There are some important checks you need to perform while submitting your Pull Request(s) for VidGear library: Submit a Related Issue: The first thing you do is submit an issue with a proposal template for your work first and then work on your Pull Request. Submit a Draft Pull Request: Submit the draft pull request from the first day of your development. Add a brief but descriptive title for your PR. Explain what the PR adds, fixes, or improves. In case of bug fixes, add a new unit test case that would fail against your bug fix. Provide output or screenshots, if you can. Make sure your pull request passed all the CI checks (triggers automatically on pushing commits against testing branch) . If it's somehow failing, then ask the maintainer for a review. Click \"ready for review\" when finished. Test, Format & lint code locally: Make sure to test, format, and lint the modified code locally before every commit. The details are discussed below \u27b6 Make sensible commit messages: If your pull request fixes a separate issue number, remember to include \"resolves #issue_number\" in the commit message. Learn more about it here \u27b6 . Keep the commit message concisely as much as possible at every submit. You can make a supplement to the previous commit with git commit --amend command. Perform Integrity Checks: Any duplicate pull request will be Rejected! Search GitHub if there's a similar open or closed PR that relates to your submission. Check if your purpose code matches the overall direction, simplicity, and structure of the VidGear and improves it. Retain copyright for your contributions, but also agree to license them for usage by the project and author(s) under the Apache 2.0 license \u27b6 . Link your Issues: For more information on Linking a pull request to an issue, See this wiki doc\u27b6 Finally, when you're confident enough, make your pull request public. You can link an issue to a pull request manually or using a supported keyword in the pull request description. It helps collaborators see that someone is working on the issue. Testing, Formatting & Linting \u2693 All Pull Request(s) must be tested, formatted & linted against our library standards as discussed below: Requirements \u2693 Testing VidGear requires additional test dependencies and dataset, which can be handled manually as follows: Install additional python libraries: You can easily install these dependencies via pip: MPEGDASH for Windows The mpegdash library has not yet been updated and bugs on windows machines. Therefore install the forked DEV-version of mpegdash as follows: python -m pip install https://github.com/abhiTronix/python-mpegdash/releases/download/0.3.0-dev2/mpegdash-0.3.0.dev2-py3-none-any.whl pip install --upgrade six flake8 black pytest pytest-asyncio mpegdash paramiko m3u8 async-asgi-testclient Download Tests Dataset: To perform tests, you also need to download additional dataset (to your temp dir) by running prepare_dataset.sh bash script as follows: chmod +x scripts/bash/prepare_dataset.sh # On linux and MacOS .scripts/bash/prepare_dataset.sh # On Windows sh scripts/bash/prepare_dataset.sh Running Tests \u2693 All tests can be run with pytest ( in VidGear's root folder ) as follows: pytest -sv #-sv for verbose output. Formatting & Linting \u2693 For formatting and linting, following libraries are used: Flake8: You must run flake8 linting for checking the code base against the coding style (PEP8), programming errors and other cyclomatic complexity: flake8 { source_file_or_directory } --count --select = E9,F63,F7,F82 --show-source --statistics Black: Vidgear follows black formatting to make code review faster by producing the smallest diffs possible. You must run it with sensible defaults as follows: black { source_file_or_directory } Frequently Asked Questions \u2693 Q1. Why do my changes taking so long to be Reviewed and/or Merged? Submission Aftermaths After your PR is merged, you can safely delete your branch and pull the changes from the main (upstream) repository. The changes will remain in testing branch until next VidGear version is released, then it will be merged into master branch. After a successful Merge, your newer contributions will be given priority over others. Pull requests will be reviewed by the maintainers and the rationale behind the maintainer\u2019s decision to accept or deny the changes will be posted in the pull request. Please wait for our code review and approval, possibly enhancing your change on request. Q2. Would you accept a huge Pull Request with Lots of Changes? First, make sure that the changes are somewhat related. Otherwise, please create separate pull requests. Anyway, before submitting a huge change, it's probably a good idea to open an issue in the VidGear Github repository to ask the maintainers if they agree with your proposed changes. Otherwise, they could refuse your proposal after you put all that hard work into making the changes. We definitely don't want you to waste your time!","title":"Submitting Pull Request(PR) Guidelines"},{"location":"contribution/PR/#submitting-pull-requestpr-guidelines","text":"The following guidelines tells you how to submit a valid PR for vidGear: Working on your first Pull Request for VidGear? If you don't know how to contribute to an Open Source Project on GitHub, then You can learn about it from here \u27b6 If you're stuck at something, please join our Gitter community channel . We will help you get started! Kindly follow the EXEMPLARY tag for some finest PR examples.","title":"Submitting Pull Request(PR) Guidelines:"},{"location":"contribution/PR/#clone-testing-branch","text":"Base Branch must be testing in your Pull Request Every PR MUST be pushed against VidGear's testing branch only, in order to trigger must needed CI testing workflows. If your's not, then change the base branch to testing \u27b6 Make sure the testing branch of your Forked repository is up-to-date with VidGear, before starting working on Pull Request. You can clone your Forked remote git to local and create your PR working branch as a sub-branch of latest testing branch as follows: Functions of different VidGear's Github Branches Following are the base branches for VidGear's code in its Github Repository: Master/Main Testing Development Branch Features: Most-Stable Includes the latest stable-release. Lacks any latest bug-fixes and changes. Everything CI tested. Cloning: # clone your forked repository and `cd` inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear Branch Features: Stable. Includes latest stable bug-fixes and changes. Used for pushing PR commits. Everything CI tested. Cloning: # clone your forked repository and `cd` inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing Branch Features: Unstable. Includes latest experimental changes. Used for pushing experimental commits. Nothing CI tested. Cloning: # clone your forked repository and `cd` inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest development branch git checkout development Workflow: Typically any feature/improvement/bug-fix code flows as follows: # clone your forked repository(change with your username) and get inside git clone https://github.com/ { YOUR USERNAME } /vidgear.git && cd vidgear # pull any recent updates git pull # checkout the latest testing branch git checkout testing # Now create your new branch with suitable name(such as \"subbranch_of_testing\") git checkout -b subbranch_of_testing Now after working with this newly created branch for your Pull Request, you can commit and push or merge it locally or remotely as usual.","title":"Clone Testing branch"},{"location":"contribution/PR/#pr-submission-checklist","text":"There are some important checks you need to perform while submitting your Pull Request(s) for VidGear library: Submit a Related Issue: The first thing you do is submit an issue with a proposal template for your work first and then work on your Pull Request. Submit a Draft Pull Request: Submit the draft pull request from the first day of your development. Add a brief but descriptive title for your PR. Explain what the PR adds, fixes, or improves. In case of bug fixes, add a new unit test case that would fail against your bug fix. Provide output or screenshots, if you can. Make sure your pull request passed all the CI checks (triggers automatically on pushing commits against testing branch) . If it's somehow failing, then ask the maintainer for a review. Click \"ready for review\" when finished. Test, Format & lint code locally: Make sure to test, format, and lint the modified code locally before every commit. The details are discussed below \u27b6 Make sensible commit messages: If your pull request fixes a separate issue number, remember to include \"resolves #issue_number\" in the commit message. Learn more about it here \u27b6 . Keep the commit message concisely as much as possible at every submit. You can make a supplement to the previous commit with git commit --amend command. Perform Integrity Checks: Any duplicate pull request will be Rejected! Search GitHub if there's a similar open or closed PR that relates to your submission. Check if your purpose code matches the overall direction, simplicity, and structure of the VidGear and improves it. Retain copyright for your contributions, but also agree to license them for usage by the project and author(s) under the Apache 2.0 license \u27b6 . Link your Issues: For more information on Linking a pull request to an issue, See this wiki doc\u27b6 Finally, when you're confident enough, make your pull request public. You can link an issue to a pull request manually or using a supported keyword in the pull request description. It helps collaborators see that someone is working on the issue.","title":"PR Submission Checklist"},{"location":"contribution/PR/#testing-formatting-linting","text":"All Pull Request(s) must be tested, formatted & linted against our library standards as discussed below:","title":"Testing, Formatting &amp; Linting"},{"location":"contribution/PR/#requirements","text":"Testing VidGear requires additional test dependencies and dataset, which can be handled manually as follows: Install additional python libraries: You can easily install these dependencies via pip: MPEGDASH for Windows The mpegdash library has not yet been updated and bugs on windows machines. Therefore install the forked DEV-version of mpegdash as follows: python -m pip install https://github.com/abhiTronix/python-mpegdash/releases/download/0.3.0-dev2/mpegdash-0.3.0.dev2-py3-none-any.whl pip install --upgrade six flake8 black pytest pytest-asyncio mpegdash paramiko m3u8 async-asgi-testclient Download Tests Dataset: To perform tests, you also need to download additional dataset (to your temp dir) by running prepare_dataset.sh bash script as follows: chmod +x scripts/bash/prepare_dataset.sh # On linux and MacOS .scripts/bash/prepare_dataset.sh # On Windows sh scripts/bash/prepare_dataset.sh","title":"Requirements"},{"location":"contribution/PR/#running-tests","text":"All tests can be run with pytest ( in VidGear's root folder ) as follows: pytest -sv #-sv for verbose output.","title":"Running Tests"},{"location":"contribution/PR/#formatting-linting","text":"For formatting and linting, following libraries are used: Flake8: You must run flake8 linting for checking the code base against the coding style (PEP8), programming errors and other cyclomatic complexity: flake8 { source_file_or_directory } --count --select = E9,F63,F7,F82 --show-source --statistics Black: Vidgear follows black formatting to make code review faster by producing the smallest diffs possible. You must run it with sensible defaults as follows: black { source_file_or_directory }","title":"Formatting &amp; Linting"},{"location":"contribution/PR/#frequently-asked-questions","text":"Q1. Why do my changes taking so long to be Reviewed and/or Merged? Submission Aftermaths After your PR is merged, you can safely delete your branch and pull the changes from the main (upstream) repository. The changes will remain in testing branch until next VidGear version is released, then it will be merged into master branch. After a successful Merge, your newer contributions will be given priority over others. Pull requests will be reviewed by the maintainers and the rationale behind the maintainer\u2019s decision to accept or deny the changes will be posted in the pull request. Please wait for our code review and approval, possibly enhancing your change on request. Q2. Would you accept a huge Pull Request with Lots of Changes? First, make sure that the changes are somewhat related. Otherwise, please create separate pull requests. Anyway, before submitting a huge change, it's probably a good idea to open an issue in the VidGear Github repository to ask the maintainers if they agree with your proposed changes. Otherwise, they could refuse your proposal after you put all that hard work into making the changes. We definitely don't want you to waste your time!","title":"Frequently Asked Questions"},{"location":"contribution/issue/","text":"Submitting an Issue Guidelines \u2693 If you've found a new bug or you've come up with some new feature which can improve the quality of the VidGear, then related issues are welcomed! But, Before you do, please read the following guidelines: First Issue on GitHub? You can easily learn about it from creating an issue wiki. Info Please note that your issue will be fixed much faster if you spend about half an hour preparing it, including the exact reproduction steps and a demo. If you're in a hurry or don't feel confident, it's fine to report issues with less details, but this makes it less likely they'll get fixed soon. Search the Docs and Previous Issues \u2693 Remember to first search GitHub for a open or closed issue that relates to your submission or already been reported. You may find related information and the discussion might inform you of workarounds that may help to resolve the issue. For quick questions, please refrain from opening an issue, as you can reach us on Gitter community channel. Also, go comprehensively through our dedicated FAQ & Troubleshooting section . Gather Required Information \u2693 All VidGear APIs provides a logging boolean flag in parameters, to log debugged output to terminal. Kindly turn this parameter True in the respective API for getting debug output, and paste it with your Issue. In order to reproduce bugs we will systematically ask you to provide a minimal reproduction code for your report. Check and paste, exact VidGear version by running command python - c \"import vidgear; print(vidgear.__version__)\" . Follow the Issue Template \u2693 Please format your issue by choosing the appropriate template. Any improper/insufficient reports will be marked with MISSING : INFORMATION and MISSING : TEMPLATE like labels, and if we don't hear back from you we may close the issue. Raise the Issue \u2693 Add a brief but descriptive title for your issue. Keep the issue phrasing in context of the problem. Attach source-code/screenshots if you have one. Finally, raise it by choosing the appropriate Issue Template: Bug report , Proposal , Question .","title":"Submitting an Issue Guidelines"},{"location":"contribution/issue/#submitting-an-issue-guidelines","text":"If you've found a new bug or you've come up with some new feature which can improve the quality of the VidGear, then related issues are welcomed! But, Before you do, please read the following guidelines: First Issue on GitHub? You can easily learn about it from creating an issue wiki. Info Please note that your issue will be fixed much faster if you spend about half an hour preparing it, including the exact reproduction steps and a demo. If you're in a hurry or don't feel confident, it's fine to report issues with less details, but this makes it less likely they'll get fixed soon.","title":"Submitting an Issue Guidelines"},{"location":"contribution/issue/#search-the-docs-and-previous-issues","text":"Remember to first search GitHub for a open or closed issue that relates to your submission or already been reported. You may find related information and the discussion might inform you of workarounds that may help to resolve the issue. For quick questions, please refrain from opening an issue, as you can reach us on Gitter community channel. Also, go comprehensively through our dedicated FAQ & Troubleshooting section .","title":"Search the Docs and Previous Issues"},{"location":"contribution/issue/#gather-required-information","text":"All VidGear APIs provides a logging boolean flag in parameters, to log debugged output to terminal. Kindly turn this parameter True in the respective API for getting debug output, and paste it with your Issue. In order to reproduce bugs we will systematically ask you to provide a minimal reproduction code for your report. Check and paste, exact VidGear version by running command python - c \"import vidgear; print(vidgear.__version__)\" .","title":"Gather Required Information"},{"location":"contribution/issue/#follow-the-issue-template","text":"Please format your issue by choosing the appropriate template. Any improper/insufficient reports will be marked with MISSING : INFORMATION and MISSING : TEMPLATE like labels, and if we don't hear back from you we may close the issue.","title":"Follow the Issue Template"},{"location":"contribution/issue/#raise-the-issue","text":"Add a brief but descriptive title for your issue. Keep the issue phrasing in context of the problem. Attach source-code/screenshots if you have one. Finally, raise it by choosing the appropriate Issue Template: Bug report , Proposal , Question .","title":"Raise the Issue"},{"location":"gears/camgear/overview/","text":"CamGear API \u2693 CamGear API's generalized workflow Overview \u2693 CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format ( upto 4k tested ), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. In addition to this, it also supports Gstreamer's RAW pipelines and various live video streaming sites like YouTube, Twitch, Dailymotion etc. CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture API with direct access to almost all of its available parameters . It relies on Threaded Queue mode for threaded, error-free and synchronized frame handling. CamGear internally implements yt_dlp backend class for seamlessly pipelining live video-frames and metadata from various streaming services like YouTube , Twitch , and many more \u27b6 \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. You can use framerate class variable to retrieve framerate of the input source. Its usage example can be found here \u27b6 \u2009 Importing \u2693 You can import CamGear API in your program as follows: from vidgear.gears import CamGear \u2009 Usage Examples \u2693 See here \ud83d\ude80 After going through CamGear Usage Examples, Checkout more of its advanced configurations here \u27b6 Parameters \u2693 See here \ud83d\ude80 References \u2693 See here \ud83d\ude80 FAQs \u2693 See here \ud83d\ude80","title":"Overview"},{"location":"gears/camgear/overview/#camgear-api","text":"CamGear API's generalized workflow","title":"CamGear API"},{"location":"gears/camgear/overview/#overview","text":"CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format ( upto 4k tested ), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. In addition to this, it also supports Gstreamer's RAW pipelines and various live video streaming sites like YouTube, Twitch, Dailymotion etc. CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture API with direct access to almost all of its available parameters . It relies on Threaded Queue mode for threaded, error-free and synchronized frame handling. CamGear internally implements yt_dlp backend class for seamlessly pipelining live video-frames and metadata from various streaming services like YouTube , Twitch , and many more \u27b6 \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. You can use framerate class variable to retrieve framerate of the input source. Its usage example can be found here \u27b6","title":"Overview"},{"location":"gears/camgear/overview/#importing","text":"You can import CamGear API in your program as follows: from vidgear.gears import CamGear","title":"Importing"},{"location":"gears/camgear/overview/#usage-examples","text":"See here \ud83d\ude80 After going through CamGear Usage Examples, Checkout more of its advanced configurations here \u27b6","title":"Usage Examples"},{"location":"gears/camgear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/camgear/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/camgear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/camgear/params/","text":"CamGear API Parameters \u2693 \u2009 source \u2693 CamGear API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: CamGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: CamGear ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled(i.e. stream_mode=True ): CamGear internally implements yt_dlp backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 CamGear ( source = 'https://www.twitch.tv/shroud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: CamGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining GStreamer Pipelining in WriteGear your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: CamGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' ) stream_mode \u2693 This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the CamGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 CamGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 . colorspace \u2693 This parameter selects the colorspace of the input stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 CamGear ( source = 0 , colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 backend \u2693 This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: CamGear ( source = 0 , backend = cv2 . CAP_DSHOW ) options \u2693 This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to CamGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it CamGear ( source = 0 , ** options ) logging \u2693 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: CamGear ( source = 0 , logging = True ) time_delay \u2693 This parameter set the time delay (in seconds) before the CamGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: CamGear ( source = 0 , time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/camgear/params/#camgear-api-parameters","text":"","title":"CamGear API Parameters"},{"location":"gears/camgear/params/#source","text":"CamGear API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: CamGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: CamGear ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled(i.e. stream_mode=True ): CamGear internally implements yt_dlp backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 CamGear ( source = 'https://www.twitch.tv/shroud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: CamGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining GStreamer Pipelining in WriteGear your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: CamGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' )","title":"source"},{"location":"gears/camgear/params/#stream_mode","text":"This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the CamGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 CamGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 .","title":"stream_mode"},{"location":"gears/camgear/params/#colorspace","text":"This parameter selects the colorspace of the input stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 CamGear ( source = 0 , colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/camgear/params/#backend","text":"This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: CamGear ( source = 0 , backend = cv2 . CAP_DSHOW )","title":"backend"},{"location":"gears/camgear/params/#options","text":"This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to CamGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it CamGear ( source = 0 , ** options )","title":"options"},{"location":"gears/camgear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: CamGear ( source = 0 , logging = True )","title":"logging"},{"location":"gears/camgear/params/#time_delay","text":"This parameter set the time delay (in seconds) before the CamGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: CamGear ( source = 0 , time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/camgear/usage/","text":"CamGear API Usage Examples: \u2693 After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6 \u2009 Bare-Minimum Usage \u2693 Following is the bare-minimum code you need to get started with CamGear API: # import required libraries from vidgear.gears import CamGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = \"myvideo.avi\" ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using Camgear with Streaming Websites \u2693 CamGear internally implements yt_dlp backend class for seamlessly pipelining live video-frames and metadata from various streaming services like Twitch , Vimeo , Dailymotion , and many more \u27b6 . All you have to do is to provide the desired Video's URL to its source parameter, and enable its stream_mode parameter. The complete usage example for Dailymotion and Twitch URLs are as follows: Bug in OpenCV's FFmpeg To workaround a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for Livestream videos. Checkout this FAQ \u27b6 for compiling OpenCV with GStreamer support. Not all resolutions are supported with GStreamer Backend. See issue #244 Exclusive CamGear Attributes for yt_dlp backend CamGear also provides exclusive attributes: STREAM_RESOLUTION (for specifying stream resolution) STREAM_PARAMS (for specifying yt_dlp parameters) with its options dictionary parameter. More information can be found here \u27b6 Supported Streaming Websites The list of all supported Streaming Websites URLs can be found here \u27b6 Accessing Stream's Metadata CamGear now provides ytv_metadata global parameter for accessing given Video's metadata as JSON Object. It can used as follows: New in v0.2.4 ytv_metadata global parameter was added in v0.2.4 . # import required libraries from vidgear.gears import CamGear # Add YouTube Video URL as input source (for e.g https://www.dailymotion.com/video/x2yrnum) # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://www.dailymotion.com/video/x2yrnum\" , stream_mode = True , logging = True , ** options ) . start () # get Video's metadata as JSON object video_metadata = stream . ytv_metadata # print all available keys print ( video_metadata . keys ()) # get data like `title` print ( video_metadata [ \"title\" ]) Dailymotion Twitch # import required libraries from vidgear.gears import CamGear import cv2 # set desired quality as 720p options = { \"STREAM_RESOLUTION\" : \"720p\" } # Add any desire Video URL as input source # for e.g https://vimeo.com/151666798 # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://www.dailymotion.com/video/x2yrnum\" , stream_mode = True , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () If Twitch user is offline, CamGear will throw ValueError. # import required libraries from vidgear.gears import CamGear import cv2 # set desired quality as 720p options = { \"STREAM_RESOLUTION\" : \"720p\" } # Add any desire Video URL as input source # for e.g hhttps://www.twitch.tv/shroud # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://www.twitch.tv/shroud\" , stream_mode = True , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using Camgear with Youtube Videos \u2693 CamGear API also provides out-of-the-box support for pipelining live video-frames and metadata from YouTube (Livestream + Normal) Videos . YouTube Playlists are not supported yet. The complete usage example is as follows: Bug in OpenCV's FFmpeg To workaround a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for Livestream videos. Checkout this FAQ \u27b6 for compiling OpenCV with GStreamer support. Not all resolutions are supported with GStreamer Backend. See issue #244 Exclusive CamGear Attributes for yt_dlp backend CamGear also provides exclusive attributes: STREAM_RESOLUTION (for specifying stream resolution) STREAM_PARAMS (for specifying yt_dlp parameters) with its options dictionary parameter. More information can be found here \u27b6 Accessing Stream's Metadata CamGear now provides ytv_metadata global parameter for accessing given Video's metadata as JSON Object. It can used as follows: New in v0.2.4 ytv_metadata global parameter was added in v0.2.4 . # import required libraries from vidgear.gears import CamGear # Add YouTube Video URL as input source (for e.g https://youtu.be/uCy5OuSQnyA) # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://youtu.be/uCy5OuSQnyA\" , stream_mode = True , logging = True , ** options ) . start () # get Video's metadata as JSON object video_metadata = stream . ytv_metadata # print all available keys print ( video_metadata . keys ()) # get data like `title` print ( video_metadata [ \"title\" ]) # import required libraries from vidgear.gears import CamGear import cv2 # Add YouTube Video URL as input source (for e.g https://youtu.be/uCy5OuSQnyA) # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://youtu.be/uCy5OuSQnyA\" , stream_mode = True , logging = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using CamGear with Variable Camera Properties \u2693 CamGear API also flexibly support various Source Tweak Parameters available within OpenCV's VideoCapture API . These tweak parameters can be used to transform input source Camera-Device properties (such as its brightness, saturation, framerate, resolution, gain etc.) seamlessly, and can be easily applied in CamGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: All the supported Source Tweak Parameters can be found here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # define suitable tweak parameters for your stream. options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , # resolution 320x240 \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 , # framerate 60fps } # To open live video stream on webcam at first index(i.e. 0) # device and apply source tweak parameters stream = CamGear ( source = 0 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using Camgear with Direct Colorspace Manipulation \u2693 CamGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-type value, will immediately revert the colorspace to default i.e. BGR . # import required libraries from vidgear.gears import CamGear import cv2 # Open any source of your choice, like Webcam first index(i.e. 0) # and change its colorspace to `HSV` stream = CamGear ( source = 0 , colorspace = \"COLOR_BGR2HSV\" , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): # directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY # Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB # Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None # Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Usage Examples"},{"location":"gears/camgear/usage/#camgear-api-usage-examples","text":"After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6","title":"CamGear API Usage Examples:"},{"location":"gears/camgear/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with CamGear API: # import required libraries from vidgear.gears import CamGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = \"myvideo.avi\" ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage"},{"location":"gears/camgear/usage/#using-camgear-with-streaming-websites","text":"CamGear internally implements yt_dlp backend class for seamlessly pipelining live video-frames and metadata from various streaming services like Twitch , Vimeo , Dailymotion , and many more \u27b6 . All you have to do is to provide the desired Video's URL to its source parameter, and enable its stream_mode parameter. The complete usage example for Dailymotion and Twitch URLs are as follows: Bug in OpenCV's FFmpeg To workaround a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for Livestream videos. Checkout this FAQ \u27b6 for compiling OpenCV with GStreamer support. Not all resolutions are supported with GStreamer Backend. See issue #244 Exclusive CamGear Attributes for yt_dlp backend CamGear also provides exclusive attributes: STREAM_RESOLUTION (for specifying stream resolution) STREAM_PARAMS (for specifying yt_dlp parameters) with its options dictionary parameter. More information can be found here \u27b6 Supported Streaming Websites The list of all supported Streaming Websites URLs can be found here \u27b6 Accessing Stream's Metadata CamGear now provides ytv_metadata global parameter for accessing given Video's metadata as JSON Object. It can used as follows: New in v0.2.4 ytv_metadata global parameter was added in v0.2.4 . # import required libraries from vidgear.gears import CamGear # Add YouTube Video URL as input source (for e.g https://www.dailymotion.com/video/x2yrnum) # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://www.dailymotion.com/video/x2yrnum\" , stream_mode = True , logging = True , ** options ) . start () # get Video's metadata as JSON object video_metadata = stream . ytv_metadata # print all available keys print ( video_metadata . keys ()) # get data like `title` print ( video_metadata [ \"title\" ]) Dailymotion Twitch # import required libraries from vidgear.gears import CamGear import cv2 # set desired quality as 720p options = { \"STREAM_RESOLUTION\" : \"720p\" } # Add any desire Video URL as input source # for e.g https://vimeo.com/151666798 # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://www.dailymotion.com/video/x2yrnum\" , stream_mode = True , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () If Twitch user is offline, CamGear will throw ValueError. # import required libraries from vidgear.gears import CamGear import cv2 # set desired quality as 720p options = { \"STREAM_RESOLUTION\" : \"720p\" } # Add any desire Video URL as input source # for e.g hhttps://www.twitch.tv/shroud # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://www.twitch.tv/shroud\" , stream_mode = True , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using Camgear with Streaming Websites"},{"location":"gears/camgear/usage/#using-camgear-with-youtube-videos","text":"CamGear API also provides out-of-the-box support for pipelining live video-frames and metadata from YouTube (Livestream + Normal) Videos . YouTube Playlists are not supported yet. The complete usage example is as follows: Bug in OpenCV's FFmpeg To workaround a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for Livestream videos. Checkout this FAQ \u27b6 for compiling OpenCV with GStreamer support. Not all resolutions are supported with GStreamer Backend. See issue #244 Exclusive CamGear Attributes for yt_dlp backend CamGear also provides exclusive attributes: STREAM_RESOLUTION (for specifying stream resolution) STREAM_PARAMS (for specifying yt_dlp parameters) with its options dictionary parameter. More information can be found here \u27b6 Accessing Stream's Metadata CamGear now provides ytv_metadata global parameter for accessing given Video's metadata as JSON Object. It can used as follows: New in v0.2.4 ytv_metadata global parameter was added in v0.2.4 . # import required libraries from vidgear.gears import CamGear # Add YouTube Video URL as input source (for e.g https://youtu.be/uCy5OuSQnyA) # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://youtu.be/uCy5OuSQnyA\" , stream_mode = True , logging = True , ** options ) . start () # get Video's metadata as JSON object video_metadata = stream . ytv_metadata # print all available keys print ( video_metadata . keys ()) # get data like `title` print ( video_metadata [ \"title\" ]) # import required libraries from vidgear.gears import CamGear import cv2 # Add YouTube Video URL as input source (for e.g https://youtu.be/uCy5OuSQnyA) # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://youtu.be/uCy5OuSQnyA\" , stream_mode = True , logging = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using Camgear with Youtube Videos"},{"location":"gears/camgear/usage/#using-camgear-with-variable-camera-properties","text":"CamGear API also flexibly support various Source Tweak Parameters available within OpenCV's VideoCapture API . These tweak parameters can be used to transform input source Camera-Device properties (such as its brightness, saturation, framerate, resolution, gain etc.) seamlessly, and can be easily applied in CamGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: All the supported Source Tweak Parameters can be found here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # define suitable tweak parameters for your stream. options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , # resolution 320x240 \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 , # framerate 60fps } # To open live video stream on webcam at first index(i.e. 0) # device and apply source tweak parameters stream = CamGear ( source = 0 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using CamGear with Variable Camera Properties"},{"location":"gears/camgear/usage/#using-camgear-with-direct-colorspace-manipulation","text":"CamGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-type value, will immediately revert the colorspace to default i.e. BGR . # import required libraries from vidgear.gears import CamGear import cv2 # Open any source of your choice, like Webcam first index(i.e. 0) # and change its colorspace to `HSV` stream = CamGear ( source = 0 , colorspace = \"COLOR_BGR2HSV\" , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): # directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY # Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB # Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None # Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using Camgear with Direct Colorspace Manipulation"},{"location":"gears/camgear/advanced/source_params/","text":"Source Tweak Parameters for CamGear API \u2693 Overview \u2693 With CamGear's options dictionary parameter, the user has the ability to alter various tweak parameters available within OpenCV's VideoCapture Class by formatting them as its attributes. These tweak parameters can be used to transform input Camera-Source properties (such as its brightness, saturation, resolution, iso, gain etc.) seamlessly. All parameters supported by CamGear API are disscussed in this document. \u2003 Exclusive CamGear Attributes \u2693 CamGear's Exclusive Attributes In addition to Source Tweak Parameters, CamGear also provides some exclusive attributes for its options dictionary parameters. These attributes are as follows: STREAM_RESOLUTION (string) : This attribute can be used in CamGear's Stream Mode ( stream_mode=True ) for specifying supported stream resolution. Its possible values can be: 144p , 240p , 360p , 480p , 720p , 1080p , 1440p , 2160p , 4320p , worst , best , and its default value is best . Its usage is as follows: In case specificed STREAM_RESOLUTION value is unavailable within Source Stream, it defaults to best ! options = { \"STREAM_RESOLUTION\" : \"720p\" } # 720p stream will be used. Its complete usage example is given here \u27b6 STREAM_PARAMS (dict) : This dictionary attribute can be used in CamGear's Stream Mode ( stream_mode=True ) for specifying parameters for its internal yt_dlp backend class. Its usage is as follows: All STREAM_PARAMS Supported Parameters All yt_dlp parameter can be found here \u27b6 options = { \"STREAM_PARAMS\" : { \"nocheckcertificate\" : True }} # disables verifying SSL certificates in yt_dlp THREADED_QUEUE_MODE (boolean) : This attribute can be used to override Threaded-Queue-Mode mode to manually disable it: Disabling Threaded-Queue-Mode can be dangerous! Read more here \u27b6 options = { \"THREADED_QUEUE_MODE\" : False } # disable Threaded Queue Mode. THREAD_TIMEOUT (int/float) : This attribute can be used to override the timeout value(positive number), that blocks the video-thread for at most timeout seconds if no video-frame was available within that time, and otherwise raises the Empty exception to prevent any never-ending deadlocks. Its default value is None , meaning no timeout at all. Its usage is as follows: New in v0.2.1 THREAD_TIMEOUT attribute added in v0.2.1 . options = { \"THREAD_TIMEOUT\" : 300 } # set Video-Thread Timeout for 5mins. Supported Source Tweak Parameters \u2693 All Source Tweak Parameters supported by CamGear API are as follows: Remember, Not all parameters are supported by all cameras devices, which is one of the most troublesome thing with OpenCV library. Each camera type, from android cameras, to USB cameras , to professional ones, offers a different interface to modify its parameters. Therefore, there are many branches in OpenCV code to support as many of them, but of course, not all possible devices are covered, and thereby works. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error . You can easily check parameter values supported by your webcam, by hooking it to a Linux machine, and using the command v4l2-ctl -d 0 --list-formats-ext (where 0 is an index of the given camera) to list the supported video parameters and their values. If that doesn't works, refer to its datasheet (if available) . These parameters can be passed to CamGear's options dictionary parameter by formatting them as its string attributes. Its complete usage example is here \u27b6 \u2009 Values Description CAP_PROP_POS_MSEC Current position of the video file in milliseconds. CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next. CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0=start of the film, 1=end of the film. CAP_PROP_FRAME_WIDTH Width of the frames in the video stream. CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream. CAP_PROP_FPS Frame rate. CAP_PROP_FOURCC 4-character code of codec. see VideoWriter::fourcc . CAP_PROP_FRAME_COUNT Number of frames in the video file. CAP_PROP_FORMAT Format of the Mat objects returned by VideoCapture::retrieve() . CAP_PROP_MODE Backend-specific value indicating the current capture mode. CAP_PROP_BRIGHTNESS Brightness of the image (only for those cameras that support). CAP_PROP_CONTRAST Contrast of the image (only for cameras). CAP_PROP_SATURATION Saturation of the image (only for cameras). CAP_PROP_HUE Hue of the image (only for cameras). CAP_PROP_GAIN Gain of the image (only for those cameras that support). CAP_PROP_EXPOSURE Exposure (only for those cameras that support). CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB. CAP_PROP_WHITE_BALANCE_BLUE_U Currently unsupported. CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently). CAP_PROP_MONOCHROME CAP_PROP_SHARPNESS CAP_PROP_AUTO_EXPOSURE DC1394: exposure control done by camera, user can adjust reference level using this feature. CAP_PROP_GAMMA CAP_PROP_TEMPERATURE CAP_PROP_TRIGGER CAP_PROP_TRIGGER_DELAY CAP_PROP_WHITE_BALANCE_RED_V CAP_PROP_ZOOM CAP_PROP_FOCUS CAP_PROP_GUID CAP_PROP_ISO_SPEED CAP_PROP_BACKLIGHT CAP_PROP_PAN CAP_PROP_TILT CAP_PROP_ROLL CAP_PROP_IRIS CAP_PROP_SETTINGS Pop up video/camera filter dialog (note: only supported by DSHOW backend currently. The property value is ignored) CAP_PROP_BUFFERSIZE CAP_PROP_AUTOFOCUS CAP_PROP_SAR_NUM Sample aspect ratio: num/den (num) CAP_PROP_SAR_DEN Sample aspect ratio: num/den (den) CAP_PROP_BACKEND Current backend (enum VideoCapture APIs). Read-only property. CAP_PROP_CHANNEL Video input or Channel Number (only for those cameras that support) CAP_PROP_AUTO_WB enable/ disable auto white-balance CAP_PROP_WB_TEMPERATURE white-balance color temperature","title":"Source Tweak Parameters"},{"location":"gears/camgear/advanced/source_params/#source-tweak-parameters-for-camgear-api","text":"","title":"Source Tweak Parameters for CamGear API"},{"location":"gears/camgear/advanced/source_params/#overview","text":"With CamGear's options dictionary parameter, the user has the ability to alter various tweak parameters available within OpenCV's VideoCapture Class by formatting them as its attributes. These tweak parameters can be used to transform input Camera-Source properties (such as its brightness, saturation, resolution, iso, gain etc.) seamlessly. All parameters supported by CamGear API are disscussed in this document.","title":"Overview"},{"location":"gears/camgear/advanced/source_params/#exclusive-camgear-attributes","text":"CamGear's Exclusive Attributes In addition to Source Tweak Parameters, CamGear also provides some exclusive attributes for its options dictionary parameters. These attributes are as follows: STREAM_RESOLUTION (string) : This attribute can be used in CamGear's Stream Mode ( stream_mode=True ) for specifying supported stream resolution. Its possible values can be: 144p , 240p , 360p , 480p , 720p , 1080p , 1440p , 2160p , 4320p , worst , best , and its default value is best . Its usage is as follows: In case specificed STREAM_RESOLUTION value is unavailable within Source Stream, it defaults to best ! options = { \"STREAM_RESOLUTION\" : \"720p\" } # 720p stream will be used. Its complete usage example is given here \u27b6 STREAM_PARAMS (dict) : This dictionary attribute can be used in CamGear's Stream Mode ( stream_mode=True ) for specifying parameters for its internal yt_dlp backend class. Its usage is as follows: All STREAM_PARAMS Supported Parameters All yt_dlp parameter can be found here \u27b6 options = { \"STREAM_PARAMS\" : { \"nocheckcertificate\" : True }} # disables verifying SSL certificates in yt_dlp THREADED_QUEUE_MODE (boolean) : This attribute can be used to override Threaded-Queue-Mode mode to manually disable it: Disabling Threaded-Queue-Mode can be dangerous! Read more here \u27b6 options = { \"THREADED_QUEUE_MODE\" : False } # disable Threaded Queue Mode. THREAD_TIMEOUT (int/float) : This attribute can be used to override the timeout value(positive number), that blocks the video-thread for at most timeout seconds if no video-frame was available within that time, and otherwise raises the Empty exception to prevent any never-ending deadlocks. Its default value is None , meaning no timeout at all. Its usage is as follows: New in v0.2.1 THREAD_TIMEOUT attribute added in v0.2.1 . options = { \"THREAD_TIMEOUT\" : 300 } # set Video-Thread Timeout for 5mins.","title":"Exclusive CamGear Attributes"},{"location":"gears/camgear/advanced/source_params/#supported-source-tweak-parameters","text":"All Source Tweak Parameters supported by CamGear API are as follows: Remember, Not all parameters are supported by all cameras devices, which is one of the most troublesome thing with OpenCV library. Each camera type, from android cameras, to USB cameras , to professional ones, offers a different interface to modify its parameters. Therefore, there are many branches in OpenCV code to support as many of them, but of course, not all possible devices are covered, and thereby works. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error . You can easily check parameter values supported by your webcam, by hooking it to a Linux machine, and using the command v4l2-ctl -d 0 --list-formats-ext (where 0 is an index of the given camera) to list the supported video parameters and their values. If that doesn't works, refer to its datasheet (if available) . These parameters can be passed to CamGear's options dictionary parameter by formatting them as its string attributes. Its complete usage example is here \u27b6 \u2009 Values Description CAP_PROP_POS_MSEC Current position of the video file in milliseconds. CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next. CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0=start of the film, 1=end of the film. CAP_PROP_FRAME_WIDTH Width of the frames in the video stream. CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream. CAP_PROP_FPS Frame rate. CAP_PROP_FOURCC 4-character code of codec. see VideoWriter::fourcc . CAP_PROP_FRAME_COUNT Number of frames in the video file. CAP_PROP_FORMAT Format of the Mat objects returned by VideoCapture::retrieve() . CAP_PROP_MODE Backend-specific value indicating the current capture mode. CAP_PROP_BRIGHTNESS Brightness of the image (only for those cameras that support). CAP_PROP_CONTRAST Contrast of the image (only for cameras). CAP_PROP_SATURATION Saturation of the image (only for cameras). CAP_PROP_HUE Hue of the image (only for cameras). CAP_PROP_GAIN Gain of the image (only for those cameras that support). CAP_PROP_EXPOSURE Exposure (only for those cameras that support). CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB. CAP_PROP_WHITE_BALANCE_BLUE_U Currently unsupported. CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently). CAP_PROP_MONOCHROME CAP_PROP_SHARPNESS CAP_PROP_AUTO_EXPOSURE DC1394: exposure control done by camera, user can adjust reference level using this feature. CAP_PROP_GAMMA CAP_PROP_TEMPERATURE CAP_PROP_TRIGGER CAP_PROP_TRIGGER_DELAY CAP_PROP_WHITE_BALANCE_RED_V CAP_PROP_ZOOM CAP_PROP_FOCUS CAP_PROP_GUID CAP_PROP_ISO_SPEED CAP_PROP_BACKLIGHT CAP_PROP_PAN CAP_PROP_TILT CAP_PROP_ROLL CAP_PROP_IRIS CAP_PROP_SETTINGS Pop up video/camera filter dialog (note: only supported by DSHOW backend currently. The property value is ignored) CAP_PROP_BUFFERSIZE CAP_PROP_AUTOFOCUS CAP_PROP_SAR_NUM Sample aspect ratio: num/den (num) CAP_PROP_SAR_DEN Sample aspect ratio: num/den (den) CAP_PROP_BACKEND Current backend (enum VideoCapture APIs). Read-only property. CAP_PROP_CHANNEL Video input or Channel Number (only for those cameras that support) CAP_PROP_AUTO_WB enable/ disable auto white-balance CAP_PROP_WB_TEMPERATURE white-balance color temperature","title":"Supported Source Tweak Parameters"},{"location":"gears/netgear/overview/","text":"NetGear API \u2693 NetGear API generalized Overview \u2693 NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time. NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. NetGear also enables real-time JPEG Frame Compression capabilities for boosting performance significantly while sending video-frames over the network in real-time. Lazy Pirate pattern in NetGear API NetGear API now internally implements robust Lazy Pirate pattern (auto-reconnection) for its synchronous messaging patterns( zmq.PAIR & zmq.REQ/zmq.REP ) at both Server and Client ends, where its API instead of doing a blocking receive, will: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. Netgear API also provides max_retries and request_timeout like attributes for controlling this polling. NetGear as of now seamlessly supports three ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) whereas the supported protocol are: tcp and ipc . \u2009 Modes of Operation \u2693 Primary Modes \u2693 NetGear API primarily has two modes of operations: Send Mode: which employs send() function to send video frames over the network in real-time. Activate this mode by setting parameter receive_mode = False . Receive Mode: which employs recv() function to receive frames, sent over the network with Send Mode in real-time. Activate this mode by setting parameter receive_mode = True . Exclusive Modes \u2693 In addition to the primary modes, NetGear API also offers application-specific Exclusive Modes: Also, checkout this compatibility chart for these modes interoperability. A. Multi-Servers Mode \u2693 In this exclusive mode, NetGear API robustly handles multiple servers at once , thereby providing seamless access to frames and unidirectional data transfer from multiple Servers/Publishers across the network in real-time. Each new Server on the network can be identified on the client's end by using its unique port address. You can learn about this mode here \u27b6 B. Multi-Clients Mode \u2693 In this exclusive mode, NetGear API robustly handles multiple clients at once , thereby providing seamless access to frames and unidirectional data transfer to multiple Client/Consumers across the network in real-time. Each new Client on the network can be uniquely identified on the Server's end by using its unique port address. You can learn about this mode here \u27b6 C. Bidirectional Mode \u2693 This exclusive mode provides seamless support for bidirectional data transmission between between Server and Client along with video frames. Using this mode, the user can now send or receive any data(of any datatype) between Server and Client easily in real-time. You can learn more about this mode here \u27b6 D. SSH Tunneling Mode \u2693 This exclusive mode allows you to connect NetGear via secure SSH connection over the untrusted network and access its intranet services across firewalls. This mode implements SSH Remote Port Forwarding which enables accessing Host(client) machine outside the network by exposing port to the public Internet. You can learn more about this mode here \u27b6 E. Secure Mode \u2693 In this exclusive mode, NetGear API provides easy access to powerful, smart & secure ZeroMQ's Security Layers that enables strong encryption on data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication for distributed systems over the network. You can learn more about this mode here \u27b6 \u2009 Important Information When compiling/installing pyzmq on UNIX systems, it is generally recommended that zeromq binaries to be installed separately, via homebrew, apt, yum, etc. as follows: # Debian-based sudo apt-get install libzmq3-dev # RHEL-based sudo yum install libzmq3-devel # OSX-based brew install zeromq If zeromq binaries are not found, pyzmq will try to build libzmq as a Python Extension, though this is not guaranteed to work! It is advised to enable logging ( logging = True ) on the first run, to easily identify any runtime errors. Kindly go through each given Usage Examples thoroughly, any incorrect settings/parameter may result in errors or no output at all. Only either of two functions (i.e. send() and recv() ) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode (for e.g using send() function in Receive Mode) , will result in ValueError . Frame Compression is enabled by default in NetGear along with fast dct and compression-quality at 90% in all connections. \u2009 Importing \u2693 You can import NetGear API in your program as follows: from vidgear.gears import NetGear Usage Examples \u2693 See here \ud83d\ude80 After going through NetGear Usage Examples, Checkout more bonus examples here \u27b6 Parameters \u2693 See here \ud83d\ude80 References \u2693 See here \ud83d\ude80 FAQs \u2693 See here \ud83d\ude80","title":"Overview"},{"location":"gears/netgear/overview/#netgear-api","text":"NetGear API generalized","title":"NetGear API"},{"location":"gears/netgear/overview/#overview","text":"NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time. NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. NetGear also enables real-time JPEG Frame Compression capabilities for boosting performance significantly while sending video-frames over the network in real-time. Lazy Pirate pattern in NetGear API NetGear API now internally implements robust Lazy Pirate pattern (auto-reconnection) for its synchronous messaging patterns( zmq.PAIR & zmq.REQ/zmq.REP ) at both Server and Client ends, where its API instead of doing a blocking receive, will: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. Netgear API also provides max_retries and request_timeout like attributes for controlling this polling. NetGear as of now seamlessly supports three ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) whereas the supported protocol are: tcp and ipc .","title":"Overview"},{"location":"gears/netgear/overview/#modes-of-operation","text":"","title":"Modes of Operation"},{"location":"gears/netgear/overview/#primary-modes","text":"NetGear API primarily has two modes of operations: Send Mode: which employs send() function to send video frames over the network in real-time. Activate this mode by setting parameter receive_mode = False . Receive Mode: which employs recv() function to receive frames, sent over the network with Send Mode in real-time. Activate this mode by setting parameter receive_mode = True .","title":"Primary Modes"},{"location":"gears/netgear/overview/#exclusive-modes","text":"In addition to the primary modes, NetGear API also offers application-specific Exclusive Modes: Also, checkout this compatibility chart for these modes interoperability.","title":"Exclusive Modes"},{"location":"gears/netgear/overview/#a-multi-servers-mode","text":"In this exclusive mode, NetGear API robustly handles multiple servers at once , thereby providing seamless access to frames and unidirectional data transfer from multiple Servers/Publishers across the network in real-time. Each new Server on the network can be identified on the client's end by using its unique port address. You can learn about this mode here \u27b6","title":"A. Multi-Servers Mode"},{"location":"gears/netgear/overview/#b-multi-clients-mode","text":"In this exclusive mode, NetGear API robustly handles multiple clients at once , thereby providing seamless access to frames and unidirectional data transfer to multiple Client/Consumers across the network in real-time. Each new Client on the network can be uniquely identified on the Server's end by using its unique port address. You can learn about this mode here \u27b6","title":"B. Multi-Clients Mode"},{"location":"gears/netgear/overview/#c-bidirectional-mode","text":"This exclusive mode provides seamless support for bidirectional data transmission between between Server and Client along with video frames. Using this mode, the user can now send or receive any data(of any datatype) between Server and Client easily in real-time. You can learn more about this mode here \u27b6","title":"C. Bidirectional Mode"},{"location":"gears/netgear/overview/#d-ssh-tunneling-mode","text":"This exclusive mode allows you to connect NetGear via secure SSH connection over the untrusted network and access its intranet services across firewalls. This mode implements SSH Remote Port Forwarding which enables accessing Host(client) machine outside the network by exposing port to the public Internet. You can learn more about this mode here \u27b6","title":"D. SSH Tunneling Mode"},{"location":"gears/netgear/overview/#e-secure-mode","text":"In this exclusive mode, NetGear API provides easy access to powerful, smart & secure ZeroMQ's Security Layers that enables strong encryption on data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication for distributed systems over the network. You can learn more about this mode here \u27b6 \u2009 Important Information When compiling/installing pyzmq on UNIX systems, it is generally recommended that zeromq binaries to be installed separately, via homebrew, apt, yum, etc. as follows: # Debian-based sudo apt-get install libzmq3-dev # RHEL-based sudo yum install libzmq3-devel # OSX-based brew install zeromq If zeromq binaries are not found, pyzmq will try to build libzmq as a Python Extension, though this is not guaranteed to work! It is advised to enable logging ( logging = True ) on the first run, to easily identify any runtime errors. Kindly go through each given Usage Examples thoroughly, any incorrect settings/parameter may result in errors or no output at all. Only either of two functions (i.e. send() and recv() ) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode (for e.g using send() function in Receive Mode) , will result in ValueError . Frame Compression is enabled by default in NetGear along with fast dct and compression-quality at 90% in all connections.","title":"E. Secure Mode"},{"location":"gears/netgear/overview/#importing","text":"You can import NetGear API in your program as follows: from vidgear.gears import NetGear","title":"Importing"},{"location":"gears/netgear/overview/#usage-examples","text":"See here \ud83d\ude80 After going through NetGear Usage Examples, Checkout more bonus examples here \u27b6","title":"Usage Examples"},{"location":"gears/netgear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/netgear/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/netgear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/netgear/params/","text":"NetGear API Parameters \u2693 \u2009 address \u2693 This parameter sets the valid Network IP address for Server/Client. Network addresses are unique identifiers across the network. Data-Type: String Default Value: Its default value is based on selected primary mode , i.e 'localhost' for Send Mode and '*' for Receive Mode on a local machine. Usage: NetGear ( address = \"192.168.0.145\" ) port \u2693 This parameter sets the valid Network Port for Server/Client. Network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered. Exception for Exclusive Modes In Multi-Servers Mode : A unique port number MUST be assigned to each Server on the network using this parameter. At Client end, a List/Tuple of all available Server(s) ports MUST be assigned using this same parameter. See its usage example here \u27b6 . In Multi-Client Mode : A unique port number MUST be assigned to each Client on the network using this parameter. At Server end, a List/Tuple of all available Client(s) ports MUST be assigned using this same parameter. See its usage example here \u27b6 . Data-Type: String or List/Tuple Default Value: Its default value is '5555' Usage: NetGear ( port = \"5575\" ) protocol \u2693 This parameter sets the valid messaging protocol between server and client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: 'tcp' and 'ipc' . Data-Type: String Default Value: Its default value is 'tcp' Usage: NetGear ( protocol = \"ipc\" ) pattern \u2693 This parameter sets the supported messaging pattern(flow of communication) between server and client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns. Data-Type: Integer Default Value: Its default value is 0 ( i.e zmq.PAIR ). Supported ZMQ patterns All supported ZMQ patterns for NetGear are: 0 ( .i.e. zmq.PAIR ): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it. 1 ( .i.e. zmq.REQ/zmq.REP ): In this pattern, it employs ZMQ REQ sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket zmq.REQ will block send unless it has successfully received a reply back and socket zmq.REP will block on recv() unless it has received a request. 2 ( .i.e. zmq.PUB/zmq.SUB ): It is an another classic pattern where senders of messages, called publishers , do not program the messages to be sent directly to specific receivers, called subscribers . Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A ZMQ.SUB can connect to multiple ZMQ.PUB (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved. Usage: NetGear ( pattern = 1 ) # sets zmq.REQ/zmq.REP pattern receive_mode \u2693 This parameter select the Netgear's Mode of operation. It basically activates Receive Mode ( if True ) and Send Mode ( if False ). Furthermore, recv() method will only work when this flag is enabled( i.e. Receive Mode ), whereas send() method will only work when this flag is disabled( i.e. Send Mode ). Data-Type: Boolean Default Value: Its default value is False ( i.e. Send Mode is activated by default ). Usage: NetGear ( receive_mode = True ) # activates Recieve Mode options \u2693 This parameter provides the flexibility to alter various NetGear API's internal properties, modes, and some PyZMQ flags. Data-Type: Dictionary Default Value: Its default value is {} Usage: Supported dictionary attributes for NetGear API multiserver_mode ( boolean ) : This internal attribute activates the exclusive Multi-Servers Mode , if enabled( True ). multiclient_mode ( boolean ) : This internal attribute activates the exclusive Multi-Clients Mode , if enabled( True ). secure_mode ( integer ) : This internal attribute selects the exclusive Secure Mode . Its possible values are: 0 (i.e. Grassland(no security)) or 1 (i.e. StoneHouse) or 2 (i.e. IronHouse) . bidirectional_mode ( boolean ) : This internal attribute activates the exclusive Bidirectional Mode , if enabled( True ). ssh_tunnel_mode ( string ) : This internal attribute activates the exclusive SSH Tunneling Mode at the Server-end only . ssh_tunnel_pwd ( string ): In SSH Tunneling Mode, This internal attribute sets the password required to authorize Host for SSH Connection at the Server-end only . More information can be found here \u27b6 ssh_tunnel_keyfile ( string ): In SSH Tunneling Mode, This internal attribute sets path to Host key that provide another way to authenticate host for SSH Connection at the Server-end only . More information can be found here \u27b6 custom_cert_location ( string ) : In Secure Mode, This internal attribute assigns user-defined location/path to directory for generating/storing Public+Secret Keypair necessary for encryption. More information can be found here \u27b6 overwrite_cert ( boolean ) : In Secure Mode, This internal attribute decides whether to overwrite existing Public+Secret Keypair/Certificates or not, at the Server-end only . More information can be found here \u27b6 jpeg_compression ( bool/str ): This internal attribute is used to activate(if True )/deactivate(if False ) JPEG Frame Compression as well as to specify incoming frames colorspace with compression. By default colorspace is BGR and compression is enabled( True ). More information can be found here \u27b6 jpeg_compression_quality ( int/float ): This internal attribute controls the JPEG quantization factor in JPEG Frame Compression. Its value varies from 10 to 100 (the higher is the better quality but performance will be lower). Its default value is 90 . More information can be found here \u27b6 jpeg_compression_fastdct ( bool ): This internal attributee if True, use fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality in JPEG Frame Compression. Its default value is also True . More information can be found here \u27b6 jpeg_compression_fastupsample ( bool ): This internal attribute if True, use fastest color upsampling method. Its default value is False . More information can be found here \u27b6 max_retries ( integer ): This internal attribute controls the maximum retries before Server/Client exit itself, if it's unable to get any response/reply from the socket before a certain amount of time, when synchronous messaging patterns like ( zmq.PAIR & zmq.REQ/zmq.REP ) are being used. It's value can anything greater than 0 , and its default value is 3 . request_timeout ( integer ): This internal attribute controls the timeout value (in seconds) , after which the Server/Client exit itself if it's unable to get any response/reply from the socket, when synchronous messaging patterns like ( zmq.PAIR & zmq.REQ/zmq.REP ) are being used. It's value can anything greater than 0 , and its default value is 10 seconds. flag ( integer ): This PyZMQ attribute value can be either 0 or zmq.NOBLOCK ( i.e. 1) . More information can be found here \u27b6 . copy ( boolean ): This PyZMQ attribute selects if message be received in a copying or non-copying manner. If False a object is returned, if True a string copy of the message is returned. track ( boolean ): This PyZMQ attribute check if the message is tracked for notification that ZMQ has finished with it. ( ignored if copy=True ). The desired attributes can be passed to NetGear API as follows: # formatting parameters as dictionary attributes options = { \"secure_mode\" : 2 , \"custom_cert_location\" : \"/home/foo/foo1/foo2\" , \"overwrite_cert\" : True , \"flag\" : 0 , \"copy\" : False , \"track\" : False , } # assigning it NetGear ( logging = True , ** options ) logging \u2693 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( logging = True )","title":"Parameters"},{"location":"gears/netgear/params/#netgear-api-parameters","text":"","title":"NetGear API Parameters"},{"location":"gears/netgear/params/#address","text":"This parameter sets the valid Network IP address for Server/Client. Network addresses are unique identifiers across the network. Data-Type: String Default Value: Its default value is based on selected primary mode , i.e 'localhost' for Send Mode and '*' for Receive Mode on a local machine. Usage: NetGear ( address = \"192.168.0.145\" )","title":"address"},{"location":"gears/netgear/params/#port","text":"This parameter sets the valid Network Port for Server/Client. Network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered. Exception for Exclusive Modes In Multi-Servers Mode : A unique port number MUST be assigned to each Server on the network using this parameter. At Client end, a List/Tuple of all available Server(s) ports MUST be assigned using this same parameter. See its usage example here \u27b6 . In Multi-Client Mode : A unique port number MUST be assigned to each Client on the network using this parameter. At Server end, a List/Tuple of all available Client(s) ports MUST be assigned using this same parameter. See its usage example here \u27b6 . Data-Type: String or List/Tuple Default Value: Its default value is '5555' Usage: NetGear ( port = \"5575\" )","title":"port"},{"location":"gears/netgear/params/#protocol","text":"This parameter sets the valid messaging protocol between server and client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: 'tcp' and 'ipc' . Data-Type: String Default Value: Its default value is 'tcp' Usage: NetGear ( protocol = \"ipc\" )","title":"protocol"},{"location":"gears/netgear/params/#pattern","text":"This parameter sets the supported messaging pattern(flow of communication) between server and client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns. Data-Type: Integer Default Value: Its default value is 0 ( i.e zmq.PAIR ). Supported ZMQ patterns All supported ZMQ patterns for NetGear are: 0 ( .i.e. zmq.PAIR ): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it. 1 ( .i.e. zmq.REQ/zmq.REP ): In this pattern, it employs ZMQ REQ sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket zmq.REQ will block send unless it has successfully received a reply back and socket zmq.REP will block on recv() unless it has received a request. 2 ( .i.e. zmq.PUB/zmq.SUB ): It is an another classic pattern where senders of messages, called publishers , do not program the messages to be sent directly to specific receivers, called subscribers . Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A ZMQ.SUB can connect to multiple ZMQ.PUB (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved. Usage: NetGear ( pattern = 1 ) # sets zmq.REQ/zmq.REP pattern","title":"pattern"},{"location":"gears/netgear/params/#receive_mode","text":"This parameter select the Netgear's Mode of operation. It basically activates Receive Mode ( if True ) and Send Mode ( if False ). Furthermore, recv() method will only work when this flag is enabled( i.e. Receive Mode ), whereas send() method will only work when this flag is disabled( i.e. Send Mode ). Data-Type: Boolean Default Value: Its default value is False ( i.e. Send Mode is activated by default ). Usage: NetGear ( receive_mode = True ) # activates Recieve Mode","title":"receive_mode"},{"location":"gears/netgear/params/#options","text":"This parameter provides the flexibility to alter various NetGear API's internal properties, modes, and some PyZMQ flags. Data-Type: Dictionary Default Value: Its default value is {} Usage: Supported dictionary attributes for NetGear API multiserver_mode ( boolean ) : This internal attribute activates the exclusive Multi-Servers Mode , if enabled( True ). multiclient_mode ( boolean ) : This internal attribute activates the exclusive Multi-Clients Mode , if enabled( True ). secure_mode ( integer ) : This internal attribute selects the exclusive Secure Mode . Its possible values are: 0 (i.e. Grassland(no security)) or 1 (i.e. StoneHouse) or 2 (i.e. IronHouse) . bidirectional_mode ( boolean ) : This internal attribute activates the exclusive Bidirectional Mode , if enabled( True ). ssh_tunnel_mode ( string ) : This internal attribute activates the exclusive SSH Tunneling Mode at the Server-end only . ssh_tunnel_pwd ( string ): In SSH Tunneling Mode, This internal attribute sets the password required to authorize Host for SSH Connection at the Server-end only . More information can be found here \u27b6 ssh_tunnel_keyfile ( string ): In SSH Tunneling Mode, This internal attribute sets path to Host key that provide another way to authenticate host for SSH Connection at the Server-end only . More information can be found here \u27b6 custom_cert_location ( string ) : In Secure Mode, This internal attribute assigns user-defined location/path to directory for generating/storing Public+Secret Keypair necessary for encryption. More information can be found here \u27b6 overwrite_cert ( boolean ) : In Secure Mode, This internal attribute decides whether to overwrite existing Public+Secret Keypair/Certificates or not, at the Server-end only . More information can be found here \u27b6 jpeg_compression ( bool/str ): This internal attribute is used to activate(if True )/deactivate(if False ) JPEG Frame Compression as well as to specify incoming frames colorspace with compression. By default colorspace is BGR and compression is enabled( True ). More information can be found here \u27b6 jpeg_compression_quality ( int/float ): This internal attribute controls the JPEG quantization factor in JPEG Frame Compression. Its value varies from 10 to 100 (the higher is the better quality but performance will be lower). Its default value is 90 . More information can be found here \u27b6 jpeg_compression_fastdct ( bool ): This internal attributee if True, use fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality in JPEG Frame Compression. Its default value is also True . More information can be found here \u27b6 jpeg_compression_fastupsample ( bool ): This internal attribute if True, use fastest color upsampling method. Its default value is False . More information can be found here \u27b6 max_retries ( integer ): This internal attribute controls the maximum retries before Server/Client exit itself, if it's unable to get any response/reply from the socket before a certain amount of time, when synchronous messaging patterns like ( zmq.PAIR & zmq.REQ/zmq.REP ) are being used. It's value can anything greater than 0 , and its default value is 3 . request_timeout ( integer ): This internal attribute controls the timeout value (in seconds) , after which the Server/Client exit itself if it's unable to get any response/reply from the socket, when synchronous messaging patterns like ( zmq.PAIR & zmq.REQ/zmq.REP ) are being used. It's value can anything greater than 0 , and its default value is 10 seconds. flag ( integer ): This PyZMQ attribute value can be either 0 or zmq.NOBLOCK ( i.e. 1) . More information can be found here \u27b6 . copy ( boolean ): This PyZMQ attribute selects if message be received in a copying or non-copying manner. If False a object is returned, if True a string copy of the message is returned. track ( boolean ): This PyZMQ attribute check if the message is tracked for notification that ZMQ has finished with it. ( ignored if copy=True ). The desired attributes can be passed to NetGear API as follows: # formatting parameters as dictionary attributes options = { \"secure_mode\" : 2 , \"custom_cert_location\" : \"/home/foo/foo1/foo2\" , \"overwrite_cert\" : True , \"flag\" : 0 , \"copy\" : False , \"track\" : False , } # assigning it NetGear ( logging = True , ** options )","title":"options"},{"location":"gears/netgear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( logging = True )","title":"logging"},{"location":"gears/netgear/usage/","text":"NetGear API Usage Examples: \u2693 Danger Kindly go through each given examples thoroughly, any incorrect settings/parameter may result in errors or no output at all. NetGear provides auto-termination feature, where if you terminate server end manually, the connected client(s) end will also terminate themselves to save resources. Only either of two functions (i.e. send() and recv() ) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode ( for e.g using send() function in Receive Mode ), will result in ValueError . After going through following Usage Examples, Checkout more bonus examples here \u27b6 \u2009 Bare-Minimum Usage \u2693 Following is the bare-minimum code you need to get started with NetGear API: Server's End \u2693 Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # Define Netgear Server with default parameters server = NetGear () # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client's End \u2693 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define Netgear Client with `receive_mode = True` and default parameter client = NetGear ( receive_mode = True ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using NetGear with Variable Parameters \u2693 Client's End \u2693 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server's End \u2693 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define Netgear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Using NetGear with OpenCV \u2693 You can easily use NetGear directly with any Video Processing library such as OpenCV itself. The complete usage example is as follows: Client's End \u2693 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 0 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the received frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server's End \u2693 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # define tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 0 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Using NetGear with Other VideoCapture Gears \u2693 You can use any VideoCapture Gear in the similar manner. Let's implement given usage example with ScreenGear: Client's End \u2693 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server's End \u2693 Now, Open the terminal on another Server System (let's say you want to transmit Monitor Screen Frames from a Laptop) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import ScreenGear from vidgear.gears import NetGear # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Start capturing live Monitor screen frames with default settings stream = ScreenGear () . start () # Define Netgear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Usage Examples"},{"location":"gears/netgear/usage/#netgear-api-usage-examples","text":"Danger Kindly go through each given examples thoroughly, any incorrect settings/parameter may result in errors or no output at all. NetGear provides auto-termination feature, where if you terminate server end manually, the connected client(s) end will also terminate themselves to save resources. Only either of two functions (i.e. send() and recv() ) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode ( for e.g using send() function in Receive Mode ), will result in ValueError . After going through following Usage Examples, Checkout more bonus examples here \u27b6","title":"NetGear API Usage Examples:"},{"location":"gears/netgear/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with NetGear API:","title":"Bare-Minimum Usage"},{"location":"gears/netgear/usage/#servers-end","text":"Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # Define Netgear Server with default parameters server = NetGear () # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/usage/#clients-end","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define Netgear Client with `receive_mode = True` and default parameter client = NetGear ( receive_mode = True ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/usage/#using-netgear-with-variable-parameters","text":"","title":"Using NetGear with Variable Parameters"},{"location":"gears/netgear/usage/#clients-end_1","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/usage/#servers-end_1","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define Netgear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/usage/#using-netgear-with-opencv","text":"You can easily use NetGear directly with any Video Processing library such as OpenCV itself. The complete usage example is as follows:","title":"Using NetGear with OpenCV"},{"location":"gears/netgear/usage/#clients-end_2","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 0 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the received frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/usage/#servers-end_2","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # define tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 0 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/usage/#using-netgear-with-other-videocapture-gears","text":"You can use any VideoCapture Gear in the similar manner. Let's implement given usage example with ScreenGear:","title":"Using NetGear with Other VideoCapture Gears"},{"location":"gears/netgear/usage/#clients-end_3","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/usage/#servers-end_3","text":"Now, Open the terminal on another Server System (let's say you want to transmit Monitor Screen Frames from a Laptop) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import ScreenGear from vidgear.gears import NetGear # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Start capturing live Monitor screen frames with default settings stream = ScreenGear () . start () # Define Netgear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/advanced/bidirectional_mode/","text":"Bidirectional Mode for NetGear API \u2693 NetGear's Bidirectional Mode Overview \u2693 Bidirectional Mode enables seamless support for Bidirectional data transmission between Client/Consumer and Sender/Publisher along with video-frames through its synchronous messaging patterns such as zmq.PAIR (ZMQ Pair Pattern) & zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern). In Bidirectional Mode, we utilizes the NetGear API's message parameter of send() method for sending data from Server-to-Client, and return_data parameter of recv() method to return data back from Client-to-Server all while transferring frames in real-time. This mode can be easily activated in NetGear through bidirectional_mode attribute of its options dictionary parameter during initialization. Important Information regarding Bidirectional Mode In Bidirectional Mode, zmq.PAIR (ZMQ Pair) & zmq.REQ/zmq.REP (ZMQ Request/Reply) are ONLY Supported messaging patterns. Accessing this mode with any other messaging pattern, will result in ValueError . Bidirectional Mode enables you to send data of ANY 1 Data-type along with frame bidirectionally. Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised! Bidirectional Mode is smart enough to sense data (if available or not) , and DOES NOT interfere with transferring of video-frames (unless data is huge) , as both mechanisms works independently. Bidirectional Mode is now compatibile with both Multi-Servers mode and Multi-Clients mode exclusive modes. Features of Bidirectional Mode \u2693 Enables easy-to-use seamless Bidirectional data transmission between two systems. Supports zmq.PAIR & zmq.REQ/zmq.REP messaging patterns. Support for sending data of almost any 1 datatype. Auto-enables reconnection if Server or Client disconnects prematurely. Exclusive Parameters \u2693 To send data bidirectionally, NetGear API provides two exclusive parameters for its methods: message : It enables user to send data to Client, directly through send() method at Server's end. return_data : It enables user to send data back to Server, directly through recv() method at Client's end. Usage Examples \u2693 Bare-Minimum Usage \u2693 Following is the bare-minimum code you need to get started with Bidirectional Mode in NetGear API: Server End \u2693 Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear Server with defined parameters server = NetGear ( logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # (1) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter. Client End \u2693 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am a Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using Bidirectional Mode with Variable Parameters \u2693 Client's End \u2693 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am a Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print recieved server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server End \u2693 Now, Open the terminal on another Server System (a Raspberry Pi with Camera Module) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear from vidgear.gears import PiGear # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # (1) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter. Using Bidirectional Mode for Video-Frames Transfer \u2693 In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time, for testing the real-time performance and synchronization between the Server and the Client using this(Bidirectional) Mode. This example is useful for building applications like Real-Time Video Chat. We're also using reducer() method for reducing frame-size on-the-go for additional performance. Remember, Sending large HQ video-frames may required more network bandwidth and packet size which may lead to video latency! Server End \u2693 Open your favorite terminal and execute the following python code: You can terminate both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears.helper import reducer import numpy as np import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = cv2 . VideoCapture ( \"test.mp4\" ) # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # reducer frames size if you want more performance, otherwise comment this line frame = reducer ( frame , percentage = 30 ) # reduce frame by 30% # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # (1) # check data just received from Client is of numpy datatype if not ( recv_data is None ) and isinstance ( recv_data , np . ndarray ): # {do something with received numpy array here} # Let's show it on output window cv2 . imshow ( \"Received Frame\" , recv_data ) key = cv2 . waitKey ( 1 ) & 0xFF except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter. Client End \u2693 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears.helper import reducer import cv2 # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # again open the same video stream stream = cv2 . VideoCapture ( \"test.mp4\" ) # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # reducer frames size if you want more performance, otherwise comment this line frame = reducer ( frame , percentage = 30 ) # reduce frame by 30% # receive data from server and also send our data data = client . recv ( return_data = frame ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close client client . close () Using Bidirectional Mode for Video-Frames Transfer with Frame Compression \u2693 This usage examples can be found here \u27b6 Additional data of numpy.ndarray data-type is ONLY SUPPORTED at Client's end with its return_data parameter. \u21a9 \u21a9","title":"Bidirectional Mode"},{"location":"gears/netgear/advanced/bidirectional_mode/#bidirectional-mode-for-netgear-api","text":"","title":"Bidirectional Mode for NetGear API"},{"location":"gears/netgear/advanced/bidirectional_mode/#overview","text":"Bidirectional Mode enables seamless support for Bidirectional data transmission between Client/Consumer and Sender/Publisher along with video-frames through its synchronous messaging patterns such as zmq.PAIR (ZMQ Pair Pattern) & zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern). In Bidirectional Mode, we utilizes the NetGear API's message parameter of send() method for sending data from Server-to-Client, and return_data parameter of recv() method to return data back from Client-to-Server all while transferring frames in real-time. This mode can be easily activated in NetGear through bidirectional_mode attribute of its options dictionary parameter during initialization. Important Information regarding Bidirectional Mode In Bidirectional Mode, zmq.PAIR (ZMQ Pair) & zmq.REQ/zmq.REP (ZMQ Request/Reply) are ONLY Supported messaging patterns. Accessing this mode with any other messaging pattern, will result in ValueError . Bidirectional Mode enables you to send data of ANY 1 Data-type along with frame bidirectionally. Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised! Bidirectional Mode is smart enough to sense data (if available or not) , and DOES NOT interfere with transferring of video-frames (unless data is huge) , as both mechanisms works independently. Bidirectional Mode is now compatibile with both Multi-Servers mode and Multi-Clients mode exclusive modes.","title":"Overview"},{"location":"gears/netgear/advanced/bidirectional_mode/#features-of-bidirectional-mode","text":"Enables easy-to-use seamless Bidirectional data transmission between two systems. Supports zmq.PAIR & zmq.REQ/zmq.REP messaging patterns. Support for sending data of almost any 1 datatype. Auto-enables reconnection if Server or Client disconnects prematurely.","title":"Features of Bidirectional Mode"},{"location":"gears/netgear/advanced/bidirectional_mode/#exclusive-parameters","text":"To send data bidirectionally, NetGear API provides two exclusive parameters for its methods: message : It enables user to send data to Client, directly through send() method at Server's end. return_data : It enables user to send data back to Server, directly through recv() method at Client's end.","title":"Exclusive Parameters"},{"location":"gears/netgear/advanced/bidirectional_mode/#usage-examples","text":"","title":"Usage Examples"},{"location":"gears/netgear/advanced/bidirectional_mode/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with Bidirectional Mode in NetGear API:","title":"Bare-Minimum Usage"},{"location":"gears/netgear/advanced/bidirectional_mode/#server-end","text":"Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear Server with defined parameters server = NetGear ( logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # (1) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter.","title":"Server End"},{"location":"gears/netgear/advanced/bidirectional_mode/#client-end","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am a Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear/advanced/bidirectional_mode/#using-bidirectional-mode-with-variable-parameters","text":"","title":"Using Bidirectional Mode with Variable Parameters"},{"location":"gears/netgear/advanced/bidirectional_mode/#clients-end","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am a Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print recieved server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/bidirectional_mode/#server-end_1","text":"Now, Open the terminal on another Server System (a Raspberry Pi with Camera Module) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear from vidgear.gears import PiGear # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # (1) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter.","title":"Server End"},{"location":"gears/netgear/advanced/bidirectional_mode/#using-bidirectional-mode-for-video-frames-transfer","text":"In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time, for testing the real-time performance and synchronization between the Server and the Client using this(Bidirectional) Mode. This example is useful for building applications like Real-Time Video Chat. We're also using reducer() method for reducing frame-size on-the-go for additional performance. Remember, Sending large HQ video-frames may required more network bandwidth and packet size which may lead to video latency!","title":"Using Bidirectional Mode for Video-Frames Transfer"},{"location":"gears/netgear/advanced/bidirectional_mode/#server-end_2","text":"Open your favorite terminal and execute the following python code: You can terminate both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears.helper import reducer import numpy as np import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = cv2 . VideoCapture ( \"test.mp4\" ) # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # reducer frames size if you want more performance, otherwise comment this line frame = reducer ( frame , percentage = 30 ) # reduce frame by 30% # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # (1) # check data just received from Client is of numpy datatype if not ( recv_data is None ) and isinstance ( recv_data , np . ndarray ): # {do something with received numpy array here} # Let's show it on output window cv2 . imshow ( \"Received Frame\" , recv_data ) key = cv2 . waitKey ( 1 ) & 0xFF except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter.","title":"Server End"},{"location":"gears/netgear/advanced/bidirectional_mode/#client-end_1","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears.helper import reducer import cv2 # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # again open the same video stream stream = cv2 . VideoCapture ( \"test.mp4\" ) # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # reducer frames size if you want more performance, otherwise comment this line frame = reducer ( frame , percentage = 30 ) # reduce frame by 30% # receive data from server and also send our data data = client . recv ( return_data = frame ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear/advanced/bidirectional_mode/#using-bidirectional-mode-for-video-frames-transfer-with-frame-compression","text":"This usage examples can be found here \u27b6 Additional data of numpy.ndarray data-type is ONLY SUPPORTED at Client's end with its return_data parameter. \u21a9 \u21a9","title":"Using Bidirectional Mode for Video-Frames Transfer with Frame Compression"},{"location":"gears/netgear/advanced/compression/","text":"Frame Compression for NetGear API \u2693 Overview \u2693 NetGear API enables real-time JPEG Frame Compression capabilities for optimizing performance significantly while sending frames over the network. For enabling Frame Compression, NetGear uses powerful simplejpeg library at its backend, which is based on recent versions of libjpeg-turbo JPEG image codec, to accelerate baseline JPEG compression and decompression on all modern systems. NetGear API employs its exposed decode_jpeg and encode_jpeg methods to encode video-frames to JFIF format before sending it at Server, and cleverly decode it at the Client(s) all in real-time, thereby leveraging performance at cost of minor loss in frame quality. Frame Compression is enabled by default in NetGear, and can be easily controlled through jpeg_compression_quality , jpeg_compression_fastdct , jpeg_compression_fastupsample like attributes of its options dictionary parameter during initialization. Useful Information about Frame Compression Frame Compression is enabled by default in NetGear along with fast dct and compression-quality at 90%. Exclusive jpeg_compression attribute can also be used to disable Frame Compression. Frame Compression can leverage performance up-to 5-10% with exclusive performance attributes . Frame Compression is compatible with all messaging pattern and modes. Frame Compression is primarily controlled by Server end. That means, if Frame Compression is enabled at Server, then Client(s) will automatically enforce the Frame Compression with defined performance attributes. Otherwise if it is disabled, then Client(s) disables it too. Exclusive Attributes \u2693 For implementing Frame Compression, NetGear API currently provide following exclusive attribute for its options dictionary parameter to leverage performance with Frame Compression: jpeg_compression : (bool/str) This internal attribute is used to activate/deactivate JPEG Frame Compression as well as to specify incoming frames colorspace with compression. Its usage is as follows: For activating JPEG Frame Compression (Boolean) : In this case, colorspace will default to BGR . You can set jpeg_compression value to False at Server end to completely disable Frame Compression. # enable jpeg encoding options = { \"jpeg_compression\" : True } For specifying Input frames colorspace (String) : In this case, JPEG Frame Compression is activated automatically. Supported colorspace values are RGB , BGR , RGBX , BGRX , XBGR , XRGB , GRAY , RGBA , BGRA , ABGR , ARGB , CMYK . More information can be found here \u27b6 # Specify incoming frames are `grayscale` options = { \"jpeg_compression\" : \"GRAY\" } Performance Attributes \u2693 jpeg_compression_quality : (int/float) This attribute controls the JPEG quantization factor. Its value varies from 10 to 100 (the higher is the better quality but performance will be lower). Its default value is 90 . Its usage is as follows: # activate jpeg encoding and set quality 95% options = { \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 95 } jpeg_compression_fastdct : (bool) This attribute if True, NetGear API uses fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality. Its default value is also True , and its usage is as follows: # activate jpeg encoding and enable fast dct options = { \"jpeg_compression\" : True , \"jpeg_compression_fastdct\" : True } jpeg_compression_fastupsample : (bool) This attribute if True, NetGear API use fastest color upsampling method. Its default value is False , and its usage is as follows: # activate jpeg encoding and enable fast upsampling options = { \"jpeg_compression\" : True , \"jpeg_compression_fastupsample\" : True } Usage Examples \u2693 Bare-Minimum Usage \u2693 Following is the bare-minimum code you need to get started with Frame Compression in NetGear API: Server End \u2693 Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate jpeg encoding and specify other related parameters options = { \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client End \u2693 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! If compression is enabled at Server, then Client will automatically enforce Frame Compression with its performance attributes. # import required libraries from vidgear.gears import NetGear import cv2 # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Bare-Minimum Usage with Variable Colorspace \u2693 Frame Compression also supports specify incoming frames colorspace with compression. In following bare-minimum code, we will be sending GRAY frames from Server to Client: New in v0.2.2 This example was added in v0.2.2 . This example works in conjunction with Source ColorSpace manipulation for VideoCapture Gears \u27b6 Supported colorspace values are RGB , BGR , RGBX , BGRX , XBGR , XRGB , GRAY , RGBA , BGRA , ABGR , ARGB , CMYK . More information can be found here \u27b6 Server End \u2693 Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # open any valid video stream(for e.g `test.mp4` file) and change its colorspace to grayscale stream = VideoGear ( source = \"test.mp4\" , colorspace = \"COLOR_BGR2GRAY\" ) . start () # activate jpeg encoding and specify other related parameters options = { \"jpeg_compression\" : \"GRAY\" , # set grayscale \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read grayscale frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # send grayscale frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client End \u2693 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! If compression is enabled at Server, then Client will automatically enforce Frame Compression with its performance attributes. Client's end also automatically enforces Server's colorspace, there's no need to define it again. # import required libraries from vidgear.gears import NetGear import cv2 # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True ) # loop over while True : # receive grayscale frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the grayscale frame here} # Show output window cv2 . imshow ( \"Output Grayscale Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using Frame Compression with Variable Parameters \u2693 Client's End \u2693 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. If compression is enabled at Server, then Client will automatically enforce Frame Compression with its performance attributes. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Define NetGear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server End \u2693 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # activate jpeg encoding and specify other related parameters options = { \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Using Bidirectional Mode for Video-Frames Transfer with Frame Compression \u2693 NetGear now supports Dual Frame Compression for transferring video-frames with its exclusive Bidirectional Mode for achieving unmatchable performance bidirectionally. You can easily enable Frame Compression with its performance attributes at both ends to boost performance bidirectionally. In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time for testing the real-time performance and synchronization between the Server and Client using Bidirectional Mode . Furthermore, we're going to use optimal Dual Frame Compression Setting for Sending and Receiving frames at both Server and Client end. This example is great for building applications like Real-time Video Chat System . This Dual Frame Compression feature also available for Multi-Clients Mode. We're also using reducer() Helper method for reducing frame-size on-the-go for additional performance. Remember to define Frame Compression's performance attributes both on Server and Client ends in Dual Frame Compression to boost performance bidirectionally! Server End \u2693 Open your favorite terminal and execute the following python code: You can terminate both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears.helper import reducer import numpy as np import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = cv2 . VideoCapture ( \"test.mp4\" ) # activate Bidirectional mode and Frame Compression options = { \"bidirectional_mode\" : True , \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 95 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # reducer frames size if you want even more performance, otherwise comment this line frame = reducer ( frame , percentage = 20 ) # reduce frame by 20% # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # (1) # check data just received from Client is of numpy datatype if not ( recv_data is None ) and isinstance ( recv_data , np . ndarray ): # {do something with received numpy array here} # Let's show it on output window cv2 . imshow ( \"Received Frame\" , recv_data ) key = cv2 . waitKey ( 1 ) & 0xFF except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter. Client End \u2693 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears.helper import reducer import cv2 # activate Bidirectional mode and Frame Compression options = { \"bidirectional_mode\" : True , \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 95 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # again open the same video stream stream = cv2 . VideoCapture ( \"test.mp4\" ) # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # reducer frames size if you want even more performance, otherwise comment this line frame = reducer ( frame , percentage = 20 ) # reduce frame by 20% # receive data from server and also send our data data = client . recv ( return_data = frame ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close client client . close ()","title":"Frame Compression"},{"location":"gears/netgear/advanced/compression/#frame-compression-for-netgear-api","text":"","title":"Frame Compression for NetGear API"},{"location":"gears/netgear/advanced/compression/#overview","text":"NetGear API enables real-time JPEG Frame Compression capabilities for optimizing performance significantly while sending frames over the network. For enabling Frame Compression, NetGear uses powerful simplejpeg library at its backend, which is based on recent versions of libjpeg-turbo JPEG image codec, to accelerate baseline JPEG compression and decompression on all modern systems. NetGear API employs its exposed decode_jpeg and encode_jpeg methods to encode video-frames to JFIF format before sending it at Server, and cleverly decode it at the Client(s) all in real-time, thereby leveraging performance at cost of minor loss in frame quality. Frame Compression is enabled by default in NetGear, and can be easily controlled through jpeg_compression_quality , jpeg_compression_fastdct , jpeg_compression_fastupsample like attributes of its options dictionary parameter during initialization. Useful Information about Frame Compression Frame Compression is enabled by default in NetGear along with fast dct and compression-quality at 90%. Exclusive jpeg_compression attribute can also be used to disable Frame Compression. Frame Compression can leverage performance up-to 5-10% with exclusive performance attributes . Frame Compression is compatible with all messaging pattern and modes. Frame Compression is primarily controlled by Server end. That means, if Frame Compression is enabled at Server, then Client(s) will automatically enforce the Frame Compression with defined performance attributes. Otherwise if it is disabled, then Client(s) disables it too.","title":"Overview"},{"location":"gears/netgear/advanced/compression/#exclusive-attributes","text":"For implementing Frame Compression, NetGear API currently provide following exclusive attribute for its options dictionary parameter to leverage performance with Frame Compression: jpeg_compression : (bool/str) This internal attribute is used to activate/deactivate JPEG Frame Compression as well as to specify incoming frames colorspace with compression. Its usage is as follows: For activating JPEG Frame Compression (Boolean) : In this case, colorspace will default to BGR . You can set jpeg_compression value to False at Server end to completely disable Frame Compression. # enable jpeg encoding options = { \"jpeg_compression\" : True } For specifying Input frames colorspace (String) : In this case, JPEG Frame Compression is activated automatically. Supported colorspace values are RGB , BGR , RGBX , BGRX , XBGR , XRGB , GRAY , RGBA , BGRA , ABGR , ARGB , CMYK . More information can be found here \u27b6 # Specify incoming frames are `grayscale` options = { \"jpeg_compression\" : \"GRAY\" }","title":"Exclusive Attributes"},{"location":"gears/netgear/advanced/compression/#performance-attributes","text":"jpeg_compression_quality : (int/float) This attribute controls the JPEG quantization factor. Its value varies from 10 to 100 (the higher is the better quality but performance will be lower). Its default value is 90 . Its usage is as follows: # activate jpeg encoding and set quality 95% options = { \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 95 } jpeg_compression_fastdct : (bool) This attribute if True, NetGear API uses fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality. Its default value is also True , and its usage is as follows: # activate jpeg encoding and enable fast dct options = { \"jpeg_compression\" : True , \"jpeg_compression_fastdct\" : True } jpeg_compression_fastupsample : (bool) This attribute if True, NetGear API use fastest color upsampling method. Its default value is False , and its usage is as follows: # activate jpeg encoding and enable fast upsampling options = { \"jpeg_compression\" : True , \"jpeg_compression_fastupsample\" : True }","title":"Performance Attributes"},{"location":"gears/netgear/advanced/compression/#usage-examples","text":"","title":"Usage Examples"},{"location":"gears/netgear/advanced/compression/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with Frame Compression in NetGear API:","title":"Bare-Minimum Usage"},{"location":"gears/netgear/advanced/compression/#server-end","text":"Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate jpeg encoding and specify other related parameters options = { \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/compression/#client-end","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! If compression is enabled at Server, then Client will automatically enforce Frame Compression with its performance attributes. # import required libraries from vidgear.gears import NetGear import cv2 # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear/advanced/compression/#bare-minimum-usage-with-variable-colorspace","text":"Frame Compression also supports specify incoming frames colorspace with compression. In following bare-minimum code, we will be sending GRAY frames from Server to Client: New in v0.2.2 This example was added in v0.2.2 . This example works in conjunction with Source ColorSpace manipulation for VideoCapture Gears \u27b6 Supported colorspace values are RGB , BGR , RGBX , BGRX , XBGR , XRGB , GRAY , RGBA , BGRA , ABGR , ARGB , CMYK . More information can be found here \u27b6","title":"Bare-Minimum Usage with Variable Colorspace"},{"location":"gears/netgear/advanced/compression/#server-end_1","text":"Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # open any valid video stream(for e.g `test.mp4` file) and change its colorspace to grayscale stream = VideoGear ( source = \"test.mp4\" , colorspace = \"COLOR_BGR2GRAY\" ) . start () # activate jpeg encoding and specify other related parameters options = { \"jpeg_compression\" : \"GRAY\" , # set grayscale \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read grayscale frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # send grayscale frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/compression/#client-end_1","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! If compression is enabled at Server, then Client will automatically enforce Frame Compression with its performance attributes. Client's end also automatically enforces Server's colorspace, there's no need to define it again. # import required libraries from vidgear.gears import NetGear import cv2 # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True ) # loop over while True : # receive grayscale frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the grayscale frame here} # Show output window cv2 . imshow ( \"Output Grayscale Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear/advanced/compression/#using-frame-compression-with-variable-parameters","text":"","title":"Using Frame Compression with Variable Parameters"},{"location":"gears/netgear/advanced/compression/#clients-end","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. If compression is enabled at Server, then Client will automatically enforce Frame Compression with its performance attributes. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Define NetGear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/compression/#server-end_2","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # activate jpeg encoding and specify other related parameters options = { \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/compression/#using-bidirectional-mode-for-video-frames-transfer-with-frame-compression","text":"NetGear now supports Dual Frame Compression for transferring video-frames with its exclusive Bidirectional Mode for achieving unmatchable performance bidirectionally. You can easily enable Frame Compression with its performance attributes at both ends to boost performance bidirectionally. In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time for testing the real-time performance and synchronization between the Server and Client using Bidirectional Mode . Furthermore, we're going to use optimal Dual Frame Compression Setting for Sending and Receiving frames at both Server and Client end. This example is great for building applications like Real-time Video Chat System . This Dual Frame Compression feature also available for Multi-Clients Mode. We're also using reducer() Helper method for reducing frame-size on-the-go for additional performance. Remember to define Frame Compression's performance attributes both on Server and Client ends in Dual Frame Compression to boost performance bidirectionally!","title":"Using Bidirectional Mode for Video-Frames Transfer with Frame Compression"},{"location":"gears/netgear/advanced/compression/#server-end_3","text":"Open your favorite terminal and execute the following python code: You can terminate both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears.helper import reducer import numpy as np import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = cv2 . VideoCapture ( \"test.mp4\" ) # activate Bidirectional mode and Frame Compression options = { \"bidirectional_mode\" : True , \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 95 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # reducer frames size if you want even more performance, otherwise comment this line frame = reducer ( frame , percentage = 20 ) # reduce frame by 20% # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # (1) # check data just received from Client is of numpy datatype if not ( recv_data is None ) and isinstance ( recv_data , np . ndarray ): # {do something with received numpy array here} # Let's show it on output window cv2 . imshow ( \"Received Frame\" , recv_data ) key = cv2 . waitKey ( 1 ) & 0xFF except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter.","title":"Server End"},{"location":"gears/netgear/advanced/compression/#client-end_2","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears.helper import reducer import cv2 # activate Bidirectional mode and Frame Compression options = { \"bidirectional_mode\" : True , \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 95 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # again open the same video stream stream = cv2 . VideoCapture ( \"test.mp4\" ) # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # reducer frames size if you want even more performance, otherwise comment this line frame = reducer ( frame , percentage = 20 ) # reduce frame by 20% # receive data from server and also send our data data = client . recv ( return_data = frame ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear/advanced/multi_client/","text":"Multi-Clients Mode for NetGear API \u2693 NetGear's Multi-Clients Mode Overview \u2693 In Multi-Clients Mode, NetGear robustly handles Multiple Clients at once thereby able to broadcast frames and data across multiple Clients/Consumers in the network at same time. This mode works contrary to Multi-Servers Mode such that every new Client that connects to single Server can be identified by its unique port address on the network. The supported patterns for this mode are Publish/Subscribe ( zmq.PUB/zmq.SUB ) and Request/Reply( zmq.REQ/zmq.REP ) and can be easily activated in NetGear API through multiclient_mode attribute of its options dictionary parameter during initialization. Multi-Clients Mode is best for broadcasting Meta-Data with Video-frames to specific limited number of clients in real time. But if you're looking to scale broadcast to a very large pool of clients, then see our WebGear or WebGear_RTC APIs. Important Information regarding Multi-Clients Mode A unique PORT address MUST be assigned to each Client on the network using its port parameter. A list/tuple of PORT addresses of all unique Clients MUST be assigned at Server's end using its port parameter for a successful connection. Patterns 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) and 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) are the only supported pattern values for this Mode. Therefore, calling any other pattern value with is mode will result in ValueError . Multi-Clients and Multi-Servers exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw ValueError . The address parameter value of each Client MUST exactly match the Server. Features of Multi-Clients Mode \u2693 Enables Multiple Client(s) connection with a single Server. Ability to send any additional data of any datatype along with frames in real-time. Number of Clients can be extended to several numbers depending upon your system's hardware limit. Employs powerful Publish/Subscribe & Request/Reply messaging patterns. Each new Client on the network can be identified at Server's end by their unique port addresses. NetGear API actively tracks the state of each connected Client. If the server gets disconnected, all the clients will automatically exit to save resources. Usage Examples \u2693 Important Frame/Data transmission will NOT START until all given Client(s) are connected to the Server. For sake of simplicity, in these examples we will use only two unique Clients, but the number of these Clients can be extended to SEVERAL numbers depending upon your Network bandwidth and System Capabilities. Bare-Minimum Usage \u2693 In this example, we will capturing live video-frames from a source (a.k.a Server) with a webcam connected to it. Afterwards, those captured frame will be sent over the network to two independent system (a.k.a Clients) using this Multi-Clients Mode in NetGear API. Finally, both Clients will be displaying recieved frames in Output Windows in real time. This example is useful for building applications like Real-Time Video Broadcasting to multiple clients in local network. Server's End \u2693 Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiclient_mode mode options = { \"multiclient_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of # all unique Server((5577,5578) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = ( 5567 , 5577 ), protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : # print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client-1's End \u2693 Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5567 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Client-2's End \u2693 Finally, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Bare-Minimum Usage with OpenCV \u2693 In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API. Server's End \u2693 Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiclient_mode mode options = { \"multiclient_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = ( 5567 , 5577 ), protocol = \"tcp\" , pattern = 2 , logging = True , ** options ) # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : # print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Client-1's End \u2693 Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5567 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Client-2's End \u2693 Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using Multi-Clients Mode for Unidirectional Custom Data Transfer \u2693 Abstract With Multi-Clients Mode, you can also send additional data of any data-type (such as list, tuple, string, int, ndarray etc.) along with frame, from all connected Clients(s) back to a Server unidirectionally. In Multi-Clients Mode, unidirectional data transfer ONLY works with pattern 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) , and NOT with pattern 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) ! In this example, We will be transferring video-frames from a single Server (consisting of Raspberry Pi with Camera Module) over the network to two independent Client for displaying them in real-time. At the same time, we will be sending data (a Text String, for the sake of simplicity) from both the Client(s) back to our Server, which will be printed onto the terminal. Server's End \u2693 Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import PiGear from vidgear.gears import NetGear # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate multiclient_mode mode options = { \"multiclient_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters server = NetGear ( address = \"192.168.x.x\" , port = ( 5577 , 5578 ), protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : # print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client-1's End \u2693 Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am 5577 Client here.\" # receive data from server and also send our data frame = client . recv ( return_data = target_data ) # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Client-2's End \u2693 Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5578\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am 5578 Client here.\" # receive data from server and also send our data frame = client . recv ( return_data = target_data ) # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5578 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using Multi-Clients Mode with Bidirectional Mode \u2693 Abstract Multi-Clients Mode now also compatible with Bidirectional Mode , which lets you send additional data of any datatype 1 along with frame in real-time bidirectionally between a single Server and all connected Client(s). Important Information Bidirectional data transfer ONLY works with pattern 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) , and NOT with pattern 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server's end with its message parameter. Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised! New in v0.2.5 This example was added in v0.2.5 . In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) from a single Server (In this case, Raspberry Pi with Camera Module) over the network to two independent Clients for displaying them both in real-time. At the same time, we will be sending data (a Text String, for the sake of simplicity) back from both the Client(s) to our Server, which will be printed onto the terminal. Server's End \u2693 Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import PiGear from vidgear.gears import NetGear # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate both multiclient and bidirectional modes options = { \"multiclient_mode\" : True , \"bidirectional_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of # all unique Server((5577,5578) in our case) and other parameters server = NetGear ( address = \"192.168.x.x\" , port = ( 5577 , 5578 ), protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client(s) recv_data = server . send ( frame , message = target_data ) # (1) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : # print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter. Client-1's End \u2693 Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate both multiclient and bidirectional modes options = { \"multiclient_mode\" : True , \"bidirectional_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am 5577 Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Client-2's End \u2693 Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate both multiclient and bidirectional modes options = { \"multiclient_mode\" : True , \"bidirectional_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5578\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am 5578 Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Client 5578 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server's end with its message parameter. \u21a9","title":"Multi-Clients Mode"},{"location":"gears/netgear/advanced/multi_client/#multi-clients-mode-for-netgear-api","text":"NetGear's Multi-Clients Mode","title":"Multi-Clients Mode for NetGear API"},{"location":"gears/netgear/advanced/multi_client/#overview","text":"In Multi-Clients Mode, NetGear robustly handles Multiple Clients at once thereby able to broadcast frames and data across multiple Clients/Consumers in the network at same time. This mode works contrary to Multi-Servers Mode such that every new Client that connects to single Server can be identified by its unique port address on the network. The supported patterns for this mode are Publish/Subscribe ( zmq.PUB/zmq.SUB ) and Request/Reply( zmq.REQ/zmq.REP ) and can be easily activated in NetGear API through multiclient_mode attribute of its options dictionary parameter during initialization. Multi-Clients Mode is best for broadcasting Meta-Data with Video-frames to specific limited number of clients in real time. But if you're looking to scale broadcast to a very large pool of clients, then see our WebGear or WebGear_RTC APIs. Important Information regarding Multi-Clients Mode A unique PORT address MUST be assigned to each Client on the network using its port parameter. A list/tuple of PORT addresses of all unique Clients MUST be assigned at Server's end using its port parameter for a successful connection. Patterns 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) and 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) are the only supported pattern values for this Mode. Therefore, calling any other pattern value with is mode will result in ValueError . Multi-Clients and Multi-Servers exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw ValueError . The address parameter value of each Client MUST exactly match the Server.","title":"Overview"},{"location":"gears/netgear/advanced/multi_client/#features-of-multi-clients-mode","text":"Enables Multiple Client(s) connection with a single Server. Ability to send any additional data of any datatype along with frames in real-time. Number of Clients can be extended to several numbers depending upon your system's hardware limit. Employs powerful Publish/Subscribe & Request/Reply messaging patterns. Each new Client on the network can be identified at Server's end by their unique port addresses. NetGear API actively tracks the state of each connected Client. If the server gets disconnected, all the clients will automatically exit to save resources.","title":"Features of Multi-Clients Mode"},{"location":"gears/netgear/advanced/multi_client/#usage-examples","text":"Important Frame/Data transmission will NOT START until all given Client(s) are connected to the Server. For sake of simplicity, in these examples we will use only two unique Clients, but the number of these Clients can be extended to SEVERAL numbers depending upon your Network bandwidth and System Capabilities.","title":"Usage Examples"},{"location":"gears/netgear/advanced/multi_client/#bare-minimum-usage","text":"In this example, we will capturing live video-frames from a source (a.k.a Server) with a webcam connected to it. Afterwards, those captured frame will be sent over the network to two independent system (a.k.a Clients) using this Multi-Clients Mode in NetGear API. Finally, both Clients will be displaying recieved frames in Output Windows in real time. This example is useful for building applications like Real-Time Video Broadcasting to multiple clients in local network.","title":"Bare-Minimum Usage"},{"location":"gears/netgear/advanced/multi_client/#servers-end","text":"Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiclient_mode mode options = { \"multiclient_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of # all unique Server((5577,5578) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = ( 5567 , 5577 ), protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : # print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end","text":"Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5567 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-1's End"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end","text":"Finally, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-2's End"},{"location":"gears/netgear/advanced/multi_client/#bare-minimum-usage-with-opencv","text":"In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API.","title":"Bare-Minimum Usage with OpenCV"},{"location":"gears/netgear/advanced/multi_client/#servers-end_1","text":"Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiclient_mode mode options = { \"multiclient_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = ( 5567 , 5577 ), protocol = \"tcp\" , pattern = 2 , logging = True , ** options ) # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : # print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end_1","text":"Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5567 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-1's End"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end_1","text":"Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-2's End"},{"location":"gears/netgear/advanced/multi_client/#using-multi-clients-mode-for-unidirectional-custom-data-transfer","text":"Abstract With Multi-Clients Mode, you can also send additional data of any data-type (such as list, tuple, string, int, ndarray etc.) along with frame, from all connected Clients(s) back to a Server unidirectionally. In Multi-Clients Mode, unidirectional data transfer ONLY works with pattern 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) , and NOT with pattern 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) ! In this example, We will be transferring video-frames from a single Server (consisting of Raspberry Pi with Camera Module) over the network to two independent Client for displaying them in real-time. At the same time, we will be sending data (a Text String, for the sake of simplicity) from both the Client(s) back to our Server, which will be printed onto the terminal.","title":"Using Multi-Clients Mode for Unidirectional Custom Data Transfer"},{"location":"gears/netgear/advanced/multi_client/#servers-end_2","text":"Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import PiGear from vidgear.gears import NetGear # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate multiclient_mode mode options = { \"multiclient_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters server = NetGear ( address = \"192.168.x.x\" , port = ( 5577 , 5578 ), protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : # print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end_2","text":"Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am 5577 Client here.\" # receive data from server and also send our data frame = client . recv ( return_data = target_data ) # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-1's End"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end_2","text":"Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5578\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am 5578 Client here.\" # receive data from server and also send our data frame = client . recv ( return_data = target_data ) # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5578 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-2's End"},{"location":"gears/netgear/advanced/multi_client/#using-multi-clients-mode-with-bidirectional-mode","text":"Abstract Multi-Clients Mode now also compatible with Bidirectional Mode , which lets you send additional data of any datatype 1 along with frame in real-time bidirectionally between a single Server and all connected Client(s). Important Information Bidirectional data transfer ONLY works with pattern 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) , and NOT with pattern 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server's end with its message parameter. Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised! New in v0.2.5 This example was added in v0.2.5 . In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) from a single Server (In this case, Raspberry Pi with Camera Module) over the network to two independent Clients for displaying them both in real-time. At the same time, we will be sending data (a Text String, for the sake of simplicity) back from both the Client(s) to our Server, which will be printed onto the terminal.","title":"Using Multi-Clients Mode with Bidirectional Mode"},{"location":"gears/netgear/advanced/multi_client/#servers-end_3","text":"Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import PiGear from vidgear.gears import NetGear # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate both multiclient and bidirectional modes options = { \"multiclient_mode\" : True , \"bidirectional_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of # all unique Server((5577,5578) in our case) and other parameters server = NetGear ( address = \"192.168.x.x\" , port = ( 5577 , 5578 ), protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client(s) recv_data = server . send ( frame , message = target_data ) # (1) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : # print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter.","title":"Server's End"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end_3","text":"Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate both multiclient and bidirectional modes options = { \"multiclient_mode\" : True , \"bidirectional_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am 5577 Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-1's End"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end_3","text":"Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate both multiclient and bidirectional modes options = { \"multiclient_mode\" : True , \"bidirectional_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5578\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am 5578 Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Client 5578 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server's end with its message parameter. \u21a9","title":"Client-2's End"},{"location":"gears/netgear/advanced/multi_server/","text":"Multi-Servers Mode for NetGear API \u2693 NetGear's Multi-Servers Mode Overview \u2693 In Multi-Servers Mode, NetGear API robustly handles Multiple Servers at once, thereby providing seamless access to frames and unidirectional data transfer across multiple Publishers/Servers in the network at the same time. Each new server connects to a single client can be identified by its unique port address on the network. The supported patterns for this mode are Publish/Subscribe ( zmq.PUB/zmq.SUB ) and Request/Reply( zmq.REQ/zmq.REP ) and can be easily activated in NetGear API through multiserver_mode attribute of its options dictionary parameter during initialization. Important Information regarding Multi-Servers Mode A unique PORT address MUST be assigned to each Server on the network using its port parameter. A list/tuple of PORT addresses of all unique Servers MUST be assigned at Client's end using its port parameter for a successful connection. Patterns 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) and 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) are the only supported values for this Mode. Therefore, calling any other pattern value with is mode will result in ValueError . Multi-Servers and Multi-Clients exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw ValueError . The address parameter value of each Server MUST exactly match the Client. Key Features \u2693 Enables Multiple Server(s) connection with a single Client. Ability to send any additional data of any 1 datatype along with frames in real-time. Number of Servers can be extended to several numbers depending upon your system's hardware limit. Employs powerful Publish/Subscribe & Request/Reply messaging patterns. Each new Server on the network can be identified at Client's end by their unique port addresses. NetGear API actively tracks the state of each connected Server. If all the connected servers on the network get disconnected, the client itself automatically exits to save resources. Usage Examples \u2693 Example Assumptions For sake of simplicity, in these examples we will use only two unique Servers, but, the number of these Servers can be extended to several numbers depending upon your system hardware limits. All of Servers will be transferring frames to a single Client system at the same time, which will be displaying received frames as a live montage (multiple frames concatenated together) . For building Frames Montage at Client's end, We are going to use imutils python library function to build montages, by concatenating together frames recieved from different servers. Therefore, Kindly install this library with pip install imutils terminal command. Bare-Minimum Usage \u2693 In this example, we will capturing live video-frames on two independent sources (a.k.a Servers) , each with a webcam connected to it. Afterwards, these frames will be sent over the network to a single system (a.k.a Client) using this Multi-Servers Mode in NetGear API in real time, and will be displayed as a live montage. This example is useful for building applications like Real-Time Security System with multiple cameras. Client's End \u2693 Open a terminal on Client System (where you want to display the input frames received from Multiple Servers) and execute the following python code: Important Notes Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages # (1) import cv2 # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple # of all unique Server((5566,5567) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = ( 5566 , 5567 ), protocol = \"tcp\" , pattern = 1 , receive_mode = True , ** options ) # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame unique_address , frame = data # {do something with the extracted frame here} # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the received frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close () For building Frames Montage you'll need imutils python library. Install it with pip install imutils command. Server-1's End \u2693 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5566\" , protocol = \"tcp\" , pattern = 1 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Server-2's End \u2693 Finally, Open the terminal on another Server System (also with a webcam connected to it at index 0 ) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 1 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Bare-Minimum Usage with OpenCV \u2693 In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API. Client's End \u2693 Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: Important Notes Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages # (1) import cv2 # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all # unique Server((5566,5567) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = ( 5566 , 5567 ), protocol = \"tcp\" , pattern = 2 , receive_mode = True , ** options ) # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame unique_address , frame = data # {do something with the extracted frame here} # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the received frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close () For building Frames Montage you'll need imutils python library. Install it with pip install imutils command. Server-1's End \u2693 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameter # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5566\" , protocol = \"tcp\" , pattern = 2 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Server-2's End \u2693 Finally, Open the terminal on another Server System (also with a webcam connected to it at index 0 ) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 2 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Using Multi-Servers Mode for Unidirectional Custom Data Transfer \u2693 Abstract With Multi-Servers Mode, you can send additional data of any datatype 1 along with frame with frame in real-time, from all connected Server(s) to a single Client unidirectionally. But numpy.ndarray data-type is NOT supported as data. In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) from two Servers (consisting of a Raspberry Pi with Camera Module & a Laptop with webcam) to a single Client over the network in real-time. The received video-frames at Client's end will displayed as a live montage, whereas the received data will be printed to the terminal. Client's End \u2693 Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: Important Notes Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages # (1) import cv2 # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = ( 5577 , 5578 ), protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame and received data unique_address , extracted_data , frame = data # {do something with the extracted frame and data here} # let's display extracted data on our extracted frame cv2 . putText ( frame , extracted_data , ( 10 , frame . shape [ 0 ] - 10 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.6 , ( 0 , 255 , 0 ), 2 , ) # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close () For building Frames Montage you'll need imutils python library. Install it with pip install imutils command. Server-1's End \u2693 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = VideoGear ( source = 0 ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data target_data = \"I'm Server-1 at Port: 5577\" # send frame and data through server server . send ( frame , message = target_data ) # (1) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter. Server-2's End \u2693 Finally, Open the terminal on another Server System (this time a Raspberry Pi with Camera Module connected to it) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.1.xxx\" , port = \"5578\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data text = \"I'm Server-2 at Port: 5578\" # send frame and data through server server . send ( frame , message = text ) except KeyboardInterrupt : break # safely close video stream. stream . stop () # safely close server server . close () Using Multi-Servers Mode with Bidirectional Mode \u2693 Abstract Multi-Servers Mode now also compatible with Bidirectional Mode , which lets you send additional data of any datatype 1 along with frame in real-time bidirectionally between a single Client and all connected Server(s). Important Information Bidirectional data transfer ONLY works with pattern 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) , and NOT with pattern 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server(s) with their message parameter. Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised! New in v0.2.5 This example was added in v0.2.5 . In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) from two Servers (consisting of a Raspberry Pi with Camera Module & a Laptop with webcam) to a single Client, and at same time sending back data (a Text String, for the sake of simplicity) to them over the network all in real-time. The received video-frames at Client's end will displayed as a live montage, whereas the received data will be printed to the terminal. Client's End \u2693 Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: Important Notes Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages # (1) import cv2 # activate both multiserver and bidirectional modes options = { \"multiserver_mode\" : True , \"bidirectional_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = ( 5577 , 5578 ), protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # prepare data to be sent target_data = \"Hi, I am a Client here.\" # receive data from server(s) and also send our data data = client . recv ( return_data = target_data ) # check if data received isn't None if data is None : break # extract unique port address and its respective frame and received data unique_address , extracted_data , frame = recv_data # {do something with the extracted frame and data here} # let's display extracted data on our extracted frame cv2 . putText ( frame , extracted_data , ( 10 , frame . shape [ 0 ] - 10 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.6 , ( 0 , 255 , 0 ), 2 , ) # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close () For building Frames Montage you'll need imutils python library. Install it with pip install imutils command. Server-1's End \u2693 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = VideoGear ( source = 0 ) . start () # activate both multiserver and bidirectional modes options = { \"multiserver_mode\" : True , \"bidirectional_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data target_data = \"I'm Server-1 at Port: 5577\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # (1) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter. Server-2's End \u2693 Finally, Open the terminal on another Server System (this time a Raspberry Pi with Camera Module connected to it) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate both multiserver and bidirectional modes options = { \"multiserver_mode\" : True , \"bidirectional_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.1.xxx\" , port = \"5578\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data target_data = \"I'm Server-2 at Port: 5578\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # (1) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream. stream . stop () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter. Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server(s) with their message parameter. \u21a9 \u21a9 \u21a9","title":"Multi-Servers Mode"},{"location":"gears/netgear/advanced/multi_server/#multi-servers-mode-for-netgear-api","text":"NetGear's Multi-Servers Mode","title":"Multi-Servers Mode for NetGear API"},{"location":"gears/netgear/advanced/multi_server/#overview","text":"In Multi-Servers Mode, NetGear API robustly handles Multiple Servers at once, thereby providing seamless access to frames and unidirectional data transfer across multiple Publishers/Servers in the network at the same time. Each new server connects to a single client can be identified by its unique port address on the network. The supported patterns for this mode are Publish/Subscribe ( zmq.PUB/zmq.SUB ) and Request/Reply( zmq.REQ/zmq.REP ) and can be easily activated in NetGear API through multiserver_mode attribute of its options dictionary parameter during initialization. Important Information regarding Multi-Servers Mode A unique PORT address MUST be assigned to each Server on the network using its port parameter. A list/tuple of PORT addresses of all unique Servers MUST be assigned at Client's end using its port parameter for a successful connection. Patterns 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) and 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) are the only supported values for this Mode. Therefore, calling any other pattern value with is mode will result in ValueError . Multi-Servers and Multi-Clients exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw ValueError . The address parameter value of each Server MUST exactly match the Client.","title":"Overview"},{"location":"gears/netgear/advanced/multi_server/#key-features","text":"Enables Multiple Server(s) connection with a single Client. Ability to send any additional data of any 1 datatype along with frames in real-time. Number of Servers can be extended to several numbers depending upon your system's hardware limit. Employs powerful Publish/Subscribe & Request/Reply messaging patterns. Each new Server on the network can be identified at Client's end by their unique port addresses. NetGear API actively tracks the state of each connected Server. If all the connected servers on the network get disconnected, the client itself automatically exits to save resources.","title":"Key Features"},{"location":"gears/netgear/advanced/multi_server/#usage-examples","text":"Example Assumptions For sake of simplicity, in these examples we will use only two unique Servers, but, the number of these Servers can be extended to several numbers depending upon your system hardware limits. All of Servers will be transferring frames to a single Client system at the same time, which will be displaying received frames as a live montage (multiple frames concatenated together) . For building Frames Montage at Client's end, We are going to use imutils python library function to build montages, by concatenating together frames recieved from different servers. Therefore, Kindly install this library with pip install imutils terminal command.","title":"Usage Examples"},{"location":"gears/netgear/advanced/multi_server/#bare-minimum-usage","text":"In this example, we will capturing live video-frames on two independent sources (a.k.a Servers) , each with a webcam connected to it. Afterwards, these frames will be sent over the network to a single system (a.k.a Client) using this Multi-Servers Mode in NetGear API in real time, and will be displayed as a live montage. This example is useful for building applications like Real-Time Security System with multiple cameras.","title":"Bare-Minimum Usage"},{"location":"gears/netgear/advanced/multi_server/#clients-end","text":"Open a terminal on Client System (where you want to display the input frames received from Multiple Servers) and execute the following python code: Important Notes Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages # (1) import cv2 # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple # of all unique Server((5566,5567) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = ( 5566 , 5567 ), protocol = \"tcp\" , pattern = 1 , receive_mode = True , ** options ) # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame unique_address , frame = data # {do something with the extracted frame here} # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the received frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close () For building Frames Montage you'll need imutils python library. Install it with pip install imutils command.","title":"Client's End"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5566\" , protocol = \"tcp\" , pattern = 1 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server-1's End"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end","text":"Finally, Open the terminal on another Server System (also with a webcam connected to it at index 0 ) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 1 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server-2's End"},{"location":"gears/netgear/advanced/multi_server/#bare-minimum-usage-with-opencv","text":"In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API.","title":"Bare-Minimum Usage with OpenCV"},{"location":"gears/netgear/advanced/multi_server/#clients-end_1","text":"Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: Important Notes Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages # (1) import cv2 # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all # unique Server((5566,5567) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = ( 5566 , 5567 ), protocol = \"tcp\" , pattern = 2 , receive_mode = True , ** options ) # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame unique_address , frame = data # {do something with the extracted frame here} # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the received frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close () For building Frames Montage you'll need imutils python library. Install it with pip install imutils command.","title":"Client's End"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end_1","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameter # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5566\" , protocol = \"tcp\" , pattern = 2 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close ()","title":"Server-1's End"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end_1","text":"Finally, Open the terminal on another Server System (also with a webcam connected to it at index 0 ) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 2 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close ()","title":"Server-2's End"},{"location":"gears/netgear/advanced/multi_server/#using-multi-servers-mode-for-unidirectional-custom-data-transfer","text":"Abstract With Multi-Servers Mode, you can send additional data of any datatype 1 along with frame with frame in real-time, from all connected Server(s) to a single Client unidirectionally. But numpy.ndarray data-type is NOT supported as data. In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) from two Servers (consisting of a Raspberry Pi with Camera Module & a Laptop with webcam) to a single Client over the network in real-time. The received video-frames at Client's end will displayed as a live montage, whereas the received data will be printed to the terminal.","title":"Using Multi-Servers Mode for Unidirectional Custom Data Transfer"},{"location":"gears/netgear/advanced/multi_server/#clients-end_2","text":"Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: Important Notes Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages # (1) import cv2 # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = ( 5577 , 5578 ), protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame and received data unique_address , extracted_data , frame = data # {do something with the extracted frame and data here} # let's display extracted data on our extracted frame cv2 . putText ( frame , extracted_data , ( 10 , frame . shape [ 0 ] - 10 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.6 , ( 0 , 255 , 0 ), 2 , ) # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close () For building Frames Montage you'll need imutils python library. Install it with pip install imutils command.","title":"Client's End"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end_2","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = VideoGear ( source = 0 ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data target_data = \"I'm Server-1 at Port: 5577\" # send frame and data through server server . send ( frame , message = target_data ) # (1) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter.","title":"Server-1's End"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end_2","text":"Finally, Open the terminal on another Server System (this time a Raspberry Pi with Camera Module connected to it) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.1.xxx\" , port = \"5578\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data text = \"I'm Server-2 at Port: 5578\" # send frame and data through server server . send ( frame , message = text ) except KeyboardInterrupt : break # safely close video stream. stream . stop () # safely close server server . close ()","title":"Server-2's End"},{"location":"gears/netgear/advanced/multi_server/#using-multi-servers-mode-with-bidirectional-mode","text":"Abstract Multi-Servers Mode now also compatible with Bidirectional Mode , which lets you send additional data of any datatype 1 along with frame in real-time bidirectionally between a single Client and all connected Server(s). Important Information Bidirectional data transfer ONLY works with pattern 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) , and NOT with pattern 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server(s) with their message parameter. Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised! New in v0.2.5 This example was added in v0.2.5 . In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) from two Servers (consisting of a Raspberry Pi with Camera Module & a Laptop with webcam) to a single Client, and at same time sending back data (a Text String, for the sake of simplicity) to them over the network all in real-time. The received video-frames at Client's end will displayed as a live montage, whereas the received data will be printed to the terminal.","title":"Using Multi-Servers Mode with Bidirectional Mode"},{"location":"gears/netgear/advanced/multi_server/#clients-end_3","text":"Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: Important Notes Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages # (1) import cv2 # activate both multiserver and bidirectional modes options = { \"multiserver_mode\" : True , \"bidirectional_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = ( 5577 , 5578 ), protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # prepare data to be sent target_data = \"Hi, I am a Client here.\" # receive data from server(s) and also send our data data = client . recv ( return_data = target_data ) # check if data received isn't None if data is None : break # extract unique port address and its respective frame and received data unique_address , extracted_data , frame = recv_data # {do something with the extracted frame and data here} # let's display extracted data on our extracted frame cv2 . putText ( frame , extracted_data , ( 10 , frame . shape [ 0 ] - 10 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.6 , ( 0 , 255 , 0 ), 2 , ) # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close () For building Frames Montage you'll need imutils python library. Install it with pip install imutils command.","title":"Client's End"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end_3","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = VideoGear ( source = 0 ) . start () # activate both multiserver and bidirectional modes options = { \"multiserver_mode\" : True , \"bidirectional_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data target_data = \"I'm Server-1 at Port: 5577\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # (1) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter.","title":"Server-1's End"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end_3","text":"Finally, Open the terminal on another Server System (this time a Raspberry Pi with Camera Module connected to it) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate both multiserver and bidirectional modes options = { \"multiserver_mode\" : True , \"bidirectional_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.1.xxx\" , port = \"5578\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data target_data = \"I'm Server-2 at Port: 5578\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # (1) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream. stream . stop () # safely close server server . close () Everything except numpy.ndarray datatype data is accepted as target_data in message parameter. Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server(s) with their message parameter. \u21a9 \u21a9 \u21a9","title":"Server-2's End"},{"location":"gears/netgear/advanced/secure_mode/","text":"Secure Mode for NetGear API \u2693 Overview \u2693 Secure Mode provides easy access to powerful, smart & secure ZeroMQ's Security Layers in NetGear API that enables strong encryption on data, and unbreakable authentication between the Server and the Client with the help of custom Certificates/keys and brings cheap, standardized privacy and authentication for distributed systems over the network. Secure Mode uses a new wire protocol, ZMTP 3.0 that adds a security handshake to all ZeroMQ connections and a new security protocol, CurveZMQ , that implements \"perfect forward security\" between two ZeroMQ peers over a TCP connection. Secure Mode can be easily activated in NetGear API through secure_mode attribute of its options dictionary parameter, during initialization. Furthermore, for managing this mode, NetGear API provides additional custom_cert_location & overwrite_cert like attribute too. Supported ZMQ Security Layers \u2693 Secure mode supports the two most powerful ZMQ security layers: Stonehouse: which switches to the CURVE security protocol that provides strong encryption on data, and almost unbreakable authentication. Stonehouse is the minimum you would use over public networks and assures clients that they are speaking to an authentic server while allowing any client to connect. This security layer is less secure but at the same time faster than IronHouse security mechanism. Ironhouse: which further extends Stonehouse layer with client public key authentication. This is the strongest security model present in ZeroMQ, protecting against every attack we know about except end-point attacks . This security layer enhanced security comes at a price of additional latency. Important Information regarding Secure Mode The secure_mode attribute value at the Client's end MUST match exactly the Server's end (i.e. IronHouse security layer is only compatible with IronHouse , and NOT with StoneHouse ) . The Public+Secret Keypairs generated at the Server end MUST be made available at the Client's end too for successful authentication. If mismatched, connection failure will occur. By Default, the Public+Secret Keypairs will be generated/stored at the $HOME/.vidgear/keys directory of your machine (e.g. /home/foo/.vidgear/keys on Linux) . But you can also use custom_cert_location attribute to set your own Custom-Path for a directory to generate/store these Keypairs. DO NOT share generated public+secret Keypairs with anyone else on the network to avoid any potential security breach. At the Server End, You can easily use the 'overwrite_cert' attribute for regenerating New-Keypairs on initialization. But make sure those newly generated Keypairs at the Server-End MUST be made available at Client's End for successful authentication. IronHouse is the strongest Security Layer available, but it involves certain security checks that lead to ADDITIONAL LATENCY . Secure Mode only supports libzmq library version >= 4.0 . Features \u2693 Supports the two most powerful ZMQ security layers: StoneHouse & IronHouse. Auto-generates, auto-validates & auto-stores the required Public+Secret Keypairs safely. Compatible with all messaging pattern, primary and exclusive modes. Strong data encryption & Unbreakable authentication. Able to protect against many man-in-the-middle (MITM) attacks. Minimum hassle and very easy to enable and integrate. Exclusive Attributes \u2693 For implementing Secure Mode, NetGear API currently provide following exclusive attribute for its options dictionary parameter: secure_mode ( integer ) : This attribute activates and sets the ZMQ security Mechanism. Its possible values are: 1 ( StoneHouse ) & 2 ( IronHouse ), and its default value is 0 ( Grassland(no security) ). Its usage is as follows: #activates IronHouse Security Mechanism options = { 'secure_mode' : 2 } custom_cert_location ( string ): This attribute sets a custom location/path to directory to generate/store Public+Secret Keypair/Certificates for enabling encryption. This attribute will force NetGear to create .vidgear folder (only if not available) at the assigned custom path (instead of home directory) , and then use that directory for storing new Keypairs/Certificates. It can be used as follows: # set custom Keypair location to '/home/foo/foo1/foo2' options = { \"secure_mode\" : 2 , \"custom_cert_location\" : \"/home/foo/foo1/foo2\" , } overwrite_cert ( bool ): [For Server-end only] This attribute sets whether to overwrite existing Public+Secret Keypair/Certificates and re-generate new ones, to protect against any potential security breach. If set to True a new Keypair/Certificates will be generated during NetGear initialization in place of old ones. Its usage is as follows: overwrite_cert parameter is disabled for Client's end! # a new Keypair will be generated options = { \"secure_mode\" : 2 , \"overwrite_cert\" : True } Usage Examples \u2693 Bare-Minimum Usage \u2693 Following is the bare-minimum code you need to get started with Secure Mode in NetGear API: Server's End \u2693 Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate StoneHouse security mechanism options = { \"secure_mode\" : 1 } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client's End \u2693 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate StoneHouse security mechanism options = { \"secure_mode\" : 1 } # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using Secure Mode with Variable Parameters \u2693 Client's End \u2693 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. You need to paste the Public+Secret Keypairs (generated at the Server End) at the $HOME/.vidgear/keys directory of your Client machine for a successful authentication! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate IronHouse security mechanism options = { \"secure_mode\" : 2 } # Define NetGear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server's End \u2693 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You also need to copy the Public+Secret Keypairs (generated on running this example code) present in the $HOME/.vidgear/keys directory, and make available at Client's end for a successful authentication. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # activate IronHouse security mechanism, and # [BEWARE!!!] generating new Keypairs for this example !!! options = { \"secure_mode\" : 2 , \"overwrite_cert\" : True } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Secure Mode"},{"location":"gears/netgear/advanced/secure_mode/#secure-mode-for-netgear-api","text":"","title":"Secure Mode for NetGear API"},{"location":"gears/netgear/advanced/secure_mode/#overview","text":"Secure Mode provides easy access to powerful, smart & secure ZeroMQ's Security Layers in NetGear API that enables strong encryption on data, and unbreakable authentication between the Server and the Client with the help of custom Certificates/keys and brings cheap, standardized privacy and authentication for distributed systems over the network. Secure Mode uses a new wire protocol, ZMTP 3.0 that adds a security handshake to all ZeroMQ connections and a new security protocol, CurveZMQ , that implements \"perfect forward security\" between two ZeroMQ peers over a TCP connection. Secure Mode can be easily activated in NetGear API through secure_mode attribute of its options dictionary parameter, during initialization. Furthermore, for managing this mode, NetGear API provides additional custom_cert_location & overwrite_cert like attribute too.","title":"Overview"},{"location":"gears/netgear/advanced/secure_mode/#supported-zmq-security-layers","text":"Secure mode supports the two most powerful ZMQ security layers: Stonehouse: which switches to the CURVE security protocol that provides strong encryption on data, and almost unbreakable authentication. Stonehouse is the minimum you would use over public networks and assures clients that they are speaking to an authentic server while allowing any client to connect. This security layer is less secure but at the same time faster than IronHouse security mechanism. Ironhouse: which further extends Stonehouse layer with client public key authentication. This is the strongest security model present in ZeroMQ, protecting against every attack we know about except end-point attacks . This security layer enhanced security comes at a price of additional latency. Important Information regarding Secure Mode The secure_mode attribute value at the Client's end MUST match exactly the Server's end (i.e. IronHouse security layer is only compatible with IronHouse , and NOT with StoneHouse ) . The Public+Secret Keypairs generated at the Server end MUST be made available at the Client's end too for successful authentication. If mismatched, connection failure will occur. By Default, the Public+Secret Keypairs will be generated/stored at the $HOME/.vidgear/keys directory of your machine (e.g. /home/foo/.vidgear/keys on Linux) . But you can also use custom_cert_location attribute to set your own Custom-Path for a directory to generate/store these Keypairs. DO NOT share generated public+secret Keypairs with anyone else on the network to avoid any potential security breach. At the Server End, You can easily use the 'overwrite_cert' attribute for regenerating New-Keypairs on initialization. But make sure those newly generated Keypairs at the Server-End MUST be made available at Client's End for successful authentication. IronHouse is the strongest Security Layer available, but it involves certain security checks that lead to ADDITIONAL LATENCY . Secure Mode only supports libzmq library version >= 4.0 .","title":"Supported ZMQ Security Layers"},{"location":"gears/netgear/advanced/secure_mode/#features","text":"Supports the two most powerful ZMQ security layers: StoneHouse & IronHouse. Auto-generates, auto-validates & auto-stores the required Public+Secret Keypairs safely. Compatible with all messaging pattern, primary and exclusive modes. Strong data encryption & Unbreakable authentication. Able to protect against many man-in-the-middle (MITM) attacks. Minimum hassle and very easy to enable and integrate.","title":"Features"},{"location":"gears/netgear/advanced/secure_mode/#exclusive-attributes","text":"For implementing Secure Mode, NetGear API currently provide following exclusive attribute for its options dictionary parameter: secure_mode ( integer ) : This attribute activates and sets the ZMQ security Mechanism. Its possible values are: 1 ( StoneHouse ) & 2 ( IronHouse ), and its default value is 0 ( Grassland(no security) ). Its usage is as follows: #activates IronHouse Security Mechanism options = { 'secure_mode' : 2 } custom_cert_location ( string ): This attribute sets a custom location/path to directory to generate/store Public+Secret Keypair/Certificates for enabling encryption. This attribute will force NetGear to create .vidgear folder (only if not available) at the assigned custom path (instead of home directory) , and then use that directory for storing new Keypairs/Certificates. It can be used as follows: # set custom Keypair location to '/home/foo/foo1/foo2' options = { \"secure_mode\" : 2 , \"custom_cert_location\" : \"/home/foo/foo1/foo2\" , } overwrite_cert ( bool ): [For Server-end only] This attribute sets whether to overwrite existing Public+Secret Keypair/Certificates and re-generate new ones, to protect against any potential security breach. If set to True a new Keypair/Certificates will be generated during NetGear initialization in place of old ones. Its usage is as follows: overwrite_cert parameter is disabled for Client's end! # a new Keypair will be generated options = { \"secure_mode\" : 2 , \"overwrite_cert\" : True }","title":"Exclusive Attributes"},{"location":"gears/netgear/advanced/secure_mode/#usage-examples","text":"","title":"Usage Examples"},{"location":"gears/netgear/advanced/secure_mode/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with Secure Mode in NetGear API:","title":"Bare-Minimum Usage"},{"location":"gears/netgear/advanced/secure_mode/#servers-end","text":"Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate StoneHouse security mechanism options = { \"secure_mode\" : 1 } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/advanced/secure_mode/#clients-end","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate StoneHouse security mechanism options = { \"secure_mode\" : 1 } # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/secure_mode/#using-secure-mode-with-variable-parameters","text":"","title":"Using Secure Mode with Variable Parameters"},{"location":"gears/netgear/advanced/secure_mode/#clients-end_1","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. You need to paste the Public+Secret Keypairs (generated at the Server End) at the $HOME/.vidgear/keys directory of your Client machine for a successful authentication! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate IronHouse security mechanism options = { \"secure_mode\" : 2 } # Define NetGear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/secure_mode/#servers-end_1","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You also need to copy the Public+Secret Keypairs (generated on running this example code) present in the $HOME/.vidgear/keys directory, and make available at Client's end for a successful authentication. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # activate IronHouse security mechanism, and # [BEWARE!!!] generating new Keypairs for this example !!! options = { \"secure_mode\" : 2 , \"overwrite_cert\" : True } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/advanced/ssh_tunnel/","text":"SSH Tunneling Mode for NetGear API \u2693 NetGear's Bidirectional Mode Overview \u2693 New in v0.2.2 This document was added in v0.2.2 . SSH Tunneling Mode allows you to connect NetGear client and server via secure SSH connection over the untrusted network and access its intranet services across firewalls. This mode works with pyzmq's zmq.ssh module for tunneling ZeroMQ connections over ssh. This mode implements SSH Remote Port Forwarding which enables accessing Host(client) machine outside the network by exposing port to the public Internet. Thereby, once you have established the tunnel, connections to local machine will actually be connections to remote machine as seen from the server. Beware \u2620\ufe0f Cybercriminals or malware could exploit SSH tunnels to hide their unauthorized communications, or to exfiltrate stolen data from the network. More information can be found here \u27b6 All patterns are valid for this mode and it can be easily activated in NetGear API at server end through ssh_tunnel_mode string attribute of its options dictionary parameter during initialization. Important SSH tunneling mode can only be enabled on Server-end to establish remote SSH connection with Client. SSH tunneling mode requires Client's SSH Port(default 22 ) to be TCP Port Forwarded by its Router, which allows Server machine to connect to it remotely. SSH tunneling mode is NOT compatible with Multi-Servers and Multi-Clients Exclusive Modes yet. Useful Tips It is advise to use pattern=2 to overcome random disconnection due to delays in network. SSH tunneling Mode is fully supports Bidirectional Mode , Secure Mode and JPEG-Frame Compression . It is advised to enable logging ( logging = True ) on the first run, to easily identify any runtime errors. Prerequisites \u2693 SSH Tunnel Mode requires pexpect or paramiko as an additional dependency which is not part of standard VidGear package. It can be easily installed via pypi as follows: Pramiko Pexpect paramiko is compatible with all platforms. paramiko support is automatically enabled in ZeroMQ if installed. # install paramiko pip install paramiko pexpect is NOT compatible with Windows Machines. # install pexpect pip install pexpect Exclusive Attributes \u2693 All these attributes will work on Server end only whereas Client end will simply discard them. For implementing SSH Tunneling Mode, NetGear API currently provide following exclusive attribute for its options dictionary parameter: ssh_tunnel_mode ( string ) : This attribute activates SSH Tunneling Mode and assigns the \"<ssh-username>@<client-public-ip-address>:<tcp-forwarded-port>\" SSH URL for tunneling at Server end. Its usage is as follows: On Server end, NetGear automatically validates if the port is open at specified Client's Public IP Address or not, and if it fails (i.e. port is closed) , NetGear will throw AssertionError ! With Default Port With Custom Port The default port value in SSH URL is 22 , meaning Server assumes TCP Port 22 is forwarded on Client's end by default. # activate SSH Tunneling and assign SSH URL options = { \"ssh_tunnel_mode\" : \"userid@52.194.1.73\" } # i.e. only connections from the Public IP address `52.194.1.73` # on default port 22 are allowed. But, you can also define your own custom TCP forwarded port instead: Here we're defining our own TCP Port 8080 , meaning Server assumes TCP Port 8080 is forwarded on Client's end. # activate SSH Tunneling and assign SSH URL options = { \"ssh_tunnel_mode\" : \"userid@52.194.1.73:8080\" } # i.e. only connections from the Public IP address `52.194.1.73` # on custom port 8080 are allowed. ssh_tunnel_pwd ( string ): This attribute sets the password required to authorize Host(client) for SSH Connection at Server end. This password grant access and controls SSH user can access what. It can be used as follows: # set password for our SSH conection options = { \"ssh_tunnel_mode\" : \"userid@52.194.1.73\" , \"ssh_tunnel_pwd\" : \"mypasswordstring\" , } ssh_tunnel_keyfile ( string ): This attribute sets path to Host key that provide another way to authenticate Host(client) for SSH Connection at Server end. Its purpose is to prevent man-in-the-middle attacks. It allows device authentication keys to be rotated and managed conveniently and every connection to be secured. It can be used as follows: You can use Ssh-keygen tool for creating new authentication key pairs for SSH Tunneling. # set keyfile path for our SSH conection options = { \"ssh_tunnel_mode\" : \"userid@52.194.1.73\" , \"ssh_tunnel_keyfile\" : \"/home/foo/.ssh/id_rsa\" , } Usage Example \u2693 Assumptions for this Example In this particular example, we assume that: Server: Server end is a Raspberry Pi with USB camera connected to it. Server is located at remote location and outside the Client's network. Client: Client end is a Regular PC/Computer located at 52.155.1.89 public IP address for displaying frames received from the remote Server. Client's SSH Port(default 22 ) is TCP Port Forwarded by its Router, which allows Server to connect to it remotely. This connection will then be tunneled back to our PC/Computer(Client) and makes TCP connection to it again via port 22 on localhost( 127.0.0.1 ). Also, there's a username test present on the PC/Computer(Client) to SSH login with password pas$wd . Setup Diagram: Assumed setup can be visualized throw diagram as follows: Setup Diagram Client's End \u2693 Open a terminal on Client System (A Regular PC where you want to display the input frames received from the Server) and execute the following python code: Requirements for Client's End To ensure a successful Remote NetGear Connection with Server: Install OpenSSH Server: (Tested) Linux Windows MacOS # Debian-based sudo apt-get install openssh-server # RHEL-based sudo yum install openssh-server See this official Microsoft doc \u27b6 brew install openssh Make sure to note down the Client's public IP address required by Server end. Make sure that Client's SSH Port(default 22 ) is TCP Port Forwarded by its Router to expose it to the public Internet. Also, this forwarded TCP port value is needed at Server end. Finding Public IP Address Only IPv4 IP-addresses are supported Enabling Dynamic DNS SSH tunneling requires public IP address to able to access host on public Internet. Thereby, if it's troublesome to remember Public IP address or your IP address change constantly, then you can use dynamic DNS services like https://www.noip.com/ A Public IP address is a globally routable IP address that is assigned to a network device, allowing it direct access to the Internet. They are assigned to the device by its ISP, and each device has a unique public IP address. Determining the public IP address involves contacting a remote server over the HTTP/HTTPS or DNS protocol and obtaining the IP address from the remote server response. On Desktop machines, the easiest way to find out your public IP address is to google \"what is my IP\" in your browser: How to TCP Port Forward in your Router For more information on Forwarding Port in Popular Home Routers. See this document \u27b6 Secsh channel X open FAILED: open failed: Administratively prohibited Error: This error means that installed OpenSSH is preventing connections to forwarded ports from outside your Client Machine. Solution: You need to change GatewayPorts no option to GatewayPorts yes in the OpenSSH server configuration file sshd_config to allows anyone to connect to the forwarded ports on Client Machine. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Define NetGear Client at given IP address and define parameters client = NetGear ( address = \"127.0.0.1\" , # don't change this port = \"5454\" , pattern = 2 , receive_mode = True , logging = True , ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server's End \u2693 Now, Open the terminal on Remote Server System (A Raspberry Pi with a webcam connected to it at index 0 ) , and execute the following python code: Make sure to replace the Client's Public IP Address and Forwarded TCP port(default is 22) in SSH URL with yours in the following example. On Server end, NetGear automatically validates if the port is open at specified Client's Public IP Address or not, and if it fails (i.e. port is closed) , NetGear will throw AssertionError ! You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # activate SSH tunneling with SSH URL, and # [BEWARE!!!] Change SSH URL and SSH password with yours for this example !!! options = { \"ssh_tunnel_mode\" : \"test@52.155.1.89\" , # defaults to port 22 \"ssh_tunnel_pwd\" : \"pas$wd\" , } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters server = NetGear ( address = \"127.0.0.1\" , # don't change this port = \"5454\" , pattern = 2 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"SSH Tunneling Mode"},{"location":"gears/netgear/advanced/ssh_tunnel/#ssh-tunneling-mode-for-netgear-api","text":"","title":"SSH Tunneling Mode for NetGear API"},{"location":"gears/netgear/advanced/ssh_tunnel/#overview","text":"New in v0.2.2 This document was added in v0.2.2 . SSH Tunneling Mode allows you to connect NetGear client and server via secure SSH connection over the untrusted network and access its intranet services across firewalls. This mode works with pyzmq's zmq.ssh module for tunneling ZeroMQ connections over ssh. This mode implements SSH Remote Port Forwarding which enables accessing Host(client) machine outside the network by exposing port to the public Internet. Thereby, once you have established the tunnel, connections to local machine will actually be connections to remote machine as seen from the server. Beware \u2620\ufe0f Cybercriminals or malware could exploit SSH tunnels to hide their unauthorized communications, or to exfiltrate stolen data from the network. More information can be found here \u27b6 All patterns are valid for this mode and it can be easily activated in NetGear API at server end through ssh_tunnel_mode string attribute of its options dictionary parameter during initialization. Important SSH tunneling mode can only be enabled on Server-end to establish remote SSH connection with Client. SSH tunneling mode requires Client's SSH Port(default 22 ) to be TCP Port Forwarded by its Router, which allows Server machine to connect to it remotely. SSH tunneling mode is NOT compatible with Multi-Servers and Multi-Clients Exclusive Modes yet. Useful Tips It is advise to use pattern=2 to overcome random disconnection due to delays in network. SSH tunneling Mode is fully supports Bidirectional Mode , Secure Mode and JPEG-Frame Compression . It is advised to enable logging ( logging = True ) on the first run, to easily identify any runtime errors.","title":"Overview"},{"location":"gears/netgear/advanced/ssh_tunnel/#prerequisites","text":"SSH Tunnel Mode requires pexpect or paramiko as an additional dependency which is not part of standard VidGear package. It can be easily installed via pypi as follows: Pramiko Pexpect paramiko is compatible with all platforms. paramiko support is automatically enabled in ZeroMQ if installed. # install paramiko pip install paramiko pexpect is NOT compatible with Windows Machines. # install pexpect pip install pexpect","title":"Prerequisites"},{"location":"gears/netgear/advanced/ssh_tunnel/#exclusive-attributes","text":"All these attributes will work on Server end only whereas Client end will simply discard them. For implementing SSH Tunneling Mode, NetGear API currently provide following exclusive attribute for its options dictionary parameter: ssh_tunnel_mode ( string ) : This attribute activates SSH Tunneling Mode and assigns the \"<ssh-username>@<client-public-ip-address>:<tcp-forwarded-port>\" SSH URL for tunneling at Server end. Its usage is as follows: On Server end, NetGear automatically validates if the port is open at specified Client's Public IP Address or not, and if it fails (i.e. port is closed) , NetGear will throw AssertionError ! With Default Port With Custom Port The default port value in SSH URL is 22 , meaning Server assumes TCP Port 22 is forwarded on Client's end by default. # activate SSH Tunneling and assign SSH URL options = { \"ssh_tunnel_mode\" : \"userid@52.194.1.73\" } # i.e. only connections from the Public IP address `52.194.1.73` # on default port 22 are allowed. But, you can also define your own custom TCP forwarded port instead: Here we're defining our own TCP Port 8080 , meaning Server assumes TCP Port 8080 is forwarded on Client's end. # activate SSH Tunneling and assign SSH URL options = { \"ssh_tunnel_mode\" : \"userid@52.194.1.73:8080\" } # i.e. only connections from the Public IP address `52.194.1.73` # on custom port 8080 are allowed. ssh_tunnel_pwd ( string ): This attribute sets the password required to authorize Host(client) for SSH Connection at Server end. This password grant access and controls SSH user can access what. It can be used as follows: # set password for our SSH conection options = { \"ssh_tunnel_mode\" : \"userid@52.194.1.73\" , \"ssh_tunnel_pwd\" : \"mypasswordstring\" , } ssh_tunnel_keyfile ( string ): This attribute sets path to Host key that provide another way to authenticate Host(client) for SSH Connection at Server end. Its purpose is to prevent man-in-the-middle attacks. It allows device authentication keys to be rotated and managed conveniently and every connection to be secured. It can be used as follows: You can use Ssh-keygen tool for creating new authentication key pairs for SSH Tunneling. # set keyfile path for our SSH conection options = { \"ssh_tunnel_mode\" : \"userid@52.194.1.73\" , \"ssh_tunnel_keyfile\" : \"/home/foo/.ssh/id_rsa\" , }","title":"Exclusive Attributes"},{"location":"gears/netgear/advanced/ssh_tunnel/#usage-example","text":"Assumptions for this Example In this particular example, we assume that: Server: Server end is a Raspberry Pi with USB camera connected to it. Server is located at remote location and outside the Client's network. Client: Client end is a Regular PC/Computer located at 52.155.1.89 public IP address for displaying frames received from the remote Server. Client's SSH Port(default 22 ) is TCP Port Forwarded by its Router, which allows Server to connect to it remotely. This connection will then be tunneled back to our PC/Computer(Client) and makes TCP connection to it again via port 22 on localhost( 127.0.0.1 ). Also, there's a username test present on the PC/Computer(Client) to SSH login with password pas$wd . Setup Diagram: Assumed setup can be visualized throw diagram as follows: Setup Diagram","title":"Usage Example"},{"location":"gears/netgear/advanced/ssh_tunnel/#clients-end","text":"Open a terminal on Client System (A Regular PC where you want to display the input frames received from the Server) and execute the following python code: Requirements for Client's End To ensure a successful Remote NetGear Connection with Server: Install OpenSSH Server: (Tested) Linux Windows MacOS # Debian-based sudo apt-get install openssh-server # RHEL-based sudo yum install openssh-server See this official Microsoft doc \u27b6 brew install openssh Make sure to note down the Client's public IP address required by Server end. Make sure that Client's SSH Port(default 22 ) is TCP Port Forwarded by its Router to expose it to the public Internet. Also, this forwarded TCP port value is needed at Server end. Finding Public IP Address Only IPv4 IP-addresses are supported Enabling Dynamic DNS SSH tunneling requires public IP address to able to access host on public Internet. Thereby, if it's troublesome to remember Public IP address or your IP address change constantly, then you can use dynamic DNS services like https://www.noip.com/ A Public IP address is a globally routable IP address that is assigned to a network device, allowing it direct access to the Internet. They are assigned to the device by its ISP, and each device has a unique public IP address. Determining the public IP address involves contacting a remote server over the HTTP/HTTPS or DNS protocol and obtaining the IP address from the remote server response. On Desktop machines, the easiest way to find out your public IP address is to google \"what is my IP\" in your browser: How to TCP Port Forward in your Router For more information on Forwarding Port in Popular Home Routers. See this document \u27b6 Secsh channel X open FAILED: open failed: Administratively prohibited Error: This error means that installed OpenSSH is preventing connections to forwarded ports from outside your Client Machine. Solution: You need to change GatewayPorts no option to GatewayPorts yes in the OpenSSH server configuration file sshd_config to allows anyone to connect to the forwarded ports on Client Machine. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Define NetGear Client at given IP address and define parameters client = NetGear ( address = \"127.0.0.1\" , # don't change this port = \"5454\" , pattern = 2 , receive_mode = True , logging = True , ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/ssh_tunnel/#servers-end","text":"Now, Open the terminal on Remote Server System (A Raspberry Pi with a webcam connected to it at index 0 ) , and execute the following python code: Make sure to replace the Client's Public IP Address and Forwarded TCP port(default is 22) in SSH URL with yours in the following example. On Server end, NetGear automatically validates if the port is open at specified Client's Public IP Address or not, and if it fails (i.e. port is closed) , NetGear will throw AssertionError ! You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # activate SSH tunneling with SSH URL, and # [BEWARE!!!] Change SSH URL and SSH password with yours for this example !!! options = { \"ssh_tunnel_mode\" : \"test@52.155.1.89\" , # defaults to port 22 \"ssh_tunnel_pwd\" : \"pas$wd\" , } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters server = NetGear ( address = \"127.0.0.1\" , # don't change this port = \"5454\" , pattern = 2 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear_async/overview/","text":"NetGear_Async API \u2693 Overview \u2693 NetGear_Async can generate the same performance as NetGear API at about one-third the memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but lacks in term of flexibility as it supports only a few NetGear's Exclusive Modes . NetGear_Async is built on zmq.asyncio , and powered by a high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. NetGear_Async can transfer thousands of frames in just a few seconds without causing any significant load on your system. NetGear_Async provides complete server-client handling and options to use variable protocols/patterns similar to NetGear API . Furthermore, NetGear_Async allows us to define our custom Server as source to transform frames easily before sending them across the network(see this doc example). NetGear_Async now supports additional bidirectional data transmission between receiver(client) and sender(server) while transferring frames. Users can easily build complex applications such as like Real-Time Video Chat in just few lines of code. In addition to all this, NetGear_Async API also provides internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network. NetGear_Async as of now supports four ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) zmq.PUSH/zmq.PULL (ZMQ Push/Pull Pattern) Whereas supported protocol are: tcp and ipc . \u2009 Helpful Tips It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. It is advised to comprehend NetGear API before using this API. \u2009 Importing \u2693 You can import NetGear_Async API in your program as follows: from vidgear.gears.asyncio import NetGear_Async \u2009 Usage Examples \u2693 See here \ud83d\ude80 After going through NetGear_Async Usage Examples, Checkout more bonus examples here \u27b6 Parameters \u2693 See here \ud83d\ude80 References \u2693 See here \ud83d\ude80 FAQs \u2693 See here \ud83d\ude80","title":"Overview"},{"location":"gears/netgear_async/overview/#netgear_async-api","text":"","title":"NetGear_Async API"},{"location":"gears/netgear_async/overview/#overview","text":"NetGear_Async can generate the same performance as NetGear API at about one-third the memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but lacks in term of flexibility as it supports only a few NetGear's Exclusive Modes . NetGear_Async is built on zmq.asyncio , and powered by a high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. NetGear_Async can transfer thousands of frames in just a few seconds without causing any significant load on your system. NetGear_Async provides complete server-client handling and options to use variable protocols/patterns similar to NetGear API . Furthermore, NetGear_Async allows us to define our custom Server as source to transform frames easily before sending them across the network(see this doc example). NetGear_Async now supports additional bidirectional data transmission between receiver(client) and sender(server) while transferring frames. Users can easily build complex applications such as like Real-Time Video Chat in just few lines of code. In addition to all this, NetGear_Async API also provides internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network. NetGear_Async as of now supports four ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) zmq.PUSH/zmq.PULL (ZMQ Push/Pull Pattern) Whereas supported protocol are: tcp and ipc . \u2009 Helpful Tips It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. It is advised to comprehend NetGear API before using this API.","title":"Overview"},{"location":"gears/netgear_async/overview/#importing","text":"You can import NetGear_Async API in your program as follows: from vidgear.gears.asyncio import NetGear_Async","title":"Importing"},{"location":"gears/netgear_async/overview/#usage-examples","text":"See here \ud83d\ude80 After going through NetGear_Async Usage Examples, Checkout more bonus examples here \u27b6","title":"Usage Examples"},{"location":"gears/netgear_async/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/netgear_async/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/netgear_async/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/netgear_async/params/","text":"NetGear_Async API Parameters \u2693 NetGear_Async provides a special internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs and their parameters. \u2009 enablePiCamera \u2693 This parameter provide access to PiGear or CamGear APIs respectively. This means the if enablePiCamera flag is True , the PiGear API will be accessed, and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 . address \u2693 This parameter sets the valid network address of the Server/Client. Network addresses unique identifiers across the network. Data-Type: String Default Value: Its default value is based on selected primary mode, i.e 'localhost' for Send Mode and '*' for Receive Mode. Usage: NetGear_Async ( address = \"192.168.0.145\" ) port \u2693 This parameter sets the valid Network Port of the Server/Client. A network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered. Data-Type: String Default Value: Its default value is '5555' Usage: NetGear_Async ( port = \"5575\" ) protocol \u2693 This parameter sets the valid messaging protocol between Server/Client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: 'tcp' and 'ipc' . Data-Type: String Default Value: Its default value is 'tcp' Usage: NetGear_Async ( protocol = \"ipc\" ) pattern \u2693 This parameter sets the supported messaging pattern(flow of communication) between Server/Client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns. Data-Type: Integer Default Value: Its default value is 0 ( i.e zmq.PAIR ). All supported ZMQ patterns for NetGear_Async are: 0 ( .i.e. zmq.PAIR ): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it. 1 ( .i.e. zmq.REQ/zmq.REP ): In this pattern, it employs ZMQ REQ sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket zmq.REQ will block send unless it has successfully received a reply back and socket zmq.REP will block on recv() unless it has received a request. 2 ( .i.e. zmq.PUB/zmq.SUB ): It is an another classic pattern where senders of messages, called publishers , do not program the messages to be sent directly to specific receivers, called subscribers . Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A ZMQ.SUB can connect to multiple ZMQ.PUB (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved. 3 ( .i.e. zmq.PUSH/zmq.PULL ): Its sockets let you distribute messages to multiple workers, arranged in a pipeline. A Push socket will distribute sent messages to its Pull clients evenly. This is equivalent to the producer/consumer model but the results computed by the consumer are not sent upstream but downstream to another pull/consumer socket. Usage: NetGear_Async ( pattern = 1 ) # sets zmq.REQ/zmq.REP pattern receive_mode \u2693 This parameter select the Netgear's Mode of operation. It basically activates Receive Mode ( if True ) and Send Mode ( if False ). Furthermore, recv() method will only work when this flag is enabled( i.e. Receive Mode ), whereas send() method will only work when this flag is disabled( i.e. Send Mode ). Data-Type: Boolean Default Value: Its default value is False ( i.e. Send Mode is activated by default ). Usage: NetGear_Async ( receive_mode = True ) # activates Recieve Mode timeout \u2693 In NetGear_Async, the Receiver-end keeps tracks if frames are received from Server-end within this specified timeout value (in seconds) , Otherwise TimeoutError will be raised, which helps to close the Receiver-end safely if the Server has lost connection prematurely. This parameter controls that timeout value (i.e. the maximum waiting time (in seconds)) after which Client exit itself with a TimeoutError to save resources. Its minimum value is 0.0 but no max limit. Data-Type: Float/Integer Default Value: Its default value is 10.0 . Usage: NetGear_Async ( timeout = 5.0 ) # sets 5secs timeout options \u2693 This parameter provides the flexibility to alter various NetGear_Async API's internal properties and modes. Data-Type: Dictionary Default Value: Its default value is {} Usage: Supported dictionary attributes for NetGear_Async API bidirectional_mode ( boolean ) : This internal attribute activates the exclusive Bidirectional Mode , if enabled( True ). The desired attributes can be passed to NetGear_Async API as follows: # formatting parameters as dictionary attributes options = { \"bidirectional_mode\" : True , } # assigning it NetGear_Async ( logging = True , ** options ) Parameters for Stabilizer Backend \u2693 Enable this backend with stabilize=True in NetGear_Async. stabilize \u2693 This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to True ( to enable ) or unset to False ( to disable ). Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 . options \u2693 This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be formatted as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' } Parameters for CamGear backend \u2693 Enable this backend with enablePiCamera=False in NetGear_Async. Default is also False . source \u2693 NetGear_Async API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: NetGear_Async ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: NetGear_Async ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) CamGear internally implements yt_dlp backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 CamGear ( source = 'https://www.twitch.tv/shroud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: NetGear_Async ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: NetGear_Async ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' ) stream_mode \u2693 This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the CamGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 NetGear_Async ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 . backend \u2693 This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: NetGear_Async ( source = 0 , backend = cv2 . CAP_DSHOW ) options \u2693 This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to NetGear_Async API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it NetGear_Async ( source = 0 , ** options ) Parameters for PiGear backend \u2693 Enable this backend with enablePiCamera=True in NetGear_Async. camera_num \u2693 This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: NetGear_Async ( enablePiCamera = True , camera_num = 0 ) resolution \u2693 This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: NetGear_Async ( enablePiCamera = True , resolution = ( 1280 , 720 )) # sets 1280x720 resolution framerate \u2693 This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: NetGear_Async ( enablePiCamera = True , framerate = 60 ) # sets 60fps framerate options \u2693 This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to NetGear_Async API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it NetGear_Async ( enablePiCamera = True , logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds Common Parameters \u2693 These are common parameters that works with every backend in NetGear_Async. colorspace \u2693 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 NetGear_Async ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 logging \u2693 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( logging = True ) time_delay \u2693 This parameter set the time delay (in seconds) before the NetGear_Async API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: NetGear_Async ( time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/netgear_async/params/#netgear_async-api-parameters","text":"NetGear_Async provides a special internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs and their parameters.","title":"NetGear_Async API Parameters"},{"location":"gears/netgear_async/params/#enablepicamera","text":"This parameter provide access to PiGear or CamGear APIs respectively. This means the if enablePiCamera flag is True , the PiGear API will be accessed, and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 .","title":"enablePiCamera"},{"location":"gears/netgear_async/params/#address","text":"This parameter sets the valid network address of the Server/Client. Network addresses unique identifiers across the network. Data-Type: String Default Value: Its default value is based on selected primary mode, i.e 'localhost' for Send Mode and '*' for Receive Mode. Usage: NetGear_Async ( address = \"192.168.0.145\" )","title":"address"},{"location":"gears/netgear_async/params/#port","text":"This parameter sets the valid Network Port of the Server/Client. A network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered. Data-Type: String Default Value: Its default value is '5555' Usage: NetGear_Async ( port = \"5575\" )","title":"port"},{"location":"gears/netgear_async/params/#protocol","text":"This parameter sets the valid messaging protocol between Server/Client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: 'tcp' and 'ipc' . Data-Type: String Default Value: Its default value is 'tcp' Usage: NetGear_Async ( protocol = \"ipc\" )","title":"protocol"},{"location":"gears/netgear_async/params/#pattern","text":"This parameter sets the supported messaging pattern(flow of communication) between Server/Client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns. Data-Type: Integer Default Value: Its default value is 0 ( i.e zmq.PAIR ). All supported ZMQ patterns for NetGear_Async are: 0 ( .i.e. zmq.PAIR ): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it. 1 ( .i.e. zmq.REQ/zmq.REP ): In this pattern, it employs ZMQ REQ sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket zmq.REQ will block send unless it has successfully received a reply back and socket zmq.REP will block on recv() unless it has received a request. 2 ( .i.e. zmq.PUB/zmq.SUB ): It is an another classic pattern where senders of messages, called publishers , do not program the messages to be sent directly to specific receivers, called subscribers . Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A ZMQ.SUB can connect to multiple ZMQ.PUB (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved. 3 ( .i.e. zmq.PUSH/zmq.PULL ): Its sockets let you distribute messages to multiple workers, arranged in a pipeline. A Push socket will distribute sent messages to its Pull clients evenly. This is equivalent to the producer/consumer model but the results computed by the consumer are not sent upstream but downstream to another pull/consumer socket. Usage: NetGear_Async ( pattern = 1 ) # sets zmq.REQ/zmq.REP pattern","title":"pattern"},{"location":"gears/netgear_async/params/#receive_mode","text":"This parameter select the Netgear's Mode of operation. It basically activates Receive Mode ( if True ) and Send Mode ( if False ). Furthermore, recv() method will only work when this flag is enabled( i.e. Receive Mode ), whereas send() method will only work when this flag is disabled( i.e. Send Mode ). Data-Type: Boolean Default Value: Its default value is False ( i.e. Send Mode is activated by default ). Usage: NetGear_Async ( receive_mode = True ) # activates Recieve Mode","title":"receive_mode"},{"location":"gears/netgear_async/params/#timeout","text":"In NetGear_Async, the Receiver-end keeps tracks if frames are received from Server-end within this specified timeout value (in seconds) , Otherwise TimeoutError will be raised, which helps to close the Receiver-end safely if the Server has lost connection prematurely. This parameter controls that timeout value (i.e. the maximum waiting time (in seconds)) after which Client exit itself with a TimeoutError to save resources. Its minimum value is 0.0 but no max limit. Data-Type: Float/Integer Default Value: Its default value is 10.0 . Usage: NetGear_Async ( timeout = 5.0 ) # sets 5secs timeout","title":"timeout"},{"location":"gears/netgear_async/params/#options","text":"This parameter provides the flexibility to alter various NetGear_Async API's internal properties and modes. Data-Type: Dictionary Default Value: Its default value is {} Usage: Supported dictionary attributes for NetGear_Async API bidirectional_mode ( boolean ) : This internal attribute activates the exclusive Bidirectional Mode , if enabled( True ). The desired attributes can be passed to NetGear_Async API as follows: # formatting parameters as dictionary attributes options = { \"bidirectional_mode\" : True , } # assigning it NetGear_Async ( logging = True , ** options )","title":"options"},{"location":"gears/netgear_async/params/#parameters-for-stabilizer-backend","text":"Enable this backend with stabilize=True in NetGear_Async.","title":"Parameters for Stabilizer Backend"},{"location":"gears/netgear_async/params/#stabilize","text":"This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to True ( to enable ) or unset to False ( to disable ). Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 .","title":"stabilize"},{"location":"gears/netgear_async/params/#options_1","text":"This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be formatted as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' }","title":"options"},{"location":"gears/netgear_async/params/#parameters-for-camgear-backend","text":"Enable this backend with enablePiCamera=False in NetGear_Async. Default is also False .","title":"Parameters for CamGear backend"},{"location":"gears/netgear_async/params/#source","text":"NetGear_Async API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: NetGear_Async ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: NetGear_Async ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) CamGear internally implements yt_dlp backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 CamGear ( source = 'https://www.twitch.tv/shroud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: NetGear_Async ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: NetGear_Async ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' )","title":"source"},{"location":"gears/netgear_async/params/#stream_mode","text":"This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the CamGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 NetGear_Async ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 .","title":"stream_mode"},{"location":"gears/netgear_async/params/#backend","text":"This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: NetGear_Async ( source = 0 , backend = cv2 . CAP_DSHOW )","title":"backend"},{"location":"gears/netgear_async/params/#options_2","text":"This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to NetGear_Async API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it NetGear_Async ( source = 0 , ** options )","title":"options"},{"location":"gears/netgear_async/params/#parameters-for-pigear-backend","text":"Enable this backend with enablePiCamera=True in NetGear_Async.","title":"Parameters for PiGear backend"},{"location":"gears/netgear_async/params/#camera_num","text":"This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: NetGear_Async ( enablePiCamera = True , camera_num = 0 )","title":"camera_num"},{"location":"gears/netgear_async/params/#resolution","text":"This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: NetGear_Async ( enablePiCamera = True , resolution = ( 1280 , 720 )) # sets 1280x720 resolution","title":"resolution"},{"location":"gears/netgear_async/params/#framerate","text":"This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: NetGear_Async ( enablePiCamera = True , framerate = 60 ) # sets 60fps framerate","title":"framerate"},{"location":"gears/netgear_async/params/#options_3","text":"This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to NetGear_Async API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it NetGear_Async ( enablePiCamera = True , logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds","title":"options"},{"location":"gears/netgear_async/params/#common-parameters","text":"These are common parameters that works with every backend in NetGear_Async.","title":"Common Parameters"},{"location":"gears/netgear_async/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 NetGear_Async ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/netgear_async/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( logging = True )","title":"logging"},{"location":"gears/netgear_async/params/#time_delay","text":"This parameter set the time delay (in seconds) before the NetGear_Async API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: NetGear_Async ( time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/netgear_async/usage/","text":"NetGear_Async API Usage Examples: \u2693 Helpful Tips It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. It is advised to comprehend NetGear API before using this API. After going through following Usage Examples, Checkout more bonus examples here \u27b6 Requirement \u2693 NetGear_Async API is the part of asyncio package of VidGear, thereby you need to install VidGear with asyncio support as follows: pip install vidgear [ asyncio ] \u2009 Bare-Minimum Usage \u2693 Following is the bare-minimum code you need to get started with NetGear_Async API: Server's End \u2693 Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio # initialize Server with suitable source server = NetGear_Async ( source = \"/home/foo/foo1.mp4\" ) . launch () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close () Client's End \u2693 Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () Using NetGear_Async with Variable Parameters \u2693 Client's End \u2693 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # define and launch Client with `receive_mode=True`. #change following IP address '192.168.x.xxx' with yours client = NetGear_Async ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () Server's End \u2693 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio # initialize Server with suitable source server = NetGear_Async ( source = 0 , address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , logging = True , ) . launch () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close () Using NetGear_Async with a Custom Source(OpenCV) \u2693 NetGear_Async allows you to easily define your own custom Source at Server-end that you want to use to transform your frames before sending them onto the network. Let's implement a bare-minimum example with a Custom Source using NetGear_Async API and OpenCV: Server's End \u2693 Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import library from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # initialize Server without any source server = NetGear_Async ( source = None , logging = True ) # !!! define your own video source here !!! # Open any video stream such as live webcam # video stream on first index(i.e. 0) device stream = cv2 . VideoCapture ( 0 ) # Create a async frame generator as custom source async def my_frame_generator (): # loop over stream until its terminated while True : # read frames ( grabbed , frame ) = stream . read () # check if frame empty if not grabbed : break # do something with the frame to be sent here # yield frame yield frame # sleep for sometime await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) # Add your custom source generator to Server configuration server . config [ \"generator\" ] = my_frame_generator () # Launch the Server server . launch () try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # close stream stream . release () # finally close the server server . close () Client's End \u2693 Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True , logging = True ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # {do something with received frames here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () Using NetGear_Async with Other Gears \u2693 NetGear_Async can be used with any other Gears without any compatibility issues. Let's implement a bare-minimum example where we are sending Stabilized frames from Server-end and saving them at Client's end with WriteGear as follows: Server's End \u2693 Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio # initialize Server with suitable source and enable stabilization server = NetGear_Async ( source = \"/home/foo/foo1.mp4\" , stabilize = True , logging = True ) . launch () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close () Client's End \u2693 Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async from vidgear.gears import WriteGear import cv2 , asyncio # define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True ) . launch () # Define writer with output filename 'Output.mp4' writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True ) # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # {do something with received frames here} # write a modified frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () # safely close writer writer . close ()","title":"Usage Examples"},{"location":"gears/netgear_async/usage/#netgear_async-api-usage-examples","text":"Helpful Tips It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. It is advised to comprehend NetGear API before using this API. After going through following Usage Examples, Checkout more bonus examples here \u27b6","title":"NetGear_Async API Usage Examples:"},{"location":"gears/netgear_async/usage/#requirement","text":"NetGear_Async API is the part of asyncio package of VidGear, thereby you need to install VidGear with asyncio support as follows: pip install vidgear [ asyncio ]","title":"Requirement"},{"location":"gears/netgear_async/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with NetGear_Async API:","title":"Bare-Minimum Usage"},{"location":"gears/netgear_async/usage/#servers-end","text":"Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio # initialize Server with suitable source server = NetGear_Async ( source = \"/home/foo/foo1.mp4\" ) . launch () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close ()","title":"Server's End"},{"location":"gears/netgear_async/usage/#clients-end","text":"Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear_async/usage/#using-netgear_async-with-variable-parameters","text":"","title":"Using NetGear_Async with Variable Parameters"},{"location":"gears/netgear_async/usage/#clients-end_1","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # define and launch Client with `receive_mode=True`. #change following IP address '192.168.x.xxx' with yours client = NetGear_Async ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear_async/usage/#servers-end_1","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio # initialize Server with suitable source server = NetGear_Async ( source = 0 , address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , logging = True , ) . launch () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close ()","title":"Server's End"},{"location":"gears/netgear_async/usage/#using-netgear_async-with-a-custom-sourceopencv","text":"NetGear_Async allows you to easily define your own custom Source at Server-end that you want to use to transform your frames before sending them onto the network. Let's implement a bare-minimum example with a Custom Source using NetGear_Async API and OpenCV:","title":"Using NetGear_Async with a Custom Source(OpenCV)"},{"location":"gears/netgear_async/usage/#servers-end_2","text":"Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import library from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # initialize Server without any source server = NetGear_Async ( source = None , logging = True ) # !!! define your own video source here !!! # Open any video stream such as live webcam # video stream on first index(i.e. 0) device stream = cv2 . VideoCapture ( 0 ) # Create a async frame generator as custom source async def my_frame_generator (): # loop over stream until its terminated while True : # read frames ( grabbed , frame ) = stream . read () # check if frame empty if not grabbed : break # do something with the frame to be sent here # yield frame yield frame # sleep for sometime await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) # Add your custom source generator to Server configuration server . config [ \"generator\" ] = my_frame_generator () # Launch the Server server . launch () try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # close stream stream . release () # finally close the server server . close ()","title":"Server's End"},{"location":"gears/netgear_async/usage/#clients-end_2","text":"Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True , logging = True ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # {do something with received frames here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear_async/usage/#using-netgear_async-with-other-gears","text":"NetGear_Async can be used with any other Gears without any compatibility issues. Let's implement a bare-minimum example where we are sending Stabilized frames from Server-end and saving them at Client's end with WriteGear as follows:","title":"Using NetGear_Async with Other Gears"},{"location":"gears/netgear_async/usage/#servers-end_3","text":"Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio # initialize Server with suitable source and enable stabilization server = NetGear_Async ( source = \"/home/foo/foo1.mp4\" , stabilize = True , logging = True ) . launch () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close ()","title":"Server's End"},{"location":"gears/netgear_async/usage/#clients-end_3","text":"Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async from vidgear.gears import WriteGear import cv2 , asyncio # define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True ) . launch () # Define writer with output filename 'Output.mp4' writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True ) # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # {do something with received frames here} # write a modified frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () # safely close writer writer . close ()","title":"Client's End"},{"location":"gears/netgear_async/advanced/bidirectional_mode/","text":"Bidirectional Mode for NetGear_Async API \u2693 NetGear_Async's Bidirectional Mode Overview \u2693 New in v0.2.2 This document was added in v0.2.2 . Bidirectional Mode enables seamless support for Bidirectional data transmission between Client and Sender along with video-frames through its synchronous messaging patterns such as zmq.PAIR (ZMQ Pair Pattern) & zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) in NetGear_Async API. In Bidirectional Mode, we utilizes the NetGear_Async API's transceive_data method for transmitting data (at Client's end) and receiving data (in Server's end) all while transferring frames in real-time. This mode can be easily activated in NetGear_Async through bidirectional_mode attribute of its options dictionary parameter during initialization. Important In Bidirectional Mode, zmq.PAIR (ZMQ Pair) & zmq.REQ/zmq.REP (ZMQ Request/Reply) are ONLY Supported messaging patterns. Accessing this mode with any other messaging pattern, will result in ValueError . Bidirectional Mode only works with User-defined Custom Source on Server end . Otherwise, NetGear_Async API will throw ValueError . Bidirectional Mode enables you to send data of ANY 1 Data-type along with frame bidirectionally. NetGear_Async API will throw RuntimeError if Bidirectional Mode is disabled at Server end or Client end but not both. Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised! Exclusive Method and Parameter \u2693 To send data bidirectionally, NetGear_Async API provides following exclusive method and parameter: transceive_data only works when Bidirectional Mode is enabled. transceive_data : It's a bidirectional mode exclusive method to transmit data (in Receive mode) and receive data (in Send mode) , all while transferring frames in real-time. data : In transceive_data method, this parameter enables user to inputs data (of ANY 1 datatype) for sending back to Server at Client's end. Usage Examples \u2693 For Bidirectional Mode, NetGear_Async must need User-defined Custom Source at its Server end otherwise it will throw ValueError. Bare-Minimum Usage with OpenCV \u2693 Following is the bare-minimum code you need to get started with Bidirectional Mode over Custom Source Server built using OpenCV and NetGear_Async API: Server End \u2693 Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import library from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # initialize Server without any source server = NetGear_Async ( source = None , logging = True , ** options ) # Create a async frame generator as custom source async def my_frame_generator (): # !!! define your own video source here !!! # Open any valid video stream(for e.g `foo.mp4` file) stream = cv2 . VideoCapture ( \"foo.mp4\" ) # loop over stream until its terminated while True : # read frames ( grabbed , frame ) = stream . read () # check for empty frame if not grabbed : break # {do something with the frame to be sent here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # receive data from Client recv_data = await server . transceive_data () # print data just received from Client if not ( recv_data is None ): print ( recv_data ) # send our frame & data yield ( target_data , frame ) # (1) # sleep for sometime await asyncio . sleep ( 0 ) # safely close video stream stream . release () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) # Add your custom source generator to Server configuration server . config [ \"generator\" ] = my_frame_generator () # Launch the Server server . launch () try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close () Everything except numpy.ndarray datatype data is accepted in target_data . Client End \u2693 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True , logging = True , ** options ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for ( data , frame ) in client . recv_generator (): # do something with receive data from server if not ( data is None ): # let's print it print ( data ) # {do something with received frames here} # Show output window(comment these lines if not required) cv2 . imshow ( \"Output Frame\" , frame ) cv2 . waitKey ( 1 ) & 0xFF # prepare data to be sent target_data = \"Hi, I am a Client here.\" # send our data to server await client . transceive_data ( data = target_data ) # await before continuing await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () Using Bidirectional Mode with Variable Parameters \u2693 Client's End \u2693 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear_Async Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear_Async ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for ( data , frame ) in client . recv_generator (): # do something with receive data from server if not ( data is None ): # let's print it print ( data ) # {do something with received frames here} # Show output window(comment these lines if not required) cv2 . imshow ( \"Output Frame\" , frame ) cv2 . waitKey ( 1 ) & 0xFF # prepare data to be sent target_data = \"Hi, I am a Client here.\" # send our data to server await client . transceive_data ( data = target_data ) # await before continuing await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () Server End \u2693 Now, Open the terminal on another Server System (a Raspberry Pi with Camera Module) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import library from vidgear.gears.asyncio import NetGear_Async from vidgear.gears import VideoGear import cv2 , asyncio # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # initialize Server without any source at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear_Async ( source = None , address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # Create a async frame generator as custom source async def my_frame_generator (): # !!! define your own video source here !!! # Open any video stream such as live webcam # video stream on first index(i.e. 0) device # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # loop over stream until its terminated while True : # read frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame to be sent here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # receive data from Client recv_data = await server . transceive_data () # print data just received from Client if not ( recv_data is None ): print ( recv_data ) # send our frame & data yield ( target_data , frame ) # (1) # sleep for sometime await asyncio . sleep ( 0 ) # safely close video stream stream . stop () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) # Add your custom source generator to Server configuration server . config [ \"generator\" ] = my_frame_generator () # Launch the Server server . launch () try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close () Everything except numpy.ndarray datatype data is accepted in target_data . Using Bidirectional Mode for Video-Frames Transfer \u2693 In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time, for testing the real-time performance and synchronization between the Server and the Client using this(Bidirectional) Mode. This feature is great for building applications like Real-Time Video Chat. We're also using reducer() method for reducing frame-size on-the-go for additional performance. Remember, Sending large HQ video-frames may required more network bandwidth and packet size which may lead to video latency! Server End \u2693 Open your favorite terminal and execute the following python code: You can terminate both side anytime by pressing Ctrl + C on your keyboard! Server end can only send numpy.ndarray datatype as frame but not as data. # import library from vidgear.gears.asyncio import NetGear_Async from vidgear.gears.asyncio.helper import reducer import cv2 , asyncio import numpy as np # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear Server without any source and with defined parameters server = NetGear_Async ( source = None , pattern = 1 , logging = True , ** options ) # Create a async frame generator as custom source async def my_frame_generator (): # !!! define your own video source here !!! # Open any valid video stream(for e.g `foo.mp4` file) stream = cv2 . VideoCapture ( \"foo.mp4\" ) # loop over stream until its terminated while True : # read frames ( grabbed , frame ) = stream . read () # check for empty frame if not grabbed : break # reducer frames size if you want more performance, otherwise comment this line frame = await reducer ( frame , percentage = 30 ) # reduce frame by 30% # {do something with the frame to be sent here} # send frame & data and also receive data from Client recv_data = await server . transceive_data () # receive data from Client if not ( recv_data is None ): # check data is a numpy frame if isinstance ( recv_data , np . ndarray ): # {do something with received numpy frame here} # Let's show it on output window cv2 . imshow ( \"Received Frame\" , recv_data ) cv2 . waitKey ( 1 ) & 0xFF else : # otherwise just print data print ( recv_data ) # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send our frame & data to client yield ( target_data , frame ) # (1) # sleep for sometime await asyncio . sleep ( 0 ) # safely close video stream stream . release () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) # Add your custom source generator to Server configuration server . config [ \"generator\" ] = my_frame_generator () # Launch the Server server . launch () try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close () Everything except numpy.ndarray datatype data is accepted in target_data . Client End \u2693 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async from vidgear.gears.asyncio.helper import reducer import cv2 , asyncio # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # define and launch Client with `receive_mode=True` client = NetGear_Async ( pattern = 1 , receive_mode = True , logging = True , ** options ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # !!! define your own video source here !!! # again open the same video stream for comparison stream = cv2 . VideoCapture ( \"foo.mp4\" ) # loop over Client's Asynchronous Frame Generator async for ( server_data , frame ) in client . recv_generator (): # check for server data if not ( server_data is None ): # {do something with the server data here} # lets print extracted server data print ( server_data ) # {do something with received frames here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # read frame target data from stream to be sent to server ( grabbed , target_data ) = stream . read () # check for frame if grabbed : # reducer frames size if you want more performance, otherwise comment this line target_data = await reducer ( target_data , percentage = 30 ) # reduce frame by 30% # send our frame data await client . transceive_data ( data = target_data ) # await before continuing await asyncio . sleep ( 0 ) # safely close video stream stream . release () if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () Additional data of numpy.ndarray datatype is ONLY SUPPORTED at Client's end with transceive_data method using its data parameter. Whereas Server end can only send numpy.ndarray datatype as frame but not as data. \u21a9 \u21a9","title":"Bidirectional Mode"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#bidirectional-mode-for-netgear_async-api","text":"","title":"Bidirectional Mode for NetGear_Async API"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#overview","text":"New in v0.2.2 This document was added in v0.2.2 . Bidirectional Mode enables seamless support for Bidirectional data transmission between Client and Sender along with video-frames through its synchronous messaging patterns such as zmq.PAIR (ZMQ Pair Pattern) & zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) in NetGear_Async API. In Bidirectional Mode, we utilizes the NetGear_Async API's transceive_data method for transmitting data (at Client's end) and receiving data (in Server's end) all while transferring frames in real-time. This mode can be easily activated in NetGear_Async through bidirectional_mode attribute of its options dictionary parameter during initialization. Important In Bidirectional Mode, zmq.PAIR (ZMQ Pair) & zmq.REQ/zmq.REP (ZMQ Request/Reply) are ONLY Supported messaging patterns. Accessing this mode with any other messaging pattern, will result in ValueError . Bidirectional Mode only works with User-defined Custom Source on Server end . Otherwise, NetGear_Async API will throw ValueError . Bidirectional Mode enables you to send data of ANY 1 Data-type along with frame bidirectionally. NetGear_Async API will throw RuntimeError if Bidirectional Mode is disabled at Server end or Client end but not both. Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised!","title":"Overview"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#exclusive-method-and-parameter","text":"To send data bidirectionally, NetGear_Async API provides following exclusive method and parameter: transceive_data only works when Bidirectional Mode is enabled. transceive_data : It's a bidirectional mode exclusive method to transmit data (in Receive mode) and receive data (in Send mode) , all while transferring frames in real-time. data : In transceive_data method, this parameter enables user to inputs data (of ANY 1 datatype) for sending back to Server at Client's end.","title":"Exclusive Method and Parameter"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#usage-examples","text":"For Bidirectional Mode, NetGear_Async must need User-defined Custom Source at its Server end otherwise it will throw ValueError.","title":"Usage Examples"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#bare-minimum-usage-with-opencv","text":"Following is the bare-minimum code you need to get started with Bidirectional Mode over Custom Source Server built using OpenCV and NetGear_Async API:","title":"Bare-Minimum Usage with OpenCV"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#server-end","text":"Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import library from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # initialize Server without any source server = NetGear_Async ( source = None , logging = True , ** options ) # Create a async frame generator as custom source async def my_frame_generator (): # !!! define your own video source here !!! # Open any valid video stream(for e.g `foo.mp4` file) stream = cv2 . VideoCapture ( \"foo.mp4\" ) # loop over stream until its terminated while True : # read frames ( grabbed , frame ) = stream . read () # check for empty frame if not grabbed : break # {do something with the frame to be sent here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # receive data from Client recv_data = await server . transceive_data () # print data just received from Client if not ( recv_data is None ): print ( recv_data ) # send our frame & data yield ( target_data , frame ) # (1) # sleep for sometime await asyncio . sleep ( 0 ) # safely close video stream stream . release () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) # Add your custom source generator to Server configuration server . config [ \"generator\" ] = my_frame_generator () # Launch the Server server . launch () try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close () Everything except numpy.ndarray datatype data is accepted in target_data .","title":"Server End"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#client-end","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True , logging = True , ** options ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for ( data , frame ) in client . recv_generator (): # do something with receive data from server if not ( data is None ): # let's print it print ( data ) # {do something with received frames here} # Show output window(comment these lines if not required) cv2 . imshow ( \"Output Frame\" , frame ) cv2 . waitKey ( 1 ) & 0xFF # prepare data to be sent target_data = \"Hi, I am a Client here.\" # send our data to server await client . transceive_data ( data = target_data ) # await before continuing await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#using-bidirectional-mode-with-variable-parameters","text":"","title":"Using Bidirectional Mode with Variable Parameters"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#clients-end","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear_Async Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear_Async ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for ( data , frame ) in client . recv_generator (): # do something with receive data from server if not ( data is None ): # let's print it print ( data ) # {do something with received frames here} # Show output window(comment these lines if not required) cv2 . imshow ( \"Output Frame\" , frame ) cv2 . waitKey ( 1 ) & 0xFF # prepare data to be sent target_data = \"Hi, I am a Client here.\" # send our data to server await client . transceive_data ( data = target_data ) # await before continuing await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#server-end_1","text":"Now, Open the terminal on another Server System (a Raspberry Pi with Camera Module) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import library from vidgear.gears.asyncio import NetGear_Async from vidgear.gears import VideoGear import cv2 , asyncio # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # initialize Server without any source at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear_Async ( source = None , address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # Create a async frame generator as custom source async def my_frame_generator (): # !!! define your own video source here !!! # Open any video stream such as live webcam # video stream on first index(i.e. 0) device # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # loop over stream until its terminated while True : # read frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame to be sent here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # receive data from Client recv_data = await server . transceive_data () # print data just received from Client if not ( recv_data is None ): print ( recv_data ) # send our frame & data yield ( target_data , frame ) # (1) # sleep for sometime await asyncio . sleep ( 0 ) # safely close video stream stream . stop () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) # Add your custom source generator to Server configuration server . config [ \"generator\" ] = my_frame_generator () # Launch the Server server . launch () try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close () Everything except numpy.ndarray datatype data is accepted in target_data .","title":"Server End"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#using-bidirectional-mode-for-video-frames-transfer","text":"In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time, for testing the real-time performance and synchronization between the Server and the Client using this(Bidirectional) Mode. This feature is great for building applications like Real-Time Video Chat. We're also using reducer() method for reducing frame-size on-the-go for additional performance. Remember, Sending large HQ video-frames may required more network bandwidth and packet size which may lead to video latency!","title":"Using Bidirectional Mode for Video-Frames Transfer"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#server-end_2","text":"Open your favorite terminal and execute the following python code: You can terminate both side anytime by pressing Ctrl + C on your keyboard! Server end can only send numpy.ndarray datatype as frame but not as data. # import library from vidgear.gears.asyncio import NetGear_Async from vidgear.gears.asyncio.helper import reducer import cv2 , asyncio import numpy as np # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear Server without any source and with defined parameters server = NetGear_Async ( source = None , pattern = 1 , logging = True , ** options ) # Create a async frame generator as custom source async def my_frame_generator (): # !!! define your own video source here !!! # Open any valid video stream(for e.g `foo.mp4` file) stream = cv2 . VideoCapture ( \"foo.mp4\" ) # loop over stream until its terminated while True : # read frames ( grabbed , frame ) = stream . read () # check for empty frame if not grabbed : break # reducer frames size if you want more performance, otherwise comment this line frame = await reducer ( frame , percentage = 30 ) # reduce frame by 30% # {do something with the frame to be sent here} # send frame & data and also receive data from Client recv_data = await server . transceive_data () # receive data from Client if not ( recv_data is None ): # check data is a numpy frame if isinstance ( recv_data , np . ndarray ): # {do something with received numpy frame here} # Let's show it on output window cv2 . imshow ( \"Received Frame\" , recv_data ) cv2 . waitKey ( 1 ) & 0xFF else : # otherwise just print data print ( recv_data ) # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send our frame & data to client yield ( target_data , frame ) # (1) # sleep for sometime await asyncio . sleep ( 0 ) # safely close video stream stream . release () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) # Add your custom source generator to Server configuration server . config [ \"generator\" ] = my_frame_generator () # Launch the Server server . launch () try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close () Everything except numpy.ndarray datatype data is accepted in target_data .","title":"Server End"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#client-end_1","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async from vidgear.gears.asyncio.helper import reducer import cv2 , asyncio # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # define and launch Client with `receive_mode=True` client = NetGear_Async ( pattern = 1 , receive_mode = True , logging = True , ** options ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # !!! define your own video source here !!! # again open the same video stream for comparison stream = cv2 . VideoCapture ( \"foo.mp4\" ) # loop over Client's Asynchronous Frame Generator async for ( server_data , frame ) in client . recv_generator (): # check for server data if not ( server_data is None ): # {do something with the server data here} # lets print extracted server data print ( server_data ) # {do something with received frames here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # read frame target data from stream to be sent to server ( grabbed , target_data ) = stream . read () # check for frame if grabbed : # reducer frames size if you want more performance, otherwise comment this line target_data = await reducer ( target_data , percentage = 30 ) # reduce frame by 30% # send our frame data await client . transceive_data ( data = target_data ) # await before continuing await asyncio . sleep ( 0 ) # safely close video stream stream . release () if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () Additional data of numpy.ndarray datatype is ONLY SUPPORTED at Client's end with transceive_data method using its data parameter. Whereas Server end can only send numpy.ndarray datatype as frame but not as data. \u21a9 \u21a9","title":"Client End"},{"location":"gears/pigear/overview/","text":"PiGear API \u2693 Raspberry Pi Camera Module Overview \u2693 PiGear is similar to CamGear API but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module) . PiGear provides a flexible multi-threaded framework around complete picamera python library, and provide us the ability to exploit almost all of its parameters like brightness, saturation, sensor_mode, iso, exposure, etc. effortlessly. Furthermore, PiGear also supports multiple camera modules, such as in the case of Raspberry-Pi Compute Module IO boards. Best of all, PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur. That means that if you're running PiGear API in your script and someone accidentally pulls the Camera-Module cable out, instead of going into possible kernel panic, API will exit safely to save resources. Make sure to enable Raspberry Pi hardware-specific settings prior using this API, otherwise nothing will work. Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. \u2009 Importing \u2693 You can import PiGear API in your program as follows: from vidgear.gears import PiGear \u2009 Usage Examples \u2693 See here \ud83d\ude80 After going through PiGear Usage Examples, Checkout more of its advanced configurations here \u27b6 Parameters \u2693 See here \ud83d\ude80 References \u2693 See here \ud83d\ude80 FAQs \u2693 See here \ud83d\ude80","title":"Overview"},{"location":"gears/pigear/overview/#pigear-api","text":"Raspberry Pi Camera Module","title":"PiGear API"},{"location":"gears/pigear/overview/#overview","text":"PiGear is similar to CamGear API but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module) . PiGear provides a flexible multi-threaded framework around complete picamera python library, and provide us the ability to exploit almost all of its parameters like brightness, saturation, sensor_mode, iso, exposure, etc. effortlessly. Furthermore, PiGear also supports multiple camera modules, such as in the case of Raspberry-Pi Compute Module IO boards. Best of all, PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur. That means that if you're running PiGear API in your script and someone accidentally pulls the Camera-Module cable out, instead of going into possible kernel panic, API will exit safely to save resources. Make sure to enable Raspberry Pi hardware-specific settings prior using this API, otherwise nothing will work. Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/pigear/overview/#importing","text":"You can import PiGear API in your program as follows: from vidgear.gears import PiGear","title":"Importing"},{"location":"gears/pigear/overview/#usage-examples","text":"See here \ud83d\ude80 After going through PiGear Usage Examples, Checkout more of its advanced configurations here \u27b6","title":"Usage Examples"},{"location":"gears/pigear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/pigear/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/pigear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/pigear/params/","text":"PiGear API Parameters \u2693 \u2009 camera_num \u2693 This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: PiGear ( camera_num = 0 ) resolution \u2693 This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: PiGear ( resolution = ( 1280 , 720 )) # sets 1280x720 resolution framerate \u2693 This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: PiGear ( framerate = 60 ) # sets 60fps framerate colorspace \u2693 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 PiGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 options \u2693 This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to PiGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it PiGear ( logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds logging \u2693 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: PiGear ( logging = True ) time_delay \u2693 This parameter set the time delay (in seconds) before the PiGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: PiGear ( time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/pigear/params/#pigear-api-parameters","text":"","title":"PiGear API Parameters"},{"location":"gears/pigear/params/#camera_num","text":"This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: PiGear ( camera_num = 0 )","title":"camera_num"},{"location":"gears/pigear/params/#resolution","text":"This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: PiGear ( resolution = ( 1280 , 720 )) # sets 1280x720 resolution","title":"resolution"},{"location":"gears/pigear/params/#framerate","text":"This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: PiGear ( framerate = 60 ) # sets 60fps framerate","title":"framerate"},{"location":"gears/pigear/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 PiGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/pigear/params/#options","text":"This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to PiGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it PiGear ( logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds","title":"options"},{"location":"gears/pigear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: PiGear ( logging = True )","title":"logging"},{"location":"gears/pigear/params/#time_delay","text":"This parameter set the time delay (in seconds) before the PiGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: PiGear ( time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/pigear/usage/","text":"PiGear API Usage Examples: \u2693 Make sure to enable Raspberry Pi hardware-specific settings prior using this API, otherwise nothing will work. After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6 \u2009 Bare-Minimum Usage \u2693 Following is the bare-minimum code you need to get started with PiGear API: # import required libraries from vidgear.gears import PiGear import cv2 # open pi video stream with default parameters stream = PiGear () . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using PiGear with Variable Camera Module Properties \u2693 PiGear supports almost every parameter available within Picamera library . These parameters can be easily applied to the source stream in PiGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: All supported parameters are listed in PiCamera Docs \u27b6 # import required libraries from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using PiGear with Direct Colorspace Manipulation \u2693 PiGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-Type value will immediately revert the colorspace to default (i.e. BGR ) . # import required libraries from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters and change colorspace to `HSV` stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , colorspace = \"COLOR_BGR2HSV\" , logging = True , ** options ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): # directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY # Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB # Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None # Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using PiGear with WriteGear API \u2693 PiGear can be easily used with WriteGear API directly without any compatibility issues. The suitable example is as follows: # import required libraries from vidgear.gears import PiGear from vidgear.gears import WriteGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Usage Examples"},{"location":"gears/pigear/usage/#pigear-api-usage-examples","text":"Make sure to enable Raspberry Pi hardware-specific settings prior using this API, otherwise nothing will work. After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6","title":"PiGear API Usage Examples:"},{"location":"gears/pigear/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with PiGear API: # import required libraries from vidgear.gears import PiGear import cv2 # open pi video stream with default parameters stream = PiGear () . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage"},{"location":"gears/pigear/usage/#using-pigear-with-variable-camera-module-properties","text":"PiGear supports almost every parameter available within Picamera library . These parameters can be easily applied to the source stream in PiGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: All supported parameters are listed in PiCamera Docs \u27b6 # import required libraries from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using PiGear with Variable Camera Module Properties"},{"location":"gears/pigear/usage/#using-pigear-with-direct-colorspace-manipulation","text":"PiGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-Type value will immediately revert the colorspace to default (i.e. BGR ) . # import required libraries from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters and change colorspace to `HSV` stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , colorspace = \"COLOR_BGR2HSV\" , logging = True , ** options ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): # directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY # Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB # Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None # Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using PiGear with Direct Colorspace Manipulation"},{"location":"gears/pigear/usage/#using-pigear-with-writegear-api","text":"PiGear can be easily used with WriteGear API directly without any compatibility issues. The suitable example is as follows: # import required libraries from vidgear.gears import PiGear from vidgear.gears import WriteGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using PiGear with WriteGear API"},{"location":"gears/screengear/overview/","text":"ScreenGear API \u2693 ScreenGear API in action Overview \u2693 ScreenGear is designed exclusively for ultra-fast Screencasting, which means it can grab frames from your monitor in real-time, either by defining an area on the computer screen or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends. ScreenGear API implements a multi-threaded wrapper around pyscreenshot & python-mss python library, and also flexibly supports its internal parameter. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV Library \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. \u2009 Importing \u2693 You can import ScreenGear API in your program as follows: from vidgear.gears import ScreenGear \u2009 Usage Examples \u2693 See here \ud83d\ude80 After going through ScreenGear Usage Examples, Checkout more of its advanced configurations here \u27b6 Parameters \u2693 See here \ud83d\ude80 References \u2693 See here \ud83d\ude80 FAQs \u2693 See here \ud83d\ude80","title":"Overview"},{"location":"gears/screengear/overview/#screengear-api","text":"ScreenGear API in action","title":"ScreenGear API"},{"location":"gears/screengear/overview/#overview","text":"ScreenGear is designed exclusively for ultra-fast Screencasting, which means it can grab frames from your monitor in real-time, either by defining an area on the computer screen or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends. ScreenGear API implements a multi-threaded wrapper around pyscreenshot & python-mss python library, and also flexibly supports its internal parameter. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV Library \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/screengear/overview/#importing","text":"You can import ScreenGear API in your program as follows: from vidgear.gears import ScreenGear","title":"Importing"},{"location":"gears/screengear/overview/#usage-examples","text":"See here \ud83d\ude80 After going through ScreenGear Usage Examples, Checkout more of its advanced configurations here \u27b6","title":"Usage Examples"},{"location":"gears/screengear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/screengear/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/screengear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/screengear/params/","text":"ScreenGear API Parameters \u2693 \u2009 monitor \u2693 This parameter enables mss usage and is most suitable for selecting index of a specific screen (from where you want retrieve frames) in multi-monitor setup. For example, its value can be assign to 2 , to fetch frames from a secondary monitor screen. More information can be found here \u27b6 You can assign monitor value to -1 to fetch frames from all connected multiple monitor screens. Implication of using monitor parameter Any value on monitor parameter other than None in ScreenGear API: Will force mss library backend. Will output BGRA colorspace frames instead of default BGR . Will disable the backend parameter. Data-Type: Integer Default Value: Its default value is None (i.e. disabled by default) . Usage: ScreenGear ( monitor =- 1 ) # to fetch frames from all connected multiple screens backend \u2693 This parameter enables pyscreenshot usage and select suitable backend for extracting frames in ScreenGear. The user have the authority of selecting suitable backend which generates best performance as well as the most compatible with their machines. The possible values are: pil , mss , scrot , maim , imagemagick , pyqt5 , pyqt , pyside2 , pyside , wx , pygdk3 , mac_screencapture , mac_quartz , gnome_dbus , gnome-screenshot , kwin_dbus . More information on these backends can be found here \u27b6 Performance Benchmarking of each backend can be found here \u27b6 Remember to install backend library and all of its dependencies you're planning to use with ScreenGear API. Any value on monitor parameter will disable the backend parameter. You cannot use both parameters at same time. Data-Type: String Default Value: Its default value is \"\" (i.e. default backend) . Usage: ScreenGear ( backend = \"mss\" ) # to enforce `mss` as backend for extracting frames. colorspace \u2693 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 . ScreenGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 options \u2693 This parameter provides the flexibility to manually set the dimensions of capture screen area. Supported Dimensional Parameters Supported Dimensional Parameters are as follows: left : the x-coordinate of the upper-left corner of the region top : the y-coordinate of the upper-left corner of the region width : the width of the region height : the height of the region Additional Exclusive Attribute such as THREAD_TIMEOUT is also supported for this parameter. Data-Type: Dictionary Default Value: Its default value is {} Usage: The desired dimensional parameters can be passed to ScreenGear API by formatting them as attributes, as follows: More information about screen dimensioning can be found here \u27b6 # formatting dimensional parameters as dictionary attributes options = { 'top' : 40 , 'left' : 0 , 'width' : 100 , 'height' : 100 } # assigning it w.r.t monitor=1 ScreenGear ( monitor = 1 , ** options ) logging \u2693 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: ScreenGear ( logging = True )","title":"Parameters"},{"location":"gears/screengear/params/#screengear-api-parameters","text":"","title":"ScreenGear API Parameters"},{"location":"gears/screengear/params/#monitor","text":"This parameter enables mss usage and is most suitable for selecting index of a specific screen (from where you want retrieve frames) in multi-monitor setup. For example, its value can be assign to 2 , to fetch frames from a secondary monitor screen. More information can be found here \u27b6 You can assign monitor value to -1 to fetch frames from all connected multiple monitor screens. Implication of using monitor parameter Any value on monitor parameter other than None in ScreenGear API: Will force mss library backend. Will output BGRA colorspace frames instead of default BGR . Will disable the backend parameter. Data-Type: Integer Default Value: Its default value is None (i.e. disabled by default) . Usage: ScreenGear ( monitor =- 1 ) # to fetch frames from all connected multiple screens","title":"monitor"},{"location":"gears/screengear/params/#backend","text":"This parameter enables pyscreenshot usage and select suitable backend for extracting frames in ScreenGear. The user have the authority of selecting suitable backend which generates best performance as well as the most compatible with their machines. The possible values are: pil , mss , scrot , maim , imagemagick , pyqt5 , pyqt , pyside2 , pyside , wx , pygdk3 , mac_screencapture , mac_quartz , gnome_dbus , gnome-screenshot , kwin_dbus . More information on these backends can be found here \u27b6 Performance Benchmarking of each backend can be found here \u27b6 Remember to install backend library and all of its dependencies you're planning to use with ScreenGear API. Any value on monitor parameter will disable the backend parameter. You cannot use both parameters at same time. Data-Type: String Default Value: Its default value is \"\" (i.e. default backend) . Usage: ScreenGear ( backend = \"mss\" ) # to enforce `mss` as backend for extracting frames.","title":"backend"},{"location":"gears/screengear/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 . ScreenGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/screengear/params/#options","text":"This parameter provides the flexibility to manually set the dimensions of capture screen area. Supported Dimensional Parameters Supported Dimensional Parameters are as follows: left : the x-coordinate of the upper-left corner of the region top : the y-coordinate of the upper-left corner of the region width : the width of the region height : the height of the region Additional Exclusive Attribute such as THREAD_TIMEOUT is also supported for this parameter. Data-Type: Dictionary Default Value: Its default value is {} Usage: The desired dimensional parameters can be passed to ScreenGear API by formatting them as attributes, as follows: More information about screen dimensioning can be found here \u27b6 # formatting dimensional parameters as dictionary attributes options = { 'top' : 40 , 'left' : 0 , 'width' : 100 , 'height' : 100 } # assigning it w.r.t monitor=1 ScreenGear ( monitor = 1 , ** options )","title":"options"},{"location":"gears/screengear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: ScreenGear ( logging = True )","title":"logging"},{"location":"gears/screengear/usage/","text":"ScreenGear API Usage Examples: \u2693 After going through ScreenGear Usage Examples, Checkout more of its advanced configurations here \u27b6 \u2009 Bare-Minimum Usage \u2693 Following is the bare-minimum code you need to get started with ScreenGear API: # import required libraries from vidgear.gears import ScreenGear import cv2 # open video stream with default parameters stream = ScreenGear () . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using ScreenGear with Variable Screen Dimensions \u2693 ScreenGear API provides us the flexibility to directly set the dimensions of capturing-area of the screen. These dimensions can be easily applied to ScreenGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: # import required libraries from vidgear.gears import ScreenGear import cv2 # define dimensions of screen w.r.t to given monitor to be captured options = { \"top\" : 40 , \"left\" : 0 , \"width\" : 100 , \"height\" : 100 } # open video stream with defined parameters stream = ScreenGear ( logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using ScreenGear with Multiple Screens \u2693 ScreenGear API provides us the flexibility to select any connected display for fetching frames, with its monitor parameter: You can assign monitor value to -1 to fetch frames from all connected multiple monitor screens. Implication of using monitor parameter Any value on monitor parameter other than None in ScreenGear API: Will force mss library backend. Will output BGRA colorspace frames instead of default BGR . Will disable the backend parameter. # import required libraries from vidgear.gears import ScreenGear import cv2 # open video stream with defined parameters with monitor at index `1` selected stream = ScreenGear ( monitor = 1 , logging = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using ScreenGear with Variable Backend \u2693 With ScreenGear API, you can select from many different backends that generates best performance as well as the most compatible with our machine by employing its backend parameter that supports many different backends: Supported backend values Its possible values are: pil , mss , scrot , maim , imagemagick , pyqt5 , pyqt , pyside2 , pyside , wx , pygdk3 , mac_screencapture , mac_quartz , gnome_dbus , gnome-screenshot , kwin_dbus . More information on these backends can be found here \u27b6 Remember to install backend library and all of its dependencies you're planning to use with ScreenGear API. More information on these backends can be found here \u27b6 Any value on monitor parameter will disable the backend parameter. You cannot use them simultaneously. # import required libraries from vidgear.gears import ScreenGear import cv2 # open video stream with defined parameters and `mss` backend for extracting frames. stream = ScreenGear ( backend = \"mss\" , logging = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using ScreenGear with Direct Colorspace Manipulation \u2693 ScreenGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-type value, will immediately revert the colorspace to default i.e. BGR . # import required libraries from vidgear.gears import ScreenGear import cv2 # Change colorspace to `HSV` stream = ScreenGear ( colorspace = \"COLOR_BGR2HSV\" , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): # directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY # Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB # Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None # Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using ScreenGear with WriteGear API \u2693 ScreenGear can be used in conjunction with WriteGear API directly without any compatibility issues. The suitable example is as follows: # import required libraries from vidgear.gears import ScreenGear from vidgear.gears import WriteGear import cv2 # define dimensions of screen w.r.t to given monitor to be captured options = { \"top\" : 40 , \"left\" : 0 , \"width\" : 100 , \"height\" : 100 } # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # open video stream with defined parameters stream = ScreenGear ( monitor = 1 , logging = True , ** options ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Usage Examples"},{"location":"gears/screengear/usage/#screengear-api-usage-examples","text":"After going through ScreenGear Usage Examples, Checkout more of its advanced configurations here \u27b6","title":"ScreenGear API Usage Examples:"},{"location":"gears/screengear/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with ScreenGear API: # import required libraries from vidgear.gears import ScreenGear import cv2 # open video stream with default parameters stream = ScreenGear () . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage"},{"location":"gears/screengear/usage/#using-screengear-with-variable-screen-dimensions","text":"ScreenGear API provides us the flexibility to directly set the dimensions of capturing-area of the screen. These dimensions can be easily applied to ScreenGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: # import required libraries from vidgear.gears import ScreenGear import cv2 # define dimensions of screen w.r.t to given monitor to be captured options = { \"top\" : 40 , \"left\" : 0 , \"width\" : 100 , \"height\" : 100 } # open video stream with defined parameters stream = ScreenGear ( logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using ScreenGear with Variable Screen Dimensions"},{"location":"gears/screengear/usage/#using-screengear-with-multiple-screens","text":"ScreenGear API provides us the flexibility to select any connected display for fetching frames, with its monitor parameter: You can assign monitor value to -1 to fetch frames from all connected multiple monitor screens. Implication of using monitor parameter Any value on monitor parameter other than None in ScreenGear API: Will force mss library backend. Will output BGRA colorspace frames instead of default BGR . Will disable the backend parameter. # import required libraries from vidgear.gears import ScreenGear import cv2 # open video stream with defined parameters with monitor at index `1` selected stream = ScreenGear ( monitor = 1 , logging = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using ScreenGear with Multiple Screens"},{"location":"gears/screengear/usage/#using-screengear-with-variable-backend","text":"With ScreenGear API, you can select from many different backends that generates best performance as well as the most compatible with our machine by employing its backend parameter that supports many different backends: Supported backend values Its possible values are: pil , mss , scrot , maim , imagemagick , pyqt5 , pyqt , pyside2 , pyside , wx , pygdk3 , mac_screencapture , mac_quartz , gnome_dbus , gnome-screenshot , kwin_dbus . More information on these backends can be found here \u27b6 Remember to install backend library and all of its dependencies you're planning to use with ScreenGear API. More information on these backends can be found here \u27b6 Any value on monitor parameter will disable the backend parameter. You cannot use them simultaneously. # import required libraries from vidgear.gears import ScreenGear import cv2 # open video stream with defined parameters and `mss` backend for extracting frames. stream = ScreenGear ( backend = \"mss\" , logging = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using ScreenGear with Variable Backend"},{"location":"gears/screengear/usage/#using-screengear-with-direct-colorspace-manipulation","text":"ScreenGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-type value, will immediately revert the colorspace to default i.e. BGR . # import required libraries from vidgear.gears import ScreenGear import cv2 # Change colorspace to `HSV` stream = ScreenGear ( colorspace = \"COLOR_BGR2HSV\" , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): # directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY # Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB # Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None # Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using ScreenGear with Direct Colorspace Manipulation"},{"location":"gears/screengear/usage/#using-screengear-with-writegear-api","text":"ScreenGear can be used in conjunction with WriteGear API directly without any compatibility issues. The suitable example is as follows: # import required libraries from vidgear.gears import ScreenGear from vidgear.gears import WriteGear import cv2 # define dimensions of screen w.r.t to given monitor to be captured options = { \"top\" : 40 , \"left\" : 0 , \"width\" : 100 , \"height\" : 100 } # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # open video stream with defined parameters stream = ScreenGear ( monitor = 1 , logging = True , ** options ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using ScreenGear with WriteGear API"},{"location":"gears/stabilizer/overview/","text":"Stabilizer Class \u2693 VidGear's Stabilizer in Action (Video Credits @SIGGRAPH2013 ) This video is transcoded with StreamGear API and hosted on GitHub Repository and served with raw.githack.com Overview \u2693 Stabilizer is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies on Fixed-Size Python Queues for error-free & ultra-fast frame handling. For more detailed information on Stabilizer working, See this blogpost \u27b6 \u2009 Features \u2693 Real-time stabilization with low latency and no extra resources. Works exceptionally well with low-frequency jitter. Integrated with VideoGear , therefore, can be applied to any incoming stream. Also seamlessly works standalone. \u2009 Important The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk! The stabilizer might be slower for High-Quality videos-frames. It is advised to enable logging on the first run for easily identifying any runtime errors. \u2009 Importing \u2693 You can import Stabilizer Class in your program as follows: from vidgear.gears.stabilizer import Stabilizer \u2009 Usage Examples \u2693 See here \ud83d\ude80 After going through Stabilizer Class Usage Examples, Checkout more of its advanced configurations here \u27b6 Parameters \u2693 See here \ud83d\ude80 References \u2693 See here \ud83d\ude80 FAQs \u2693 See here \ud83d\ude80","title":"Overview"},{"location":"gears/stabilizer/overview/#stabilizer-class","text":"VidGear's Stabilizer in Action (Video Credits @SIGGRAPH2013 ) This video is transcoded with StreamGear API and hosted on GitHub Repository and served with raw.githack.com","title":"Stabilizer Class"},{"location":"gears/stabilizer/overview/#overview","text":"Stabilizer is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies on Fixed-Size Python Queues for error-free & ultra-fast frame handling. For more detailed information on Stabilizer working, See this blogpost \u27b6","title":"Overview"},{"location":"gears/stabilizer/overview/#features","text":"Real-time stabilization with low latency and no extra resources. Works exceptionally well with low-frequency jitter. Integrated with VideoGear , therefore, can be applied to any incoming stream. Also seamlessly works standalone. \u2009 Important The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk! The stabilizer might be slower for High-Quality videos-frames. It is advised to enable logging on the first run for easily identifying any runtime errors.","title":"Features"},{"location":"gears/stabilizer/overview/#importing","text":"You can import Stabilizer Class in your program as follows: from vidgear.gears.stabilizer import Stabilizer","title":"Importing"},{"location":"gears/stabilizer/overview/#usage-examples","text":"See here \ud83d\ude80 After going through Stabilizer Class Usage Examples, Checkout more of its advanced configurations here \u27b6","title":"Usage Examples"},{"location":"gears/stabilizer/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/stabilizer/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/stabilizer/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/stabilizer/params/","text":"Stabilizer Class Parameters \u2693 \u2009 smoothing_radius \u2693 This parameter can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Data-Type: Integer Default Value: Its default value is 25 . Usage: You can easily pass this parameter as follows: Stabilizer ( smoothing_radius = 30 ) border_size \u2693 This parameter enables and set the value for extended border size that compensates for reduction of black borders during stabilization. Data-Type: Integer Default Value: Its default value is 0 (no borders). Usage: You can easily pass this parameter as follows: Stabilizer ( border_size = 10 ) crop_n_zoom \u2693 This parameter enables cropping and zooming of frames (to original size) to reduce the black borders from being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) during stabilization. It simply works in conjunction with the border_size parameter, i.e. when this parameter is enabled, border_size will be used for cropping border instead of extending them. Data-Type: Boolean Default Value: Its default value is False . Usage: You can easily pass this parameter as follows: Stabilizer ( border_size = 10 , crop_n_zoom = True ) border_type \u2693 This parameter can be used to change the extended border type. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Altering border_type parameter is DISABLED when crop_n_zoom is enabled! Data-Type: String Default Value: Its default value is 'black' . Usage: You can easily pass this parameter as follows: Stabilizer ( border_type = 'reflect' ) logging \u2693 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: Stabilizer ( logging = True )","title":"Parameters"},{"location":"gears/stabilizer/params/#stabilizer-class-parameters","text":"","title":"Stabilizer Class Parameters"},{"location":"gears/stabilizer/params/#smoothing_radius","text":"This parameter can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Data-Type: Integer Default Value: Its default value is 25 . Usage: You can easily pass this parameter as follows: Stabilizer ( smoothing_radius = 30 )","title":"smoothing_radius"},{"location":"gears/stabilizer/params/#border_size","text":"This parameter enables and set the value for extended border size that compensates for reduction of black borders during stabilization. Data-Type: Integer Default Value: Its default value is 0 (no borders). Usage: You can easily pass this parameter as follows: Stabilizer ( border_size = 10 )","title":"border_size"},{"location":"gears/stabilizer/params/#crop_n_zoom","text":"This parameter enables cropping and zooming of frames (to original size) to reduce the black borders from being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) during stabilization. It simply works in conjunction with the border_size parameter, i.e. when this parameter is enabled, border_size will be used for cropping border instead of extending them. Data-Type: Boolean Default Value: Its default value is False . Usage: You can easily pass this parameter as follows: Stabilizer ( border_size = 10 , crop_n_zoom = True )","title":"crop_n_zoom"},{"location":"gears/stabilizer/params/#border_type","text":"This parameter can be used to change the extended border type. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Altering border_type parameter is DISABLED when crop_n_zoom is enabled! Data-Type: String Default Value: Its default value is 'black' . Usage: You can easily pass this parameter as follows: Stabilizer ( border_type = 'reflect' )","title":"border_type"},{"location":"gears/stabilizer/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: Stabilizer ( logging = True )","title":"logging"},{"location":"gears/stabilizer/usage/","text":"Stabilizer Class Usage Examples: \u2693 \u2009 The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk! The stabilizer might be slower for High-Quality/Resolution videos-frames. It is advised to enable logging on the first run for easily identifying any runtime errors. After going through Stabilizer Class Usage Examples, Checkout more of its advanced configurations here \u27b6 \u2009 \u2009 Bare-Minimum Usage with VideoCapture Gears \u2693 Following is the bare-minimum code you need to get started with Stabilizer Class and various VideoCapture Gears: You can use any VideoCapture Gear instead of CamGear in the similar manner, as shown in this usage example. # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear import cv2 # To open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # initiate stabilizer object with default parameters stab = Stabilizer () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized frame here} # Show output window cv2 . imshow ( \"Output Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . stop () Bare-Minimum Usage with OpenCV \u2693 The VidGear's stabilizer class can also work standalone easily with any Computer Vision library such as OpenCV itself. Following is the bare-minimum code you need to get started with Stabilizer Class and OpenCV: # import required libraries from vidgear.gears.stabilizer import Stabilizer import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # initiate stabilizer object with default parameters stab = Stabilizer () # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized frame here} # Show output window cv2 . imshow ( \"Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . release () Using Stabilizer with Variable Parameters \u2693 Stabilizer class provide certain parameters which you can use to tweak its internal properties. The complete usage example is as follows: # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear import cv2 # To open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # initiate stabilizer object with defined parameters stab = Stabilizer ( smoothing_radius = 30 , crop_n_zoom = True , border_size = 5 , logging = True ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized frame here} # Show output window cv2 . imshow ( \"Output Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . stop () Using Stabilizer with WriteGear \u2693 VideoGear's stabilizer can be used in conjunction with WriteGear API directly without any compatibility issues. The complete usage example is as follows: You can also add live audio input to WriteGear pipeline. See this bonus example # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open suitable video stream stream = CamGear ( source = \"unstabilized_stream.mp4\" ) . start () # initiate stabilizer object with default parameters stab = Stabilizer () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized frame here} # write stabilized frame to writer writer . write ( stabilized_frame ) # Show output window cv2 . imshow ( \"Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . stop () # safely close writer writer . close () Using VideoGear with Stabilizer backend \u2693 VideoGear API provides a special internal wrapper around Stabilizer class that enables easy stabilization for various video-streams (real-time or not) with minimum effort and writing way fewer lines of code. The complete usage example can be found here \u27b6","title":"Usage Examples"},{"location":"gears/stabilizer/usage/#stabilizer-class-usage-examples","text":"The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk! The stabilizer might be slower for High-Quality/Resolution videos-frames. It is advised to enable logging on the first run for easily identifying any runtime errors. After going through Stabilizer Class Usage Examples, Checkout more of its advanced configurations here \u27b6","title":"Stabilizer Class Usage Examples:"},{"location":"gears/stabilizer/usage/#bare-minimum-usage-with-videocapture-gears","text":"Following is the bare-minimum code you need to get started with Stabilizer Class and various VideoCapture Gears: You can use any VideoCapture Gear instead of CamGear in the similar manner, as shown in this usage example. # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear import cv2 # To open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # initiate stabilizer object with default parameters stab = Stabilizer () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized frame here} # Show output window cv2 . imshow ( \"Output Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage with VideoCapture Gears"},{"location":"gears/stabilizer/usage/#bare-minimum-usage-with-opencv","text":"The VidGear's stabilizer class can also work standalone easily with any Computer Vision library such as OpenCV itself. Following is the bare-minimum code you need to get started with Stabilizer Class and OpenCV: # import required libraries from vidgear.gears.stabilizer import Stabilizer import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # initiate stabilizer object with default parameters stab = Stabilizer () # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized frame here} # Show output window cv2 . imshow ( \"Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . release ()","title":"Bare-Minimum Usage with OpenCV"},{"location":"gears/stabilizer/usage/#using-stabilizer-with-variable-parameters","text":"Stabilizer class provide certain parameters which you can use to tweak its internal properties. The complete usage example is as follows: # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear import cv2 # To open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # initiate stabilizer object with defined parameters stab = Stabilizer ( smoothing_radius = 30 , crop_n_zoom = True , border_size = 5 , logging = True ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized frame here} # Show output window cv2 . imshow ( \"Output Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . stop ()","title":"Using Stabilizer with Variable Parameters"},{"location":"gears/stabilizer/usage/#using-stabilizer-with-writegear","text":"VideoGear's stabilizer can be used in conjunction with WriteGear API directly without any compatibility issues. The complete usage example is as follows: You can also add live audio input to WriteGear pipeline. See this bonus example # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open suitable video stream stream = CamGear ( source = \"unstabilized_stream.mp4\" ) . start () # initiate stabilizer object with default parameters stab = Stabilizer () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized frame here} # write stabilized frame to writer writer . write ( stabilized_frame ) # Show output window cv2 . imshow ( \"Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Stabilizer with WriteGear"},{"location":"gears/stabilizer/usage/#using-videogear-with-stabilizer-backend","text":"VideoGear API provides a special internal wrapper around Stabilizer class that enables easy stabilization for various video-streams (real-time or not) with minimum effort and writing way fewer lines of code. The complete usage example can be found here \u27b6","title":"Using VideoGear with Stabilizer backend"},{"location":"gears/streamgear/ffmpeg_install/","text":"FFmpeg Installation Instructions \u2693 StreamGear must requires FFmpeg executables for transcoding Media Chunks. You can following machine-specific instructions for its installation: StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. Enable logging ( logging=True ) for debugging FFmpeg validation process. \u2009 Linux FFmpeg Installation \u2693 The StreamGear API supports Auto-Detection and Manual Configuration methods on a Linux machine: A. Auto-Detection \u2693 This is a recommended approach on Linux Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6 B. Manual Configuration \u2693 Download: You can also manually download the latest Linux Static Binaries( based on your machine arch(x86/x64) ) from the link below: Linux Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError ! Windows FFmpeg Installation \u2693 The StreamGear API supports Auto-Installation and Manual Configuration methods on Windows systems. A. Auto-Installation \u2693 This is a recommended approach on Windows Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on Windows system StreamGear API auto-generates the required FFmpeg Static Binaries from a dedicated Github Server into the temporary directory (for e.g. C:\\Temp ) of your machine. Warning The files downloaded to temporary directory (for e.g. C:\\TEMP ) , may get erased if your machine shutdowns/restarts. You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through -ffmpeg_download_path parameter. If binaries were found at the specified path, StreamGear automatically skips the auto-installation step. If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then StreamGear API will exit with RuntimeError ! B. Manual Configuration \u2693 Download: You can also manually download the latest Windows Static Binaries( based on your machine arch(x86/x64) ) from the link below: Windows Static Binaries: https://ffmpeg.org/download.html#build-windows Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'C:/foo/Downloads/ffmpeg/bin' ) or path of ffmpeg.exe executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError ! MacOS FFmpeg Installation \u2693 The StreamGear API supports Auto-Detection and Manual Configuration methods on a macOS machine. A. Auto-Detection \u2693 This is a recommended approach on MacOS Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6 B. Manual Configuration \u2693 Download: You can also manually download the latest macOS Static Binaries( only x64 Binaries ) from the link below: MacOS Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError !","title":"FFmpeg Installation"},{"location":"gears/streamgear/ffmpeg_install/#ffmpeg-installation-instructions","text":"StreamGear must requires FFmpeg executables for transcoding Media Chunks. You can following machine-specific instructions for its installation: StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. Enable logging ( logging=True ) for debugging FFmpeg validation process.","title":"FFmpeg Installation Instructions"},{"location":"gears/streamgear/ffmpeg_install/#linux-ffmpeg-installation","text":"The StreamGear API supports Auto-Detection and Manual Configuration methods on a Linux machine:","title":" Linux FFmpeg Installation"},{"location":"gears/streamgear/ffmpeg_install/#a-auto-detection","text":"This is a recommended approach on Linux Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6","title":"A. Auto-Detection"},{"location":"gears/streamgear/ffmpeg_install/#b-manual-configuration","text":"Download: You can also manually download the latest Linux Static Binaries( based on your machine arch(x86/x64) ) from the link below: Linux Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError !","title":"B. Manual Configuration"},{"location":"gears/streamgear/ffmpeg_install/#windows-ffmpeg-installation","text":"The StreamGear API supports Auto-Installation and Manual Configuration methods on Windows systems.","title":" Windows FFmpeg Installation"},{"location":"gears/streamgear/ffmpeg_install/#a-auto-installation","text":"This is a recommended approach on Windows Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on Windows system StreamGear API auto-generates the required FFmpeg Static Binaries from a dedicated Github Server into the temporary directory (for e.g. C:\\Temp ) of your machine. Warning The files downloaded to temporary directory (for e.g. C:\\TEMP ) , may get erased if your machine shutdowns/restarts. You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through -ffmpeg_download_path parameter. If binaries were found at the specified path, StreamGear automatically skips the auto-installation step. If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then StreamGear API will exit with RuntimeError !","title":"A. Auto-Installation"},{"location":"gears/streamgear/ffmpeg_install/#b-manual-configuration_1","text":"Download: You can also manually download the latest Windows Static Binaries( based on your machine arch(x86/x64) ) from the link below: Windows Static Binaries: https://ffmpeg.org/download.html#build-windows Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'C:/foo/Downloads/ffmpeg/bin' ) or path of ffmpeg.exe executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError !","title":"B. Manual Configuration"},{"location":"gears/streamgear/ffmpeg_install/#macos-ffmpeg-installation","text":"The StreamGear API supports Auto-Detection and Manual Configuration methods on a macOS machine.","title":" MacOS FFmpeg Installation"},{"location":"gears/streamgear/ffmpeg_install/#a-auto-detection_1","text":"This is a recommended approach on MacOS Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6","title":"A. Auto-Detection"},{"location":"gears/streamgear/ffmpeg_install/#b-manual-configuration_2","text":"Download: You can also manually download the latest macOS Static Binaries( only x64 Binaries ) from the link below: MacOS Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError !","title":"B. Manual Configuration"},{"location":"gears/streamgear/introduction/","text":"StreamGear API \u2693 StreamGear API's generalized workflow Overview \u2693 StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats (such as MPEG-DASH and Apple HLS) in just few lines of python code. StreamGear provides a standalone, highly extensible, and flexible wrapper around FFmpeg multimedia framework for generating chunked-encoded media segments of the content. SteamGear is an out-of-the-box solution for transcoding source videos/audio files & real-time video frames and breaking them into a sequence of multiple smaller chunks/segments of suitable lengths. These segments make it possible to stream videos at different quality levels (different bitrates or spatial resolutions) and can be switched in the middle of a video from one quality level to another \u2013 if bandwidth permits \u2013 on a per-segment basis. A user can serve these segments on a web server that makes it easier to download them through HTTP standard-compliant GET requests. SteamGear currently supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) and Apple HLS (HTTP Live Streaming) . SteamGear also creates a Manifest file (such as MPD in-case of DASH) or a Master Playlist (such as M3U8 in-case of Apple HLS) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and adaptive bit rates) and is provided to the client before the streaming session. For streaming with older traditional protocols such as RTMP, RTSP/RTP you could use WriteGear API instead. \u2009 New in v0.2.2 Apple HLS support was added in v0.2.2 . Important StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executable on your system. It is advised to enable logging ( logging=True ) on the first run for easily identifying any runtime errors. Useful Links Checkout this detailed blogpost on how MPEG-DASH works. Checkout this detailed blogpost on how HLS works. Checkout this detailed blogpost for HLS vs. MPEG-DASH comparison. \u2009 Mode of Operations \u2693 StreamGear primarily operates in following independent modes for transcoding: Real-time Frames Mode is NOT Live-Streaming. Rather, you can enable live-streaming in Real-time Frames Mode by using the exclusive -livestream attribute of stream_params dictionary parameter in StreamGear API. Checkout this usage example for more information. Single-Source Mode : In this mode, StreamGear transcodes entire video file (as opposed to frame-by-frame) into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well when you're transcoding long-duration lossless videos(with audio) for streaming that required no interruptions. But on the downside, the provided source cannot be flexibly manipulated or transformed before sending onto FFmpeg Pipeline for processing. Real-time Frames Mode : In this mode, StreamGear directly transcodes frame-by-frame (as opposed to a entire video file) , into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well when you desire to flexibility manipulate or transform numpy.ndarray frames in real-time before sending them onto FFmpeg Pipeline for processing. But on the downside, audio has to added manually (as separate source) for streams. \u2009 Importing \u2693 You can import StreamGear API in your program as follows: from vidgear.gears import StreamGear \u2009 Watch Demo \u2693 Watch MPEG-DASH Stream Watch APPLE HLS Stream Watch StreamGear transcoded MPEG-DASH Stream: Powered by clappr & shaka-player This video assets (Manifest and segments) are hosted on GitHub Repository and served with raw.githack.com Video Credits: \"Tears of Steel\" - Project Mango Teaser Watch StreamGear transcoded APPLE HLS Stream: Powered by clappr & HlsjsPlayback This video assets (Playlist and segments) are hosted on GitHub Repository and served with raw.githack.com Video Credits: \"Sintel\" - Project Durian Teaser \u2009 Recommended Players \u2693 GUI Players Command-Line Players Online Players MPV Player : (recommended) MPV is a free, open source, and cross-platform media player. It supports a wide variety of media file formats, audio and video codecs, and subtitle types. VLC Player : VLC is a free and open source cross-platform multimedia player and framework that plays most multimedia files as well as DVDs, Audio CDs, VCDs, and various streaming protocols. Parole : (UNIX only) Parole is a modern simple media player based on the GStreamer framework for Unix and Unix-like operating systems. MP4Client : GPAC provides a highly configurable multimedia player called MP4Client. GPAC itself is an open source multimedia framework developed for research and academic purposes, and used in many media production chains. ffplay : FFplay is a very simple and portable media player using the FFmpeg libraries and the SDL library. It is mostly used as a testbed for the various FFmpeg APIs. To run Online players locally, you'll need a HTTP server. For creating one yourself, See this well-curated list \u27b6 Clapper : Clappr is an extensible media player for the web. Shaka Player : Shaka Player is an open-source JavaScript library for playing adaptive media in a browser. MediaElementPlayer : MediaElementPlayer is a complete HTML/CSS audio/video player. Native MPEG-Dash + HLS Playback (Chrome Extension): Allow the browser to play HLS (m3u8) or MPEG-Dash (mpd) video urls 'natively' on chrome browsers. \u2009 Parameters \u2693 See here \ud83d\ude80 References \u2693 See here \ud83d\ude80 FAQs \u2693 See here \ud83d\ude80","title":"Introduction"},{"location":"gears/streamgear/introduction/#streamgear-api","text":"StreamGear API's generalized workflow","title":"StreamGear API"},{"location":"gears/streamgear/introduction/#overview","text":"StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats (such as MPEG-DASH and Apple HLS) in just few lines of python code. StreamGear provides a standalone, highly extensible, and flexible wrapper around FFmpeg multimedia framework for generating chunked-encoded media segments of the content. SteamGear is an out-of-the-box solution for transcoding source videos/audio files & real-time video frames and breaking them into a sequence of multiple smaller chunks/segments of suitable lengths. These segments make it possible to stream videos at different quality levels (different bitrates or spatial resolutions) and can be switched in the middle of a video from one quality level to another \u2013 if bandwidth permits \u2013 on a per-segment basis. A user can serve these segments on a web server that makes it easier to download them through HTTP standard-compliant GET requests. SteamGear currently supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) and Apple HLS (HTTP Live Streaming) . SteamGear also creates a Manifest file (such as MPD in-case of DASH) or a Master Playlist (such as M3U8 in-case of Apple HLS) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and adaptive bit rates) and is provided to the client before the streaming session. For streaming with older traditional protocols such as RTMP, RTSP/RTP you could use WriteGear API instead. \u2009 New in v0.2.2 Apple HLS support was added in v0.2.2 . Important StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executable on your system. It is advised to enable logging ( logging=True ) on the first run for easily identifying any runtime errors. Useful Links Checkout this detailed blogpost on how MPEG-DASH works. Checkout this detailed blogpost on how HLS works. Checkout this detailed blogpost for HLS vs. MPEG-DASH comparison.","title":"Overview"},{"location":"gears/streamgear/introduction/#mode-of-operations","text":"StreamGear primarily operates in following independent modes for transcoding: Real-time Frames Mode is NOT Live-Streaming. Rather, you can enable live-streaming in Real-time Frames Mode by using the exclusive -livestream attribute of stream_params dictionary parameter in StreamGear API. Checkout this usage example for more information. Single-Source Mode : In this mode, StreamGear transcodes entire video file (as opposed to frame-by-frame) into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well when you're transcoding long-duration lossless videos(with audio) for streaming that required no interruptions. But on the downside, the provided source cannot be flexibly manipulated or transformed before sending onto FFmpeg Pipeline for processing. Real-time Frames Mode : In this mode, StreamGear directly transcodes frame-by-frame (as opposed to a entire video file) , into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well when you desire to flexibility manipulate or transform numpy.ndarray frames in real-time before sending them onto FFmpeg Pipeline for processing. But on the downside, audio has to added manually (as separate source) for streams.","title":"Mode of Operations"},{"location":"gears/streamgear/introduction/#importing","text":"You can import StreamGear API in your program as follows: from vidgear.gears import StreamGear","title":"Importing"},{"location":"gears/streamgear/introduction/#watch-demo","text":"Watch MPEG-DASH Stream Watch APPLE HLS Stream Watch StreamGear transcoded MPEG-DASH Stream: Powered by clappr & shaka-player This video assets (Manifest and segments) are hosted on GitHub Repository and served with raw.githack.com Video Credits: \"Tears of Steel\" - Project Mango Teaser Watch StreamGear transcoded APPLE HLS Stream: Powered by clappr & HlsjsPlayback This video assets (Playlist and segments) are hosted on GitHub Repository and served with raw.githack.com Video Credits: \"Sintel\" - Project Durian Teaser","title":"Watch Demo"},{"location":"gears/streamgear/introduction/#recommended-players","text":"GUI Players Command-Line Players Online Players MPV Player : (recommended) MPV is a free, open source, and cross-platform media player. It supports a wide variety of media file formats, audio and video codecs, and subtitle types. VLC Player : VLC is a free and open source cross-platform multimedia player and framework that plays most multimedia files as well as DVDs, Audio CDs, VCDs, and various streaming protocols. Parole : (UNIX only) Parole is a modern simple media player based on the GStreamer framework for Unix and Unix-like operating systems. MP4Client : GPAC provides a highly configurable multimedia player called MP4Client. GPAC itself is an open source multimedia framework developed for research and academic purposes, and used in many media production chains. ffplay : FFplay is a very simple and portable media player using the FFmpeg libraries and the SDL library. It is mostly used as a testbed for the various FFmpeg APIs. To run Online players locally, you'll need a HTTP server. For creating one yourself, See this well-curated list \u27b6 Clapper : Clappr is an extensible media player for the web. Shaka Player : Shaka Player is an open-source JavaScript library for playing adaptive media in a browser. MediaElementPlayer : MediaElementPlayer is a complete HTML/CSS audio/video player. Native MPEG-Dash + HLS Playback (Chrome Extension): Allow the browser to play HLS (m3u8) or MPEG-Dash (mpd) video urls 'natively' on chrome browsers.","title":"Recommended Players"},{"location":"gears/streamgear/introduction/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/streamgear/introduction/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/streamgear/introduction/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/streamgear/params/","text":"StreamGear API Parameters \u2693 \u2009 output \u2693 This parameter sets the valid filename/path for storing the StreamGear assets (Manifest file (such as MPD in-case of DASH) or a Master Playlist (such as M3U8 in-case of Apple HLS) & Transcoded sequence of segments) . StreamGear API will throw ValueError if output provided is empty or invalid. Make sure to provide valid filename with valid file-extension for selected format value (such as .mpd in case of MPEG-DASH and .m3u8 in case of APPLE-HLS) , otherwise StreamGear will throw AssertionError . StreamGear generated sequence of multiple chunks/segments are also stored in the same directory. You can easily delete all previous assets at output location, by using -clear_prev_assets attribute of stream_params dictionary parameter. Data-Type: String Usage: Its valid input can be one of the following: Path to directory : Valid path of the directory. In this case, StreamGear API will automatically assign a unique filename for Manifest file. This can be defined as follows: DASH HLS streamer = StreamGear ( output = \"/home/foo/foo1\" ) # Define streamer with manifest saving directory path streamer = StreamGear ( output = \"/home/foo/foo1\" , format = \"hls\" ) # Define streamer with playlist saving directory path Filename (with/without path) : Valid filename( with valid extension ) of the output Manifest file. In case filename is provided without path, then current working directory will be used. DASH HLS streamer = StreamGear ( output = \"output_foo.mpd\" ) # Define streamer with manifest file name streamer = StreamGear ( output = \"output_foo.m3u8\" , format = \"hls\" ) # Define streamer with playlist file name URL : Valid URL of a network stream with a protocol supported by installed FFmpeg (verify with command ffmpeg -protocols ) only. This is useful for directly storing assets to a network server. For example, you can use a http protocol URL as follows: DASH HLS streamer = StreamGear ( output = \"http://195.167.1.101/live/test.mpd\" ) #Define streamer streamer = StreamGear ( output = \"http://195.167.1.101/live/test.m3u8\" , format = \"hls\" ) #Define streamer format \u2693 This parameter select the adaptive HTTP streaming formats. For now, the supported format are: dash (i.e MPEG-DASH ) and hls (i.e Apple HLS ) . Any invalid value to format parameter will result in ValueError! Make sure to provide valid filename with valid file-extension in output for selected format value (such as .mpd in case of MPEG-DASH and .m3u8 in case of APPLE-HLS) , otherwise StreamGear will throw AssertionError . Data-Type: String Default Value: Its default value is dash Usage: DASH HLS StreamGear ( output = \"output_foo.mpd\" , format = \"dash\" ) StreamGear ( output = \"output_foo.m3u8\" , format = \"hls\" ) custom_ffmpeg \u2693 This parameter assigns the custom path/directory where the custom/downloaded FFmpeg executables are located. Behavior on Windows If a custom FFmpeg executable's path | directory is not provided through custom_ffmpeg parameter on Windows machine, then StreamGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . Data-Type: String Default Value: Its default value is None . Usage: # If ffmpeg executables are located at \"/foo/foo1/ffmpeg\" StreamGear ( output = 'output_foo.mpd' , custom_ffmpeg = \"/foo/foo1/ffmpeg\" ) stream_params \u2693 This parameter allows us to exploit almost all FFmpeg supported parameters effortlessly and flexibly change its internal settings for transcoding and seamlessly generating high-quality streams. All supported parameters can formatting as attributes for this dictionary parameter: Kindly read FFmpeg Docs carefully, before passing any additional values to stream_params parameter. Wrong values may result in undesired errors or no output at all. Data-Type: Dictionary Default Value: Its default value is {} . Supported Parameters \u2693 A. Exclusive Parameters \u2693 StreamGear API provides some exclusive internal parameters to easily generate Streaming Assets and effortlessly tweak its internal properties. These parameters are discussed below: -streams (list of dicts) : This important attribute makes it simple and pretty straight-forward to define additional multiple streams as list of dictionaries of different quality levels (i.e. different bitrates or spatial resolutions) for streaming. Important -streams attribute facts On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate 1 as the input Video, at the index 0 . You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically using -bpps and -resolution values. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. To construct the additional stream dictionaries, you'll will need following sub-attributes: -resolution (string) : It is compulsory to define the required resolution/dimension/size for the stream, otherwise given stream will be rejected. Its value can be a \"{width}x{height}\" as follows: \"-streams\" = [{ \"-resolution\" : \"1280x720\" }] # to produce a 1280x720 resolution/scale -video_bitrate (string) : It is an optional (can be ignored if -framerate parameter is defined) sub-attribute that generally determines the bandwidth and quality of stream, i.e. the higher the bitrate, the better the quality and the larger will be bandwidth and more will be strain on network. It value is generally in kbps (kilobits per second) for OBS (Open Broadcasting Softwares). You can easily define this attribute as follows: \"-streams\" : [{ \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"2000k\" }] # to produce a 1280x720 resolution and 2000kbps bitrate stream -framerate (float/int) : It is another optional (can be ignored if -video_bitrate parameter is defined) sub-attribute that defines the assumed framerate for the stream. It's value can be float/integer as follows: \"-streams\" : [{ \"-resolution\" : \"1280x720\" , \"-framerate\" : \"60.0\" }] # to produce a 1280x720 resolution and 60fps framerate stream Usage: You can easily define any number of streams using -streams attribute as follows: Usage example can be found here \u27b6 stream_params = { \"-streams\" : [{ \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : \"30.0\" }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : \"60.0\" }, # Stream3: 640x360 at 60fps ]} \u2002 -video_source (string) : This attribute takes valid Video path as input and activates Single-Source Mode , for transcoding it into multiple smaller chunks/segments for streaming after successful validation. Its value be one of the following: Usage example can be found here \u27b6 Video Filename : Valid path to Video file as follows: stream_params = { \"-video_source\" : \"/home/foo/foo1.mp4\" } # set input video source: /home/foo/foo1.mp4 Video URL : Valid URL of a network video stream as follows: Make sure given Video URL has protocol that is supported by installed FFmpeg. (verify with ffmpeg -protocols terminal command) stream_params = { \"-video_source\" : \"http://livefeed.com:5050\" } # set input video source: http://livefeed.com:5050 \u2002 -audio (string/list) : This attribute takes external custom audio path (as string ) or audio device name followed by suitable demuxer (as list ) as audio source input for all StreamGear streams. Its value be one of the following: Make sure this audio-source is compatible with provided video -source, otherwise you could encounter multiple errors, or even no output at all! Audio Filename (string) : Valid path to Audio file as follows: stream_params = { \"-audio\" : \"/home/foo/foo1.aac\" } # set input audio source: /home/foo/foo1.aac !!! tip \"Usage example can be found here \u27b6 \" Audio URL (string) : Valid URL of a network audio stream as follows: Make sure given Video URL has protocol that is supported by installed FFmpeg. (verify with ffmpeg -protocols terminal command) stream_params = { \"-audio\" : \"https://exampleaudio.org/example-160.mp3\" } # set input audio source: https://exampleaudio.org/example-160.mp3 Device name and Demuxer (list) : Valid audio device name followed by suitable demuxer as follows: stream_params = { \"-audio\" : \"https://exampleaudio.org/example-160.mp3\" } # set input audio source: https://exampleaudio.org/example-160.mp3 Usage example can be found here \u27b6 \u2002 -livestream (bool) : (optional) specifies whether to enable Livestream Support (chunks will contain information for new frames only) for the selected mode, or not. You can easily set it to True to enable this feature, and default value is False . It can be used as follows: Use window_size & extra_window_size FFmpeg parameters for controlling number of frames to be kept in New Chunks. stream_params = { \"-livestream\" : True } # enable livestreaming \u2002 -input_framerate (float/int) : (optional) specifies the assumed input video source framerate, and only works in Real-time Frames Mode . It can be used as follows: Usage example can be found here \u27b6 stream_params = { \"-input_framerate\" : 60.0 } # set input video source framerate to 60fps \u2002 -bpp (float/int) : (optional) This attribute controls constant Bits-Per-Pixel (BPP) value, which is kind of a constant value to ensure good quality of high motion scenes ,and thereby used in calculating desired video-bitrate for streams. Higher the BPP, better will be motion quality. Its default value is 0.1 . Going over 0.1 helps to fill gaps between current bitrate and upload limit/ingest cap. Its value can be anything above 0.001 , can be used as follows: Important BPP tips for streaming -bpp a sensitive value, try 0.001, and then make increments in 0.0001 to fine tune If your desired resolution/fps/audio combination is below maximum service bitrate, raise BPP to match it for extra quality. It is generally better to lower resolution (and/or fps) and raise BPP than raise resolution and loose on BPP. stream_params = { \"-bpp\" : 0.05 } # sets BPP to 0.05 \u2002 -gop (float/int) : (optional) specifies the number of frames between two I-frames for accurate GOP length. By increasing the length of the GOP, there will be fewer I-frames per time frame, which minimizes bandwidth consumption. So, for example, with extremely complex subjects such as water sports or action mode, you\u2019ll want to use a shorter GOP length such as 15 or below that results in excellent video quality. For more static video such as talking heads, then much longer GOP sizes are not only sufficient but also more efficient. It can be used as follows: The larger the GOP size, the more efficient the compression and the less bandwidth you will need By default, StreamGear automatically sets recommended fixed GOP value (i.e. every two seconds) w.r.t input framerate and selected encoder. stream_params = { \"-gop\" : 70 } # set GOP length to 70 \u2002 -clones (list) : (optional) sets the special FFmpeg parameters that are repeated more than once in the command (For more info., see this issue ) as list only. Usage is as follows: stream_params = { \"-clones\" : [ '-map' , '0:v:0' , '-map' , '1:a?' ]} \u2002 -ffmpeg_download_path (string) : (optional) sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows: stream_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # will be saved to \"C:/User/foo/foo1\" \u2002 -clear_prev_assets (bool) : (optional) specify whether to force-delete any previous copies of StreamGear Assets (i.e. Manifest files(.mpd) & streaming chunks(.m4s) etc.) present at path specified by output parameter. You can easily set it to True to enable this feature, and default value is False . It can be used as follows: In Single-Source Mode, additional segments (such as .webm , .mp4 chunks) are also cleared automatically. stream_params = { \"-clear_prev_assets\" : True } # will delete all previous assets \u2002 B. FFmpeg Parameters \u2693 Almost all FFmpeg parameter can be passed as dictionary attributes in stream_params . For example, for using libx264 encoder to produce a lossless output video, we can pass required FFmpeg parameters as dictionary attributes, as follows: Kindly check H.264 docs \u27b6 and other FFmpeg Docs \u27b6 for more information on these parameters All ffmpeg parameters are case-sensitive. Remember to double check every parameter if any error occurs. In addition to these parameters, almost any FFmpeg parameter (supported by installed FFmpeg) is also supported. But make sure to read FFmpeg Docs carefully first. stream_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" , \"-tune\" : \"zerolatency\" } \u2002 Supported Encoders and Decoders \u2693 All the encoders and decoders that are compiled with FFmpeg in use, are supported by WriteGear API. You can easily check the compiled encoders by running following command in your terminal: Similarily, supported demuxers and filters depends upons compiled FFmpeg in use. # for checking encoder ffmpeg -encoders # use `ffmpeg.exe -encoders` on windows # for checking decoders ffmpeg -decoders # use `ffmpeg.exe -decoders` on windows logging \u2693 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: StreamGear ( logging = True ) In Real-time Frames Mode, the Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25fps. \u21a9","title":"Parameters"},{"location":"gears/streamgear/params/#streamgear-api-parameters","text":"","title":"StreamGear API Parameters"},{"location":"gears/streamgear/params/#output","text":"This parameter sets the valid filename/path for storing the StreamGear assets (Manifest file (such as MPD in-case of DASH) or a Master Playlist (such as M3U8 in-case of Apple HLS) & Transcoded sequence of segments) . StreamGear API will throw ValueError if output provided is empty or invalid. Make sure to provide valid filename with valid file-extension for selected format value (such as .mpd in case of MPEG-DASH and .m3u8 in case of APPLE-HLS) , otherwise StreamGear will throw AssertionError . StreamGear generated sequence of multiple chunks/segments are also stored in the same directory. You can easily delete all previous assets at output location, by using -clear_prev_assets attribute of stream_params dictionary parameter. Data-Type: String Usage: Its valid input can be one of the following: Path to directory : Valid path of the directory. In this case, StreamGear API will automatically assign a unique filename for Manifest file. This can be defined as follows: DASH HLS streamer = StreamGear ( output = \"/home/foo/foo1\" ) # Define streamer with manifest saving directory path streamer = StreamGear ( output = \"/home/foo/foo1\" , format = \"hls\" ) # Define streamer with playlist saving directory path Filename (with/without path) : Valid filename( with valid extension ) of the output Manifest file. In case filename is provided without path, then current working directory will be used. DASH HLS streamer = StreamGear ( output = \"output_foo.mpd\" ) # Define streamer with manifest file name streamer = StreamGear ( output = \"output_foo.m3u8\" , format = \"hls\" ) # Define streamer with playlist file name URL : Valid URL of a network stream with a protocol supported by installed FFmpeg (verify with command ffmpeg -protocols ) only. This is useful for directly storing assets to a network server. For example, you can use a http protocol URL as follows: DASH HLS streamer = StreamGear ( output = \"http://195.167.1.101/live/test.mpd\" ) #Define streamer streamer = StreamGear ( output = \"http://195.167.1.101/live/test.m3u8\" , format = \"hls\" ) #Define streamer","title":"output"},{"location":"gears/streamgear/params/#format","text":"This parameter select the adaptive HTTP streaming formats. For now, the supported format are: dash (i.e MPEG-DASH ) and hls (i.e Apple HLS ) . Any invalid value to format parameter will result in ValueError! Make sure to provide valid filename with valid file-extension in output for selected format value (such as .mpd in case of MPEG-DASH and .m3u8 in case of APPLE-HLS) , otherwise StreamGear will throw AssertionError . Data-Type: String Default Value: Its default value is dash Usage: DASH HLS StreamGear ( output = \"output_foo.mpd\" , format = \"dash\" ) StreamGear ( output = \"output_foo.m3u8\" , format = \"hls\" )","title":"format"},{"location":"gears/streamgear/params/#custom_ffmpeg","text":"This parameter assigns the custom path/directory where the custom/downloaded FFmpeg executables are located. Behavior on Windows If a custom FFmpeg executable's path | directory is not provided through custom_ffmpeg parameter on Windows machine, then StreamGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . Data-Type: String Default Value: Its default value is None . Usage: # If ffmpeg executables are located at \"/foo/foo1/ffmpeg\" StreamGear ( output = 'output_foo.mpd' , custom_ffmpeg = \"/foo/foo1/ffmpeg\" )","title":"custom_ffmpeg"},{"location":"gears/streamgear/params/#stream_params","text":"This parameter allows us to exploit almost all FFmpeg supported parameters effortlessly and flexibly change its internal settings for transcoding and seamlessly generating high-quality streams. All supported parameters can formatting as attributes for this dictionary parameter: Kindly read FFmpeg Docs carefully, before passing any additional values to stream_params parameter. Wrong values may result in undesired errors or no output at all. Data-Type: Dictionary Default Value: Its default value is {} .","title":"stream_params"},{"location":"gears/streamgear/params/#supported-parameters","text":"","title":"Supported Parameters"},{"location":"gears/streamgear/params/#a-exclusive-parameters","text":"StreamGear API provides some exclusive internal parameters to easily generate Streaming Assets and effortlessly tweak its internal properties. These parameters are discussed below: -streams (list of dicts) : This important attribute makes it simple and pretty straight-forward to define additional multiple streams as list of dictionaries of different quality levels (i.e. different bitrates or spatial resolutions) for streaming. Important -streams attribute facts On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate 1 as the input Video, at the index 0 . You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically using -bpps and -resolution values. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. To construct the additional stream dictionaries, you'll will need following sub-attributes: -resolution (string) : It is compulsory to define the required resolution/dimension/size for the stream, otherwise given stream will be rejected. Its value can be a \"{width}x{height}\" as follows: \"-streams\" = [{ \"-resolution\" : \"1280x720\" }] # to produce a 1280x720 resolution/scale -video_bitrate (string) : It is an optional (can be ignored if -framerate parameter is defined) sub-attribute that generally determines the bandwidth and quality of stream, i.e. the higher the bitrate, the better the quality and the larger will be bandwidth and more will be strain on network. It value is generally in kbps (kilobits per second) for OBS (Open Broadcasting Softwares). You can easily define this attribute as follows: \"-streams\" : [{ \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"2000k\" }] # to produce a 1280x720 resolution and 2000kbps bitrate stream -framerate (float/int) : It is another optional (can be ignored if -video_bitrate parameter is defined) sub-attribute that defines the assumed framerate for the stream. It's value can be float/integer as follows: \"-streams\" : [{ \"-resolution\" : \"1280x720\" , \"-framerate\" : \"60.0\" }] # to produce a 1280x720 resolution and 60fps framerate stream Usage: You can easily define any number of streams using -streams attribute as follows: Usage example can be found here \u27b6 stream_params = { \"-streams\" : [{ \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : \"30.0\" }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : \"60.0\" }, # Stream3: 640x360 at 60fps ]} \u2002 -video_source (string) : This attribute takes valid Video path as input and activates Single-Source Mode , for transcoding it into multiple smaller chunks/segments for streaming after successful validation. Its value be one of the following: Usage example can be found here \u27b6 Video Filename : Valid path to Video file as follows: stream_params = { \"-video_source\" : \"/home/foo/foo1.mp4\" } # set input video source: /home/foo/foo1.mp4 Video URL : Valid URL of a network video stream as follows: Make sure given Video URL has protocol that is supported by installed FFmpeg. (verify with ffmpeg -protocols terminal command) stream_params = { \"-video_source\" : \"http://livefeed.com:5050\" } # set input video source: http://livefeed.com:5050 \u2002 -audio (string/list) : This attribute takes external custom audio path (as string ) or audio device name followed by suitable demuxer (as list ) as audio source input for all StreamGear streams. Its value be one of the following: Make sure this audio-source is compatible with provided video -source, otherwise you could encounter multiple errors, or even no output at all! Audio Filename (string) : Valid path to Audio file as follows: stream_params = { \"-audio\" : \"/home/foo/foo1.aac\" } # set input audio source: /home/foo/foo1.aac !!! tip \"Usage example can be found here \u27b6 \" Audio URL (string) : Valid URL of a network audio stream as follows: Make sure given Video URL has protocol that is supported by installed FFmpeg. (verify with ffmpeg -protocols terminal command) stream_params = { \"-audio\" : \"https://exampleaudio.org/example-160.mp3\" } # set input audio source: https://exampleaudio.org/example-160.mp3 Device name and Demuxer (list) : Valid audio device name followed by suitable demuxer as follows: stream_params = { \"-audio\" : \"https://exampleaudio.org/example-160.mp3\" } # set input audio source: https://exampleaudio.org/example-160.mp3 Usage example can be found here \u27b6 \u2002 -livestream (bool) : (optional) specifies whether to enable Livestream Support (chunks will contain information for new frames only) for the selected mode, or not. You can easily set it to True to enable this feature, and default value is False . It can be used as follows: Use window_size & extra_window_size FFmpeg parameters for controlling number of frames to be kept in New Chunks. stream_params = { \"-livestream\" : True } # enable livestreaming \u2002 -input_framerate (float/int) : (optional) specifies the assumed input video source framerate, and only works in Real-time Frames Mode . It can be used as follows: Usage example can be found here \u27b6 stream_params = { \"-input_framerate\" : 60.0 } # set input video source framerate to 60fps \u2002 -bpp (float/int) : (optional) This attribute controls constant Bits-Per-Pixel (BPP) value, which is kind of a constant value to ensure good quality of high motion scenes ,and thereby used in calculating desired video-bitrate for streams. Higher the BPP, better will be motion quality. Its default value is 0.1 . Going over 0.1 helps to fill gaps between current bitrate and upload limit/ingest cap. Its value can be anything above 0.001 , can be used as follows: Important BPP tips for streaming -bpp a sensitive value, try 0.001, and then make increments in 0.0001 to fine tune If your desired resolution/fps/audio combination is below maximum service bitrate, raise BPP to match it for extra quality. It is generally better to lower resolution (and/or fps) and raise BPP than raise resolution and loose on BPP. stream_params = { \"-bpp\" : 0.05 } # sets BPP to 0.05 \u2002 -gop (float/int) : (optional) specifies the number of frames between two I-frames for accurate GOP length. By increasing the length of the GOP, there will be fewer I-frames per time frame, which minimizes bandwidth consumption. So, for example, with extremely complex subjects such as water sports or action mode, you\u2019ll want to use a shorter GOP length such as 15 or below that results in excellent video quality. For more static video such as talking heads, then much longer GOP sizes are not only sufficient but also more efficient. It can be used as follows: The larger the GOP size, the more efficient the compression and the less bandwidth you will need By default, StreamGear automatically sets recommended fixed GOP value (i.e. every two seconds) w.r.t input framerate and selected encoder. stream_params = { \"-gop\" : 70 } # set GOP length to 70 \u2002 -clones (list) : (optional) sets the special FFmpeg parameters that are repeated more than once in the command (For more info., see this issue ) as list only. Usage is as follows: stream_params = { \"-clones\" : [ '-map' , '0:v:0' , '-map' , '1:a?' ]} \u2002 -ffmpeg_download_path (string) : (optional) sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows: stream_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # will be saved to \"C:/User/foo/foo1\" \u2002 -clear_prev_assets (bool) : (optional) specify whether to force-delete any previous copies of StreamGear Assets (i.e. Manifest files(.mpd) & streaming chunks(.m4s) etc.) present at path specified by output parameter. You can easily set it to True to enable this feature, and default value is False . It can be used as follows: In Single-Source Mode, additional segments (such as .webm , .mp4 chunks) are also cleared automatically. stream_params = { \"-clear_prev_assets\" : True } # will delete all previous assets","title":"A. Exclusive Parameters"},{"location":"gears/streamgear/params/#b-ffmpeg-parameters","text":"Almost all FFmpeg parameter can be passed as dictionary attributes in stream_params . For example, for using libx264 encoder to produce a lossless output video, we can pass required FFmpeg parameters as dictionary attributes, as follows: Kindly check H.264 docs \u27b6 and other FFmpeg Docs \u27b6 for more information on these parameters All ffmpeg parameters are case-sensitive. Remember to double check every parameter if any error occurs. In addition to these parameters, almost any FFmpeg parameter (supported by installed FFmpeg) is also supported. But make sure to read FFmpeg Docs carefully first. stream_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" , \"-tune\" : \"zerolatency\" }","title":"B. FFmpeg Parameters"},{"location":"gears/streamgear/params/#supported-encoders-and-decoders","text":"All the encoders and decoders that are compiled with FFmpeg in use, are supported by WriteGear API. You can easily check the compiled encoders by running following command in your terminal: Similarily, supported demuxers and filters depends upons compiled FFmpeg in use. # for checking encoder ffmpeg -encoders # use `ffmpeg.exe -encoders` on windows # for checking decoders ffmpeg -decoders # use `ffmpeg.exe -decoders` on windows","title":"Supported Encoders and Decoders"},{"location":"gears/streamgear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: StreamGear ( logging = True ) In Real-time Frames Mode, the Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25fps. \u21a9","title":"logging"},{"location":"gears/streamgear/rtfm/overview/","text":"StreamGear API: Real-time Frames Mode \u2693 Real-time Frames Mode generalized workflow Overview \u2693 When no valid input is received on -video_source attribute of stream_params dictionary parameter, StreamGear API activates this mode where it directly transcodes real-time numpy.ndarray video-frames (as opposed to a entire video file) into a sequence of multiple smaller chunks/segments for adaptive streaming. This mode works exceptionally well when you desire to flexibility manipulate or transform video-frames in real-time before sending them onto FFmpeg Pipeline for processing. But on the downside, StreamGear DOES NOT automatically maps video-source's audio to generated streams with this mode. You need to manually assign separate audio-source through -audio attribute of stream_params dictionary parameter. SteamGear supports both MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) and Apple HLS (HTTP Live Streaming) with this mode. For this mode, StreamGear API provides exclusive stream() method for directly trancoding video-frames into streamable chunks. \u2003 New in v0.2.2 Apple HLS support was added in v0.2.2 . Real-time Frames Mode is NOT Live-Streaming. Rather, you can easily enable live-streaming in Real-time Frames Mode by using StreamGear API's exclusive -livestream attribute of stream_params dictionary parameter. Checkout its usage example here . Danger Using transcode_source() function instead of stream() in Real-time Frames Mode will instantly result in RuntimeError ! NEVER assign anything to -video_source attribute of stream_params dictionary parameter, otherwise Single-Source Mode may get activated, and as a result, using stream() function will throw RuntimeError ! You MUST use -input_framerate attribute to set exact value of input framerate when using external audio in this mode, otherwise audio delay will occur in output streams. Input framerate defaults to 25.0 fps if -input_framerate attribute value not defined. \u2009 Usage Examples \u2693 See here \ud83d\ude80 After going through StreamGear Usage Examples, Checkout more of its advanced configurations here \u27b6 Parameters \u2693 See here \ud83d\ude80 References \u2693 See here \ud83d\ude80 FAQs \u2693 See here \ud83d\ude80","title":"Overview"},{"location":"gears/streamgear/rtfm/overview/#streamgear-api-real-time-frames-mode","text":"Real-time Frames Mode generalized workflow","title":"StreamGear API: Real-time Frames Mode"},{"location":"gears/streamgear/rtfm/overview/#overview","text":"When no valid input is received on -video_source attribute of stream_params dictionary parameter, StreamGear API activates this mode where it directly transcodes real-time numpy.ndarray video-frames (as opposed to a entire video file) into a sequence of multiple smaller chunks/segments for adaptive streaming. This mode works exceptionally well when you desire to flexibility manipulate or transform video-frames in real-time before sending them onto FFmpeg Pipeline for processing. But on the downside, StreamGear DOES NOT automatically maps video-source's audio to generated streams with this mode. You need to manually assign separate audio-source through -audio attribute of stream_params dictionary parameter. SteamGear supports both MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) and Apple HLS (HTTP Live Streaming) with this mode. For this mode, StreamGear API provides exclusive stream() method for directly trancoding video-frames into streamable chunks. \u2003 New in v0.2.2 Apple HLS support was added in v0.2.2 . Real-time Frames Mode is NOT Live-Streaming. Rather, you can easily enable live-streaming in Real-time Frames Mode by using StreamGear API's exclusive -livestream attribute of stream_params dictionary parameter. Checkout its usage example here . Danger Using transcode_source() function instead of stream() in Real-time Frames Mode will instantly result in RuntimeError ! NEVER assign anything to -video_source attribute of stream_params dictionary parameter, otherwise Single-Source Mode may get activated, and as a result, using stream() function will throw RuntimeError ! You MUST use -input_framerate attribute to set exact value of input framerate when using external audio in this mode, otherwise audio delay will occur in output streams. Input framerate defaults to 25.0 fps if -input_framerate attribute value not defined.","title":"Overview"},{"location":"gears/streamgear/rtfm/overview/#usage-examples","text":"See here \ud83d\ude80 After going through StreamGear Usage Examples, Checkout more of its advanced configurations here \u27b6","title":"Usage Examples"},{"location":"gears/streamgear/rtfm/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/streamgear/rtfm/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/streamgear/rtfm/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/streamgear/rtfm/usage/","text":"StreamGear API Usage Examples: Real-time Frames Mode \u2693 Real-time Frames Mode is NOT Live-Streaming. Rather you can easily enable live-streaming in Real-time Frames Mode by using StreamGear API's exclusive -livestream attribute of stream_params dictionary parameter. Checkout following usage example . Important Information StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. By default, StreamGear generates a primary stream of same resolution and framerate 1 as the input video (at the index 0 ) . Always use terminate() function at the very end of the main code. After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6 \u2009 Bare-Minimum Usage \u2693 Following is the bare-minimum code you need to get started with StreamGear API in Real-time Frames Mode: We are using CamGear in this Bare-Minimum example, but any VideoCapture Gear will work in the similar manner. DASH HLS # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () After running this bare-minimum example, StreamGear will produce a Manifest file ( dash.mpd ) with streamable chunks that contains information about a Primary Stream of same resolution and framerate 1 as input (without any audio) . \u2009 Bare-Minimum Usage with Live-Streaming \u2693 You can easily activate Low-latency Livestreaming in Real-time Frames Mode , where chunks will contain information for few new frames only and forgets all previous ones), using exclusive -livestream attribute of stream_params dictionary parameter as follows: Use -window_size & -extra_window_size FFmpeg parameters for controlling number of frames to be kept in Chunks. Less these value, less will be latency. After every few chunks (equal to the sum of -window_size & -extra_window_size values) , all chunks will be overwritten in Live-Streaming. Thereby, since newer chunks in manifest/playlist will contain NO information of any older ones, and therefore resultant DASH/HLS stream will play only the most recent frames. In this mode, StreamGear DOES NOT automatically maps video-source audio to generated streams. You need to manually assign separate audio-source through -audio attribute of stream_params dictionary parameter. DASH HLS # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(from web-camera attached at index `0`) stream = CamGear ( source = 0 ) . start () # enable livestreaming and retrieve framerate from CamGear Stream and # pass it as `-input_framerate` parameter for controlled framerate stream_params = { \"-input_framerate\" : stream . framerate , \"-livestream\" : True } # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(from web-camera attached at index `0`) stream = CamGear ( source = 0 ) . start () # enable livestreaming and retrieve framerate from CamGear Stream and # pass it as `-input_framerate` parameter for controlled framerate stream_params = { \"-input_framerate\" : stream . framerate , \"-livestream\" : True } # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () \u2009 Bare-Minimum Usage with RGB Mode \u2693 In Real-time Frames Mode, StreamGear API provide rgb_mode boolean parameter with its stream() function, which if enabled (i.e. rgb_mode=True ) , specifies that incoming frames are of RGB format (instead of default BGR format) , thereby also known as RGB Mode . The complete usage example is as follows: DASH HLS # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {simulating RGB frame for this example} frame_rgb = frame [:,:,:: - 1 ] # send frame to streamer streamer . stream ( frame_rgb , rgb_mode = True ) #activate RGB Mode # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {simulating RGB frame for this example} frame_rgb = frame [:,:,:: - 1 ] # send frame to streamer streamer . stream ( frame_rgb , rgb_mode = True ) #activate RGB Mode # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () \u2009 Bare-Minimum Usage with controlled Input-framerate \u2693 In Real-time Frames Mode, StreamGear API provides exclusive -input_framerate attribute for its stream_params dictionary parameter, that allow us to set the assumed constant framerate for incoming frames. In this example, we will retrieve framerate from webcam video-stream, and set it as value for -input_framerate attribute in StreamGear: Remember, Input framerate default to 25.0 fps if -input_framerate attribute value not defined in Real-time Frames mode. DASH HLS # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # retrieve framerate from CamGear Stream and pass it as `-input_framerate` value stream_params = { \"-input_framerate\" : stream . framerate } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # retrieve framerate from CamGear Stream and pass it as `-input_framerate` value stream_params = { \"-input_framerate\" : stream . framerate } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () \u2009 Bare-Minimum Usage with OpenCV \u2693 You can easily use StreamGear API directly with any other Video Processing library( For e.g. OpenCV itself ) in Real-time Frames Mode. The complete usage example is as follows: This just a bare-minimum example with OpenCV, but any other Real-time Frames Mode feature/example will work in the similar manner. DASH HLS # import required libraries from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # send frame to streamer streamer . stream ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # send frame to streamer streamer . stream ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close streamer streamer . terminate () \u2009 Usage with Additional Streams \u2693 Similar to Single-Source Mode, you can easily generate any number of additional Secondary Streams of variable bitrates or spatial resolutions, using exclusive -streams attribute of stream_params dictionary parameter. You just need to add each resolution and bitrate/framerate as list of dictionaries to this attribute, and rest is done automatically. A more detailed information on -streams attribute can be found here \u27b6 The complete example is as follows: Important -streams attribute Information On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate 1 as the input, at the index 0 . Make sure your System/Machine/Server/Network is able to handle these additional streams, discretion is advised! You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. Always use -stream attribute to define additional streams safely, any duplicate or incorrect definition can break things! DASH HLS # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # define various streams stream_params = { \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # define various streams stream_params = { \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () \u2009 Usage with File Audio-Input \u2693 In Real-time Frames Mode, if you want to add audio to your streams, you've to use exclusive -audio attribute of stream_params dictionary parameter. You just need to input the path of your audio file to this attribute as string value, and the API will automatically validate as well as maps it to all generated streams. The complete example is as follows: Make sure this -audio audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all. You MUST use -input_framerate attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams. You can also assign a valid Audio URL as input, rather than filepath. More details can be found here \u27b6 DASH HLS # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # add various streams, along with custom audio stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-input_framerate\" : stream . framerate , # controlled framerate for audio-video sync !!! don't forget this line !!! \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # add various streams, along with custom audio stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-input_framerate\" : stream . framerate , # controlled framerate for audio-video sync !!! don't forget this line !!! \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () \u2009 Usage with Device Audio-Input \u2693 In Real-time Frames Mode, you've can also use exclusive -audio attribute of stream_params dictionary parameter for streaming live audio from external device. You just need to format your audio device name followed by suitable demuxer as list and assign to this attribute, and the API will automatically validate as well as map it to all generated streams. The complete example is as follows: Example Assumptions You're running are Windows machine with all neccessary audio drivers and software installed. There's a audio device with named \"Microphone (USB2.0 Camera)\" connected to your windows machine. Using devices with -audio attribute on different OS platforms Windows Linux MacOS Windows OS users can use the dshow (DirectShow) to list audio input device which is the preferred option for Windows users. You can refer following steps to identify and specify your sound card: [OPTIONAL] Enable sound card(if disabled): First enable your Stereo Mix by opening the \"Sound\" window and select the \"Recording\" tab, then right click on the window and select \"Show Disabled Devices\" to toggle the Stereo Mix device visibility. Follow this post \u27b6 for more details. Identify Sound Card: Then, You can locate your soundcard using dshow as follows: c: \\> ffmpeg -list_devices true -f dshow -i dummy ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ dshow @ 03ACF580 ] DirectShow video devices [ dshow @ 03ACF580 ] \"Integrated Camera\" [ dshow @ 03ACF580 ] \"USB2.0 Camera\" [ dshow @ 03ACF580 ] DirectShow audio devices [ dshow @ 03ACF580 ] \"Microphone (Realtek High Definition Audio)\" [ dshow @ 03ACF580 ] \"Microphone (USB2.0 Camera)\" dummy: Immediate exit requested Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows: # assign appropriate input audio-source device and demuxer device and demuxer stream_params = { \"-audio\" : [ \"-f\" , \"dshow\" , \"-i\" , \"audio=Microphone (USB2.0 Camera)\" ]} If audio still doesn't work then checkout this troubleshooting guide \u27b6 or reach us out on Gitter \u27b6 Community channel Linux OS users can use the alsa to list input device to capture live audio input such as from a webcam. You can refer following steps to identify and specify your sound card: Identify Sound Card: To get the list of all installed cards on your machine, you can type arecord -l or arecord -L (longer output) . arecord -l **** List of CAPTURE Hardware Devices **** card 0 : ICH5 [ Intel ICH5 ] , device 0 : Intel ICH [ Intel ICH5 ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 1 : Intel ICH - MIC ADC [ Intel ICH5 - MIC ADC ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 2 : Intel ICH - MIC2 ADC [ Intel ICH5 - MIC2 ADC ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 3 : Intel ICH - ADC2 [ Intel ICH5 - ADC2 ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 1 : U0x46d0x809 [ USB Device 0x46d:0x809 ] , device 0 : USB Audio [ USB Audio ] Subdevices: 1 /1 Subdevice #0: subdevice #0 Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows: The easiest thing to do is to reference sound card directly, namely \"card 0\" (Intel ICH5) and \"card 1\" (Microphone on the USB web cam), as hw:0 or hw:1 # assign appropriate input audio-source device and demuxer device and demuxer stream_params = { \"-audio\" : [ \"-f\" , \"alsa\" , \"-i\" , \"hw:1\" ]} If audio still doesn't work then reach us out on Gitter \u27b6 Community channel MAC OS users can use the avfoundation to list input devices for grabbing audio from integrated iSight cameras as well as cameras connected via USB or FireWire. You can refer following steps to identify and specify your sound card on MacOS/OSX machines: Identify Sound Card: Then, You can locate your soundcard using avfoundation as follows: ffmpeg -f qtkit -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows: # assign appropriate input audio-source device and demuxer stream_params = { \"-audio\" : [ \"-f\" , \"avfoundation\" , \"-audio_device_index\" , \"0\" ]} If audio still doesn't work then reach us out on Gitter \u27b6 Community channel Make sure this -audio audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all. You MUST use -input_framerate attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams. It is advised to use this example with live-streaming enabled(True) by using StreamGear API's exclusive -livestream attribute of stream_params dictionary parameter. DASH HLS # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = \"foo1.mp4\" ) . start () # add various streams, along with custom audio stream_params = { \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"4000k\" , }, # Stream1: 1280x720 at 4000kbs bitrate { \"-resolution\" : \"640x360\" , \"-framerate\" : 30.0 }, # Stream2: 640x360 at 30fps ], \"-input_framerate\" : stream . framerate , # controlled framerate for audio-video sync !!! don't forget this line !!! \"-audio\" : [ \"-f\" , \"dshow\" , \"-i\" , \"audio=Microphone (USB2.0 Camera)\" , ], # assign appropriate input audio-source device and demuxer } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = \"foo1.mp4\" ) . start () # add various streams, along with custom audio stream_params = { \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"4000k\" , }, # Stream1: 1280x720 at 4000kbs bitrate { \"-resolution\" : \"640x360\" , \"-framerate\" : 30.0 }, # Stream2: 640x360 at 30fps ], \"-input_framerate\" : stream . framerate , # controlled framerate for audio-video sync !!! don't forget this line !!! \"-audio\" : [ \"-f\" , \"dshow\" , \"-i\" , \"audio=Microphone (USB2.0 Camera)\" , ], # assign appropriate input audio-source device and demuxer } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.m3u8\" , format = \"hls\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () \u2009 Usage with Hardware Video-Encoder \u2693 In Real-time Frames Mode, you can also easily change encoder as per your requirement just by passing -vcodec FFmpeg parameter as an attribute in stream_params dictionary parameter. In addition to this, you can also specify the additional properties/features/optimizations for your system's GPU similarly. In this example, we will be using h264_vaapi as our hardware encoder and also optionally be specifying our device hardware's location (i.e. '-vaapi_device':'/dev/dri/renderD128' ) and other features such as '-vf':'format=nv12,hwupload' like properties by formatting them as option dictionary parameter's attributes, as follows: Check VAAPI support This example is just conveying the idea on how to use FFmpeg's hardware encoders with WriteGear API in Compression mode, which MAY/MAY-NOT suit your system. Kindly use suitable parameters based your supported system and FFmpeg configurations only. To use h264_vaapi encoder, remember to check if its available and your FFmpeg compiled with VAAPI support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: ffmpeg -hide_banner -encoders | grep vaapi V..... h264_vaapi H.264/AVC ( VAAPI ) ( codec h264 ) V..... hevc_vaapi H.265/HEVC ( VAAPI ) ( codec hevc ) V..... mjpeg_vaapi MJPEG ( VAAPI ) ( codec mjpeg ) V..... mpeg2_vaapi MPEG-2 ( VAAPI ) ( codec mpeg2video ) V..... vp8_vaapi VP8 ( VAAPI ) ( codec vp8 ) DASH HLS # import required libraries from vidgear.gears import VideoGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = VideoGear ( source = 0 ) . start () # add various streams with custom Video Encoder and optimizations stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-vcodec\" : \"h264_vaapi\" , # define custom Video encoder \"-vaapi_device\" : \"/dev/dri/renderD128\" , # define device location \"-vf\" : \"format=nv12,hwupload\" , # define video pixformat } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import VideoGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = VideoGear ( source = 0 ) . start () # add various streams with custom Video Encoder and optimizations stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-vcodec\" : \"h264_vaapi\" , # define custom Video encoder \"-vaapi_device\" : \"/dev/dri/renderD128\" , # define device location \"-vf\" : \"format=nv12,hwupload\" , # define video pixformat } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () In Real-time Frames Mode, the Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25fps. \u21a9 \u21a9 \u21a9","title":"Usage Examples"},{"location":"gears/streamgear/rtfm/usage/#streamgear-api-usage-examples-real-time-frames-mode","text":"Real-time Frames Mode is NOT Live-Streaming. Rather you can easily enable live-streaming in Real-time Frames Mode by using StreamGear API's exclusive -livestream attribute of stream_params dictionary parameter. Checkout following usage example . Important Information StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. By default, StreamGear generates a primary stream of same resolution and framerate 1 as the input video (at the index 0 ) . Always use terminate() function at the very end of the main code. After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6","title":"StreamGear API Usage Examples: Real-time Frames Mode"},{"location":"gears/streamgear/rtfm/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with StreamGear API in Real-time Frames Mode: We are using CamGear in this Bare-Minimum example, but any VideoCapture Gear will work in the similar manner. DASH HLS # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () After running this bare-minimum example, StreamGear will produce a Manifest file ( dash.mpd ) with streamable chunks that contains information about a Primary Stream of same resolution and framerate 1 as input (without any audio) .","title":"Bare-Minimum Usage"},{"location":"gears/streamgear/rtfm/usage/#bare-minimum-usage-with-live-streaming","text":"You can easily activate Low-latency Livestreaming in Real-time Frames Mode , where chunks will contain information for few new frames only and forgets all previous ones), using exclusive -livestream attribute of stream_params dictionary parameter as follows: Use -window_size & -extra_window_size FFmpeg parameters for controlling number of frames to be kept in Chunks. Less these value, less will be latency. After every few chunks (equal to the sum of -window_size & -extra_window_size values) , all chunks will be overwritten in Live-Streaming. Thereby, since newer chunks in manifest/playlist will contain NO information of any older ones, and therefore resultant DASH/HLS stream will play only the most recent frames. In this mode, StreamGear DOES NOT automatically maps video-source audio to generated streams. You need to manually assign separate audio-source through -audio attribute of stream_params dictionary parameter. DASH HLS # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(from web-camera attached at index `0`) stream = CamGear ( source = 0 ) . start () # enable livestreaming and retrieve framerate from CamGear Stream and # pass it as `-input_framerate` parameter for controlled framerate stream_params = { \"-input_framerate\" : stream . framerate , \"-livestream\" : True } # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(from web-camera attached at index `0`) stream = CamGear ( source = 0 ) . start () # enable livestreaming and retrieve framerate from CamGear Stream and # pass it as `-input_framerate` parameter for controlled framerate stream_params = { \"-input_framerate\" : stream . framerate , \"-livestream\" : True } # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"Bare-Minimum Usage with Live-Streaming"},{"location":"gears/streamgear/rtfm/usage/#bare-minimum-usage-with-rgb-mode","text":"In Real-time Frames Mode, StreamGear API provide rgb_mode boolean parameter with its stream() function, which if enabled (i.e. rgb_mode=True ) , specifies that incoming frames are of RGB format (instead of default BGR format) , thereby also known as RGB Mode . The complete usage example is as follows: DASH HLS # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {simulating RGB frame for this example} frame_rgb = frame [:,:,:: - 1 ] # send frame to streamer streamer . stream ( frame_rgb , rgb_mode = True ) #activate RGB Mode # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {simulating RGB frame for this example} frame_rgb = frame [:,:,:: - 1 ] # send frame to streamer streamer . stream ( frame_rgb , rgb_mode = True ) #activate RGB Mode # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"Bare-Minimum Usage with RGB Mode"},{"location":"gears/streamgear/rtfm/usage/#bare-minimum-usage-with-controlled-input-framerate","text":"In Real-time Frames Mode, StreamGear API provides exclusive -input_framerate attribute for its stream_params dictionary parameter, that allow us to set the assumed constant framerate for incoming frames. In this example, we will retrieve framerate from webcam video-stream, and set it as value for -input_framerate attribute in StreamGear: Remember, Input framerate default to 25.0 fps if -input_framerate attribute value not defined in Real-time Frames mode. DASH HLS # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # retrieve framerate from CamGear Stream and pass it as `-input_framerate` value stream_params = { \"-input_framerate\" : stream . framerate } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # retrieve framerate from CamGear Stream and pass it as `-input_framerate` value stream_params = { \"-input_framerate\" : stream . framerate } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"Bare-Minimum Usage with controlled Input-framerate"},{"location":"gears/streamgear/rtfm/usage/#bare-minimum-usage-with-opencv","text":"You can easily use StreamGear API directly with any other Video Processing library( For e.g. OpenCV itself ) in Real-time Frames Mode. The complete usage example is as follows: This just a bare-minimum example with OpenCV, but any other Real-time Frames Mode feature/example will work in the similar manner. DASH HLS # import required libraries from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # send frame to streamer streamer . stream ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # send frame to streamer streamer . stream ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close streamer streamer . terminate ()","title":"Bare-Minimum Usage with OpenCV"},{"location":"gears/streamgear/rtfm/usage/#usage-with-additional-streams","text":"Similar to Single-Source Mode, you can easily generate any number of additional Secondary Streams of variable bitrates or spatial resolutions, using exclusive -streams attribute of stream_params dictionary parameter. You just need to add each resolution and bitrate/framerate as list of dictionaries to this attribute, and rest is done automatically. A more detailed information on -streams attribute can be found here \u27b6 The complete example is as follows: Important -streams attribute Information On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate 1 as the input, at the index 0 . Make sure your System/Machine/Server/Network is able to handle these additional streams, discretion is advised! You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. Always use -stream attribute to define additional streams safely, any duplicate or incorrect definition can break things! DASH HLS # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # define various streams stream_params = { \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # define various streams stream_params = { \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"Usage with Additional Streams"},{"location":"gears/streamgear/rtfm/usage/#usage-with-file-audio-input","text":"In Real-time Frames Mode, if you want to add audio to your streams, you've to use exclusive -audio attribute of stream_params dictionary parameter. You just need to input the path of your audio file to this attribute as string value, and the API will automatically validate as well as maps it to all generated streams. The complete example is as follows: Make sure this -audio audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all. You MUST use -input_framerate attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams. You can also assign a valid Audio URL as input, rather than filepath. More details can be found here \u27b6 DASH HLS # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # add various streams, along with custom audio stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-input_framerate\" : stream . framerate , # controlled framerate for audio-video sync !!! don't forget this line !!! \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # add various streams, along with custom audio stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-input_framerate\" : stream . framerate , # controlled framerate for audio-video sync !!! don't forget this line !!! \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"Usage with File Audio-Input"},{"location":"gears/streamgear/rtfm/usage/#usage-with-device-audio-input","text":"In Real-time Frames Mode, you've can also use exclusive -audio attribute of stream_params dictionary parameter for streaming live audio from external device. You just need to format your audio device name followed by suitable demuxer as list and assign to this attribute, and the API will automatically validate as well as map it to all generated streams. The complete example is as follows: Example Assumptions You're running are Windows machine with all neccessary audio drivers and software installed. There's a audio device with named \"Microphone (USB2.0 Camera)\" connected to your windows machine. Using devices with -audio attribute on different OS platforms Windows Linux MacOS Windows OS users can use the dshow (DirectShow) to list audio input device which is the preferred option for Windows users. You can refer following steps to identify and specify your sound card: [OPTIONAL] Enable sound card(if disabled): First enable your Stereo Mix by opening the \"Sound\" window and select the \"Recording\" tab, then right click on the window and select \"Show Disabled Devices\" to toggle the Stereo Mix device visibility. Follow this post \u27b6 for more details. Identify Sound Card: Then, You can locate your soundcard using dshow as follows: c: \\> ffmpeg -list_devices true -f dshow -i dummy ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ dshow @ 03ACF580 ] DirectShow video devices [ dshow @ 03ACF580 ] \"Integrated Camera\" [ dshow @ 03ACF580 ] \"USB2.0 Camera\" [ dshow @ 03ACF580 ] DirectShow audio devices [ dshow @ 03ACF580 ] \"Microphone (Realtek High Definition Audio)\" [ dshow @ 03ACF580 ] \"Microphone (USB2.0 Camera)\" dummy: Immediate exit requested Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows: # assign appropriate input audio-source device and demuxer device and demuxer stream_params = { \"-audio\" : [ \"-f\" , \"dshow\" , \"-i\" , \"audio=Microphone (USB2.0 Camera)\" ]} If audio still doesn't work then checkout this troubleshooting guide \u27b6 or reach us out on Gitter \u27b6 Community channel Linux OS users can use the alsa to list input device to capture live audio input such as from a webcam. You can refer following steps to identify and specify your sound card: Identify Sound Card: To get the list of all installed cards on your machine, you can type arecord -l or arecord -L (longer output) . arecord -l **** List of CAPTURE Hardware Devices **** card 0 : ICH5 [ Intel ICH5 ] , device 0 : Intel ICH [ Intel ICH5 ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 1 : Intel ICH - MIC ADC [ Intel ICH5 - MIC ADC ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 2 : Intel ICH - MIC2 ADC [ Intel ICH5 - MIC2 ADC ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 3 : Intel ICH - ADC2 [ Intel ICH5 - ADC2 ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 1 : U0x46d0x809 [ USB Device 0x46d:0x809 ] , device 0 : USB Audio [ USB Audio ] Subdevices: 1 /1 Subdevice #0: subdevice #0 Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows: The easiest thing to do is to reference sound card directly, namely \"card 0\" (Intel ICH5) and \"card 1\" (Microphone on the USB web cam), as hw:0 or hw:1 # assign appropriate input audio-source device and demuxer device and demuxer stream_params = { \"-audio\" : [ \"-f\" , \"alsa\" , \"-i\" , \"hw:1\" ]} If audio still doesn't work then reach us out on Gitter \u27b6 Community channel MAC OS users can use the avfoundation to list input devices for grabbing audio from integrated iSight cameras as well as cameras connected via USB or FireWire. You can refer following steps to identify and specify your sound card on MacOS/OSX machines: Identify Sound Card: Then, You can locate your soundcard using avfoundation as follows: ffmpeg -f qtkit -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows: # assign appropriate input audio-source device and demuxer stream_params = { \"-audio\" : [ \"-f\" , \"avfoundation\" , \"-audio_device_index\" , \"0\" ]} If audio still doesn't work then reach us out on Gitter \u27b6 Community channel Make sure this -audio audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all. You MUST use -input_framerate attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams. It is advised to use this example with live-streaming enabled(True) by using StreamGear API's exclusive -livestream attribute of stream_params dictionary parameter. DASH HLS # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = \"foo1.mp4\" ) . start () # add various streams, along with custom audio stream_params = { \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"4000k\" , }, # Stream1: 1280x720 at 4000kbs bitrate { \"-resolution\" : \"640x360\" , \"-framerate\" : 30.0 }, # Stream2: 640x360 at 30fps ], \"-input_framerate\" : stream . framerate , # controlled framerate for audio-video sync !!! don't forget this line !!! \"-audio\" : [ \"-f\" , \"dshow\" , \"-i\" , \"audio=Microphone (USB2.0 Camera)\" , ], # assign appropriate input audio-source device and demuxer } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = \"foo1.mp4\" ) . start () # add various streams, along with custom audio stream_params = { \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"4000k\" , }, # Stream1: 1280x720 at 4000kbs bitrate { \"-resolution\" : \"640x360\" , \"-framerate\" : 30.0 }, # Stream2: 640x360 at 30fps ], \"-input_framerate\" : stream . framerate , # controlled framerate for audio-video sync !!! don't forget this line !!! \"-audio\" : [ \"-f\" , \"dshow\" , \"-i\" , \"audio=Microphone (USB2.0 Camera)\" , ], # assign appropriate input audio-source device and demuxer } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.m3u8\" , format = \"hls\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"Usage with Device Audio-Input"},{"location":"gears/streamgear/rtfm/usage/#usage-with-hardware-video-encoder","text":"In Real-time Frames Mode, you can also easily change encoder as per your requirement just by passing -vcodec FFmpeg parameter as an attribute in stream_params dictionary parameter. In addition to this, you can also specify the additional properties/features/optimizations for your system's GPU similarly. In this example, we will be using h264_vaapi as our hardware encoder and also optionally be specifying our device hardware's location (i.e. '-vaapi_device':'/dev/dri/renderD128' ) and other features such as '-vf':'format=nv12,hwupload' like properties by formatting them as option dictionary parameter's attributes, as follows: Check VAAPI support This example is just conveying the idea on how to use FFmpeg's hardware encoders with WriteGear API in Compression mode, which MAY/MAY-NOT suit your system. Kindly use suitable parameters based your supported system and FFmpeg configurations only. To use h264_vaapi encoder, remember to check if its available and your FFmpeg compiled with VAAPI support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: ffmpeg -hide_banner -encoders | grep vaapi V..... h264_vaapi H.264/AVC ( VAAPI ) ( codec h264 ) V..... hevc_vaapi H.265/HEVC ( VAAPI ) ( codec hevc ) V..... mjpeg_vaapi MJPEG ( VAAPI ) ( codec mjpeg ) V..... mpeg2_vaapi MPEG-2 ( VAAPI ) ( codec mpeg2video ) V..... vp8_vaapi VP8 ( VAAPI ) ( codec vp8 ) DASH HLS # import required libraries from vidgear.gears import VideoGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = VideoGear ( source = 0 ) . start () # add various streams with custom Video Encoder and optimizations stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-vcodec\" : \"h264_vaapi\" , # define custom Video encoder \"-vaapi_device\" : \"/dev/dri/renderD128\" , # define device location \"-vf\" : \"format=nv12,hwupload\" , # define video pixformat } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import VideoGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = VideoGear ( source = 0 ) . start () # add various streams with custom Video Encoder and optimizations stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-vcodec\" : \"h264_vaapi\" , # define custom Video encoder \"-vaapi_device\" : \"/dev/dri/renderD128\" , # define device location \"-vf\" : \"format=nv12,hwupload\" , # define video pixformat } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () In Real-time Frames Mode, the Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25fps. \u21a9 \u21a9 \u21a9","title":"Usage with Hardware Video-Encoder"},{"location":"gears/streamgear/ssm/overview/","text":"StreamGear API: Single-Source Mode \u2693 Single-Source Mode generalized workflow Overview \u2693 In this mode, StreamGear transcodes entire audio-video file (as opposed to frames-by-frame) into a sequence of multiple smaller chunks/segments for adaptive streaming. This mode works exceptionally well when you're transcoding long-duration lossless videos(with audio) files for streaming that requires no interruptions. But on the downside, the provided source cannot be flexibly manipulated or transformed before sending onto FFmpeg Pipeline for processing. SteamGear supports both MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) and Apple HLS (HTTP Live Streaming) with this mode. For this mode, StreamGear API provides exclusive transcode_source() method to easily process audio-video files into streamable chunks. This mode can be easily activated by assigning suitable video path as input to -video_source attribute of stream_params dictionary parameter, during StreamGear initialization. \u2003 New in v0.2.2 Apple HLS support was added in v0.2.2 . Warning Using stream() function instead of transcode_source() in Single-Source Mode will instantly result in RuntimeError ! Any invalid value to the -video_source attribute will result in AssertionError ! \u2009 Usage Examples \u2693 See here \ud83d\ude80 After going through StreamGear Usage Examples, Checkout more of its advanced configurations here \u27b6 Parameters \u2693 See here \ud83d\ude80 References \u2693 See here \ud83d\ude80 FAQs \u2693 See here \ud83d\ude80","title":"Overview"},{"location":"gears/streamgear/ssm/overview/#streamgear-api-single-source-mode","text":"Single-Source Mode generalized workflow","title":"StreamGear API: Single-Source Mode"},{"location":"gears/streamgear/ssm/overview/#overview","text":"In this mode, StreamGear transcodes entire audio-video file (as opposed to frames-by-frame) into a sequence of multiple smaller chunks/segments for adaptive streaming. This mode works exceptionally well when you're transcoding long-duration lossless videos(with audio) files for streaming that requires no interruptions. But on the downside, the provided source cannot be flexibly manipulated or transformed before sending onto FFmpeg Pipeline for processing. SteamGear supports both MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) and Apple HLS (HTTP Live Streaming) with this mode. For this mode, StreamGear API provides exclusive transcode_source() method to easily process audio-video files into streamable chunks. This mode can be easily activated by assigning suitable video path as input to -video_source attribute of stream_params dictionary parameter, during StreamGear initialization. \u2003 New in v0.2.2 Apple HLS support was added in v0.2.2 . Warning Using stream() function instead of transcode_source() in Single-Source Mode will instantly result in RuntimeError ! Any invalid value to the -video_source attribute will result in AssertionError !","title":"Overview"},{"location":"gears/streamgear/ssm/overview/#usage-examples","text":"See here \ud83d\ude80 After going through StreamGear Usage Examples, Checkout more of its advanced configurations here \u27b6","title":"Usage Examples"},{"location":"gears/streamgear/ssm/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/streamgear/ssm/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/streamgear/ssm/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/streamgear/ssm/usage/","text":"StreamGear API Usage Examples: Single-Source Mode \u2693 Important Information StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. By default, StreamGear generates a primary stream of same resolution and framerate 1 as the input video (at the index 0 ) . Always use terminate() function at the very end of the main code. After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6 \u2009 Bare-Minimum Usage \u2693 Following is the bare-minimum code you need to get started with StreamGear API in Single-Source Mode: If input video-source (i.e. -video_source ) contains any audio stream/channel, then it automatically gets mapped to all generated streams without any extra efforts. DASH HLS # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode with valid video input stream_params = { \"-video_source\" : \"foo.mp4\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode with valid video input stream_params = { \"-video_source\" : \"foo.mp4\" } # describe a suitable master playlist location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () After running this bare-minimum example, StreamGear will produce a Manifest file ( dash.mpd ) with streamable chunks that contains information about a Primary Stream of same resolution and framerate as the input. \u2009 Bare-Minimum Usage with Live-Streaming \u2693 You can easily activate Low-latency Livestreaming in Single-Source Mode , where chunks will contain information for few new frames only and forgets all previous ones), using exclusive -livestream attribute of stream_params dictionary parameter as follows: Use -window_size & -extra_window_size FFmpeg parameters for controlling number of frames to be kept in Chunks. Less these value, less will be latency. After every few chunks (equal to the sum of -window_size & -extra_window_size values) , all chunks will be overwritten in Live-Streaming. Thereby, since newer chunks in manifest/playlist will contain NO information of any older ones, and therefore resultant DASH/HLS stream will play only the most recent frames. If input video-source (i.e. -video_source ) contains any audio stream/channel, then it automatically gets mapped to all generated streams without any extra efforts. DASH HLS # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode with valid video input and enable livestreaming stream_params = { \"-video_source\" : 0 , \"-livestream\" : True } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode with valid video input and enable livestreaming stream_params = { \"-video_source\" : 0 , \"-livestream\" : True } # describe a suitable master playlist location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () \u2009 Usage with Additional Streams \u2693 In addition to Primary Stream, you can easily generate any number of additional Secondary Streams of variable bitrates or spatial resolutions, using exclusive -streams attribute of stream_params dictionary parameter. You just need to add each resolution and bitrate/framerate as list of dictionaries to this attribute, and rest is done automatically. A more detailed information on -streams attribute can be found here \u27b6 The complete example is as follows: If input video-source contains any audio stream/channel, then it automatically gets assigned to all generated streams without any extra efforts. Important -streams attribute Information On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate as the input, at the index 0 . Make sure your System/Machine/Server/Network is able to handle these additional streams, discretion is advised! You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. Always use -stream attribute to define additional streams safely, any duplicate or incorrect definition can break things! DASH HLS # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and also define various streams stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and also define various streams stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable master playlist location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () \u2009 Usage with Custom Audio \u2693 By default, if input video-source (i.e. -video_source ) contains any audio, then it gets automatically mapped to all generated streams. But, if you want to add any custom audio, you can easily do it by using exclusive -audio attribute of stream_params dictionary parameter. You just need to input the path of your audio file to this attribute as string , and the API will automatically validate as well as map it to all generated streams. The complete example is as follows: Make sure this -audio audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all. You can also assign a valid Audio URL as input, rather than filepath. More details can be found here \u27b6 DASH HLS # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various streams, along with custom audio stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various streams, along with custom audio stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable master playlist location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () \u2009 Usage with Variable FFmpeg Parameters \u2693 For seamlessly generating these streaming assets, StreamGear provides a highly extensible and flexible wrapper around FFmpeg and access to almost all of its parameter. Thereby, you can access almost any parameter available with FFmpeg itself as dictionary attributes in stream_params dictionary parameter , and use it to manipulate transcoding as you like. For this example, let us use our own H.265/HEVC video and AAC audio encoder, and set custom audio bitrate, and various other optimizations: This example is just conveying the idea on how to use FFmpeg's encoders/parameters with StreamGear API. You can use any FFmpeg parameter in the similar manner. Kindly read FFmpeg Docs carefully, before passing any FFmpeg values to stream_params parameter. Wrong values may result in undesired errors or no output at all. Always use -streams attribute to define additional streams safely, any duplicate or incorrect stream definition can break things! DASH HLS # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various other parameters stream_params = { \"-video_source\" : \"foo.mp4\" , # define Video-Source \"-vcodec\" : \"libx265\" , # assigns H.265/HEVC video encoder \"-x265-params\" : \"lossless=1\" , # enables Lossless encoding \"-crf\" : 25 , # Constant Rate Factor: 25 \"-bpp\" : \"0.15\" , # Bits-Per-Pixel(BPP), an Internal StreamGear parameter to ensure good quality of high motion scenes \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1280x720 at 4000kbs bitrate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream2: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" , # define input audio-source: \"/home/foo/foo1.aac\", \"-acodec\" : \"libfdk_aac\" , # assign lossless AAC audio encoder \"-vbr\" : 4 , # Variable Bit Rate: `4` } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , logging = True , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various other parameters stream_params = { \"-video_source\" : \"foo.mp4\" , # define Video-Source \"-vcodec\" : \"libx265\" , # assigns H.265/HEVC video encoder \"-x265-params\" : \"lossless=1\" , # enables Lossless encoding \"-crf\" : 25 , # Constant Rate Factor: 25 \"-bpp\" : \"0.15\" , # Bits-Per-Pixel(BPP), an Internal StreamGear parameter to ensure good quality of high motion scenes \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1280x720 at 4000kbs bitrate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream2: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" , # define input audio-source: \"/home/foo/foo1.aac\", \"-acodec\" : \"libfdk_aac\" , # assign lossless AAC audio encoder \"-vbr\" : 4 , # Variable Bit Rate: `4` } # describe a suitable master playlist file location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , logging = True , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () In Real-time Frames Mode, the Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25fps. \u21a9","title":"Usage Examples"},{"location":"gears/streamgear/ssm/usage/#streamgear-api-usage-examples-single-source-mode","text":"Important Information StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. By default, StreamGear generates a primary stream of same resolution and framerate 1 as the input video (at the index 0 ) . Always use terminate() function at the very end of the main code. After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6","title":"StreamGear API Usage Examples: Single-Source Mode"},{"location":"gears/streamgear/ssm/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with StreamGear API in Single-Source Mode: If input video-source (i.e. -video_source ) contains any audio stream/channel, then it automatically gets mapped to all generated streams without any extra efforts. DASH HLS # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode with valid video input stream_params = { \"-video_source\" : \"foo.mp4\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode with valid video input stream_params = { \"-video_source\" : \"foo.mp4\" } # describe a suitable master playlist location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () After running this bare-minimum example, StreamGear will produce a Manifest file ( dash.mpd ) with streamable chunks that contains information about a Primary Stream of same resolution and framerate as the input.","title":"Bare-Minimum Usage"},{"location":"gears/streamgear/ssm/usage/#bare-minimum-usage-with-live-streaming","text":"You can easily activate Low-latency Livestreaming in Single-Source Mode , where chunks will contain information for few new frames only and forgets all previous ones), using exclusive -livestream attribute of stream_params dictionary parameter as follows: Use -window_size & -extra_window_size FFmpeg parameters for controlling number of frames to be kept in Chunks. Less these value, less will be latency. After every few chunks (equal to the sum of -window_size & -extra_window_size values) , all chunks will be overwritten in Live-Streaming. Thereby, since newer chunks in manifest/playlist will contain NO information of any older ones, and therefore resultant DASH/HLS stream will play only the most recent frames. If input video-source (i.e. -video_source ) contains any audio stream/channel, then it automatically gets mapped to all generated streams without any extra efforts. DASH HLS # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode with valid video input and enable livestreaming stream_params = { \"-video_source\" : 0 , \"-livestream\" : True } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode with valid video input and enable livestreaming stream_params = { \"-video_source\" : 0 , \"-livestream\" : True } # describe a suitable master playlist location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate ()","title":"Bare-Minimum Usage with Live-Streaming"},{"location":"gears/streamgear/ssm/usage/#usage-with-additional-streams","text":"In addition to Primary Stream, you can easily generate any number of additional Secondary Streams of variable bitrates or spatial resolutions, using exclusive -streams attribute of stream_params dictionary parameter. You just need to add each resolution and bitrate/framerate as list of dictionaries to this attribute, and rest is done automatically. A more detailed information on -streams attribute can be found here \u27b6 The complete example is as follows: If input video-source contains any audio stream/channel, then it automatically gets assigned to all generated streams without any extra efforts. Important -streams attribute Information On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate as the input, at the index 0 . Make sure your System/Machine/Server/Network is able to handle these additional streams, discretion is advised! You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. Always use -stream attribute to define additional streams safely, any duplicate or incorrect definition can break things! DASH HLS # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and also define various streams stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and also define various streams stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable master playlist location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate ()","title":"Usage with Additional Streams"},{"location":"gears/streamgear/ssm/usage/#usage-with-custom-audio","text":"By default, if input video-source (i.e. -video_source ) contains any audio, then it gets automatically mapped to all generated streams. But, if you want to add any custom audio, you can easily do it by using exclusive -audio attribute of stream_params dictionary parameter. You just need to input the path of your audio file to this attribute as string , and the API will automatically validate as well as map it to all generated streams. The complete example is as follows: Make sure this -audio audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all. You can also assign a valid Audio URL as input, rather than filepath. More details can be found here \u27b6 DASH HLS # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various streams, along with custom audio stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various streams, along with custom audio stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable master playlist location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate ()","title":"Usage with Custom Audio"},{"location":"gears/streamgear/ssm/usage/#usage-with-variable-ffmpeg-parameters","text":"For seamlessly generating these streaming assets, StreamGear provides a highly extensible and flexible wrapper around FFmpeg and access to almost all of its parameter. Thereby, you can access almost any parameter available with FFmpeg itself as dictionary attributes in stream_params dictionary parameter , and use it to manipulate transcoding as you like. For this example, let us use our own H.265/HEVC video and AAC audio encoder, and set custom audio bitrate, and various other optimizations: This example is just conveying the idea on how to use FFmpeg's encoders/parameters with StreamGear API. You can use any FFmpeg parameter in the similar manner. Kindly read FFmpeg Docs carefully, before passing any FFmpeg values to stream_params parameter. Wrong values may result in undesired errors or no output at all. Always use -streams attribute to define additional streams safely, any duplicate or incorrect stream definition can break things! DASH HLS # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various other parameters stream_params = { \"-video_source\" : \"foo.mp4\" , # define Video-Source \"-vcodec\" : \"libx265\" , # assigns H.265/HEVC video encoder \"-x265-params\" : \"lossless=1\" , # enables Lossless encoding \"-crf\" : 25 , # Constant Rate Factor: 25 \"-bpp\" : \"0.15\" , # Bits-Per-Pixel(BPP), an Internal StreamGear parameter to ensure good quality of high motion scenes \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1280x720 at 4000kbs bitrate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream2: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" , # define input audio-source: \"/home/foo/foo1.aac\", \"-acodec\" : \"libfdk_aac\" , # assign lossless AAC audio encoder \"-vbr\" : 4 , # Variable Bit Rate: `4` } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , logging = True , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various other parameters stream_params = { \"-video_source\" : \"foo.mp4\" , # define Video-Source \"-vcodec\" : \"libx265\" , # assigns H.265/HEVC video encoder \"-x265-params\" : \"lossless=1\" , # enables Lossless encoding \"-crf\" : 25 , # Constant Rate Factor: 25 \"-bpp\" : \"0.15\" , # Bits-Per-Pixel(BPP), an Internal StreamGear parameter to ensure good quality of high motion scenes \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1280x720 at 4000kbs bitrate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream2: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" , # define input audio-source: \"/home/foo/foo1.aac\", \"-acodec\" : \"libfdk_aac\" , # assign lossless AAC audio encoder \"-vbr\" : 4 , # Variable Bit Rate: `4` } # describe a suitable master playlist file location/name and assign params streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , logging = True , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () In Real-time Frames Mode, the Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25fps. \u21a9","title":"Usage with Variable FFmpeg Parameters"},{"location":"gears/videogear/overview/","text":"VideoGear API \u2693 VideoGear API's generalized workflow Overview \u2693 VideoGear API provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. VideoGear also acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and their parameters with an exclusive enablePiCamera boolean flag. VideoGear is ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and writing way fewer lines of code. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. \u2009 Importing \u2693 You can import VideoGear API in your program as follows: from vidgear.gears import VideoGear \u2009 Usage Examples \u2693 See here \ud83d\ude80 After going through VideoGear Usage Examples, Checkout more of its advanced configurations here \u27b6 Parameters \u2693 See here \ud83d\ude80 References \u2693 See here \ud83d\ude80 FAQs \u2693 See here \ud83d\ude80","title":"Overview"},{"location":"gears/videogear/overview/#videogear-api","text":"VideoGear API's generalized workflow","title":"VideoGear API"},{"location":"gears/videogear/overview/#overview","text":"VideoGear API provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. VideoGear also acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and their parameters with an exclusive enablePiCamera boolean flag. VideoGear is ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and writing way fewer lines of code. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/videogear/overview/#importing","text":"You can import VideoGear API in your program as follows: from vidgear.gears import VideoGear","title":"Importing"},{"location":"gears/videogear/overview/#usage-examples","text":"See here \ud83d\ude80 After going through VideoGear Usage Examples, Checkout more of its advanced configurations here \u27b6","title":"Usage Examples"},{"location":"gears/videogear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/videogear/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/videogear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/videogear/params/","text":"VideoGear API Parameters \u2693 VideoGear acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and their parameters. \u2009 enablePiCamera \u2693 This parameter provide direct access to PiGear or CamGear APIs respectively in VideoGear. This means the if enablePiCamera flag is True , the PiGear API will be accessed, and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 . Parameters for Stabilizer Backend \u2693 Enable this backend with stabilize=True in VideoGear. stabilize \u2693 This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to True ( to enable ) or unset to False ( to disable ). Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 . options \u2693 This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be formatted as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' } Parameters for CamGear backend \u2693 Enable this backend with enablePiCamera=False in VideoGear. Default is also False . source \u2693 VideoGear API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: VideoGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: VideoGear ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) CamGear internally implements yt_dlp backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows: Supported Streaming Websites The list of all supported Streaming Websites URLs can be found here \u27b6 CamGear ( source = 'https://www.twitch.tv/shroud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: VideoGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: VideoGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' ) stream_mode \u2693 This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the VideoGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend ( backend=cv2.CAP_GSTREAMER ) for any livestreams (such as Twitch) . VideoGear automatically enforce GStreamer backend (backend= cv2.CAP_GSTREAMER ) for YouTube-livestreams! VideoGear will exit with RuntimeError for YouTube livestreams, if OpenCV is not compiled with GStreamer( >=v1.0.0 ) support. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 . backend \u2693 This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: VideoGear ( source = 0 , backend = cv2 . CAP_DSHOW ) options \u2693 This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to VideoGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it VideoGear ( source = 0 , ** options ) Parameters for PiGear backend \u2693 Enable this backend with enablePiCamera=True in VideoGear. camera_num \u2693 This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: VideoGear ( enablePiCamera = True , camera_num = 0 ) resolution \u2693 This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: VideoGear ( enablePiCamera = True , resolution = ( 1280 , 720 )) # sets 1280x720 resolution framerate \u2693 This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: VideoGear ( enablePiCamera = True , framerate = 60 ) # sets 60fps framerate options \u2693 This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to VideoGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it VideoGear ( enablePiCamera = True , logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds Common Parameters \u2693 These are common parameters that works with every backend in VideoGear. colorspace \u2693 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 VideoGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 logging \u2693 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( logging = True ) time_delay \u2693 This parameter set the time delay (in seconds) before the VideoGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: VideoGear ( time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/videogear/params/#videogear-api-parameters","text":"VideoGear acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and their parameters.","title":"VideoGear API Parameters"},{"location":"gears/videogear/params/#enablepicamera","text":"This parameter provide direct access to PiGear or CamGear APIs respectively in VideoGear. This means the if enablePiCamera flag is True , the PiGear API will be accessed, and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 .","title":"enablePiCamera"},{"location":"gears/videogear/params/#parameters-for-stabilizer-backend","text":"Enable this backend with stabilize=True in VideoGear.","title":"Parameters for Stabilizer Backend"},{"location":"gears/videogear/params/#stabilize","text":"This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to True ( to enable ) or unset to False ( to disable ). Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 .","title":"stabilize"},{"location":"gears/videogear/params/#options","text":"This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be formatted as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' }","title":"options"},{"location":"gears/videogear/params/#parameters-for-camgear-backend","text":"Enable this backend with enablePiCamera=False in VideoGear. Default is also False .","title":"Parameters for CamGear backend"},{"location":"gears/videogear/params/#source","text":"VideoGear API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: VideoGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: VideoGear ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) CamGear internally implements yt_dlp backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows: Supported Streaming Websites The list of all supported Streaming Websites URLs can be found here \u27b6 CamGear ( source = 'https://www.twitch.tv/shroud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: VideoGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: VideoGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' )","title":"source"},{"location":"gears/videogear/params/#stream_mode","text":"This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the VideoGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend ( backend=cv2.CAP_GSTREAMER ) for any livestreams (such as Twitch) . VideoGear automatically enforce GStreamer backend (backend= cv2.CAP_GSTREAMER ) for YouTube-livestreams! VideoGear will exit with RuntimeError for YouTube livestreams, if OpenCV is not compiled with GStreamer( >=v1.0.0 ) support. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 .","title":"stream_mode"},{"location":"gears/videogear/params/#backend","text":"This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: VideoGear ( source = 0 , backend = cv2 . CAP_DSHOW )","title":"backend"},{"location":"gears/videogear/params/#options_1","text":"This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to VideoGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it VideoGear ( source = 0 , ** options )","title":"options"},{"location":"gears/videogear/params/#parameters-for-pigear-backend","text":"Enable this backend with enablePiCamera=True in VideoGear.","title":"Parameters for PiGear backend"},{"location":"gears/videogear/params/#camera_num","text":"This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: VideoGear ( enablePiCamera = True , camera_num = 0 )","title":"camera_num"},{"location":"gears/videogear/params/#resolution","text":"This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: VideoGear ( enablePiCamera = True , resolution = ( 1280 , 720 )) # sets 1280x720 resolution","title":"resolution"},{"location":"gears/videogear/params/#framerate","text":"This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: VideoGear ( enablePiCamera = True , framerate = 60 ) # sets 60fps framerate","title":"framerate"},{"location":"gears/videogear/params/#options_2","text":"This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to VideoGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it VideoGear ( enablePiCamera = True , logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds","title":"options"},{"location":"gears/videogear/params/#common-parameters","text":"These are common parameters that works with every backend in VideoGear.","title":"Common Parameters"},{"location":"gears/videogear/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 VideoGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/videogear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( logging = True )","title":"logging"},{"location":"gears/videogear/params/#time_delay","text":"This parameter set the time delay (in seconds) before the VideoGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: VideoGear ( time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/videogear/usage/","text":"VideoGear API Usage Examples: \u2693 After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6 \u2009 Bare-Minimum Usage with CamGear backend \u2693 VideoGear by default provides direct internal access to CamGear API . Following is the bare-minimum code you need to access CamGear API with VideoGear: # import required libraries from vidgear.gears import VideoGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = VideoGear ( source = \"myvideo.avi\" ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Bare-Minimum Usage with PiGear backend \u2693 VideoGear contains a special enablePiCamera flag that when True provides internal access to PiGear API . Following is the bare-minimum code you need to access PiGear API with VideoGear: Make sure to enable Raspberry Pi hardware-specific settings prior using PiGear Backend, otherwise nothing will work. # import required libraries from vidgear.gears import VideoGear import cv2 # enable enablePiCamera boolean flag to access PiGear API backend stream = VideoGear ( enablePiCamera = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using VideoGear with Video Stabilizer backend \u2693 VideoGear API provides a special internal wrapper around VidGear's Exclusive Video Stabilizer class and provides easy way of activating stabilization for various video-streams (real-time or not) with its stabilize boolean parameter during initialization. The usage example is as follows: For a more detailed information on Video-Stabilizer Class, Read here \u27b6 The stabilizer might be slower for High-Quality/Resolution videos-frames. # import required libraries from vidgear.gears import VideoGear import numpy as np import cv2 # open any valid video stream with stabilization enabled(`stabilize = True`) stream_stab = VideoGear ( source = \"test.mp4\" , stabilize = True ) . start () # loop over while True : # read stabilized frames frame_stab = stream_stab . read () # check for stabilized frame if None-type if frame_stab is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Stabilized Output\" , frame_stab ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close streams stream_stab . stop () Advanced VideoGear usage with CamGear Backend \u2693 VideoGear provides internal access to both CamGear and PiGear APIs, and thereby all additional parameters of PiGear API or CamGear API are also easily accessible within VideoGear API. The usage example of VideoGear API with Variable Camera Properties is as follows: Info This example is basically a VideoGear API implementation of this CamGear usage example for controlling its properties (such as its brightness, saturation, resolution, framerate, gain etc.) . Thereby, any CamGear or PiGear usage examples can be implemented with VideoGear API in the similar manner. All the supported Source Tweak Parameters can be found here \u27b6 # import required libraries from vidgear.gears import VideoGear import cv2 # define suitable tweak parameters for your stream. options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , # resolution 320x240 \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 , # framerate 60fps } # To open live video stream on webcam at first index(i.e. 0) # device and apply source tweak parameters stream = VideoGear ( source = 0 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Advanced VideoGear usage with PiGear Backend \u2693 VideoGear provides internal access to both CamGear and PiGear APIs, and thereby all additional parameters of PiGear API or CamGear API are also easily accessible within VideoGear API. The usage example of VideoGear API with Variable PiCamera Properties is as follows: Info This example is basically a VideoGear API implementation of this PiGear usage example . Thereby, any CamGear or PiGear usage examples can be implemented with VideoGear API in the similar manner. Make sure to enable Raspberry Pi hardware-specific settings prior using PiGear Backend, otherwise nothing will work. # import required libraries from vidgear.gears import VideoGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # activate enablePiCamera and open pi video stream with defined parameters stream = VideoGear ( enablePiCamera = True , resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using VideoGear with Colorspace Manipulation \u2693 VideoGear API also supports Colorspace Manipulation but NOT Direct like other VideoCapture Gears. Important color_space global variable is NOT Supported in VideoGear API, calling it will result in AttribueError . More details can be found here \u27b6 Any incorrect or None-type value on colorspace parameter will be skipped automatically. In following example code, we will convert source colorspace to HSV on initialization: # import required libraries from vidgear.gears import VideoGear import cv2 # Open any source of your choice, like Webcam first index(i.e. 0) and change its colorspace to `HSV` stream = VideoGear ( source = 0 , colorspace = \"COLOR_BGR2HSV\" , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Bonus Examples \u2693 Checkout more advanced VideoGear examples with unusual configuration here \u27b6","title":"Usage Examples"},{"location":"gears/videogear/usage/#videogear-api-usage-examples","text":"After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6","title":"VideoGear API Usage Examples:"},{"location":"gears/videogear/usage/#bare-minimum-usage-with-camgear-backend","text":"VideoGear by default provides direct internal access to CamGear API . Following is the bare-minimum code you need to access CamGear API with VideoGear: # import required libraries from vidgear.gears import VideoGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = VideoGear ( source = \"myvideo.avi\" ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage with CamGear backend"},{"location":"gears/videogear/usage/#bare-minimum-usage-with-pigear-backend","text":"VideoGear contains a special enablePiCamera flag that when True provides internal access to PiGear API . Following is the bare-minimum code you need to access PiGear API with VideoGear: Make sure to enable Raspberry Pi hardware-specific settings prior using PiGear Backend, otherwise nothing will work. # import required libraries from vidgear.gears import VideoGear import cv2 # enable enablePiCamera boolean flag to access PiGear API backend stream = VideoGear ( enablePiCamera = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage with PiGear backend"},{"location":"gears/videogear/usage/#using-videogear-with-video-stabilizer-backend","text":"VideoGear API provides a special internal wrapper around VidGear's Exclusive Video Stabilizer class and provides easy way of activating stabilization for various video-streams (real-time or not) with its stabilize boolean parameter during initialization. The usage example is as follows: For a more detailed information on Video-Stabilizer Class, Read here \u27b6 The stabilizer might be slower for High-Quality/Resolution videos-frames. # import required libraries from vidgear.gears import VideoGear import numpy as np import cv2 # open any valid video stream with stabilization enabled(`stabilize = True`) stream_stab = VideoGear ( source = \"test.mp4\" , stabilize = True ) . start () # loop over while True : # read stabilized frames frame_stab = stream_stab . read () # check for stabilized frame if None-type if frame_stab is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Stabilized Output\" , frame_stab ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close streams stream_stab . stop ()","title":"Using VideoGear with Video Stabilizer backend"},{"location":"gears/videogear/usage/#advanced-videogear-usage-with-camgear-backend","text":"VideoGear provides internal access to both CamGear and PiGear APIs, and thereby all additional parameters of PiGear API or CamGear API are also easily accessible within VideoGear API. The usage example of VideoGear API with Variable Camera Properties is as follows: Info This example is basically a VideoGear API implementation of this CamGear usage example for controlling its properties (such as its brightness, saturation, resolution, framerate, gain etc.) . Thereby, any CamGear or PiGear usage examples can be implemented with VideoGear API in the similar manner. All the supported Source Tweak Parameters can be found here \u27b6 # import required libraries from vidgear.gears import VideoGear import cv2 # define suitable tweak parameters for your stream. options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , # resolution 320x240 \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 , # framerate 60fps } # To open live video stream on webcam at first index(i.e. 0) # device and apply source tweak parameters stream = VideoGear ( source = 0 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Advanced VideoGear usage with CamGear Backend"},{"location":"gears/videogear/usage/#advanced-videogear-usage-with-pigear-backend","text":"VideoGear provides internal access to both CamGear and PiGear APIs, and thereby all additional parameters of PiGear API or CamGear API are also easily accessible within VideoGear API. The usage example of VideoGear API with Variable PiCamera Properties is as follows: Info This example is basically a VideoGear API implementation of this PiGear usage example . Thereby, any CamGear or PiGear usage examples can be implemented with VideoGear API in the similar manner. Make sure to enable Raspberry Pi hardware-specific settings prior using PiGear Backend, otherwise nothing will work. # import required libraries from vidgear.gears import VideoGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # activate enablePiCamera and open pi video stream with defined parameters stream = VideoGear ( enablePiCamera = True , resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Advanced VideoGear usage with PiGear Backend"},{"location":"gears/videogear/usage/#using-videogear-with-colorspace-manipulation","text":"VideoGear API also supports Colorspace Manipulation but NOT Direct like other VideoCapture Gears. Important color_space global variable is NOT Supported in VideoGear API, calling it will result in AttribueError . More details can be found here \u27b6 Any incorrect or None-type value on colorspace parameter will be skipped automatically. In following example code, we will convert source colorspace to HSV on initialization: # import required libraries from vidgear.gears import VideoGear import cv2 # Open any source of your choice, like Webcam first index(i.e. 0) and change its colorspace to `HSV` stream = VideoGear ( source = 0 , colorspace = \"COLOR_BGR2HSV\" , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using VideoGear with Colorspace Manipulation"},{"location":"gears/videogear/usage/#bonus-examples","text":"Checkout more advanced VideoGear examples with unusual configuration here \u27b6","title":"Bonus Examples"},{"location":"gears/webgear/advanced/","text":"WebGear API Advanced Usage: \u2693 This is a continuation of the WebGear doc \u27b6 . Thereby, It's advised to first get familiarize with this API, and its requirements . After going through following Usage Examples, Checkout more bonus examples here \u27b6 \u2009 Using WebGear with Variable Colorspace \u2693 WebGear by default only supports \"BGR\" colorspace frames as input, but you can use jpeg_compression_colorspace string attribute through its options dictionary parameter to specify incoming frames colorspace. Let's implement a bare-minimum example using WebGear, where we will be sending GRAY frames to client browser: New in v0.2.2 This example was added in v0.2.2 . This example works in conjunction with Source ColorSpace manipulation for VideoCapture Gears \u27b6 Supported jpeg_compression_colorspace colorspace values are RGB , BGR , RGBX , BGRX , XBGR , XRGB , GRAY , RGBA , BGRA , ABGR , ARGB , CMYK . More information can be found here \u27b6 # import required libraries import uvicorn from vidgear.gears.asyncio import WebGear # various performance tweaks and enable grayscale input options = { \"frame_size_reduction\" : 25 , \"jpeg_compression_colorspace\" : \"GRAY\" , # set grayscale \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # initialize WebGear app and change its colorspace to grayscale web = WebGear ( source = \"foo.mp4\" , colorspace = \"COLOR_BGR2GRAY\" , logging = True , ** options ) # run this app on Uvicorn server at address http://0.0.0.0:8000/ uvicorn . run ( web (), host = \"0.0.0.0\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/ address on your local machine. \u2009 Using WebGear with a Custom Source(OpenCV) \u2693 New in v0.2.1 This example was added in v0.2.1 . WebGear allows you to easily define your own custom Source that you want to use to transform your frames before sending them onto the browser. JPEG Frame-Compression and all of its performance enhancing attributes are disabled with a Custom Source! Let's implement a bare-minimum example with a Custom Source using WebGear API and OpenCV: # import necessary libs import uvicorn , asyncio , cv2 from vidgear.gears.asyncio import WebGear from vidgear.gears.asyncio.helper import reducer # initialize WebGear app without any source web = WebGear ( logging = True ) # create your own custom frame producer async def my_frame_producer (): # !!! define your own video source here !!! # Open any video stream such as live webcam # video stream on first index(i.e. 0) device stream = cv2 . VideoCapture ( 0 ) # loop over frames while True : # read frame from provided source ( grabbed , frame ) = stream . read () # break if NoneType if not grabbed : break # do something with your OpenCV frame here # reducer frames size if you want more performance otherwise comment this line frame = await reducer ( frame , percentage = 30 , interpolation = cv2 . INTER_AREA ) # reduce frame by 30% # handle JPEG encoding encodedImage = cv2 . imencode ( \".jpg\" , frame )[ 1 ] . tobytes () # yield frame in byte format yield ( b \"--frame \\r\\n Content-Type:image/jpeg \\r\\n\\r\\n \" + encodedImage + b \" \\r\\n \" ) await asyncio . sleep ( 0 ) # close stream stream . release () # add your custom frame producer to config web . config [ \"generator\" ] = my_frame_producer # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/ address. Using WebGear with Custom Mounting Points \u2693 With our highly extensible WebGear API, you can add your own mounting points, where additional files located, as follows: # import libs import uvicorn from starlette.routing import Mount from starlette.staticfiles import StaticFiles from vidgear.gears.asyncio import WebGear # various performance tweaks options = { \"frame_size_reduction\" : 40 , \"jpeg_compression_quality\" : 80 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : False , } # initialize WebGear app web = WebGear ( source = \"foo.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # append new route i.e. mount another folder called `test` located at `/home/foo/.vidgear/test` directory web . routes . append ( Mount ( \"/test\" , app = StaticFiles ( directory = \"/home/foo/.vidgear/test\" ), name = \"test\" ) ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () Then you can use this folder in your HTML page, to host data-files. For example, if we have jQuery script jquery-3.3.1.slim.min.js in this folder and want to integrate it, then, we can do something like this: < script src = \"{{ url_for('test', path='jquery-3.3.1.slim.min.js') }}\" ></ script > Using WebGear with Custom Webpage Routes \u2693 With Webgear's flexible API, you can even add your additional HTML Static webpages without any extra efforts. Suppose we want to add a simple hello world webpage to our WebGear server. So let's create a bare-minimum hello.html file with HTML code as follows: < html > < header > < title > This is Hello world page </ title > </ header > < body > < h1 > Hello World </ h1 > < p > how ya doing? </ p > </ body > </ html > Then in our application code, we can integrate this webpage route, as follows: # import libs import uvicorn , asyncio from starlette.templating import Jinja2Templates from starlette.routing import Route from vidgear.gears.asyncio import WebGear # Build out Jinja2 template render at `/home/foo/.vidgear/custom_template` path in which our `hello.html` file is located template = Jinja2Templates ( directory = \"/home/foo/.vidgear/custom_template\" ) # render and return our webpage template async def hello_world ( request ): page = \"hello.html\" context = { \"request\" : request } return template . TemplateResponse ( page , context ) # add various performance tweaks as usual options = { \"frame_size_reduction\" : 40 , \"jpeg_compression_quality\" : 80 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : False , } # initialize WebGear app with a valid source web = WebGear ( source = \"/home/foo/foo1.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # append new route to point our rendered webpage web . routes . append ( Route ( \"/hello\" , endpoint = hello_world )) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/hello address. Using WebGear with MiddleWares \u2693 WebGear natively supports ASGI middleware classes with Starlette for implementing behavior that is applied across your entire ASGI application easily. New in v0.2.2 This example was added in v0.2.2 . All supported middlewares can be found here \u27b6 For this example, let's use CORSMiddleware for implementing appropriate CORS headers to outgoing responses in our application in order to allow cross-origin requests from browsers, as follows: The default parameters used by the CORSMiddleware implementation are restrictive by default, so you'll need to explicitly enable particular origins, methods, or headers, in order for browsers to be permitted to use them in a Cross-Domain context. Starlette provides several arguments for enabling origins, methods, or headers for CORSMiddleware API. More information can be found here \u27b6 # import libs import uvicorn , asyncio from starlette.middleware import Middleware from starlette.middleware.cors import CORSMiddleware from vidgear.gears.asyncio import WebGear # add various performance tweaks as usual options = { \"frame_size_reduction\" : 40 , \"jpeg_compression_quality\" : 80 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : False , } # initialize WebGear app with a valid source web = WebGear ( source = \"/home/foo/foo1.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # define and assign suitable cors middlewares web . middleware = [ Middleware ( CORSMiddleware , allow_origins = [ \"*\" ], allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) ] # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000 address. Rules for Altering WebGear Files and Folders \u2693 WebGear gives us complete freedom of altering data files generated in Auto-Generation Process , But you've to keep the following rules in mind: Rules for Altering Data Files \u2693 You allowed to alter/change code in all existing default downloaded files at your convenience without any restrictions. You allowed to delete/rename all existing data files, except remember NOT to delete/rename three critical data-files (i.e index.html , 404.html & 500.html ) present in templates folder inside the webgear directory at the default location , otherwise, it will trigger Auto-generation process , and it will overwrite the existing files with Server ones. You're allowed to add your own additional .html , .css , .js , etc. files in the respective folders at the default location and custom mounted Data folders . Rules for Altering Data Folders \u2693 You're allowed to add/mount any number of additional folder as shown in this example above . You're allowed to delete/rename existing folders at the default location except remember NOT to delete/rename templates folder in the webgear directory where critical data-files (i.e index.html , 404.html & 500.html ) are located, otherwise, it will trigger Auto-generation process . Bonus Examples \u2693 Checkout more advanced WebGear examples with unusual configuration here \u27b6","title":"Advanced Usages"},{"location":"gears/webgear/advanced/#webgear-api-advanced-usage","text":"This is a continuation of the WebGear doc \u27b6 . Thereby, It's advised to first get familiarize with this API, and its requirements . After going through following Usage Examples, Checkout more bonus examples here \u27b6","title":"WebGear API Advanced Usage:"},{"location":"gears/webgear/advanced/#using-webgear-with-variable-colorspace","text":"WebGear by default only supports \"BGR\" colorspace frames as input, but you can use jpeg_compression_colorspace string attribute through its options dictionary parameter to specify incoming frames colorspace. Let's implement a bare-minimum example using WebGear, where we will be sending GRAY frames to client browser: New in v0.2.2 This example was added in v0.2.2 . This example works in conjunction with Source ColorSpace manipulation for VideoCapture Gears \u27b6 Supported jpeg_compression_colorspace colorspace values are RGB , BGR , RGBX , BGRX , XBGR , XRGB , GRAY , RGBA , BGRA , ABGR , ARGB , CMYK . More information can be found here \u27b6 # import required libraries import uvicorn from vidgear.gears.asyncio import WebGear # various performance tweaks and enable grayscale input options = { \"frame_size_reduction\" : 25 , \"jpeg_compression_colorspace\" : \"GRAY\" , # set grayscale \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # initialize WebGear app and change its colorspace to grayscale web = WebGear ( source = \"foo.mp4\" , colorspace = \"COLOR_BGR2GRAY\" , logging = True , ** options ) # run this app on Uvicorn server at address http://0.0.0.0:8000/ uvicorn . run ( web (), host = \"0.0.0.0\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/ address on your local machine.","title":"Using WebGear with Variable Colorspace"},{"location":"gears/webgear/advanced/#using-webgear-with-a-custom-sourceopencv","text":"New in v0.2.1 This example was added in v0.2.1 . WebGear allows you to easily define your own custom Source that you want to use to transform your frames before sending them onto the browser. JPEG Frame-Compression and all of its performance enhancing attributes are disabled with a Custom Source! Let's implement a bare-minimum example with a Custom Source using WebGear API and OpenCV: # import necessary libs import uvicorn , asyncio , cv2 from vidgear.gears.asyncio import WebGear from vidgear.gears.asyncio.helper import reducer # initialize WebGear app without any source web = WebGear ( logging = True ) # create your own custom frame producer async def my_frame_producer (): # !!! define your own video source here !!! # Open any video stream such as live webcam # video stream on first index(i.e. 0) device stream = cv2 . VideoCapture ( 0 ) # loop over frames while True : # read frame from provided source ( grabbed , frame ) = stream . read () # break if NoneType if not grabbed : break # do something with your OpenCV frame here # reducer frames size if you want more performance otherwise comment this line frame = await reducer ( frame , percentage = 30 , interpolation = cv2 . INTER_AREA ) # reduce frame by 30% # handle JPEG encoding encodedImage = cv2 . imencode ( \".jpg\" , frame )[ 1 ] . tobytes () # yield frame in byte format yield ( b \"--frame \\r\\n Content-Type:image/jpeg \\r\\n\\r\\n \" + encodedImage + b \" \\r\\n \" ) await asyncio . sleep ( 0 ) # close stream stream . release () # add your custom frame producer to config web . config [ \"generator\" ] = my_frame_producer # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/ address.","title":"Using WebGear with a Custom Source(OpenCV)"},{"location":"gears/webgear/advanced/#using-webgear-with-custom-mounting-points","text":"With our highly extensible WebGear API, you can add your own mounting points, where additional files located, as follows: # import libs import uvicorn from starlette.routing import Mount from starlette.staticfiles import StaticFiles from vidgear.gears.asyncio import WebGear # various performance tweaks options = { \"frame_size_reduction\" : 40 , \"jpeg_compression_quality\" : 80 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : False , } # initialize WebGear app web = WebGear ( source = \"foo.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # append new route i.e. mount another folder called `test` located at `/home/foo/.vidgear/test` directory web . routes . append ( Mount ( \"/test\" , app = StaticFiles ( directory = \"/home/foo/.vidgear/test\" ), name = \"test\" ) ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () Then you can use this folder in your HTML page, to host data-files. For example, if we have jQuery script jquery-3.3.1.slim.min.js in this folder and want to integrate it, then, we can do something like this: < script src = \"{{ url_for('test', path='jquery-3.3.1.slim.min.js') }}\" ></ script >","title":"Using WebGear with Custom Mounting Points"},{"location":"gears/webgear/advanced/#using-webgear-with-custom-webpage-routes","text":"With Webgear's flexible API, you can even add your additional HTML Static webpages without any extra efforts. Suppose we want to add a simple hello world webpage to our WebGear server. So let's create a bare-minimum hello.html file with HTML code as follows: < html > < header > < title > This is Hello world page </ title > </ header > < body > < h1 > Hello World </ h1 > < p > how ya doing? </ p > </ body > </ html > Then in our application code, we can integrate this webpage route, as follows: # import libs import uvicorn , asyncio from starlette.templating import Jinja2Templates from starlette.routing import Route from vidgear.gears.asyncio import WebGear # Build out Jinja2 template render at `/home/foo/.vidgear/custom_template` path in which our `hello.html` file is located template = Jinja2Templates ( directory = \"/home/foo/.vidgear/custom_template\" ) # render and return our webpage template async def hello_world ( request ): page = \"hello.html\" context = { \"request\" : request } return template . TemplateResponse ( page , context ) # add various performance tweaks as usual options = { \"frame_size_reduction\" : 40 , \"jpeg_compression_quality\" : 80 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : False , } # initialize WebGear app with a valid source web = WebGear ( source = \"/home/foo/foo1.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # append new route to point our rendered webpage web . routes . append ( Route ( \"/hello\" , endpoint = hello_world )) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/hello address.","title":"Using WebGear with Custom Webpage Routes"},{"location":"gears/webgear/advanced/#using-webgear-with-middlewares","text":"WebGear natively supports ASGI middleware classes with Starlette for implementing behavior that is applied across your entire ASGI application easily. New in v0.2.2 This example was added in v0.2.2 . All supported middlewares can be found here \u27b6 For this example, let's use CORSMiddleware for implementing appropriate CORS headers to outgoing responses in our application in order to allow cross-origin requests from browsers, as follows: The default parameters used by the CORSMiddleware implementation are restrictive by default, so you'll need to explicitly enable particular origins, methods, or headers, in order for browsers to be permitted to use them in a Cross-Domain context. Starlette provides several arguments for enabling origins, methods, or headers for CORSMiddleware API. More information can be found here \u27b6 # import libs import uvicorn , asyncio from starlette.middleware import Middleware from starlette.middleware.cors import CORSMiddleware from vidgear.gears.asyncio import WebGear # add various performance tweaks as usual options = { \"frame_size_reduction\" : 40 , \"jpeg_compression_quality\" : 80 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : False , } # initialize WebGear app with a valid source web = WebGear ( source = \"/home/foo/foo1.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # define and assign suitable cors middlewares web . middleware = [ Middleware ( CORSMiddleware , allow_origins = [ \"*\" ], allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) ] # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000 address.","title":"Using WebGear with MiddleWares"},{"location":"gears/webgear/advanced/#rules-for-altering-webgear-files-and-folders","text":"WebGear gives us complete freedom of altering data files generated in Auto-Generation Process , But you've to keep the following rules in mind:","title":"Rules for Altering WebGear Files and Folders"},{"location":"gears/webgear/advanced/#rules-for-altering-data-files","text":"You allowed to alter/change code in all existing default downloaded files at your convenience without any restrictions. You allowed to delete/rename all existing data files, except remember NOT to delete/rename three critical data-files (i.e index.html , 404.html & 500.html ) present in templates folder inside the webgear directory at the default location , otherwise, it will trigger Auto-generation process , and it will overwrite the existing files with Server ones. You're allowed to add your own additional .html , .css , .js , etc. files in the respective folders at the default location and custom mounted Data folders .","title":"Rules for Altering Data Files"},{"location":"gears/webgear/advanced/#rules-for-altering-data-folders","text":"You're allowed to add/mount any number of additional folder as shown in this example above . You're allowed to delete/rename existing folders at the default location except remember NOT to delete/rename templates folder in the webgear directory where critical data-files (i.e index.html , 404.html & 500.html ) are located, otherwise, it will trigger Auto-generation process .","title":"Rules for Altering Data Folders"},{"location":"gears/webgear/advanced/#bonus-examples","text":"Checkout more advanced WebGear examples with unusual configuration here \u27b6","title":"Bonus Examples"},{"location":"gears/webgear/overview/","text":"WebGear API \u2693 WebGear API's Video Server running at http://localhost:8000/ address. Overview \u2693 WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting Motion-JPEG -frames from a single source to multiple recipients via the browser. WebGear API works on Starlette 's ASGI application and provides a highly extensible and flexible async wrapper around its complete framework. WebGear can flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes , Routing tables , Static Files , Templating engine(with Jinja2) , etc. WebGear API uses an intraframe-only compression scheme under the hood where the sequence of video-frames are first encoded as JPEG-DIB (JPEG with Device-Independent Bit compression) and then streamed over HTTP using Starlette's Multipart Streaming Response and a Uvicorn ASGI Server. This method imposes lower processing and memory requirements, but the quality is not the best, since JPEG compression is not very efficient for motion video. In layman's terms, WebGear acts as a powerful Video Broadcaster that transmits live video-frames to any web-browser in the network. Additionally, WebGear API also provides internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network. \u2009 Data-Files Auto-Generation WorkFlow for WebGear \u2693 On initializing WebGear API, it automatically checks for three critical data files (i.e index.html , 404.html & 500.html ) inside the templates folder of the webgear directory at the default location which gives rise to the following two possible scenario: If data-files found: it will proceed normally for instantiating the Starlette application. If data-files not found: it will trigger the Auto-Generation process Default Location \u2693 A default location is the path of the directory where data files/folders are downloaded/generated/saved. By default, the .vidgear the folder at the home directory of your machine (for e.g /home/foo/.vidgear on Linux) serves as the default location . But you can also use WebGear's custom_data_location dictionary attribute to change/alter default location path to somewhere else. Tip You can set logging=True during initialization, for easily identifying the selected default location , which will be something like this (on a Linux machine) : WebGear :: DEBUG :: ` /home/foo/.vidgear ` is the default location for saving WebGear data-files. Auto-Generation process \u2693 Info You can also force trigger the Auto-generation process to overwrite existing data-files using overwrite_default_files dictionary attribute. Remember, only downloaded default data files(given above) will be overwritten in this process but any other file/folder will NOT be affected. It is advised to enable logging( logging=True ) on the first run for easily identifying any runtime errors On triggering this process, WebGear API creates webgear directory, and templates and static folders inside along with js , css , img sub-folders at the assigned default location . Thereby at this default location , the necessary default data files will be downloaded from a dedicated Github Server inside respective folders in the following order: .vidgear \u2514\u2500\u2500 webgear \u251c\u2500\u2500 static \u2502 \u251c\u2500\u2500 css \u2502 \u2502 \u2514\u2500\u2500 custom.css \u2502 \u251c\u2500\u2500 img \u2502 \u2502 \u2514\u2500\u2500 favicon-32x32.png \u2502 \u2514\u2500\u2500 js \u2502 \u2514\u2500\u2500 custom.js \u2514\u2500\u2500 templates \u251c\u2500\u2500 404 .html \u251c\u2500\u2500 500 .html \u251c\u2500\u2500 base.html \u2514\u2500\u2500 index.html 6 directories, 7 files Finally these downloaded files thereby are verified for errors and API proceeds for instantiating the Starlette application normally. Importing \u2693 You can import WebGear API in your program as follows: from vidgear.gears.asyncio import WebGear \u2009 WebGear's Default Template \u2693 New in v0.2.1 New Standalone WebGear's Default Theme was added in v0.2.1 . The WebGear API by default uses simple & elegant WebGear's Default Theme which looks like something as follows: Index.html \u2693 Can be accessed by visiting WebGear app server, running at http://localhost:8000/ : 404.html \u2693 Appears when respective URL is not found, for example http://localhost:8000/ok : 500.html \u2693 Appears when an API Error is encountered: If logging is enabled and an error occurs, then instead of displaying this 500 handler, WebGear will respond with a traceback response. Usage Examples \u2693 See here \ud83d\ude80 After going through WebGear Usage Examples, Checkout more bonus examples here \u27b6 Parameters \u2693 See here \ud83d\ude80 References \u2693 See here \ud83d\ude80 FAQs \u2693 See here \ud83d\ude80","title":"Overview"},{"location":"gears/webgear/overview/#webgear-api","text":"WebGear API's Video Server running at http://localhost:8000/ address.","title":"WebGear API"},{"location":"gears/webgear/overview/#overview","text":"WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting Motion-JPEG -frames from a single source to multiple recipients via the browser. WebGear API works on Starlette 's ASGI application and provides a highly extensible and flexible async wrapper around its complete framework. WebGear can flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes , Routing tables , Static Files , Templating engine(with Jinja2) , etc. WebGear API uses an intraframe-only compression scheme under the hood where the sequence of video-frames are first encoded as JPEG-DIB (JPEG with Device-Independent Bit compression) and then streamed over HTTP using Starlette's Multipart Streaming Response and a Uvicorn ASGI Server. This method imposes lower processing and memory requirements, but the quality is not the best, since JPEG compression is not very efficient for motion video. In layman's terms, WebGear acts as a powerful Video Broadcaster that transmits live video-frames to any web-browser in the network. Additionally, WebGear API also provides internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network.","title":"Overview"},{"location":"gears/webgear/overview/#data-files-auto-generation-workflow-for-webgear","text":"On initializing WebGear API, it automatically checks for three critical data files (i.e index.html , 404.html & 500.html ) inside the templates folder of the webgear directory at the default location which gives rise to the following two possible scenario: If data-files found: it will proceed normally for instantiating the Starlette application. If data-files not found: it will trigger the Auto-Generation process","title":"Data-Files Auto-Generation WorkFlow for WebGear"},{"location":"gears/webgear/overview/#default-location","text":"A default location is the path of the directory where data files/folders are downloaded/generated/saved. By default, the .vidgear the folder at the home directory of your machine (for e.g /home/foo/.vidgear on Linux) serves as the default location . But you can also use WebGear's custom_data_location dictionary attribute to change/alter default location path to somewhere else. Tip You can set logging=True during initialization, for easily identifying the selected default location , which will be something like this (on a Linux machine) : WebGear :: DEBUG :: ` /home/foo/.vidgear ` is the default location for saving WebGear data-files.","title":"Default Location"},{"location":"gears/webgear/overview/#auto-generation-process","text":"Info You can also force trigger the Auto-generation process to overwrite existing data-files using overwrite_default_files dictionary attribute. Remember, only downloaded default data files(given above) will be overwritten in this process but any other file/folder will NOT be affected. It is advised to enable logging( logging=True ) on the first run for easily identifying any runtime errors On triggering this process, WebGear API creates webgear directory, and templates and static folders inside along with js , css , img sub-folders at the assigned default location . Thereby at this default location , the necessary default data files will be downloaded from a dedicated Github Server inside respective folders in the following order: .vidgear \u2514\u2500\u2500 webgear \u251c\u2500\u2500 static \u2502 \u251c\u2500\u2500 css \u2502 \u2502 \u2514\u2500\u2500 custom.css \u2502 \u251c\u2500\u2500 img \u2502 \u2502 \u2514\u2500\u2500 favicon-32x32.png \u2502 \u2514\u2500\u2500 js \u2502 \u2514\u2500\u2500 custom.js \u2514\u2500\u2500 templates \u251c\u2500\u2500 404 .html \u251c\u2500\u2500 500 .html \u251c\u2500\u2500 base.html \u2514\u2500\u2500 index.html 6 directories, 7 files Finally these downloaded files thereby are verified for errors and API proceeds for instantiating the Starlette application normally.","title":"Auto-Generation process"},{"location":"gears/webgear/overview/#importing","text":"You can import WebGear API in your program as follows: from vidgear.gears.asyncio import WebGear","title":"Importing"},{"location":"gears/webgear/overview/#webgears-default-template","text":"New in v0.2.1 New Standalone WebGear's Default Theme was added in v0.2.1 . The WebGear API by default uses simple & elegant WebGear's Default Theme which looks like something as follows:","title":"WebGear's Default Template"},{"location":"gears/webgear/overview/#indexhtml","text":"Can be accessed by visiting WebGear app server, running at http://localhost:8000/ :","title":"Index.html"},{"location":"gears/webgear/overview/#404html","text":"Appears when respective URL is not found, for example http://localhost:8000/ok :","title":"404.html"},{"location":"gears/webgear/overview/#500html","text":"Appears when an API Error is encountered: If logging is enabled and an error occurs, then instead of displaying this 500 handler, WebGear will respond with a traceback response.","title":"500.html"},{"location":"gears/webgear/overview/#usage-examples","text":"See here \ud83d\ude80 After going through WebGear Usage Examples, Checkout more bonus examples here \u27b6","title":"Usage Examples"},{"location":"gears/webgear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/webgear/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/webgear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/webgear/params/","text":"WebGear API Parameters \u2693 WebGear provides a special internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs and their parameters. \u2009 enablePiCamera \u2693 This parameter provide direct access to PiGear or CamGear APIs respectively in WebGear. This means the if enablePiCamera flag is True , the PiGear API will be accessed, and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 . options \u2693 This parameter can be used to pass user-defined parameter to WebGear API by formatting them as this parameter's attribute. Data-Type: Dictionary Default Value: Its default value is {} WebGear Specific attributes \u2693 custom_data_location (string) : Can be used to change/alter default location path to somewhere else. Its usage is as follows: # set default location to '/home/foo/foo1' options = { \"custom_data_location\" : \"/home/foo/foo1\" } # assign it WebGear ( logging = True , ** options ) overwrite_default_files (boolean) : Can be used to force trigger the Auto-generation process to overwrite existing data-files. Its usage is as follows: Remember only downloaded files will be overwritten in this process, and any other file/folder will NOT be affected/overwritten. # force trigger the Auto-generation process options = { \"overwrite_default_files\" : True } # assign it WebGear ( logging = True , ** options ) frame_size_reduction (int/float) : This attribute controls the size reduction (in percentage) of the frame to be streamed on Server and it has the most significant effect on performance. The value defaults to 25 , and must be no higher than 90 (fastest, max compression, Barely Visible frame-size) and no lower than 0 (slowest, no compression, Original frame-size) . Its recommended value is between 40-60 . Its usage is as follows: # frame-size will be reduced by 50% options = { \"frame_size_reduction\" : 50 } # assign it WebGear ( logging = True , ** options ) jpeg_compression_quality : (int/float) This attribute controls the JPEG quantization factor. Its value varies from 10 to 100 (the higher is the better quality but performance will be lower). Its default value is 90 . Its usage is as follows: New in v0.2.2 jpeg_compression_quality attribute was added in v0.2.2 . # activate jpeg encoding and set quality 95% options = { \"jpeg_compression_quality\" : 95 } # assign it WebGear ( logging = True , ** options ) jpeg_compression_fastdct : (bool) This attribute if True, WebGear API uses fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality. Its default value is also True , and its usage is as follows: New in v0.2.2 jpeg_compression_fastdct attribute was added in v0.2.2 . # activate jpeg encoding and enable fast dct options = { \"jpeg_compression_fastdct\" : True } # assign it WebGear ( logging = True , ** options ) jpeg_compression_fastupsample : (bool) This attribute if True, WebGear API use fastest color upsampling method. Its default value is False , and its usage is as follows: New in v0.2.2 jpeg_compression_fastupsample attribute was added in v0.2.2 . # activate jpeg encoding and enable fast upsampling options = { \"jpeg_compression_fastupsample\" : True } # assign it WebGear ( logging = True , ** options ) jpeg_compression_colorspace : (str) This internal attribute is used to specify incoming frames colorspace with compression. Its usage is as follows: Supported jpeg_compression_colorspace colorspace values are RGB , BGR , RGBX , BGRX , XBGR , XRGB , GRAY , RGBA , BGRA , ABGR , ARGB , CMYK . More information can be found here \u27b6 New in v0.2.2 jpeg_compression_colorspace attribute was added in v0.2.2 . # Specify incoming frames are `grayscale` options = { \"jpeg_compression\" : \"GRAY\" } # assign it WebGear ( logging = True , ** options ) enable_infinite_frames (boolean) : Can be used to continue streaming (instead of terminating immediately) with emulated blank frames with text \"No Input\", whenever the input source disconnects. Its default value is False . Its usage is as follows New in v0.2.1 enable_infinite_frames attribute was added in v0.2.1 . # emulate infinite frames options = { \"enable_infinite_frames\" : True } # assign it WebGear ( logging = True , ** options ) Parameters for Stabilizer Backend \u2693 Enable this backend with stabilize=True in WebGear. stabilize \u2693 This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to True ( to enable ) or unset to False ( to disable ). Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 . options \u2693 This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be formatted as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' } Parameters for CamGear backend \u2693 Enable this backend with enablePiCamera=False in WebGear. Default is also False . source \u2693 WebGear API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: WebGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: WebGear ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) CamGear internally implements yt_dlp backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 WebGear ( source = 'https://www.twitch.tv/shroud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: WebGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: WebGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' ) stream_mode \u2693 This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the CamGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 WebGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 . backend \u2693 This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: WebGear ( source = 0 , backend = cv2 . CAP_DSHOW ) options \u2693 This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to WebGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it WebGear ( source = 0 , ** options ) Parameters for PiGear backend \u2693 Enable this backend with enablePiCamera=True in WebGear. camera_num \u2693 This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear ( enablePiCamera = True , camera_num = 0 ) resolution \u2693 This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: WebGear ( enablePiCamera = True , resolution = ( 1280 , 720 )) # sets 1280x720 resolution framerate \u2693 This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: WebGear ( enablePiCamera = True , framerate = 60 ) # sets 60fps framerate options \u2693 This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to WebGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it WebGear ( enablePiCamera = True , logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds Common Parameters \u2693 These are common parameters that works with every backend in WebGear. colorspace \u2693 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 WebGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 logging \u2693 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( logging = True ) time_delay \u2693 This parameter set the time delay (in seconds) before the WebGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear ( time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/webgear/params/#webgear-api-parameters","text":"WebGear provides a special internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs and their parameters.","title":"WebGear API Parameters"},{"location":"gears/webgear/params/#enablepicamera","text":"This parameter provide direct access to PiGear or CamGear APIs respectively in WebGear. This means the if enablePiCamera flag is True , the PiGear API will be accessed, and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 .","title":"enablePiCamera"},{"location":"gears/webgear/params/#options","text":"This parameter can be used to pass user-defined parameter to WebGear API by formatting them as this parameter's attribute. Data-Type: Dictionary Default Value: Its default value is {}","title":"options"},{"location":"gears/webgear/params/#webgear-specific-attributes","text":"custom_data_location (string) : Can be used to change/alter default location path to somewhere else. Its usage is as follows: # set default location to '/home/foo/foo1' options = { \"custom_data_location\" : \"/home/foo/foo1\" } # assign it WebGear ( logging = True , ** options ) overwrite_default_files (boolean) : Can be used to force trigger the Auto-generation process to overwrite existing data-files. Its usage is as follows: Remember only downloaded files will be overwritten in this process, and any other file/folder will NOT be affected/overwritten. # force trigger the Auto-generation process options = { \"overwrite_default_files\" : True } # assign it WebGear ( logging = True , ** options ) frame_size_reduction (int/float) : This attribute controls the size reduction (in percentage) of the frame to be streamed on Server and it has the most significant effect on performance. The value defaults to 25 , and must be no higher than 90 (fastest, max compression, Barely Visible frame-size) and no lower than 0 (slowest, no compression, Original frame-size) . Its recommended value is between 40-60 . Its usage is as follows: # frame-size will be reduced by 50% options = { \"frame_size_reduction\" : 50 } # assign it WebGear ( logging = True , ** options ) jpeg_compression_quality : (int/float) This attribute controls the JPEG quantization factor. Its value varies from 10 to 100 (the higher is the better quality but performance will be lower). Its default value is 90 . Its usage is as follows: New in v0.2.2 jpeg_compression_quality attribute was added in v0.2.2 . # activate jpeg encoding and set quality 95% options = { \"jpeg_compression_quality\" : 95 } # assign it WebGear ( logging = True , ** options ) jpeg_compression_fastdct : (bool) This attribute if True, WebGear API uses fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality. Its default value is also True , and its usage is as follows: New in v0.2.2 jpeg_compression_fastdct attribute was added in v0.2.2 . # activate jpeg encoding and enable fast dct options = { \"jpeg_compression_fastdct\" : True } # assign it WebGear ( logging = True , ** options ) jpeg_compression_fastupsample : (bool) This attribute if True, WebGear API use fastest color upsampling method. Its default value is False , and its usage is as follows: New in v0.2.2 jpeg_compression_fastupsample attribute was added in v0.2.2 . # activate jpeg encoding and enable fast upsampling options = { \"jpeg_compression_fastupsample\" : True } # assign it WebGear ( logging = True , ** options ) jpeg_compression_colorspace : (str) This internal attribute is used to specify incoming frames colorspace with compression. Its usage is as follows: Supported jpeg_compression_colorspace colorspace values are RGB , BGR , RGBX , BGRX , XBGR , XRGB , GRAY , RGBA , BGRA , ABGR , ARGB , CMYK . More information can be found here \u27b6 New in v0.2.2 jpeg_compression_colorspace attribute was added in v0.2.2 . # Specify incoming frames are `grayscale` options = { \"jpeg_compression\" : \"GRAY\" } # assign it WebGear ( logging = True , ** options ) enable_infinite_frames (boolean) : Can be used to continue streaming (instead of terminating immediately) with emulated blank frames with text \"No Input\", whenever the input source disconnects. Its default value is False . Its usage is as follows New in v0.2.1 enable_infinite_frames attribute was added in v0.2.1 . # emulate infinite frames options = { \"enable_infinite_frames\" : True } # assign it WebGear ( logging = True , ** options )","title":"WebGear Specific attributes"},{"location":"gears/webgear/params/#parameters-for-stabilizer-backend","text":"Enable this backend with stabilize=True in WebGear.","title":"Parameters for Stabilizer Backend"},{"location":"gears/webgear/params/#stabilize","text":"This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to True ( to enable ) or unset to False ( to disable ). Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 .","title":"stabilize"},{"location":"gears/webgear/params/#options_1","text":"This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be formatted as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' }","title":"options"},{"location":"gears/webgear/params/#parameters-for-camgear-backend","text":"Enable this backend with enablePiCamera=False in WebGear. Default is also False .","title":"Parameters for CamGear backend"},{"location":"gears/webgear/params/#source","text":"WebGear API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: WebGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: WebGear ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) CamGear internally implements yt_dlp backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 WebGear ( source = 'https://www.twitch.tv/shroud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: WebGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: WebGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' )","title":"source"},{"location":"gears/webgear/params/#stream_mode","text":"This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the CamGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 WebGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 .","title":"stream_mode"},{"location":"gears/webgear/params/#backend","text":"This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: WebGear ( source = 0 , backend = cv2 . CAP_DSHOW )","title":"backend"},{"location":"gears/webgear/params/#options_2","text":"This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to WebGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it WebGear ( source = 0 , ** options )","title":"options"},{"location":"gears/webgear/params/#parameters-for-pigear-backend","text":"Enable this backend with enablePiCamera=True in WebGear.","title":"Parameters for PiGear backend"},{"location":"gears/webgear/params/#camera_num","text":"This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear ( enablePiCamera = True , camera_num = 0 )","title":"camera_num"},{"location":"gears/webgear/params/#resolution","text":"This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: WebGear ( enablePiCamera = True , resolution = ( 1280 , 720 )) # sets 1280x720 resolution","title":"resolution"},{"location":"gears/webgear/params/#framerate","text":"This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: WebGear ( enablePiCamera = True , framerate = 60 ) # sets 60fps framerate","title":"framerate"},{"location":"gears/webgear/params/#options_3","text":"This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to WebGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it WebGear ( enablePiCamera = True , logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds","title":"options"},{"location":"gears/webgear/params/#common-parameters","text":"These are common parameters that works with every backend in WebGear.","title":"Common Parameters"},{"location":"gears/webgear/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 WebGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/webgear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( logging = True )","title":"logging"},{"location":"gears/webgear/params/#time_delay","text":"This parameter set the time delay (in seconds) before the WebGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear ( time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/webgear/usage/","text":"WebGear API Usage Examples: \u2693 Requirements \u2693 Installation with Asyncio Support \u2693 WebGear API is the part of asyncio package of VidGear, thereby you need to install VidGear with asyncio support as follows: pip install vidgear [ asyncio ] ASGI Server \u2693 You'll also need to install an ASGI Server to run following WebGear usage examples, and by default WebGear ships the state-of-the-art uvicorn Server. But you can also use other ASGI server such as daphne , or hypercorn with it. \u2009 Performance Enhancements \u2693 WebGear provides certain performance enhancing attributes for its options dictionary parameter to cope with performance-throttling. Performance Enhancing Attributes frame_size_reduction : (int/float) This attribute controls the size reduction(in percentage) of the frame to be streamed on Server. Its value has the most significant effect on WebGear performance: More its value, smaller will be frame size and faster will be live streaming. The value defaults to 20 , and must be no higher than 90 (fastest, max compression, Barely Visible frame-size) and no lower than 0 (slowest, no compression, Original frame-size) . Its recommended value is between 40~60 . Its usage is as follows: options = { \"frame_size_reduction\" : 50 } #frame-size will be reduced by 50% Various Encoding Parameters: In WebGear API, the input video frames are first encoded into Motion JPEG (M-JPEG or MJPEG ) compression format, in which each video frame or interlaced field of a digital video sequence is compressed separately as a JPEG image using simplejpeg library, before sending onto a server. Therefore, WebGear API provides various attributes to have full control over JPEG encoding performance and quality, which are as follows: jpeg_compression_quality : (int/float) This attribute controls the JPEG quantization factor. Its value varies from 10 to 100 (the higher is the better quality but performance will be lower). Its default value is 90 . Its usage is as follows: # activate jpeg encoding and set quality 95% options = { \"jpeg_compression_quality\" : 95 } jpeg_compression_fastdct : (bool) This attribute if True, WebGear API uses fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality. Its default value is also True , and its usage is as follows: # activate jpeg encoding and enable fast dct options = { \"jpeg_compression_fastdct\" : True } jpeg_compression_fastupsample : (bool) This attribute if True, WebGear API use fastest color upsampling method. Its default value is False , and its usage is as follows: # activate jpeg encoding and enable fast upsampling options = { \"jpeg_compression_fastupsample\" : True } Bare-Minimum Usage with Performance Enhancements \u2693 Let's implement our Bare-Minimum usage example with these Performance Enhancing Attributes \u27b6 for speeding up the output. Running Programmatically \u2693 You can access and run WebGear VideoStreamer Server programmatically in your python script in just a few lines of code, as follows: For accessing WebGear on different Client Devices on the network, use \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine. More information can be found here \u27b6 # import required libraries import uvicorn from vidgear.gears.asyncio import WebGear # various performance tweaks options = { \"frame_size_reduction\" : 40 , \"jpeg_compression_quality\" : 80 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : False , } # initialize WebGear app web = WebGear ( source = \"foo.mp4\" , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () which can be accessed on any browser on your machine at http://localhost:8000/ . Running from Terminal \u2693 You can also access and run WebGear Server directly from the terminal commandline. The following command will run a WebGear VideoStreamer server at http://localhost:8000/ : Make sure your PYTHON_PATH is set to python 3.7+ versions only. If you're using --options/-op flag, then kindly wrap your dictionary value in single '' quotes. python3 -m vidgear.gears.asyncio --source test.avi --logging True --options '{\"frame_size_reduction\": 50, \"jpeg_compression_quality\": 80, \"jpeg_compression_fastdct\": True, \"jpeg_compression_fastupsample\": False}' which can also be accessed on any browser on the network at http://localhost:8000/ . Advanced Usage from Terminal You can run python3 - m vidgear . gears . asyncio - h help command to see all the advanced settings, as follows: usage: python -m vidgear.gears.asyncio [ -h ] [ -m MODE ] [ -s SOURCE ] [ -ep ENABLEPICAMERA ] [ -S STABILIZE ] [ -cn CAMERA_NUM ] [ -yt stream_mode ] [ -b BACKEND ] [ -cs COLORSPACE ] [ -r RESOLUTION ] [ -f FRAMERATE ] [ -td TIME_DELAY ] [ -ip IPADDRESS ] [ -pt PORT ] [ -l LOGGING ] [ -op OPTIONS ] Runs WebGear/WebGear_RTC Video Server through terminal. optional arguments: -h, --help show this help message and exit -m { mjpeg,webrtc } , --mode { mjpeg,webrtc } Whether to use \"MJPEG\" or \"WebRTC\" mode for streaming. -s SOURCE, --source SOURCE Path to input source for CamGear API. -ep ENABLEPICAMERA, --enablePiCamera ENABLEPICAMERA Sets the flag to access PiGear ( if True ) or otherwise CamGear API respectively. -S STABILIZE, --stabilize STABILIZE Enables/disables real-time video stabilization. -cn CAMERA_NUM, --camera_num CAMERA_NUM Sets the camera module index that will be used by PiGear API. -yt STREAM_MODE, --stream_mode STREAM_MODE Enables YouTube Mode in CamGear API. -b BACKEND, --backend BACKEND Sets the backend of the video source in CamGear API. -cs COLORSPACE, --colorspace COLORSPACE Sets the colorspace of the output video stream. -r RESOLUTION, --resolution RESOLUTION Sets the resolution ( width,height ) for camera module in PiGear API. -f FRAMERATE, --framerate FRAMERATE Sets the framerate for camera module in PiGear API. -td TIME_DELAY, --time_delay TIME_DELAY Sets the time delay ( in seconds ) before start reading the frames. -ip IPADDRESS, --ipaddress IPADDRESS Uvicorn binds the socket to this ipaddress. -pt PORT, --port PORT Uvicorn binds the socket to this port. -l LOGGING, --logging LOGGING Enables/disables error logging, essential for debugging. -op OPTIONS, --options OPTIONS Sets the parameters supported by APIs ( whichever being accessed ) to the input videostream, But make sure to wrap your dict value in single or double quotes.","title":"Usage Examples"},{"location":"gears/webgear/usage/#webgear-api-usage-examples","text":"","title":"WebGear API Usage Examples:"},{"location":"gears/webgear/usage/#requirements","text":"","title":"Requirements"},{"location":"gears/webgear/usage/#installation-with-asyncio-support","text":"WebGear API is the part of asyncio package of VidGear, thereby you need to install VidGear with asyncio support as follows: pip install vidgear [ asyncio ]","title":"Installation with Asyncio Support"},{"location":"gears/webgear/usage/#asgi-server","text":"You'll also need to install an ASGI Server to run following WebGear usage examples, and by default WebGear ships the state-of-the-art uvicorn Server. But you can also use other ASGI server such as daphne , or hypercorn with it.","title":"ASGI Server"},{"location":"gears/webgear/usage/#performance-enhancements","text":"WebGear provides certain performance enhancing attributes for its options dictionary parameter to cope with performance-throttling. Performance Enhancing Attributes frame_size_reduction : (int/float) This attribute controls the size reduction(in percentage) of the frame to be streamed on Server. Its value has the most significant effect on WebGear performance: More its value, smaller will be frame size and faster will be live streaming. The value defaults to 20 , and must be no higher than 90 (fastest, max compression, Barely Visible frame-size) and no lower than 0 (slowest, no compression, Original frame-size) . Its recommended value is between 40~60 . Its usage is as follows: options = { \"frame_size_reduction\" : 50 } #frame-size will be reduced by 50% Various Encoding Parameters: In WebGear API, the input video frames are first encoded into Motion JPEG (M-JPEG or MJPEG ) compression format, in which each video frame or interlaced field of a digital video sequence is compressed separately as a JPEG image using simplejpeg library, before sending onto a server. Therefore, WebGear API provides various attributes to have full control over JPEG encoding performance and quality, which are as follows: jpeg_compression_quality : (int/float) This attribute controls the JPEG quantization factor. Its value varies from 10 to 100 (the higher is the better quality but performance will be lower). Its default value is 90 . Its usage is as follows: # activate jpeg encoding and set quality 95% options = { \"jpeg_compression_quality\" : 95 } jpeg_compression_fastdct : (bool) This attribute if True, WebGear API uses fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality. Its default value is also True , and its usage is as follows: # activate jpeg encoding and enable fast dct options = { \"jpeg_compression_fastdct\" : True } jpeg_compression_fastupsample : (bool) This attribute if True, WebGear API use fastest color upsampling method. Its default value is False , and its usage is as follows: # activate jpeg encoding and enable fast upsampling options = { \"jpeg_compression_fastupsample\" : True }","title":"Performance Enhancements"},{"location":"gears/webgear/usage/#bare-minimum-usage-with-performance-enhancements","text":"Let's implement our Bare-Minimum usage example with these Performance Enhancing Attributes \u27b6 for speeding up the output.","title":"Bare-Minimum Usage with Performance Enhancements"},{"location":"gears/webgear/usage/#running-programmatically","text":"You can access and run WebGear VideoStreamer Server programmatically in your python script in just a few lines of code, as follows: For accessing WebGear on different Client Devices on the network, use \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine. More information can be found here \u27b6 # import required libraries import uvicorn from vidgear.gears.asyncio import WebGear # various performance tweaks options = { \"frame_size_reduction\" : 40 , \"jpeg_compression_quality\" : 80 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : False , } # initialize WebGear app web = WebGear ( source = \"foo.mp4\" , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () which can be accessed on any browser on your machine at http://localhost:8000/ .","title":"Running Programmatically"},{"location":"gears/webgear/usage/#running-from-terminal","text":"You can also access and run WebGear Server directly from the terminal commandline. The following command will run a WebGear VideoStreamer server at http://localhost:8000/ : Make sure your PYTHON_PATH is set to python 3.7+ versions only. If you're using --options/-op flag, then kindly wrap your dictionary value in single '' quotes. python3 -m vidgear.gears.asyncio --source test.avi --logging True --options '{\"frame_size_reduction\": 50, \"jpeg_compression_quality\": 80, \"jpeg_compression_fastdct\": True, \"jpeg_compression_fastupsample\": False}' which can also be accessed on any browser on the network at http://localhost:8000/ . Advanced Usage from Terminal You can run python3 - m vidgear . gears . asyncio - h help command to see all the advanced settings, as follows: usage: python -m vidgear.gears.asyncio [ -h ] [ -m MODE ] [ -s SOURCE ] [ -ep ENABLEPICAMERA ] [ -S STABILIZE ] [ -cn CAMERA_NUM ] [ -yt stream_mode ] [ -b BACKEND ] [ -cs COLORSPACE ] [ -r RESOLUTION ] [ -f FRAMERATE ] [ -td TIME_DELAY ] [ -ip IPADDRESS ] [ -pt PORT ] [ -l LOGGING ] [ -op OPTIONS ] Runs WebGear/WebGear_RTC Video Server through terminal. optional arguments: -h, --help show this help message and exit -m { mjpeg,webrtc } , --mode { mjpeg,webrtc } Whether to use \"MJPEG\" or \"WebRTC\" mode for streaming. -s SOURCE, --source SOURCE Path to input source for CamGear API. -ep ENABLEPICAMERA, --enablePiCamera ENABLEPICAMERA Sets the flag to access PiGear ( if True ) or otherwise CamGear API respectively. -S STABILIZE, --stabilize STABILIZE Enables/disables real-time video stabilization. -cn CAMERA_NUM, --camera_num CAMERA_NUM Sets the camera module index that will be used by PiGear API. -yt STREAM_MODE, --stream_mode STREAM_MODE Enables YouTube Mode in CamGear API. -b BACKEND, --backend BACKEND Sets the backend of the video source in CamGear API. -cs COLORSPACE, --colorspace COLORSPACE Sets the colorspace of the output video stream. -r RESOLUTION, --resolution RESOLUTION Sets the resolution ( width,height ) for camera module in PiGear API. -f FRAMERATE, --framerate FRAMERATE Sets the framerate for camera module in PiGear API. -td TIME_DELAY, --time_delay TIME_DELAY Sets the time delay ( in seconds ) before start reading the frames. -ip IPADDRESS, --ipaddress IPADDRESS Uvicorn binds the socket to this ipaddress. -pt PORT, --port PORT Uvicorn binds the socket to this port. -l LOGGING, --logging LOGGING Enables/disables error logging, essential for debugging. -op OPTIONS, --options OPTIONS Sets the parameters supported by APIs ( whichever being accessed ) to the input videostream, But make sure to wrap your dict value in single or double quotes.","title":"Running from Terminal"},{"location":"gears/webgear_rtc/advanced/","text":"WebGear_RTC API Advanced Usage: \u2693 This is a continuation of the WebGear_RTC doc \u27b6 . Thereby, It's advised to first get familiarize with this API, and its requirements . After going through following Usage Examples, Checkout more bonus examples here \u27b6 \u2009 Using WebGear_RTC as Real-time Broadcaster \u2693 WebGear_RTC by default only supports one-to-one peer connection with a single consumer or client. But you can use enable_live_broadcast boolean attribute through its options dictionary parameter to easily enable live broadcast/stream to multiple peer consumers/clients at the same time. Let's implement a bare-minimum example using WebGear_RTC as Real-time Broadcaster: enable_infinite_frames is enforced by default with this( enable_live_broadcast ) attribute. For accessing WebGear_RTC on different Client Devices on the network, we use \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine. More information can be found here \u27b6 # import required libraries import uvicorn from vidgear.gears.asyncio import WebGear_RTC # various performance tweaks and enable live broadcasting options = { \"frame_size_reduction\" : 25 , \"enable_live_broadcast\" : True , } # initialize WebGear_RTC app web = WebGear_RTC ( source = \"foo.mp4\" , logging = True , ** options ) # run this app on Uvicorn server at address http://0.0.0.0:8000/ uvicorn . run ( web (), host = \"0.0.0.0\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/ address on your local machine. Using WebGear_RTC with a Custom Source(OpenCV) \u2693 WebGear_RTC provides custom_stream attribute with its options parameter that allows you to easily define your own Custom Streaming Class with suitable source that you want to use to transform your frames before sending them onto the browser. Let's implement a bare-minimum example with a Custom Source using WebGear_RTC API and OpenCV: New in v0.2.4 This implementation was added in v0.2.4 . Auto-Reconnection or Auto-Refresh works out-of-the-box with this implementation. Make sure your Custom Streaming Class at-least implements read() and stop() methods as shown in following example, otherwise WebGear_RTC will throw ValueError! Using Vidgear's VideoCapture APIs instead of OpenCV You can directly replace Custom Streaming Class( Custom_Stream_Class in following example) with any VideoCapture APIs . These APIs implements read() and stop() methods by-default, so they're also supported out-of-the-box. See this example \u27b6 for more information. # import necessary libs import uvicorn , cv2 from vidgear.gears.asyncio import WebGear_RTC # create your own custom streaming class class Custom_Stream_Class : \"\"\" Custom Streaming using OpenCV \"\"\" def __init__ ( self , source = 0 ): # !!! define your own video source here !!! self . source = cv2 . VideoCapture ( source ) # define running flag self . running = True def read ( self ): # don't forget this function!!! # check if source was initialized or not if self . source is None : return None # check if we're still running if self . running : # read frame from provided source ( grabbed , frame ) = self . source . read () # check if frame is available if grabbed : # do something with your OpenCV frame here # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # return our gray frame return gray else : # signal we're not running now self . running = False # return None-type return None def stop ( self ): # don't forget this function!!! # flag that we're not running self . running = False # close stream if not self . source is None : self . source . release () # assign your Custom Streaming Class with adequate source (for e.g. foo.mp4) # to `custom_stream` attribute in options parameter options = { \"custom_stream\" : Custom_Stream_Class ( source = \"foo.mp4\" )} # initialize WebGear_RTC app without any source web = WebGear_RTC ( logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/ address. Using WebGear_RTC with Custom Mounting Points \u2693 With our highly extensible WebGear_RTC API, you can add your own mounting points, where additional files located, as follows: # import libs import uvicorn from starlette.routing import Mount from starlette.staticfiles import StaticFiles from vidgear.gears.asyncio import WebGear_RTC # various performance tweaks options = { \"frame_size_reduction\" : 25 , } # initialize WebGear_RTC app web = WebGear_RTC ( source = \"foo.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # append new route i.e. mount another folder called `test` located at `/home/foo/.vidgear/test` directory web . routes . append ( Mount ( \"/test\" , app = StaticFiles ( directory = \"/home/foo/.vidgear/test\" ), name = \"test\" ) ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () Then you can use this folder in your HTML page, to host data-files. For example, if we have jQuery script jquery-3.3.1.slim.min.js in this folder and want to integrate it, then, we can do something like this: < script src = \"{{ url_for('test', path='jquery-3.3.1.slim.min.js') }}\" ></ script > Using WebGear_RTC with Custom Webpage Routes \u2693 With Webgear_RTC's flexible API, you can even add your additional HTML Static webpages without any extra efforts. Suppose we want to add a simple hello world webpage to our WebGear_RTC server. So let's create a bare-minimum hello.html file with HTML code as follows: < html > < header > < title > This is Hello world page </ title > </ header > < body > < h1 > Hello World </ h1 > < p > how ya doing? </ p > </ body > </ html > Then in our application code, we can integrate this webpage route, as follows: # import libs import uvicorn , asyncio from starlette.templating import Jinja2Templates from starlette.routing import Route from vidgear.gears.asyncio import WebGear_RTC # Build out Jinja2 template render at `/home/foo/.vidgear/custom_template` path in which our `hello.html` file is located template = Jinja2Templates ( directory = \"/home/foo/.vidgear/custom_template\" ) # render and return our webpage template async def hello_world ( request ): page = \"hello.html\" context = { \"request\" : request } return template . TemplateResponse ( page , context ) # add various performance tweaks as usual options = { \"frame_size_reduction\" : 25 , } # initialize WebGear_RTC app with a valid source web = WebGear_RTC ( source = \"/home/foo/foo1.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # append new route to point our rendered webpage web . routes . append ( Route ( \"/hello\" , endpoint = hello_world )) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/hello address. Using WebGear_RTC with MiddleWares \u2693 WebGear_RTC also natively supports ASGI middleware classes with Starlette for implementing behavior that is applied across your entire ASGI application easily. New in v0.2.2 This example was added in v0.2.2 . All supported middlewares can be found here \u27b6 For this example, let's use CORSMiddleware for implementing appropriate CORS headers to outgoing responses in our application in order to allow cross-origin requests from browsers, as follows: The default parameters used by the CORSMiddleware implementation are restrictive by default, so you'll need to explicitly enable particular origins, methods, or headers, in order for browsers to be permitted to use them in a Cross-Domain context. Starlette provides several arguments for enabling origins, methods, or headers for CORSMiddleware API. More information can be found here \u27b6 # import libs import uvicorn , asyncio from starlette.middleware import Middleware from starlette.middleware.cors import CORSMiddleware from vidgear.gears.asyncio import WebGear_RTC # add various performance tweaks as usual options = { \"frame_size_reduction\" : 25 , } # initialize WebGear_RTC app with a valid source web = WebGear_RTC ( source = \"/home/foo/foo1.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # define and assign suitable cors middlewares web . middleware = [ Middleware ( CORSMiddleware , allow_origins = [ \"*\" ], allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) ] # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000 address. Rules for Altering WebGear_RTC Files and Folders \u2693 WebGear_RTC gives us complete freedom of altering data files generated in Auto-Generation Process , But you've to keep the following rules in mind: Rules for Altering Data Files \u2693 You allowed to alter/change code in all existing default downloaded files at your convenience without any restrictions. You allowed to delete/rename all existing data files, except remember NOT to delete/rename three critical data-files (i.e index.html , 404.html & 500.html ) present in templates folder inside the webgear_rtc directory at the default location , otherwise, it will trigger Auto-generation process , and it will overwrite the existing files with Server ones. You're allowed to add your own additional .html , .css , .js , etc. files in the respective folders at the default location and custom mounted Data folders . Rules for Altering Data Folders \u2693 You're allowed to add/mount any number of additional folder as shown in this example above . You're allowed to delete/rename existing folders at the default location except remember NOT to delete/rename templates folder in the webgear_rtc directory where critical data-files (i.e index.html , 404.html & 500.html ) are located, otherwise, it will trigger Auto-generation process . Bonus Examples \u2693 Checkout more advanced WebGear_RTC examples with unusual configuration here \u27b6","title":"Advanced Usages"},{"location":"gears/webgear_rtc/advanced/#webgear_rtc-api-advanced-usage","text":"This is a continuation of the WebGear_RTC doc \u27b6 . Thereby, It's advised to first get familiarize with this API, and its requirements . After going through following Usage Examples, Checkout more bonus examples here \u27b6","title":"WebGear_RTC API Advanced Usage:"},{"location":"gears/webgear_rtc/advanced/#using-webgear_rtc-as-real-time-broadcaster","text":"WebGear_RTC by default only supports one-to-one peer connection with a single consumer or client. But you can use enable_live_broadcast boolean attribute through its options dictionary parameter to easily enable live broadcast/stream to multiple peer consumers/clients at the same time. Let's implement a bare-minimum example using WebGear_RTC as Real-time Broadcaster: enable_infinite_frames is enforced by default with this( enable_live_broadcast ) attribute. For accessing WebGear_RTC on different Client Devices on the network, we use \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine. More information can be found here \u27b6 # import required libraries import uvicorn from vidgear.gears.asyncio import WebGear_RTC # various performance tweaks and enable live broadcasting options = { \"frame_size_reduction\" : 25 , \"enable_live_broadcast\" : True , } # initialize WebGear_RTC app web = WebGear_RTC ( source = \"foo.mp4\" , logging = True , ** options ) # run this app on Uvicorn server at address http://0.0.0.0:8000/ uvicorn . run ( web (), host = \"0.0.0.0\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/ address on your local machine.","title":"Using WebGear_RTC as Real-time Broadcaster"},{"location":"gears/webgear_rtc/advanced/#using-webgear_rtc-with-a-custom-sourceopencv","text":"WebGear_RTC provides custom_stream attribute with its options parameter that allows you to easily define your own Custom Streaming Class with suitable source that you want to use to transform your frames before sending them onto the browser. Let's implement a bare-minimum example with a Custom Source using WebGear_RTC API and OpenCV: New in v0.2.4 This implementation was added in v0.2.4 . Auto-Reconnection or Auto-Refresh works out-of-the-box with this implementation. Make sure your Custom Streaming Class at-least implements read() and stop() methods as shown in following example, otherwise WebGear_RTC will throw ValueError! Using Vidgear's VideoCapture APIs instead of OpenCV You can directly replace Custom Streaming Class( Custom_Stream_Class in following example) with any VideoCapture APIs . These APIs implements read() and stop() methods by-default, so they're also supported out-of-the-box. See this example \u27b6 for more information. # import necessary libs import uvicorn , cv2 from vidgear.gears.asyncio import WebGear_RTC # create your own custom streaming class class Custom_Stream_Class : \"\"\" Custom Streaming using OpenCV \"\"\" def __init__ ( self , source = 0 ): # !!! define your own video source here !!! self . source = cv2 . VideoCapture ( source ) # define running flag self . running = True def read ( self ): # don't forget this function!!! # check if source was initialized or not if self . source is None : return None # check if we're still running if self . running : # read frame from provided source ( grabbed , frame ) = self . source . read () # check if frame is available if grabbed : # do something with your OpenCV frame here # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # return our gray frame return gray else : # signal we're not running now self . running = False # return None-type return None def stop ( self ): # don't forget this function!!! # flag that we're not running self . running = False # close stream if not self . source is None : self . source . release () # assign your Custom Streaming Class with adequate source (for e.g. foo.mp4) # to `custom_stream` attribute in options parameter options = { \"custom_stream\" : Custom_Stream_Class ( source = \"foo.mp4\" )} # initialize WebGear_RTC app without any source web = WebGear_RTC ( logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/ address.","title":"Using WebGear_RTC with a Custom Source(OpenCV)"},{"location":"gears/webgear_rtc/advanced/#using-webgear_rtc-with-custom-mounting-points","text":"With our highly extensible WebGear_RTC API, you can add your own mounting points, where additional files located, as follows: # import libs import uvicorn from starlette.routing import Mount from starlette.staticfiles import StaticFiles from vidgear.gears.asyncio import WebGear_RTC # various performance tweaks options = { \"frame_size_reduction\" : 25 , } # initialize WebGear_RTC app web = WebGear_RTC ( source = \"foo.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # append new route i.e. mount another folder called `test` located at `/home/foo/.vidgear/test` directory web . routes . append ( Mount ( \"/test\" , app = StaticFiles ( directory = \"/home/foo/.vidgear/test\" ), name = \"test\" ) ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () Then you can use this folder in your HTML page, to host data-files. For example, if we have jQuery script jquery-3.3.1.slim.min.js in this folder and want to integrate it, then, we can do something like this: < script src = \"{{ url_for('test', path='jquery-3.3.1.slim.min.js') }}\" ></ script >","title":"Using WebGear_RTC with Custom Mounting Points"},{"location":"gears/webgear_rtc/advanced/#using-webgear_rtc-with-custom-webpage-routes","text":"With Webgear_RTC's flexible API, you can even add your additional HTML Static webpages without any extra efforts. Suppose we want to add a simple hello world webpage to our WebGear_RTC server. So let's create a bare-minimum hello.html file with HTML code as follows: < html > < header > < title > This is Hello world page </ title > </ header > < body > < h1 > Hello World </ h1 > < p > how ya doing? </ p > </ body > </ html > Then in our application code, we can integrate this webpage route, as follows: # import libs import uvicorn , asyncio from starlette.templating import Jinja2Templates from starlette.routing import Route from vidgear.gears.asyncio import WebGear_RTC # Build out Jinja2 template render at `/home/foo/.vidgear/custom_template` path in which our `hello.html` file is located template = Jinja2Templates ( directory = \"/home/foo/.vidgear/custom_template\" ) # render and return our webpage template async def hello_world ( request ): page = \"hello.html\" context = { \"request\" : request } return template . TemplateResponse ( page , context ) # add various performance tweaks as usual options = { \"frame_size_reduction\" : 25 , } # initialize WebGear_RTC app with a valid source web = WebGear_RTC ( source = \"/home/foo/foo1.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # append new route to point our rendered webpage web . routes . append ( Route ( \"/hello\" , endpoint = hello_world )) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/hello address.","title":"Using WebGear_RTC with Custom Webpage Routes"},{"location":"gears/webgear_rtc/advanced/#using-webgear_rtc-with-middlewares","text":"WebGear_RTC also natively supports ASGI middleware classes with Starlette for implementing behavior that is applied across your entire ASGI application easily. New in v0.2.2 This example was added in v0.2.2 . All supported middlewares can be found here \u27b6 For this example, let's use CORSMiddleware for implementing appropriate CORS headers to outgoing responses in our application in order to allow cross-origin requests from browsers, as follows: The default parameters used by the CORSMiddleware implementation are restrictive by default, so you'll need to explicitly enable particular origins, methods, or headers, in order for browsers to be permitted to use them in a Cross-Domain context. Starlette provides several arguments for enabling origins, methods, or headers for CORSMiddleware API. More information can be found here \u27b6 # import libs import uvicorn , asyncio from starlette.middleware import Middleware from starlette.middleware.cors import CORSMiddleware from vidgear.gears.asyncio import WebGear_RTC # add various performance tweaks as usual options = { \"frame_size_reduction\" : 25 , } # initialize WebGear_RTC app with a valid source web = WebGear_RTC ( source = \"/home/foo/foo1.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # define and assign suitable cors middlewares web . middleware = [ Middleware ( CORSMiddleware , allow_origins = [ \"*\" ], allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) ] # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000 address.","title":"Using WebGear_RTC with MiddleWares"},{"location":"gears/webgear_rtc/advanced/#rules-for-altering-webgear_rtc-files-and-folders","text":"WebGear_RTC gives us complete freedom of altering data files generated in Auto-Generation Process , But you've to keep the following rules in mind:","title":"Rules for Altering WebGear_RTC Files and Folders"},{"location":"gears/webgear_rtc/advanced/#rules-for-altering-data-files","text":"You allowed to alter/change code in all existing default downloaded files at your convenience without any restrictions. You allowed to delete/rename all existing data files, except remember NOT to delete/rename three critical data-files (i.e index.html , 404.html & 500.html ) present in templates folder inside the webgear_rtc directory at the default location , otherwise, it will trigger Auto-generation process , and it will overwrite the existing files with Server ones. You're allowed to add your own additional .html , .css , .js , etc. files in the respective folders at the default location and custom mounted Data folders .","title":"Rules for Altering Data Files"},{"location":"gears/webgear_rtc/advanced/#rules-for-altering-data-folders","text":"You're allowed to add/mount any number of additional folder as shown in this example above . You're allowed to delete/rename existing folders at the default location except remember NOT to delete/rename templates folder in the webgear_rtc directory where critical data-files (i.e index.html , 404.html & 500.html ) are located, otherwise, it will trigger Auto-generation process .","title":"Rules for Altering Data Folders"},{"location":"gears/webgear_rtc/advanced/#bonus-examples","text":"Checkout more advanced WebGear_RTC examples with unusual configuration here \u27b6","title":"Bonus Examples"},{"location":"gears/webgear_rtc/overview/","text":"WebGear_RTC API \u2693 WebGear_RTC API's Video Server running at http://localhost:8000/ address. Overview \u2693 WebGear_RTC is similar to WeGear API in many aspects but utilizes WebRTC technology under the hood instead of Motion JPEG, which makes it suitable for building powerful video-streaming solutions for all modern browsers as well as native clients available on all major platforms. New in v0.2.1 WebGear_RTC API was added in v0.2.1 . WebGear_RTC is implemented with the help of aiortc library which is built on top of asynchronous I/O framework for Web Real-Time Communication (WebRTC) and Object Real-Time Communication (ORTC) and supports many features like SDP generation/parsing, Interactive Connectivity Establishment with half-trickle and mDNS support, DTLS key and certificate generation, DTLS handshake, etc. WebGear_RTC can handle multiple consumers seamlessly and provides native support for ICE (Interactive Connectivity Establishment) protocol, STUN (Session Traversal Utilities for NAT) , and TURN (Traversal Using Relays around NAT) servers that help us to seamlessly establish direct media connection with the remote peers for uninterrupted data flow. It also allows us to define our custom streaming class with suitable source to transform frames easily before sending them across the network(see this doc example). WebGear_RTC API works in conjunction with Starlette ASGI application and can also flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes , Routing tables , Static Files , Templating engine(with Jinja2) , etc. Additionally, WebGear_RTC API also provides internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs. \u2009 Data-Files Auto-Generation WorkFlow for WebGear_RTC \u2693 Same as WebGear , WebGear_RTC API automatically checks for three critical data files (i.e index.html , 404.html & 500.html ) on initialization inside the templates folder of the webgear_rtc directory at the default location which gives rise to the following two possible scenario: If data-files found: it will proceed normally for instantiating the WebRTC media server through Starlette application. If data-files not found: it will trigger the Auto-Generation process Default Location \u2693 A default location is the path of the directory where data files/folders are downloaded/generated/saved. By default, the .vidgear the folder at the home directory of your machine (for e.g /home/foo/.vidgear on Linux) serves as the default location . But you can also use WebGear_RTC's custom_data_location dictionary attribute to change/alter default location path to somewhere else. Tip You can set logging=True during initialization, for easily identifying the selected default location , which will be something like this (on a Linux machine) : WebGear_RTC :: DEBUG :: ` /home/foo/.vidgear ` is the default location for saving WebGear_RTC data-files. Auto-Generation process \u2693 Info You can also force trigger the Auto-generation process to overwrite existing data-files using overwrite_default_files dictionary attribute. Remember, only downloaded default data files(given above) will be overwritten in this process but any other file/folder will NOT be affected. It is advised to enable logging( logging=True ) on the first run for easily identifying any runtime errors On triggering this process, WebGear_RTC API creates webgear_rtc directory, and templates and static folders inside along with js , css , img sub-folders at the assigned default location . Thereby at this default location , the necessary default data files will be downloaded from a dedicated Github Server inside respective folders in the following order: .vidgear \u2514\u2500\u2500 webgear_rtc \u251c\u2500\u2500 static \u2502 \u251c\u2500\u2500 css \u2502 \u2502 \u2514\u2500\u2500 custom.css \u2502 \u251c\u2500\u2500 img \u2502 \u2502 \u2514\u2500\u2500 favicon-32x32.png \u2502 \u2514\u2500\u2500 js \u2502 \u2514\u2500\u2500 custom.js \u2514\u2500\u2500 templates \u251c\u2500\u2500 404 .html \u251c\u2500\u2500 500 .html \u251c\u2500\u2500 base.html \u2514\u2500\u2500 index.html 6 directories, 7 files Finally these downloaded files thereby are verified for errors and API proceeds for instantiating the Starlette application normally. Importing \u2693 You can import WebGear_RTC API in your program as follows: from vidgear.gears.asyncio import WebGear_RTC \u2009 WebGear_RTC's Default Template \u2693 The WebGear_RTC API by default uses simple & elegant WebGear_RTC's Default Theme which looks like something as follows: Index.html \u2693 Can be accessed by visiting WebGear_RTC app server, running at http://localhost:8000/ : 404.html \u2693 Appears when respective URL is not found, for example http://localhost:8000/ok : 500.html \u2693 Appears when an API Error is encountered: If logging is enabled and an error occurs, then instead of displaying this 500 handler, WebGear_RTC will respond with a traceback response. Usage Examples \u2693 See here \ud83d\ude80 After going through WebGear_RTC Usage Examples, Checkout more bonus examples here \u27b6 Parameters \u2693 See here \ud83d\ude80 References \u2693 See here \ud83d\ude80 FAQs \u2693 See here \ud83d\ude80","title":"Overview"},{"location":"gears/webgear_rtc/overview/#webgear_rtc-api","text":"WebGear_RTC API's Video Server running at http://localhost:8000/ address.","title":"WebGear_RTC API"},{"location":"gears/webgear_rtc/overview/#overview","text":"WebGear_RTC is similar to WeGear API in many aspects but utilizes WebRTC technology under the hood instead of Motion JPEG, which makes it suitable for building powerful video-streaming solutions for all modern browsers as well as native clients available on all major platforms. New in v0.2.1 WebGear_RTC API was added in v0.2.1 . WebGear_RTC is implemented with the help of aiortc library which is built on top of asynchronous I/O framework for Web Real-Time Communication (WebRTC) and Object Real-Time Communication (ORTC) and supports many features like SDP generation/parsing, Interactive Connectivity Establishment with half-trickle and mDNS support, DTLS key and certificate generation, DTLS handshake, etc. WebGear_RTC can handle multiple consumers seamlessly and provides native support for ICE (Interactive Connectivity Establishment) protocol, STUN (Session Traversal Utilities for NAT) , and TURN (Traversal Using Relays around NAT) servers that help us to seamlessly establish direct media connection with the remote peers for uninterrupted data flow. It also allows us to define our custom streaming class with suitable source to transform frames easily before sending them across the network(see this doc example). WebGear_RTC API works in conjunction with Starlette ASGI application and can also flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes , Routing tables , Static Files , Templating engine(with Jinja2) , etc. Additionally, WebGear_RTC API also provides internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs.","title":"Overview"},{"location":"gears/webgear_rtc/overview/#data-files-auto-generation-workflow-for-webgear_rtc","text":"Same as WebGear , WebGear_RTC API automatically checks for three critical data files (i.e index.html , 404.html & 500.html ) on initialization inside the templates folder of the webgear_rtc directory at the default location which gives rise to the following two possible scenario: If data-files found: it will proceed normally for instantiating the WebRTC media server through Starlette application. If data-files not found: it will trigger the Auto-Generation process","title":"Data-Files Auto-Generation WorkFlow for WebGear_RTC"},{"location":"gears/webgear_rtc/overview/#default-location","text":"A default location is the path of the directory where data files/folders are downloaded/generated/saved. By default, the .vidgear the folder at the home directory of your machine (for e.g /home/foo/.vidgear on Linux) serves as the default location . But you can also use WebGear_RTC's custom_data_location dictionary attribute to change/alter default location path to somewhere else. Tip You can set logging=True during initialization, for easily identifying the selected default location , which will be something like this (on a Linux machine) : WebGear_RTC :: DEBUG :: ` /home/foo/.vidgear ` is the default location for saving WebGear_RTC data-files.","title":"Default Location"},{"location":"gears/webgear_rtc/overview/#auto-generation-process","text":"Info You can also force trigger the Auto-generation process to overwrite existing data-files using overwrite_default_files dictionary attribute. Remember, only downloaded default data files(given above) will be overwritten in this process but any other file/folder will NOT be affected. It is advised to enable logging( logging=True ) on the first run for easily identifying any runtime errors On triggering this process, WebGear_RTC API creates webgear_rtc directory, and templates and static folders inside along with js , css , img sub-folders at the assigned default location . Thereby at this default location , the necessary default data files will be downloaded from a dedicated Github Server inside respective folders in the following order: .vidgear \u2514\u2500\u2500 webgear_rtc \u251c\u2500\u2500 static \u2502 \u251c\u2500\u2500 css \u2502 \u2502 \u2514\u2500\u2500 custom.css \u2502 \u251c\u2500\u2500 img \u2502 \u2502 \u2514\u2500\u2500 favicon-32x32.png \u2502 \u2514\u2500\u2500 js \u2502 \u2514\u2500\u2500 custom.js \u2514\u2500\u2500 templates \u251c\u2500\u2500 404 .html \u251c\u2500\u2500 500 .html \u251c\u2500\u2500 base.html \u2514\u2500\u2500 index.html 6 directories, 7 files Finally these downloaded files thereby are verified for errors and API proceeds for instantiating the Starlette application normally.","title":"Auto-Generation process"},{"location":"gears/webgear_rtc/overview/#importing","text":"You can import WebGear_RTC API in your program as follows: from vidgear.gears.asyncio import WebGear_RTC","title":"Importing"},{"location":"gears/webgear_rtc/overview/#webgear_rtcs-default-template","text":"The WebGear_RTC API by default uses simple & elegant WebGear_RTC's Default Theme which looks like something as follows:","title":"WebGear_RTC's Default Template"},{"location":"gears/webgear_rtc/overview/#indexhtml","text":"Can be accessed by visiting WebGear_RTC app server, running at http://localhost:8000/ :","title":"Index.html"},{"location":"gears/webgear_rtc/overview/#404html","text":"Appears when respective URL is not found, for example http://localhost:8000/ok :","title":"404.html"},{"location":"gears/webgear_rtc/overview/#500html","text":"Appears when an API Error is encountered: If logging is enabled and an error occurs, then instead of displaying this 500 handler, WebGear_RTC will respond with a traceback response.","title":"500.html"},{"location":"gears/webgear_rtc/overview/#usage-examples","text":"See here \ud83d\ude80 After going through WebGear_RTC Usage Examples, Checkout more bonus examples here \u27b6","title":"Usage Examples"},{"location":"gears/webgear_rtc/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/webgear_rtc/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/webgear_rtc/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/webgear_rtc/params/","text":"WebGear_RTC API Parameters \u2693 WebGear_RTC provides a special internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs and their parameters. \u2009 enablePiCamera \u2693 This parameter provide direct access to PiGear or CamGear APIs respectively in WebGear_RTC. This means the if enablePiCamera flag is True , the PiGear API will be accessed, and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear_RTC ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 . options \u2693 This parameter can be used to pass user-defined parameter to WebGear_RTC API by formatting them as this parameter's attribute. Data-Type: Dictionary Default Value: Its default value is {} WebGear_RTC Specific attributes \u2693 custom_stream (class) : Can be used to easily define your own Custom Streaming Class with suitable custom source(such as OpenCV) that you want to use to transform your frames before sending them onto the browser. Make sure your Custom Streaming Class at-least implements read() and stop() methods, otherwise WebGear_RTC will throw ValueError! New in v0.2.4 This attribute was added in v0.2.4 . Using Vidgear's VideoCapture APIs instead of OpenCV You can directly replace Custom Streaming Class with any VideoCapture APIs . These APIs implements read() and stop() methods by-default, so they're also supported out-of-the-box. See this example \u27b6 for more information. Its complete usage example is given here \u27b6 . # set CamGear as custom streaming class with adequate parameters options = { \"custom_stream\" : CamGear ( source = \"foo.mp4\" , logging = True )} # assign it WebGear_RTC ( logging = True , ** options ) custom_data_location (string) : Can be used to change/alter default location path to somewhere else. Its usage is as follows: # set default location to '/home/foo/foo1' options = { \"custom_data_location\" : \"/home/foo/foo1\" } # assign it WebGear_RTC ( logging = True , ** options ) overwrite_default_files (boolean) : Can be used to force trigger the Auto-generation process to overwrite existing data-files. Its usage is as follows: Remember only downloaded files will be overwritten in this process, and any other file/folder will NOT be affected/overwritten. # force trigger the Auto-generation process options = { \"overwrite_default_files\" : True } # assign it WebGear_RTC ( logging = True , ** options ) frame_size_reduction (int/float) : This attribute controls the size reduction (in percentage) of the frame to be streamed on Server and it has the most significant effect on performance. The value defaults to 20 , and must be no higher than 90 (fastest, max compression, Barely Visible frame-size) and no lower than 0 (slowest, no compression, Original frame-size) . Its recommended value is between 40-60 . Its usage is as follows: # frame-size will be reduced by 50% options = { \"frame_size_reduction\" : 50 } # assign it WebGear_RTC ( logging = True , ** options ) enable_live_broadcast (boolean) : WebGear_RTC by default only supports one-to-one peer connection with a single consumer/client, Hence this boolean attribute can be used to enable live broadcast to multiple peer consumers/clients at same time. Its default value is False . Its usage is as follows: enable_infinite_frames is enforced by default when this attribute is enabled( True ). For accessing WebGear_RTC on different Client Devices on the network, use \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine. More information can be found here \u27b6 New in v0.2.2 enable_live_broadcast attribute was added in v0.2.2 . # enable live boadcast to multiple consumers. options = { \"enable_live_broadcast\" : True } # assign it WebGear_RTC ( logging = True , ** options ) Its complete usage example is given here \u27b6 . enable_infinite_frames (boolean) : Can be used to continue streaming (instead of terminating immediately) with emulated blank frames with text \"No Input\", whenever the input source disconnects. Its default value is False . Its usage is as follows: enable_infinite_frames is disabled when enable_live_broadcast attribute is enabled( True ). New in v0.2.1 enable_infinite_frames attribute was added in v0.2.1 . # emulate infinite frames options = { \"enable_infinite_frames\" : True } # assign it WebGear_RTC ( logging = True , ** options ) Parameters for Stabilizer Backend \u2693 Enable this backend with stabilize=True in WebGear_RTC. Default is also False . stabilize \u2693 This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to True ( to enable ) or unset to False ( to disable ). Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear_RTC ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 . options \u2693 This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be formatted as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' } Parameters for CamGear backend \u2693 Enable this backend with enablePiCamera=False in WebGear_RTC. source \u2693 WebGear_RTC API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: WebGear_RTC ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: WebGear_RTC ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) CamGear internally implements yt_dlp backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 CamGear ( source = 'https://www.twitch.tv/shroud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: WebGear_RTC ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: WebGear_RTC ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' ) stream_mode \u2693 This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the CamGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 WebGear_RTC ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 . backend \u2693 This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: WebGear_RTC ( source = 0 , backend = cv2 . CAP_DSHOW ) options \u2693 This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to WebGear_RTC API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it WebGear_RTC ( source = 0 , ** options ) Parameters for PiGear backend \u2693 Enable this backend with enablePiCamera=True in WebGear_RTC. camera_num \u2693 This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear_RTC ( enablePiCamera = True , camera_num = 0 ) resolution \u2693 This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: WebGear_RTC ( enablePiCamera = True , resolution = ( 1280 , 720 )) # sets 1280x720 resolution framerate \u2693 This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: WebGear_RTC ( enablePiCamera = True , framerate = 60 ) # sets 60fps framerate options \u2693 This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to WebGear_RTC API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it WebGear_RTC ( enablePiCamera = True , logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds Common Parameters \u2693 These are common parameters that works with every backend in WebGear_RTC. colorspace \u2693 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 WebGear_RTC ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 logging \u2693 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear_RTC ( logging = True ) time_delay \u2693 This parameter set the time delay (in seconds) before the WebGear_RTC API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear_RTC ( time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/webgear_rtc/params/#webgear_rtc-api-parameters","text":"WebGear_RTC provides a special internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs and their parameters.","title":"WebGear_RTC API Parameters"},{"location":"gears/webgear_rtc/params/#enablepicamera","text":"This parameter provide direct access to PiGear or CamGear APIs respectively in WebGear_RTC. This means the if enablePiCamera flag is True , the PiGear API will be accessed, and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear_RTC ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 .","title":"enablePiCamera"},{"location":"gears/webgear_rtc/params/#options","text":"This parameter can be used to pass user-defined parameter to WebGear_RTC API by formatting them as this parameter's attribute. Data-Type: Dictionary Default Value: Its default value is {}","title":"options"},{"location":"gears/webgear_rtc/params/#webgear_rtc-specific-attributes","text":"custom_stream (class) : Can be used to easily define your own Custom Streaming Class with suitable custom source(such as OpenCV) that you want to use to transform your frames before sending them onto the browser. Make sure your Custom Streaming Class at-least implements read() and stop() methods, otherwise WebGear_RTC will throw ValueError! New in v0.2.4 This attribute was added in v0.2.4 . Using Vidgear's VideoCapture APIs instead of OpenCV You can directly replace Custom Streaming Class with any VideoCapture APIs . These APIs implements read() and stop() methods by-default, so they're also supported out-of-the-box. See this example \u27b6 for more information. Its complete usage example is given here \u27b6 . # set CamGear as custom streaming class with adequate parameters options = { \"custom_stream\" : CamGear ( source = \"foo.mp4\" , logging = True )} # assign it WebGear_RTC ( logging = True , ** options ) custom_data_location (string) : Can be used to change/alter default location path to somewhere else. Its usage is as follows: # set default location to '/home/foo/foo1' options = { \"custom_data_location\" : \"/home/foo/foo1\" } # assign it WebGear_RTC ( logging = True , ** options ) overwrite_default_files (boolean) : Can be used to force trigger the Auto-generation process to overwrite existing data-files. Its usage is as follows: Remember only downloaded files will be overwritten in this process, and any other file/folder will NOT be affected/overwritten. # force trigger the Auto-generation process options = { \"overwrite_default_files\" : True } # assign it WebGear_RTC ( logging = True , ** options ) frame_size_reduction (int/float) : This attribute controls the size reduction (in percentage) of the frame to be streamed on Server and it has the most significant effect on performance. The value defaults to 20 , and must be no higher than 90 (fastest, max compression, Barely Visible frame-size) and no lower than 0 (slowest, no compression, Original frame-size) . Its recommended value is between 40-60 . Its usage is as follows: # frame-size will be reduced by 50% options = { \"frame_size_reduction\" : 50 } # assign it WebGear_RTC ( logging = True , ** options ) enable_live_broadcast (boolean) : WebGear_RTC by default only supports one-to-one peer connection with a single consumer/client, Hence this boolean attribute can be used to enable live broadcast to multiple peer consumers/clients at same time. Its default value is False . Its usage is as follows: enable_infinite_frames is enforced by default when this attribute is enabled( True ). For accessing WebGear_RTC on different Client Devices on the network, use \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine. More information can be found here \u27b6 New in v0.2.2 enable_live_broadcast attribute was added in v0.2.2 . # enable live boadcast to multiple consumers. options = { \"enable_live_broadcast\" : True } # assign it WebGear_RTC ( logging = True , ** options ) Its complete usage example is given here \u27b6 . enable_infinite_frames (boolean) : Can be used to continue streaming (instead of terminating immediately) with emulated blank frames with text \"No Input\", whenever the input source disconnects. Its default value is False . Its usage is as follows: enable_infinite_frames is disabled when enable_live_broadcast attribute is enabled( True ). New in v0.2.1 enable_infinite_frames attribute was added in v0.2.1 . # emulate infinite frames options = { \"enable_infinite_frames\" : True } # assign it WebGear_RTC ( logging = True , ** options )","title":"WebGear_RTC Specific attributes"},{"location":"gears/webgear_rtc/params/#parameters-for-stabilizer-backend","text":"Enable this backend with stabilize=True in WebGear_RTC. Default is also False .","title":"Parameters for Stabilizer Backend"},{"location":"gears/webgear_rtc/params/#stabilize","text":"This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to True ( to enable ) or unset to False ( to disable ). Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear_RTC ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 .","title":"stabilize"},{"location":"gears/webgear_rtc/params/#options_1","text":"This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be formatted as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' }","title":"options"},{"location":"gears/webgear_rtc/params/#parameters-for-camgear-backend","text":"Enable this backend with enablePiCamera=False in WebGear_RTC.","title":"Parameters for CamGear backend"},{"location":"gears/webgear_rtc/params/#source","text":"WebGear_RTC API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: WebGear_RTC ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: WebGear_RTC ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) CamGear internally implements yt_dlp backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 CamGear ( source = 'https://www.twitch.tv/shroud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: WebGear_RTC ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: WebGear_RTC ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' )","title":"source"},{"location":"gears/webgear_rtc/params/#stream_mode","text":"This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the CamGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: Supported Streaming Websites The complete list of all supported Streaming Websites URLs can be found here \u27b6 WebGear_RTC ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 .","title":"stream_mode"},{"location":"gears/webgear_rtc/params/#backend","text":"This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: WebGear_RTC ( source = 0 , backend = cv2 . CAP_DSHOW )","title":"backend"},{"location":"gears/webgear_rtc/params/#options_2","text":"This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to WebGear_RTC API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it WebGear_RTC ( source = 0 , ** options )","title":"options"},{"location":"gears/webgear_rtc/params/#parameters-for-pigear-backend","text":"Enable this backend with enablePiCamera=True in WebGear_RTC.","title":"Parameters for PiGear backend"},{"location":"gears/webgear_rtc/params/#camera_num","text":"This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear_RTC ( enablePiCamera = True , camera_num = 0 )","title":"camera_num"},{"location":"gears/webgear_rtc/params/#resolution","text":"This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: WebGear_RTC ( enablePiCamera = True , resolution = ( 1280 , 720 )) # sets 1280x720 resolution","title":"resolution"},{"location":"gears/webgear_rtc/params/#framerate","text":"This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: WebGear_RTC ( enablePiCamera = True , framerate = 60 ) # sets 60fps framerate","title":"framerate"},{"location":"gears/webgear_rtc/params/#options_3","text":"This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to WebGear_RTC API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it WebGear_RTC ( enablePiCamera = True , logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds","title":"options"},{"location":"gears/webgear_rtc/params/#common-parameters","text":"These are common parameters that works with every backend in WebGear_RTC.","title":"Common Parameters"},{"location":"gears/webgear_rtc/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 WebGear_RTC ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/webgear_rtc/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear_RTC ( logging = True )","title":"logging"},{"location":"gears/webgear_rtc/params/#time_delay","text":"This parameter set the time delay (in seconds) before the WebGear_RTC API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear_RTC ( time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/webgear_rtc/usage/","text":"WebGear_RTC API Usage Examples: \u2693 Requirements \u2693 Installation with Asyncio Support \u2693 WebGear_RTC API is the part of asyncio package of VidGear, thereby you need to install VidGear with asyncio support as follows: pip install vidgear [ asyncio ] Aiortc \u2693 Must Required with WebGear_RTC API. You can easily install it via pip: Microsoft Visual C++ 14.0 is required. Installing aiortc on windows requires Microsoft Build Tools for Visual C++ libraries installed. You can easily fix this error by installing any ONE of these choices: While the error is calling for VC++ 14.0 - but newer versions of Visual C++ libraries works as well. Microsoft Build Tools for Visual Studio . Alternative link to Microsoft Build Tools for Visual Studio . Offline installer: vs_buildtools.exe Afterwards, Select: Workloads \u2192 Desktop development with C++, then for Individual Components, select only: Windows 10 SDK C++ x64/x86 build tools Finally, proceed installing aiortc via pip. pip install aiortc ASGI Server \u2693 You'll also need to install an ASGI Server to run following WebGear_RTC usage examples, and by default WebGear_RTC ships the state-of-the-art uvicorn Server. But you can also use other ASGI server such as daphne , or hypercorn with it. Bare-Minimum Usage \u2693 Let's implement a Bare-Minimum usage example: Running Programmatically \u2693 You can access and run WebGear_RTC VideoStreamer Server programmatically in your python script in just a few lines of code, as follows: For accessing WebGear_RTC on different Client Devices on the network, use \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine. More information can be found here \u27b6 We are using frame_size_reduction attribute for frame size reduction (in percentage) to be streamed with its options dictionary parameter to cope with performance-throttling in this example. # import required libraries import uvicorn from vidgear.gears.asyncio import WebGear_RTC # various performance tweaks options = { \"frame_size_reduction\" : 25 , } # initialize WebGear_RTC app web = WebGear_RTC ( source = \"foo.mp4\" , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () which can be accessed on any browser on your machine at http://localhost:8000/ . Running from Terminal \u2693 You can also access and run WebGear_RTC Server directly from the terminal commandline. The following command will run a WebGear_RTC VideoStreamer server at http://localhost:8000/ : Make sure your PYTHON_PATH is set to python 3.7+ versions only. If you're using --options/-op flag, then kindly wrap your dictionary value in single '' quotes. python3 -m vidgear.gears.asyncio --mode webrtc --source test.avi --logging True --options '{\"frame_size_reduction\": 50, \"frame_jpeg_quality\": 80, \"frame_jpeg_optimize\": True, \"frame_jpeg_progressive\": False}' which can also be accessed on any browser on the network at http://localhost:8000/ . Advanced Usage from Terminal You can run python3 - m vidgear . gears . asyncio - h help command to see all the advanced settings, as follows: usage: python -m vidgear.gears.asyncio [ -h ] [ -m MODE ] [ -s SOURCE ] [ -ep ENABLEPICAMERA ] [ -S STABILIZE ] [ -cn CAMERA_NUM ] [ -yt stream_mode ] [ -b BACKEND ] [ -cs COLORSPACE ] [ -r RESOLUTION ] [ -f FRAMERATE ] [ -td TIME_DELAY ] [ -ip IPADDRESS ] [ -pt PORT ] [ -l LOGGING ] [ -op OPTIONS ] Runs WebGear/WebGear_RTC Video Server through terminal. optional arguments: -h, --help show this help message and exit -m { mjpeg,webrtc } , --mode { mjpeg,webrtc } Whether to use \"MJPEG\" or \"WebRTC\" mode for streaming. -s SOURCE, --source SOURCE Path to input source for CamGear API. -ep ENABLEPICAMERA, --enablePiCamera ENABLEPICAMERA Sets the flag to access PiGear ( if True ) or otherwise CamGear API respectively. -S STABILIZE, --stabilize STABILIZE Enables/disables real-time video stabilization. -cn CAMERA_NUM, --camera_num CAMERA_NUM Sets the camera module index that will be used by PiGear API. -yt STREAM_MODE, --stream_mode STREAM_MODE Enables YouTube Mode in CamGear API. -b BACKEND, --backend BACKEND Sets the backend of the video source in CamGear API. -cs COLORSPACE, --colorspace COLORSPACE Sets the colorspace of the output video stream. -r RESOLUTION, --resolution RESOLUTION Sets the resolution ( width,height ) for camera module in PiGear API. -f FRAMERATE, --framerate FRAMERATE Sets the framerate for camera module in PiGear API. -td TIME_DELAY, --time_delay TIME_DELAY Sets the time delay ( in seconds ) before start reading the frames. -ip IPADDRESS, --ipaddress IPADDRESS Uvicorn binds the socket to this ipaddress. -pt PORT, --port PORT Uvicorn binds the socket to this port. -l LOGGING, --logging LOGGING Enables/disables error logging, essential for debugging. -op OPTIONS, --options OPTIONS Sets the parameters supported by APIs ( whichever being accessed ) to the input videostream, But make sure to wrap your dict value in single or double quotes.","title":"Usage Examples"},{"location":"gears/webgear_rtc/usage/#webgear_rtc-api-usage-examples","text":"","title":"WebGear_RTC API Usage Examples:"},{"location":"gears/webgear_rtc/usage/#requirements","text":"","title":"Requirements"},{"location":"gears/webgear_rtc/usage/#installation-with-asyncio-support","text":"WebGear_RTC API is the part of asyncio package of VidGear, thereby you need to install VidGear with asyncio support as follows: pip install vidgear [ asyncio ]","title":"Installation with Asyncio Support"},{"location":"gears/webgear_rtc/usage/#aiortc","text":"Must Required with WebGear_RTC API. You can easily install it via pip: Microsoft Visual C++ 14.0 is required. Installing aiortc on windows requires Microsoft Build Tools for Visual C++ libraries installed. You can easily fix this error by installing any ONE of these choices: While the error is calling for VC++ 14.0 - but newer versions of Visual C++ libraries works as well. Microsoft Build Tools for Visual Studio . Alternative link to Microsoft Build Tools for Visual Studio . Offline installer: vs_buildtools.exe Afterwards, Select: Workloads \u2192 Desktop development with C++, then for Individual Components, select only: Windows 10 SDK C++ x64/x86 build tools Finally, proceed installing aiortc via pip. pip install aiortc","title":"Aiortc"},{"location":"gears/webgear_rtc/usage/#asgi-server","text":"You'll also need to install an ASGI Server to run following WebGear_RTC usage examples, and by default WebGear_RTC ships the state-of-the-art uvicorn Server. But you can also use other ASGI server such as daphne , or hypercorn with it.","title":"ASGI Server"},{"location":"gears/webgear_rtc/usage/#bare-minimum-usage","text":"Let's implement a Bare-Minimum usage example:","title":"Bare-Minimum Usage"},{"location":"gears/webgear_rtc/usage/#running-programmatically","text":"You can access and run WebGear_RTC VideoStreamer Server programmatically in your python script in just a few lines of code, as follows: For accessing WebGear_RTC on different Client Devices on the network, use \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine. More information can be found here \u27b6 We are using frame_size_reduction attribute for frame size reduction (in percentage) to be streamed with its options dictionary parameter to cope with performance-throttling in this example. # import required libraries import uvicorn from vidgear.gears.asyncio import WebGear_RTC # various performance tweaks options = { \"frame_size_reduction\" : 25 , } # initialize WebGear_RTC app web = WebGear_RTC ( source = \"foo.mp4\" , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () which can be accessed on any browser on your machine at http://localhost:8000/ .","title":"Running Programmatically"},{"location":"gears/webgear_rtc/usage/#running-from-terminal","text":"You can also access and run WebGear_RTC Server directly from the terminal commandline. The following command will run a WebGear_RTC VideoStreamer server at http://localhost:8000/ : Make sure your PYTHON_PATH is set to python 3.7+ versions only. If you're using --options/-op flag, then kindly wrap your dictionary value in single '' quotes. python3 -m vidgear.gears.asyncio --mode webrtc --source test.avi --logging True --options '{\"frame_size_reduction\": 50, \"frame_jpeg_quality\": 80, \"frame_jpeg_optimize\": True, \"frame_jpeg_progressive\": False}' which can also be accessed on any browser on the network at http://localhost:8000/ . Advanced Usage from Terminal You can run python3 - m vidgear . gears . asyncio - h help command to see all the advanced settings, as follows: usage: python -m vidgear.gears.asyncio [ -h ] [ -m MODE ] [ -s SOURCE ] [ -ep ENABLEPICAMERA ] [ -S STABILIZE ] [ -cn CAMERA_NUM ] [ -yt stream_mode ] [ -b BACKEND ] [ -cs COLORSPACE ] [ -r RESOLUTION ] [ -f FRAMERATE ] [ -td TIME_DELAY ] [ -ip IPADDRESS ] [ -pt PORT ] [ -l LOGGING ] [ -op OPTIONS ] Runs WebGear/WebGear_RTC Video Server through terminal. optional arguments: -h, --help show this help message and exit -m { mjpeg,webrtc } , --mode { mjpeg,webrtc } Whether to use \"MJPEG\" or \"WebRTC\" mode for streaming. -s SOURCE, --source SOURCE Path to input source for CamGear API. -ep ENABLEPICAMERA, --enablePiCamera ENABLEPICAMERA Sets the flag to access PiGear ( if True ) or otherwise CamGear API respectively. -S STABILIZE, --stabilize STABILIZE Enables/disables real-time video stabilization. -cn CAMERA_NUM, --camera_num CAMERA_NUM Sets the camera module index that will be used by PiGear API. -yt STREAM_MODE, --stream_mode STREAM_MODE Enables YouTube Mode in CamGear API. -b BACKEND, --backend BACKEND Sets the backend of the video source in CamGear API. -cs COLORSPACE, --colorspace COLORSPACE Sets the colorspace of the output video stream. -r RESOLUTION, --resolution RESOLUTION Sets the resolution ( width,height ) for camera module in PiGear API. -f FRAMERATE, --framerate FRAMERATE Sets the framerate for camera module in PiGear API. -td TIME_DELAY, --time_delay TIME_DELAY Sets the time delay ( in seconds ) before start reading the frames. -ip IPADDRESS, --ipaddress IPADDRESS Uvicorn binds the socket to this ipaddress. -pt PORT, --port PORT Uvicorn binds the socket to this port. -l LOGGING, --logging LOGGING Enables/disables error logging, essential for debugging. -op OPTIONS, --options OPTIONS Sets the parameters supported by APIs ( whichever being accessed ) to the input videostream, But make sure to wrap your dict value in single or double quotes.","title":"Running from Terminal"},{"location":"gears/writegear/introduction/","text":"WriteGear API \u2693 WriteGear API generalized workflow Overview \u2693 WriteGear handles various powerful Video-Writer Tools that provide us the freedom to do almost anything imaginable with multimedia data. WriteGear API provides a complete, flexible, and robust wrapper around FFmpeg , a leading multimedia framework. WriteGear can process real-time frames into a lossless compressed video-file with any suitable specifications (such as bitrate, codec, framerate, resolution, subtitles, etc. ) . WriteGear also supports streaming with traditional protocols such as RTSP/RTP , RTMP. It is powerful enough to perform complex tasks such as Live-Streaming (such as for Twitch, YouTube etc.) and Multiplexing Video-Audio with real-time frames in just few lines of code. Best of all, WriteGear grants users the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function (see this doc ) without relying on any third-party API. In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API tools for video-frames encoding without compression. \u2009 Modes of Operation \u2693 WriteGear primarily operates in following modes: Compression Mode : In this mode, WriteGear utilizes powerful FFmpeg inbuilt encoders to encode lossless multimedia files. This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly, and while doing that it robustly handles all errors/warnings quietly. Non-Compression Mode : In this mode, WriteGear utilizes basic OpenCV's inbuilt VideoWriter API tools. This mode also supports all parameter transformations available within OpenCV's VideoWriter API, but it lacks the ability to manipulate encoding parameters and other important features like video compression, audio encoding, etc. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. \u2009 Importing \u2693 You can import WriteGear API in your program as follows: from vidgear.gears import WriteGear \u2009 FAQs \u2693 See here \ud83d\ude80","title":"Introduction"},{"location":"gears/writegear/introduction/#writegear-api","text":"WriteGear API generalized workflow","title":"WriteGear API"},{"location":"gears/writegear/introduction/#overview","text":"WriteGear handles various powerful Video-Writer Tools that provide us the freedom to do almost anything imaginable with multimedia data. WriteGear API provides a complete, flexible, and robust wrapper around FFmpeg , a leading multimedia framework. WriteGear can process real-time frames into a lossless compressed video-file with any suitable specifications (such as bitrate, codec, framerate, resolution, subtitles, etc. ) . WriteGear also supports streaming with traditional protocols such as RTSP/RTP , RTMP. It is powerful enough to perform complex tasks such as Live-Streaming (such as for Twitch, YouTube etc.) and Multiplexing Video-Audio with real-time frames in just few lines of code. Best of all, WriteGear grants users the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function (see this doc ) without relying on any third-party API. In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API tools for video-frames encoding without compression.","title":"Overview"},{"location":"gears/writegear/introduction/#modes-of-operation","text":"WriteGear primarily operates in following modes: Compression Mode : In this mode, WriteGear utilizes powerful FFmpeg inbuilt encoders to encode lossless multimedia files. This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly, and while doing that it robustly handles all errors/warnings quietly. Non-Compression Mode : In this mode, WriteGear utilizes basic OpenCV's inbuilt VideoWriter API tools. This mode also supports all parameter transformations available within OpenCV's VideoWriter API, but it lacks the ability to manipulate encoding parameters and other important features like video compression, audio encoding, etc. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Modes of Operation"},{"location":"gears/writegear/introduction/#importing","text":"You can import WriteGear API in your program as follows: from vidgear.gears import WriteGear","title":"Importing"},{"location":"gears/writegear/introduction/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/writegear/compression/overview/","text":"WriteGear API: Compression Mode \u2693 WriteGear API's Compression Mode generalized workflow Overview \u2693 When compression_mode parameter is enabled (.i.e compression_mode = True ), WriteGear API provides a complete, flexible & robust wrapper around FFmpeg to encode lossless & compressed multimedia files. This mode can process real-time video frames into a lossless compressed format with any suitable setting video/audio properties such as bitrate, codec, framerate, resolution, subtitles, and much more in just a few easy lines of code. It can also perform complex tasks such as Live-Streaming (such as for Twitch) , multiplexing video with audio in real-time (see this usage example ) while handling all errors robustly. Important Information WriteGear MUST requires FFmpeg executables for its Compression capabilities. Follow these dedicated Installation Instructions \u27b6 for its installation. In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode . It is advised to enable logging( logging = True ) to see the FFmpeg command that is being executed in WriteGear's pipeline. This helps you debug any issues/errors easily and make suitable adjustments accordingly. You can speed up the execution time by disabling logging (.i.e logging = False ) for production use, and by tweaking FFmpeg parameters in output_params values. Look into FFmpeg docs \u27b6 for such hacks. Custom FFmpeg Commands in WriteGear API \u2693 WriteGear API now provides the execute_ffmpeg_cmd Function in Compression Mode, that enables the user to pass any custom CLI commands as an input to its internal FFmpeg Pipeline by formating it as a list. This function opens endless possibilities of exploiting any FFmpeg supported parameter within WriteGear, without relying on a third-party library/API to do the same, and while doing that it robustly handles all errors/warnings quietly. A complete guide on execute_ffmpeg_cmd Function can be found here \u27b6 Usage Examples \u2693 See here \ud83d\ude80 After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6 Parameters \u2693 See here \ud83d\ude80","title":"Overview"},{"location":"gears/writegear/compression/overview/#writegear-api-compression-mode","text":"WriteGear API's Compression Mode generalized workflow","title":"WriteGear API: Compression Mode"},{"location":"gears/writegear/compression/overview/#overview","text":"When compression_mode parameter is enabled (.i.e compression_mode = True ), WriteGear API provides a complete, flexible & robust wrapper around FFmpeg to encode lossless & compressed multimedia files. This mode can process real-time video frames into a lossless compressed format with any suitable setting video/audio properties such as bitrate, codec, framerate, resolution, subtitles, and much more in just a few easy lines of code. It can also perform complex tasks such as Live-Streaming (such as for Twitch) , multiplexing video with audio in real-time (see this usage example ) while handling all errors robustly. Important Information WriteGear MUST requires FFmpeg executables for its Compression capabilities. Follow these dedicated Installation Instructions \u27b6 for its installation. In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode . It is advised to enable logging( logging = True ) to see the FFmpeg command that is being executed in WriteGear's pipeline. This helps you debug any issues/errors easily and make suitable adjustments accordingly. You can speed up the execution time by disabling logging (.i.e logging = False ) for production use, and by tweaking FFmpeg parameters in output_params values. Look into FFmpeg docs \u27b6 for such hacks.","title":"Overview"},{"location":"gears/writegear/compression/overview/#custom-ffmpeg-commands-in-writegear-api","text":"WriteGear API now provides the execute_ffmpeg_cmd Function in Compression Mode, that enables the user to pass any custom CLI commands as an input to its internal FFmpeg Pipeline by formating it as a list. This function opens endless possibilities of exploiting any FFmpeg supported parameter within WriteGear, without relying on a third-party library/API to do the same, and while doing that it robustly handles all errors/warnings quietly. A complete guide on execute_ffmpeg_cmd Function can be found here \u27b6","title":"Custom FFmpeg Commands in WriteGear API"},{"location":"gears/writegear/compression/overview/#usage-examples","text":"See here \ud83d\ude80 After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6","title":"Usage Examples"},{"location":"gears/writegear/compression/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/writegear/compression/params/","text":"WriteGear API Parameters: Compression Mode \u2693 \u2009 output_filename \u2693 This parameter sets the valid filename/path/URL for the video output. Warning WriteGear API will throw ValueError if output_filename provided is empty or invalid. Data-Type: String Usage: Its valid input can be one of the following: Path to directory : Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename ( with a default extension i.e. .mp4 ) as follows: writer = WriteGear ( output_filename = '/home/foo/foo1' ) #Define writer Filename (with/without path) : Valid filename( with valid extension ) of the output video file. In case filename is provided without path, then current working directory will be used. writer = WriteGear ( output_filename = 'output.mp4' ) #Define writer Make sure to provide valid filename with valid file-extension based on the encoder in use. URL : Valid URL of a network stream with a protocol supported by installed FFmpeg (verify with command ffmpeg -protocols ) only. This is useful for building a Video-Streaming Server with FFmpeg in WriteGear API. For example, you can stream on a rtmp protocol URL as follows: writer = WriteGear ( output_filename = 'rtmp://localhost/live/test' ) #Define writer compression_mode \u2693 This parameter selects the WriteGear's Primary Mode of Operation , i.e. if this parameter is enabled (.i.e compression_mode = True ) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e compression_mode = False ) , the OpenCV's VideoWriter API will be used for encoding files/streams. Data-Type: Boolean Default Value: Its default value is True . Usage: WriteGear ( output_filename = 'output.mp4' , compression_mode = True ) custom_ffmpeg \u2693 This parameter assigns the custom path/directory where the custom FFmpeg executables are located in Compression Mode only. Compression Mode Behavior on Windows In Compression Mode, if a custom FFmpeg executable's path | directory is not provided through custom_ffmpeg parameter on Windows machine, then WriteGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . Data-Type: String Default Value: Its default value is None . Usage: # if ffmpeg executables are located at \"/foo/foo1/FFmpeg\" WriteGear ( output_filename = 'output.mp4' , custom_ffmpeg = \"/foo/foo1/FFmpeg\" ) output_params \u2693 This parameter allows us to exploit almost all FFmpeg supported parameters effortlessly and flexibly for encoding in Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and encoders for compression mode discussed below: Kindly read FFmpeg Docs carefully, before passing any values to output_param dictionary parameter. Wrong values may result in undesired Errors or no output at all. Data-Type: Dictionary Default Value: Its default value is {} . Supported Parameters \u2693 FFmpeg Parameters: All parameters based on selected encoder in use, are supported, and can be passed as dictionary attributes in output_param . For example, for using libx264 encoder to produce a lossless output video, we can pass required FFmpeg parameters as dictionary attributes, as follows: While providing additional av-source with -i FFmpeg parameter in output_params make sure it don't interfere with WriteGear's frame pipeline otherwise it will break things! All ffmpeg parameters are case-sensitive. Remember to double check every parameter if any error occurs. Kindly check H.264 docs \u27b6 and other FFmpeg Docs \u27b6 for more information on these parameters output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" , \"-tune\" : \"zerolatency\" } Special Internal Parameters: In addition to FFmpeg parameters, WriteGear API also supports some Special Parameters to tweak its internal properties. These parameters are discussed below: -ffmpeg_download_path (string) : sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows: output_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # will be saved to \"C:/User/foo/foo1\" -input_framerate (float/int) : sets the constant framerate of the output. It can be used as follows: output_params = { \"-input_framerate\" : 60.0 } # set the constant framerate to 60fps Its usage example can be found here \u27b6 -output_dimensions (tuple/list) : sets the custom dimensions( size/resolution ) of the output video (otherwise input video-frame size will be used) . Its value can either be a tuple => (width,height) or a list => [width, height] , Its usage is as follows: output_params = { \"-output_dimensions\" : ( 1280 , 720 )} # to produce a 1280x720 resolution/scale output video -clones (list) : required to set special FFmpeg parameters that are repeated more than once in the command (For more info., see this issue ) or in cases where you want to preserve order of multiple FFmpeg parameters. This attribute only accepts list datatype as value. Its usage is as follows: Turn on logging( logging = True ) to see the FFmpeg command that is being executed in WriteGear's pipeline. This helps you debug/address any issues and make adjustments accordingly. WriteGear by automatically applies -format or -f , -pix_fmt and -vcodec or -v:f like critical input parameters for every stream. Therefore if you need multiple values for these parameter just define them with -clones attribute. output_params = { \"-i\" : \"plug:dsnoopUSB\" , \"-f\" : \"alsa\" , \"-ac\" : \"1\" , \"-ar\" : \"48000\" , \"-clones\" : [ \"-vcodec\" , \"mpeg1video\" , \"-f\" , \"mpegts\" ], } -ffpreheaders (list) : required to set special FFmpeg parameters that are present at the starting of command(such as -re ). This attribute only accepts list datatype as value. Its usage is as follows: This attribute is quite powerful and can break FFmpeg pipeline easily if not used correctly. User Discretion is advised! Turn on logging( logging = True ) to see the FFmpeg command that is being executed in WriteGear's pipeline. This helps you debug/address any issues and make adjustments accordingly. output_params = { \"-ffpreheaders\" : [ \"-re\" ], # executes as `ffmpeg -re <rest of command>` } -disable_force_termination (bool) : sets a special flag to manually disable the default forced-termination behaviour in WriteGear API when -i FFmpeg parameter is used (For more details, see issue: #149 ) . Its usage is as follows: -disable_force_termination flag is a absolute necessity when video duration is too short(<60sec), otherwise WriteGear will not produce any valid output. output_params = { \"-disable_force_termination\" : True } # disable the default forced-termination behaviour Supported Encoders \u2693 All the encoders that are compiled with FFmpeg in use, are supported by WriteGear API. You can easily check the compiled encoders by running following command in your terminal: Similarily, supported demuxers and filters depends upons compiled FFmpeg in use. ffmpeg -encoders # use `ffmpeg.exe -encoders` on windows logging \u2693 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WriteGear ( output_filename = 'output.mp4' , logging = True )","title":"Parameters"},{"location":"gears/writegear/compression/params/#writegear-api-parameters-compression-mode","text":"","title":"WriteGear API Parameters: Compression Mode"},{"location":"gears/writegear/compression/params/#output_filename","text":"This parameter sets the valid filename/path/URL for the video output. Warning WriteGear API will throw ValueError if output_filename provided is empty or invalid. Data-Type: String Usage: Its valid input can be one of the following: Path to directory : Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename ( with a default extension i.e. .mp4 ) as follows: writer = WriteGear ( output_filename = '/home/foo/foo1' ) #Define writer Filename (with/without path) : Valid filename( with valid extension ) of the output video file. In case filename is provided without path, then current working directory will be used. writer = WriteGear ( output_filename = 'output.mp4' ) #Define writer Make sure to provide valid filename with valid file-extension based on the encoder in use. URL : Valid URL of a network stream with a protocol supported by installed FFmpeg (verify with command ffmpeg -protocols ) only. This is useful for building a Video-Streaming Server with FFmpeg in WriteGear API. For example, you can stream on a rtmp protocol URL as follows: writer = WriteGear ( output_filename = 'rtmp://localhost/live/test' ) #Define writer","title":"output_filename"},{"location":"gears/writegear/compression/params/#compression_mode","text":"This parameter selects the WriteGear's Primary Mode of Operation , i.e. if this parameter is enabled (.i.e compression_mode = True ) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e compression_mode = False ) , the OpenCV's VideoWriter API will be used for encoding files/streams. Data-Type: Boolean Default Value: Its default value is True . Usage: WriteGear ( output_filename = 'output.mp4' , compression_mode = True )","title":"compression_mode"},{"location":"gears/writegear/compression/params/#custom_ffmpeg","text":"This parameter assigns the custom path/directory where the custom FFmpeg executables are located in Compression Mode only. Compression Mode Behavior on Windows In Compression Mode, if a custom FFmpeg executable's path | directory is not provided through custom_ffmpeg parameter on Windows machine, then WriteGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . Data-Type: String Default Value: Its default value is None . Usage: # if ffmpeg executables are located at \"/foo/foo1/FFmpeg\" WriteGear ( output_filename = 'output.mp4' , custom_ffmpeg = \"/foo/foo1/FFmpeg\" )","title":"custom_ffmpeg"},{"location":"gears/writegear/compression/params/#output_params","text":"This parameter allows us to exploit almost all FFmpeg supported parameters effortlessly and flexibly for encoding in Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and encoders for compression mode discussed below: Kindly read FFmpeg Docs carefully, before passing any values to output_param dictionary parameter. Wrong values may result in undesired Errors or no output at all. Data-Type: Dictionary Default Value: Its default value is {} .","title":"output_params"},{"location":"gears/writegear/compression/params/#supported-parameters","text":"FFmpeg Parameters: All parameters based on selected encoder in use, are supported, and can be passed as dictionary attributes in output_param . For example, for using libx264 encoder to produce a lossless output video, we can pass required FFmpeg parameters as dictionary attributes, as follows: While providing additional av-source with -i FFmpeg parameter in output_params make sure it don't interfere with WriteGear's frame pipeline otherwise it will break things! All ffmpeg parameters are case-sensitive. Remember to double check every parameter if any error occurs. Kindly check H.264 docs \u27b6 and other FFmpeg Docs \u27b6 for more information on these parameters output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" , \"-tune\" : \"zerolatency\" } Special Internal Parameters: In addition to FFmpeg parameters, WriteGear API also supports some Special Parameters to tweak its internal properties. These parameters are discussed below: -ffmpeg_download_path (string) : sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows: output_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # will be saved to \"C:/User/foo/foo1\" -input_framerate (float/int) : sets the constant framerate of the output. It can be used as follows: output_params = { \"-input_framerate\" : 60.0 } # set the constant framerate to 60fps Its usage example can be found here \u27b6 -output_dimensions (tuple/list) : sets the custom dimensions( size/resolution ) of the output video (otherwise input video-frame size will be used) . Its value can either be a tuple => (width,height) or a list => [width, height] , Its usage is as follows: output_params = { \"-output_dimensions\" : ( 1280 , 720 )} # to produce a 1280x720 resolution/scale output video -clones (list) : required to set special FFmpeg parameters that are repeated more than once in the command (For more info., see this issue ) or in cases where you want to preserve order of multiple FFmpeg parameters. This attribute only accepts list datatype as value. Its usage is as follows: Turn on logging( logging = True ) to see the FFmpeg command that is being executed in WriteGear's pipeline. This helps you debug/address any issues and make adjustments accordingly. WriteGear by automatically applies -format or -f , -pix_fmt and -vcodec or -v:f like critical input parameters for every stream. Therefore if you need multiple values for these parameter just define them with -clones attribute. output_params = { \"-i\" : \"plug:dsnoopUSB\" , \"-f\" : \"alsa\" , \"-ac\" : \"1\" , \"-ar\" : \"48000\" , \"-clones\" : [ \"-vcodec\" , \"mpeg1video\" , \"-f\" , \"mpegts\" ], } -ffpreheaders (list) : required to set special FFmpeg parameters that are present at the starting of command(such as -re ). This attribute only accepts list datatype as value. Its usage is as follows: This attribute is quite powerful and can break FFmpeg pipeline easily if not used correctly. User Discretion is advised! Turn on logging( logging = True ) to see the FFmpeg command that is being executed in WriteGear's pipeline. This helps you debug/address any issues and make adjustments accordingly. output_params = { \"-ffpreheaders\" : [ \"-re\" ], # executes as `ffmpeg -re <rest of command>` } -disable_force_termination (bool) : sets a special flag to manually disable the default forced-termination behaviour in WriteGear API when -i FFmpeg parameter is used (For more details, see issue: #149 ) . Its usage is as follows: -disable_force_termination flag is a absolute necessity when video duration is too short(<60sec), otherwise WriteGear will not produce any valid output. output_params = { \"-disable_force_termination\" : True } # disable the default forced-termination behaviour","title":"Supported Parameters"},{"location":"gears/writegear/compression/params/#supported-encoders","text":"All the encoders that are compiled with FFmpeg in use, are supported by WriteGear API. You can easily check the compiled encoders by running following command in your terminal: Similarily, supported demuxers and filters depends upons compiled FFmpeg in use. ffmpeg -encoders # use `ffmpeg.exe -encoders` on windows","title":"Supported Encoders"},{"location":"gears/writegear/compression/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WriteGear ( output_filename = 'output.mp4' , logging = True )","title":"logging"},{"location":"gears/writegear/compression/usage/","text":"WriteGear API Usage Examples: Compression Mode \u2693 Important Information WriteGear MUST requires FFmpeg executables for its Compression capabilities in Compression Mode. Follow these dedicated Installation Instructions \u27b6 for its installation. In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode . DO NOT feed frames with different dimensions or channels to WriteGear, otherwise WriteGear will exit with ValueError . While providing additional av-source with -i FFmpeg parameter in output_params make sure it don't interfere with WriteGear's frame pipeline otherwise it will break things! Use -disable_force_termination flag when video duration is too short(<60sec), otherwise WriteGear will not produce any valid output. Heavy resolution multimedia files take time to render which can last up to 0.1-1 seconds . Kindly wait till the WriteGear API terminates itself, and DO NOT try to kill the process instead. Always use writer.close() at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior. After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6 \u2009 Bare-Minimum Usage \u2693 Following is the bare-minimum code you need to get started with WriteGear API in Compression Mode: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = \"myvideo.avi\" ) . start () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Compression Mode in RGB Mode \u2693 In Compression Mode, WriteGear API contains rgb_mode boolean parameter for RGB Mode, which when enabled (i.e. rgb_mode=True ) , specifies that incoming frames are of RGB format (instead of default BGR format) . This mode makes WriteGear directly compatible with libraries that only supports RGB format. The complete usage example is as follows: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # simulating RGB frame for example frame_rgb = frame [:, :, :: - 1 ] # writing RGB frame to writer writer . write ( frame_rgb , rgb_mode = True ) # activate RGB Mode # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Compression Mode with controlled FrameRate \u2693 WriteGear API provides -input_framerate attribute for its options dictionary parameter in Compression Mode, which allow us to control/set the constant framerate of the output video. Advanced Tip for setting constant framerate If -input_framerate attribute doesn't works for you, then define it in conjunction with another -r FFmpeg parameter as attribute: # set output constant framerate to (say 60 fps) output_params = { \"-input_framerate\" : 60 , \"-r\" : 60 } # assign that to WriteGear writer = WriteGear ( output_filename = \"out.mp4\" , logging = True , ** output_params ) But make sure you MUST set value of -r and -input_framerate parameter less than or equal to your input source framerate. In this code we will retrieve framerate from video stream, and set it as -input_framerate attribute for option parameter in WriteGear API: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # retrieve framerate from CamGear Stream and pass it as `-input_framerate` parameter output_params = { \"-input_framerate\" : stream . framerate } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Compression Mode for live streaming \u2693 In Compression Mode, WriteGear also allows URL strings (as output) for live streaming realtime frames with its output_filename parameter. In this example, we will stream live camera frames directly to Twitch : For streaming with traditional protocols such as RTSP/RTP, Checkout this WriteGear's Bonus Examples \u27b6 . YouTube-Live Streaming example code also available in WriteGear's Bonus Examples \u27b6 This example assume you already have a Twitch Account for publishing video. Make sure to change Twitch Stream Key with yours in following code before running! # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live webcam video stream on first index(i.e. 0) device stream = CamGear ( source = 0 , logging = True ) . start () # define required FFmpeg optimizing parameters for your writer output_params = { \"-preset:v\" : \"veryfast\" , \"-g\" : 60 , \"-keyint_min\" : 60 , \"-sc_threshold\" : 0 , \"-bufsize\" : \"2500k\" , \"-f\" : \"flv\" , } # [WARNING] Change your Twitch Stream Key here: TWITCH_KEY = \"live_XXXXXXXXXX~XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\" # Define writer with defined parameters and writer = WriteGear ( output_filename = \"rtmp://live.twitch.tv/app/ {} \" . format ( TWITCH_KEY ), logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Compression Mode with Hardware encoders \u2693 By default, WriteGear API uses libx264 encoder for encoding output files in Compression Mode. But you can easily change encoder to your suitable supported encoder by passing -vcodec FFmpeg parameter as an attribute with its output_param dictionary parameter. In addition to this, you can also specify the additional properties/features of your system's GPU easily. User Discretion Advised This example is just conveying the idea on how to use FFmpeg's hardware encoders with WriteGear API in Compression mode, which MAY/MAY NOT suit your system. Kindly use suitable parameters based your system hardware settings only. In this example, we will be using h264_vaapi as our hardware encoder and also optionally be specifying our device hardware's location (i.e. '-vaapi_device':'/dev/dri/renderD128' ) and other features such as '-vf':'format=nv12,hwupload' : Remember to check VAAPI support To use h264_vaapi encoder, remember to check if its available and your FFmpeg compiled with VAAPI support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: ffmpeg -hide_banner -encoders | grep vaapi V..... h264_vaapi H.264/AVC ( VAAPI ) ( codec h264 ) V..... hevc_vaapi H.265/HEVC ( VAAPI ) ( codec hevc ) V..... mjpeg_vaapi MJPEG ( VAAPI ) ( codec mjpeg ) V..... mpeg2_vaapi MPEG-2 ( VAAPI ) ( codec mpeg2video ) V..... vp8_vaapi VP8 ( VAAPI ) ( codec vp8 ) # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live webcam video stream on first index(i.e. 0) device stream = CamGear ( source = 0 , logging = True ) . start () # define required FFmpeg parameters for your writer output_params = { \"-vcodec\" : \"h264_vaapi\" , \"-vaapi_device\" : \"/dev/dri/renderD128\" , \"-vf\" : \"format=nv12,hwupload\" , } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Compression Mode with OpenCV \u2693 You can easily use WriterGear API directly with any Video Processing library( For e.g OpenCV itself ) in Compression Mode. The complete usage example is as follows: # import required libraries from vidgear.gears import WriteGear import cv2 # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . close () Using Compression Mode with Live Audio Input \u2693 In Compression Mode, WriteGear API allows us to exploit almost all FFmpeg supported parameters that you can think of in its Compression Mode. Hence, combining audio with live video frames is pretty easy. In this example code, we will merging the audio from a Audio Device (for e.g. Webcam inbuilt mic) to live frames incoming from the Video Source (for e.g external webcam) , and save the output as a compressed video file, all in real time: Example Assumptions You're running are Linux machine. You already have appropriate audio driver and software installed on your machine. Identifying and Specifying sound card on different OS platforms Windows Linux MacOS Windows OS users can use the dshow (DirectShow) to list audio input device which is the preferred option for Windows users. You can refer following steps to identify and specify your sound card: [OPTIONAL] Enable sound card(if disabled): First enable your Stereo Mix by opening the \"Sound\" window and select the \"Recording\" tab, then right click on the window and select \"Show Disabled Devices\" to toggle the Stereo Mix device visibility. Follow this post \u27b6 for more details. Identify Sound Card: Then, You can locate your soundcard using dshow as follows: c: \\> ffmpeg -list_devices true -f dshow -i dummy ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ dshow @ 03ACF580 ] DirectShow video devices [ dshow @ 03ACF580 ] \"Integrated Camera\" [ dshow @ 03ACF580 ] \"USB2.0 Camera\" [ dshow @ 03ACF580 ] DirectShow audio devices [ dshow @ 03ACF580 ] \"Microphone (Realtek High Definition Audio)\" [ dshow @ 03ACF580 ] \"Microphone (USB2.0 Camera)\" dummy: Immediate exit requested Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows: # assign appropriate input audio-source output_params = { \"-f\" : \"dshow\" , # !!! warning: always keep this line above \"-i\" parameter !!! \"-i\" : \"audio=Microphone (USB2.0 Camera)\" , \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-acodec\" : \"aac\" , \"-ar\" : \"44100\" , } If audio still doesn't work then checkout this troubleshooting guide \u27b6 or reach us out on Gitter \u27b6 Community channel Linux OS users can use the alsa to list input device to capture live audio input such as from a webcam. You can refer following steps to identify and specify your sound card: Identify Sound Card: To get the list of all installed cards on your machine, you can type arecord -l or arecord -L (longer output) . arecord -l **** List of CAPTURE Hardware Devices **** card 0 : ICH5 [ Intel ICH5 ] , device 0 : Intel ICH [ Intel ICH5 ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 1 : Intel ICH - MIC ADC [ Intel ICH5 - MIC ADC ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 2 : Intel ICH - MIC2 ADC [ Intel ICH5 - MIC2 ADC ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 3 : Intel ICH - ADC2 [ Intel ICH5 - ADC2 ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 1 : U0x46d0x809 [ USB Device 0x46d:0x809 ] , device 0 : USB Audio [ USB Audio ] Subdevices: 1 /1 Subdevice #0: subdevice #0 Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows: The easiest thing to do is to reference sound card directly, namely \"card 0\" (Intel ICH5) and \"card 1\" (Microphone on the USB web cam), as hw:0 or hw:1 # assign appropriate input audio-source output_params = { \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-ar\" : \"48000\" , \"-f\" : \"alsa\" , # !!! warning: always keep this line above \"-i\" parameter !!! \"-i\" : \"hw:1\" , } If audio still doesn't work then reach us out on Gitter \u27b6 Community channel MAC OS users can use the avfoundation to list input devices for grabbing audio from integrated iSight cameras as well as cameras connected via USB or FireWire. You can refer following steps to identify and specify your sound card on MacOS/OSX machines: Identify Sound Card: Then, You can locate your soundcard using avfoundation as follows: ffmpeg -f qtkit -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows: # assign appropriate input audio-source output_params = { \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-ar\" : \"48000\" , \"-f\" : \"avfoundation\" , # !!! warning: always keep this line above \"-audio_device_index\" parameter !!! \"-audio_device_index\" : \"0\" , } If audio still doesn't work then reach us out on Gitter \u27b6 Community channel Make sure this -i audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all. You MUST use -input_framerate attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams. # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # change with your webcam soundcard, plus add additional required FFmpeg parameters for your writer output_params = { \"-input_framerate\" : stream . framerate , \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-ar\" : \"48000\" , \"-f\" : \"alsa\" , # !!! warning: always keep this line above \"-i\" parameter !!! \"-i\" : \"hw:1\" , } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4 writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Usage Examples"},{"location":"gears/writegear/compression/usage/#writegear-api-usage-examples-compression-mode","text":"Important Information WriteGear MUST requires FFmpeg executables for its Compression capabilities in Compression Mode. Follow these dedicated Installation Instructions \u27b6 for its installation. In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode . DO NOT feed frames with different dimensions or channels to WriteGear, otherwise WriteGear will exit with ValueError . While providing additional av-source with -i FFmpeg parameter in output_params make sure it don't interfere with WriteGear's frame pipeline otherwise it will break things! Use -disable_force_termination flag when video duration is too short(<60sec), otherwise WriteGear will not produce any valid output. Heavy resolution multimedia files take time to render which can last up to 0.1-1 seconds . Kindly wait till the WriteGear API terminates itself, and DO NOT try to kill the process instead. Always use writer.close() at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior. After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6","title":"WriteGear API Usage Examples: Compression Mode"},{"location":"gears/writegear/compression/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with WriteGear API in Compression Mode: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = \"myvideo.avi\" ) . start () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Bare-Minimum Usage"},{"location":"gears/writegear/compression/usage/#using-compression-mode-in-rgb-mode","text":"In Compression Mode, WriteGear API contains rgb_mode boolean parameter for RGB Mode, which when enabled (i.e. rgb_mode=True ) , specifies that incoming frames are of RGB format (instead of default BGR format) . This mode makes WriteGear directly compatible with libraries that only supports RGB format. The complete usage example is as follows: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # simulating RGB frame for example frame_rgb = frame [:, :, :: - 1 ] # writing RGB frame to writer writer . write ( frame_rgb , rgb_mode = True ) # activate RGB Mode # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Compression Mode in RGB Mode"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-controlled-framerate","text":"WriteGear API provides -input_framerate attribute for its options dictionary parameter in Compression Mode, which allow us to control/set the constant framerate of the output video. Advanced Tip for setting constant framerate If -input_framerate attribute doesn't works for you, then define it in conjunction with another -r FFmpeg parameter as attribute: # set output constant framerate to (say 60 fps) output_params = { \"-input_framerate\" : 60 , \"-r\" : 60 } # assign that to WriteGear writer = WriteGear ( output_filename = \"out.mp4\" , logging = True , ** output_params ) But make sure you MUST set value of -r and -input_framerate parameter less than or equal to your input source framerate. In this code we will retrieve framerate from video stream, and set it as -input_framerate attribute for option parameter in WriteGear API: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # retrieve framerate from CamGear Stream and pass it as `-input_framerate` parameter output_params = { \"-input_framerate\" : stream . framerate } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Compression Mode with controlled FrameRate"},{"location":"gears/writegear/compression/usage/#using-compression-mode-for-live-streaming","text":"In Compression Mode, WriteGear also allows URL strings (as output) for live streaming realtime frames with its output_filename parameter. In this example, we will stream live camera frames directly to Twitch : For streaming with traditional protocols such as RTSP/RTP, Checkout this WriteGear's Bonus Examples \u27b6 . YouTube-Live Streaming example code also available in WriteGear's Bonus Examples \u27b6 This example assume you already have a Twitch Account for publishing video. Make sure to change Twitch Stream Key with yours in following code before running! # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live webcam video stream on first index(i.e. 0) device stream = CamGear ( source = 0 , logging = True ) . start () # define required FFmpeg optimizing parameters for your writer output_params = { \"-preset:v\" : \"veryfast\" , \"-g\" : 60 , \"-keyint_min\" : 60 , \"-sc_threshold\" : 0 , \"-bufsize\" : \"2500k\" , \"-f\" : \"flv\" , } # [WARNING] Change your Twitch Stream Key here: TWITCH_KEY = \"live_XXXXXXXXXX~XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\" # Define writer with defined parameters and writer = WriteGear ( output_filename = \"rtmp://live.twitch.tv/app/ {} \" . format ( TWITCH_KEY ), logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Compression Mode for live streaming"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-hardware-encoders","text":"By default, WriteGear API uses libx264 encoder for encoding output files in Compression Mode. But you can easily change encoder to your suitable supported encoder by passing -vcodec FFmpeg parameter as an attribute with its output_param dictionary parameter. In addition to this, you can also specify the additional properties/features of your system's GPU easily. User Discretion Advised This example is just conveying the idea on how to use FFmpeg's hardware encoders with WriteGear API in Compression mode, which MAY/MAY NOT suit your system. Kindly use suitable parameters based your system hardware settings only. In this example, we will be using h264_vaapi as our hardware encoder and also optionally be specifying our device hardware's location (i.e. '-vaapi_device':'/dev/dri/renderD128' ) and other features such as '-vf':'format=nv12,hwupload' : Remember to check VAAPI support To use h264_vaapi encoder, remember to check if its available and your FFmpeg compiled with VAAPI support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: ffmpeg -hide_banner -encoders | grep vaapi V..... h264_vaapi H.264/AVC ( VAAPI ) ( codec h264 ) V..... hevc_vaapi H.265/HEVC ( VAAPI ) ( codec hevc ) V..... mjpeg_vaapi MJPEG ( VAAPI ) ( codec mjpeg ) V..... mpeg2_vaapi MPEG-2 ( VAAPI ) ( codec mpeg2video ) V..... vp8_vaapi VP8 ( VAAPI ) ( codec vp8 ) # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live webcam video stream on first index(i.e. 0) device stream = CamGear ( source = 0 , logging = True ) . start () # define required FFmpeg parameters for your writer output_params = { \"-vcodec\" : \"h264_vaapi\" , \"-vaapi_device\" : \"/dev/dri/renderD128\" , \"-vf\" : \"format=nv12,hwupload\" , } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Compression Mode with Hardware encoders"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-opencv","text":"You can easily use WriterGear API directly with any Video Processing library( For e.g OpenCV itself ) in Compression Mode. The complete usage example is as follows: # import required libraries from vidgear.gears import WriteGear import cv2 # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . close ()","title":"Using Compression Mode with OpenCV"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-live-audio-input","text":"In Compression Mode, WriteGear API allows us to exploit almost all FFmpeg supported parameters that you can think of in its Compression Mode. Hence, combining audio with live video frames is pretty easy. In this example code, we will merging the audio from a Audio Device (for e.g. Webcam inbuilt mic) to live frames incoming from the Video Source (for e.g external webcam) , and save the output as a compressed video file, all in real time: Example Assumptions You're running are Linux machine. You already have appropriate audio driver and software installed on your machine. Identifying and Specifying sound card on different OS platforms Windows Linux MacOS Windows OS users can use the dshow (DirectShow) to list audio input device which is the preferred option for Windows users. You can refer following steps to identify and specify your sound card: [OPTIONAL] Enable sound card(if disabled): First enable your Stereo Mix by opening the \"Sound\" window and select the \"Recording\" tab, then right click on the window and select \"Show Disabled Devices\" to toggle the Stereo Mix device visibility. Follow this post \u27b6 for more details. Identify Sound Card: Then, You can locate your soundcard using dshow as follows: c: \\> ffmpeg -list_devices true -f dshow -i dummy ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ dshow @ 03ACF580 ] DirectShow video devices [ dshow @ 03ACF580 ] \"Integrated Camera\" [ dshow @ 03ACF580 ] \"USB2.0 Camera\" [ dshow @ 03ACF580 ] DirectShow audio devices [ dshow @ 03ACF580 ] \"Microphone (Realtek High Definition Audio)\" [ dshow @ 03ACF580 ] \"Microphone (USB2.0 Camera)\" dummy: Immediate exit requested Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows: # assign appropriate input audio-source output_params = { \"-f\" : \"dshow\" , # !!! warning: always keep this line above \"-i\" parameter !!! \"-i\" : \"audio=Microphone (USB2.0 Camera)\" , \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-acodec\" : \"aac\" , \"-ar\" : \"44100\" , } If audio still doesn't work then checkout this troubleshooting guide \u27b6 or reach us out on Gitter \u27b6 Community channel Linux OS users can use the alsa to list input device to capture live audio input such as from a webcam. You can refer following steps to identify and specify your sound card: Identify Sound Card: To get the list of all installed cards on your machine, you can type arecord -l or arecord -L (longer output) . arecord -l **** List of CAPTURE Hardware Devices **** card 0 : ICH5 [ Intel ICH5 ] , device 0 : Intel ICH [ Intel ICH5 ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 1 : Intel ICH - MIC ADC [ Intel ICH5 - MIC ADC ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 2 : Intel ICH - MIC2 ADC [ Intel ICH5 - MIC2 ADC ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 3 : Intel ICH - ADC2 [ Intel ICH5 - ADC2 ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 1 : U0x46d0x809 [ USB Device 0x46d:0x809 ] , device 0 : USB Audio [ USB Audio ] Subdevices: 1 /1 Subdevice #0: subdevice #0 Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows: The easiest thing to do is to reference sound card directly, namely \"card 0\" (Intel ICH5) and \"card 1\" (Microphone on the USB web cam), as hw:0 or hw:1 # assign appropriate input audio-source output_params = { \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-ar\" : \"48000\" , \"-f\" : \"alsa\" , # !!! warning: always keep this line above \"-i\" parameter !!! \"-i\" : \"hw:1\" , } If audio still doesn't work then reach us out on Gitter \u27b6 Community channel MAC OS users can use the avfoundation to list input devices for grabbing audio from integrated iSight cameras as well as cameras connected via USB or FireWire. You can refer following steps to identify and specify your sound card on MacOS/OSX machines: Identify Sound Card: Then, You can locate your soundcard using avfoundation as follows: ffmpeg -f qtkit -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows: # assign appropriate input audio-source output_params = { \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-ar\" : \"48000\" , \"-f\" : \"avfoundation\" , # !!! warning: always keep this line above \"-audio_device_index\" parameter !!! \"-audio_device_index\" : \"0\" , } If audio still doesn't work then reach us out on Gitter \u27b6 Community channel Make sure this -i audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all. You MUST use -input_framerate attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams. # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # change with your webcam soundcard, plus add additional required FFmpeg parameters for your writer output_params = { \"-input_framerate\" : stream . framerate , \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-ar\" : \"48000\" , \"-f\" : \"alsa\" , # !!! warning: always keep this line above \"-i\" parameter !!! \"-i\" : \"hw:1\" , } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4 writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Compression Mode with Live Audio Input"},{"location":"gears/writegear/compression/advanced/cciw/","text":"Custom FFmpeg Commands in WriteGear API \u2693 WriteGear API now provides the execute_ffmpeg_cmd Method in Compression Mode that enables the user to pass any custom FFmpeg CLI (Command Line Interface) commands as input to its internal FFmpeg Pipeline by formating it as a list. This opens endless possibilities of exploiting every FFmpeg params within WriteGear without relying on a third-party API to do the same and while doing that it robustly handles all errors/warnings quietly. Important Information This Feature Requires WriteGear's Compression Mode enabled( compression_mode = True ) . Follow these dedicated Installation Instructions \u27b6 for its installation. Only python list is a valid datatype as input for this function, any other value will throw ValueError . Kindly read FFmpeg Docs carefully, before passing any values to output_param dictionary parameter. Wrong values may result in undesired Errors or no output at all. Features \u2693 Provides the ability to pass any custom command to WriteGear FFmpeg Pipeline. Compatible with any FFmpeg terminal command. Standalone On-the-fly functioning. Can work without interfering with WriteGear API's Writer pipeline. Minimum hassle and extremely easy to enable and use. Methods \u2693 execute_ffmpeg_cmd \u2693 This method allows the users to pass the custom FFmpeg terminal commands as a formatted list directly to WriteGear API's FFmpeg pipeline for processing/execution. Its usage is as follows: # format FFmpeg terminal command `ffmpeg -y -i source_video -acodec copy input_audio.aac` as a list ffmpeg_command = [ \"-y\" , \"-i\" , source_video , \"-acodec\" , \"copy\" , \"input_audio.aac\" ] # execute this list using this function execute_ffmpeg_cmd ( ffmpeg_command ) Usage Examples \u2693 Following usage examples is just an idea of what can be done with this powerful function. So just Tinker with various FFmpeg parameters/commands yourself and see it working. Also, if you're unable to run any terminal FFmpeg command, then report an issue . Using WriteGear to separate Audio from Video \u2693 In this example, we will extract and save audio from a URL stream: # import required libraries from vidgear.gears import WriteGear # define a valid url url_to_stream = ( \"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4\" ) # Define writer with default parameters writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True ) # format command to convert stream audio as 'output_audio.aac' as list ffmpeg_command_to_save_audio = [ \"-y\" , \"-i\" , url_to_stream , \"output_audio.aac\" , ] # `-y` parameter is to overwrite outputfile if exists # execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command_to_save_audio ) # safely close writer writer . close () After running this script, You will get the final 'output_audio.aac' audio file. Using WriteGear to merge Audio with Video \u2693 In this example, we will merge audio with video: You can also directly add external audio input to video-frames in WriteGear. For more information, See this FAQ example \u27b6 Example Assumptions You already have a separate video(i.e 'input-video.mp4' ) and audio(i.e 'input-audio.aac' ) files. Both these Audio and Video files are compatible. # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 import time # Open input video stream stream = VideoGear ( source = \"input-video.mp4\" ) . start () # set input audio stream path input_audio = \"input-audio.aac\" # define your parameters output_params = { \"-input_framerate\" : stream . framerate } # output framerate must match source framerate # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () # sleep 1 sec as the above video might still be rendering time . sleep ( 1 ) # format FFmpeg command to generate `Output_with_audio.mp4` by merging input_audio in above rendered `Output.mp4` ffmpeg_command = [ \"-y\" , \"-i\" , \"Output.mp4\" , \"-i\" , input_audio , \"-c:v\" , \"copy\" , \"-c:a\" , \"copy\" , \"-map\" , \"0:v:0\" , \"-map\" , \"1:a:0\" , \"-shortest\" , \"Output_with_audio.mp4\" , ] # `-y` parameter is to overwrite outputfile if exists # execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command ) After running this script, You will get the final 'Output_with_audio.mp4' file with both video and audio merged.","title":"Custom FFmpeg Commands"},{"location":"gears/writegear/compression/advanced/cciw/#custom-ffmpeg-commands-in-writegear-api","text":"WriteGear API now provides the execute_ffmpeg_cmd Method in Compression Mode that enables the user to pass any custom FFmpeg CLI (Command Line Interface) commands as input to its internal FFmpeg Pipeline by formating it as a list. This opens endless possibilities of exploiting every FFmpeg params within WriteGear without relying on a third-party API to do the same and while doing that it robustly handles all errors/warnings quietly. Important Information This Feature Requires WriteGear's Compression Mode enabled( compression_mode = True ) . Follow these dedicated Installation Instructions \u27b6 for its installation. Only python list is a valid datatype as input for this function, any other value will throw ValueError . Kindly read FFmpeg Docs carefully, before passing any values to output_param dictionary parameter. Wrong values may result in undesired Errors or no output at all.","title":"Custom FFmpeg Commands in WriteGear API"},{"location":"gears/writegear/compression/advanced/cciw/#features","text":"Provides the ability to pass any custom command to WriteGear FFmpeg Pipeline. Compatible with any FFmpeg terminal command. Standalone On-the-fly functioning. Can work without interfering with WriteGear API's Writer pipeline. Minimum hassle and extremely easy to enable and use.","title":"Features"},{"location":"gears/writegear/compression/advanced/cciw/#methods","text":"","title":"Methods"},{"location":"gears/writegear/compression/advanced/cciw/#execute_ffmpeg_cmd","text":"This method allows the users to pass the custom FFmpeg terminal commands as a formatted list directly to WriteGear API's FFmpeg pipeline for processing/execution. Its usage is as follows: # format FFmpeg terminal command `ffmpeg -y -i source_video -acodec copy input_audio.aac` as a list ffmpeg_command = [ \"-y\" , \"-i\" , source_video , \"-acodec\" , \"copy\" , \"input_audio.aac\" ] # execute this list using this function execute_ffmpeg_cmd ( ffmpeg_command )","title":"execute_ffmpeg_cmd"},{"location":"gears/writegear/compression/advanced/cciw/#usage-examples","text":"Following usage examples is just an idea of what can be done with this powerful function. So just Tinker with various FFmpeg parameters/commands yourself and see it working. Also, if you're unable to run any terminal FFmpeg command, then report an issue .","title":"Usage Examples"},{"location":"gears/writegear/compression/advanced/cciw/#using-writegear-to-separate-audio-from-video","text":"In this example, we will extract and save audio from a URL stream: # import required libraries from vidgear.gears import WriteGear # define a valid url url_to_stream = ( \"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4\" ) # Define writer with default parameters writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True ) # format command to convert stream audio as 'output_audio.aac' as list ffmpeg_command_to_save_audio = [ \"-y\" , \"-i\" , url_to_stream , \"output_audio.aac\" , ] # `-y` parameter is to overwrite outputfile if exists # execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command_to_save_audio ) # safely close writer writer . close () After running this script, You will get the final 'output_audio.aac' audio file.","title":"Using WriteGear to separate Audio from Video"},{"location":"gears/writegear/compression/advanced/cciw/#using-writegear-to-merge-audio-with-video","text":"In this example, we will merge audio with video: You can also directly add external audio input to video-frames in WriteGear. For more information, See this FAQ example \u27b6 Example Assumptions You already have a separate video(i.e 'input-video.mp4' ) and audio(i.e 'input-audio.aac' ) files. Both these Audio and Video files are compatible. # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 import time # Open input video stream stream = VideoGear ( source = \"input-video.mp4\" ) . start () # set input audio stream path input_audio = \"input-audio.aac\" # define your parameters output_params = { \"-input_framerate\" : stream . framerate } # output framerate must match source framerate # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () # sleep 1 sec as the above video might still be rendering time . sleep ( 1 ) # format FFmpeg command to generate `Output_with_audio.mp4` by merging input_audio in above rendered `Output.mp4` ffmpeg_command = [ \"-y\" , \"-i\" , \"Output.mp4\" , \"-i\" , input_audio , \"-c:v\" , \"copy\" , \"-c:a\" , \"copy\" , \"-map\" , \"0:v:0\" , \"-map\" , \"1:a:0\" , \"-shortest\" , \"Output_with_audio.mp4\" , ] # `-y` parameter is to overwrite outputfile if exists # execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command ) After running this script, You will get the final 'Output_with_audio.mp4' file with both video and audio merged.","title":"Using WriteGear to merge Audio with Video"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/","text":"FFmpeg Installation Instructions \u2693 WriteGear must requires FFmpeg executables for its Compression capabilities in Compression Mode. You can following machine-specific instructions for its installation: In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode . Linux FFmpeg Installation \u2693 The WriteGear API supports Auto-Detection and Manual Configuration methods on a Linux machine: A. Auto-Detection \u2693 This is a recommended approach on Linux Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6 B. Manual Configuration \u2693 Download: You can also manually download the latest Linux Static Binaries( based on your machine arch(x86/x64) ) from the link below: Linux Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode! Windows FFmpeg Installation \u2693 The WriteGear API supports Auto-Installation and Manual Configuration methods on Windows systems. A. Auto-Installation \u2693 This is a recommended approach on Windows Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on Windows system WriteGear API auto-generates the required FFmpeg Static Binaries from a dedicated Github Server into the temporary directory (for e.g. C:\\Temp ) of your machine. Warning The files downloaded to temporary directory (for e.g. C:\\TEMP ) , may get erased if your machine shutdowns/restarts. You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through -ffmpeg_download_path parameter. If binaries were found at the specified path, WriteGear automatically skips the auto-installation step. If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then, WriteGear API will auto-disable the Compression Mode and switches to Non-Compression Mode ! B. Manual Configuration \u2693 Download: You can also manually download the latest Windows Static Binaries( based on your machine arch(x86/x64) ) from the link below: Windows Static Binaries: https://ffmpeg.org/download.html#build-windows Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'C:/foo/Downloads/ffmpeg/bin' ) or path of ffmpeg.exe executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode! MacOS FFmpeg Installation \u2693 The WriteGear API supports Auto-Detection and Manual Configuration methods on a macOS machine. A. Auto-Detection \u2693 This is a recommended approach on MacOS Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6 B. Manual Configuration \u2693 Download: You can also manually download the latest macOS Static Binaries( only x64 Binaries ) from the link below: MacOS Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!","title":"FFmpeg Installation"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#ffmpeg-installation-instructions","text":"WriteGear must requires FFmpeg executables for its Compression capabilities in Compression Mode. You can following machine-specific instructions for its installation: In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode .","title":"FFmpeg Installation Instructions"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#linux-ffmpeg-installation","text":"The WriteGear API supports Auto-Detection and Manual Configuration methods on a Linux machine:","title":" Linux FFmpeg Installation"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#a-auto-detection","text":"This is a recommended approach on Linux Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6","title":"A. Auto-Detection"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#b-manual-configuration","text":"Download: You can also manually download the latest Linux Static Binaries( based on your machine arch(x86/x64) ) from the link below: Linux Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!","title":"B. Manual Configuration"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#windows-ffmpeg-installation","text":"The WriteGear API supports Auto-Installation and Manual Configuration methods on Windows systems.","title":" Windows FFmpeg Installation"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#a-auto-installation","text":"This is a recommended approach on Windows Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on Windows system WriteGear API auto-generates the required FFmpeg Static Binaries from a dedicated Github Server into the temporary directory (for e.g. C:\\Temp ) of your machine. Warning The files downloaded to temporary directory (for e.g. C:\\TEMP ) , may get erased if your machine shutdowns/restarts. You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through -ffmpeg_download_path parameter. If binaries were found at the specified path, WriteGear automatically skips the auto-installation step. If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then, WriteGear API will auto-disable the Compression Mode and switches to Non-Compression Mode !","title":"A. Auto-Installation"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#b-manual-configuration_1","text":"Download: You can also manually download the latest Windows Static Binaries( based on your machine arch(x86/x64) ) from the link below: Windows Static Binaries: https://ffmpeg.org/download.html#build-windows Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'C:/foo/Downloads/ffmpeg/bin' ) or path of ffmpeg.exe executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!","title":"B. Manual Configuration"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#macos-ffmpeg-installation","text":"The WriteGear API supports Auto-Detection and Manual Configuration methods on a macOS machine.","title":" MacOS FFmpeg Installation"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#a-auto-detection_1","text":"This is a recommended approach on MacOS Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6","title":"A. Auto-Detection"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#b-manual-configuration_2","text":"Download: You can also manually download the latest macOS Static Binaries( only x64 Binaries ) from the link below: MacOS Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!","title":"B. Manual Configuration"},{"location":"gears/writegear/non_compression/overview/","text":"WriteGear API: Non-Compression Mode \u2693 WriteGear API's Non-Compression Mode generalized workflow Overview \u2693 When compression_mode parameter is disabled (.i.e compression_mode = False ), WriteGear API uses basic OpenCV's inbuilt VideoWriter API tools for encoding multimedia files but without compression. This mode provides flexible access to OpenCV's VideoWriter API ,and also supports various parameters available within this API, but lacks the ability to control output quality, compression, and other important features like lossless video compression, audio encoding, etc. which are only available in Compression Mode . Thereby, the resultant output video-file size will be many times larger as compared to Compression Mode. Important Information In case WriteGear API fails to detect valid FFmpeg executables on your system, it will automatically switches to this(Non-Compression) Mode. It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. \u2009 Usage Examples \u2693 See here \ud83d\ude80 After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6 Parameters \u2693 See here \ud83d\ude80","title":"Overview"},{"location":"gears/writegear/non_compression/overview/#writegear-api-non-compression-mode","text":"WriteGear API's Non-Compression Mode generalized workflow","title":"WriteGear API: Non-Compression Mode"},{"location":"gears/writegear/non_compression/overview/#overview","text":"When compression_mode parameter is disabled (.i.e compression_mode = False ), WriteGear API uses basic OpenCV's inbuilt VideoWriter API tools for encoding multimedia files but without compression. This mode provides flexible access to OpenCV's VideoWriter API ,and also supports various parameters available within this API, but lacks the ability to control output quality, compression, and other important features like lossless video compression, audio encoding, etc. which are only available in Compression Mode . Thereby, the resultant output video-file size will be many times larger as compared to Compression Mode. Important Information In case WriteGear API fails to detect valid FFmpeg executables on your system, it will automatically switches to this(Non-Compression) Mode. It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/writegear/non_compression/overview/#usage-examples","text":"See here \ud83d\ude80 After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6","title":"Usage Examples"},{"location":"gears/writegear/non_compression/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/writegear/non_compression/params/","text":"WriteGear API Parameters: Non-Compression Mode \u2693 \u2009 output_filename \u2693 This parameter sets the valid output Video filename/path for the output video. WriteGear API will throw RuntimeError if output_filename provided is empty or invalid. Data-Type: String Default Value: Its default value is 0 . Usage: Make sure to provide valid filename with valid file-extension based on the encoder in use (default is .mp4 ) . Its valid input can be one of the following: Path to directory : Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename ( with a default extension i.e. .mp4 ) as follows: writer = WriteGear ( output_filename = '/home/foo/foo1' , compression_mode = False ) # Define writer Filename (with/without path) : Valid filename( with valid extension ) of the output video file. In case filename is provided without path, then current working directory will be used. writer = WriteGear ( output_filename = 'output.mp4' , compression_mode = False ) # Define writer GStreamer Pipeline: WriteGear API also supports GStreamer Pipeline as input to its output_filename parameter in Non-Compression Mode, when GStreamer Pipeline Mode is enabled. It can be used as follows: Requirement for GStreamer Pipelining GStreamer Pipelining in WriteGear requires your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. New in v0.2.5 This feature was added in v0.2.5 . # enable GStreamer Pipeline Mode for writer output_params = { \"-gst_pipeline_mode\" : True } # Define writer writer = WriteGear ( output_filename = \"appsrc ! videoconvert ! avenc_mpeg4 bitrate=100000 ! mp4mux ! filesink location=foo.mp4\" , compression_mode = False ) compression_mode \u2693 This parameter selects the WriteGear's Primary Mode of Operation , i.e. if this parameter is enabled (.i.e compression_mode = True ) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e compression_mode = False ) , the OpenCV's VideoWriter API will be used for encoding files/streams. Data-Type: Boolean Default Value: Its default value is True . Usage: WriteGear ( output_filename = 'output.mp4' , compression_mode = False ) custom_ffmpeg \u2693 Not supported in Non-Compression Mode! output_params \u2693 This parameter allows us to exploit almost all OpenCV's VideoWriter API supported parameters effortlessly and flexibly for video-encoding in Non-Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and FOURCC codecs for compression mode discussed below: Remember, Non-Compression mode lacks the ability to control output quality and other important features like lossless video compression, audio encoding, etc. , which are available with WriteGear's Compression Mode only. Data-Type: Dictionary Default Value: Its default value is {} . \u2009 Supported Attributes \u2693 Non-Compression Mode only gives access to a limited number of Parameters through its output_params parameter's attributes, which are as follows: A. OpenCV Parameters \u2693 WriteGear provides access to all available OpenCV's VideoWriter API parameters in Non-Compression Mode. Parameters Description -fourcc 4-character code of codec used to encode frames -fps controls the framerate of output video(Default value: 25) -backend (optional) In case of multiple backends, this parameter allows us to specify VideoWriter API's backends to use. Its valid values are CAP_FFMPEG or CAP_GSTREAMER (if enabled) -color (optional) If it is not zero(0), the encoder will expect and encode color frames, otherwise it will work with grayscale frames (the flag is currently supported on Windows only) -height and -width parameter are no longer supported and are automatically derived from the input frames. B. Exclusive Parameters \u2693 In addition to OpenCV Parameters, WriteGear API also provides few exclusive attribute, which are as follows: -gst_pipeline_mode : a boolean attribute to enable GStreamer Pipeline Mode to supports GStreamer Pipeline as input to its output_filename parameter in Non-Compression Mode. Enabling -gst_pipeline_mode will enforce -backend parameter value to \"CAP_GSTREAMER\" New in v0.2.5 -gst_pipeline_mode attribute was added in v0.2.5 . Its usage example can be found here \u27b6 . Usage: To assign desired parameters in Non-Compression Mode, you can format it as dictionary attribute and pass through this( output_params ) parameter as follows: # format parameter as dictionary attribute output_params = { \"-fps\" : 30 } # and then, assign it WriteGear ( output_filename = 'output.mp4' , ** output_params ) Its usage example can be found here \u27b6 . \u2009 Supported FOURCC Codecs \u2693 FOURCC is a 4-character code of the codec used to encode video in Non-Compression Mode(OpenCV's VideoWriter API) without compression. List of all supported FOURCC codecs can found here \u27b6 Usage: To select desired FOURCC codec in Non-Compression Mode, you can format it as dictionary attribute and pass through this( output_params ) parameter. For example, using MJPG as codec, we can: # format codec as dictionary attribute output_params = { \"-fourcc\" : \"MJPG\" } # and then, assign it WriteGear ( output_filename = 'output.mp4' , ** output_params ) Its usage example can be found here \u27b6 . logging \u2693 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WriteGear ( output_filename = 'output.mp4' , logging = True )","title":"Parameters"},{"location":"gears/writegear/non_compression/params/#writegear-api-parameters-non-compression-mode","text":"","title":"WriteGear API Parameters: Non-Compression Mode"},{"location":"gears/writegear/non_compression/params/#output_filename","text":"This parameter sets the valid output Video filename/path for the output video. WriteGear API will throw RuntimeError if output_filename provided is empty or invalid. Data-Type: String Default Value: Its default value is 0 . Usage: Make sure to provide valid filename with valid file-extension based on the encoder in use (default is .mp4 ) . Its valid input can be one of the following: Path to directory : Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename ( with a default extension i.e. .mp4 ) as follows: writer = WriteGear ( output_filename = '/home/foo/foo1' , compression_mode = False ) # Define writer Filename (with/without path) : Valid filename( with valid extension ) of the output video file. In case filename is provided without path, then current working directory will be used. writer = WriteGear ( output_filename = 'output.mp4' , compression_mode = False ) # Define writer GStreamer Pipeline: WriteGear API also supports GStreamer Pipeline as input to its output_filename parameter in Non-Compression Mode, when GStreamer Pipeline Mode is enabled. It can be used as follows: Requirement for GStreamer Pipelining GStreamer Pipelining in WriteGear requires your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. New in v0.2.5 This feature was added in v0.2.5 . # enable GStreamer Pipeline Mode for writer output_params = { \"-gst_pipeline_mode\" : True } # Define writer writer = WriteGear ( output_filename = \"appsrc ! videoconvert ! avenc_mpeg4 bitrate=100000 ! mp4mux ! filesink location=foo.mp4\" , compression_mode = False )","title":"output_filename"},{"location":"gears/writegear/non_compression/params/#compression_mode","text":"This parameter selects the WriteGear's Primary Mode of Operation , i.e. if this parameter is enabled (.i.e compression_mode = True ) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e compression_mode = False ) , the OpenCV's VideoWriter API will be used for encoding files/streams. Data-Type: Boolean Default Value: Its default value is True . Usage: WriteGear ( output_filename = 'output.mp4' , compression_mode = False )","title":"compression_mode"},{"location":"gears/writegear/non_compression/params/#custom_ffmpeg","text":"Not supported in Non-Compression Mode!","title":"custom_ffmpeg"},{"location":"gears/writegear/non_compression/params/#output_params","text":"This parameter allows us to exploit almost all OpenCV's VideoWriter API supported parameters effortlessly and flexibly for video-encoding in Non-Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and FOURCC codecs for compression mode discussed below: Remember, Non-Compression mode lacks the ability to control output quality and other important features like lossless video compression, audio encoding, etc. , which are available with WriteGear's Compression Mode only. Data-Type: Dictionary Default Value: Its default value is {} .","title":"output_params"},{"location":"gears/writegear/non_compression/params/#supported-attributes","text":"Non-Compression Mode only gives access to a limited number of Parameters through its output_params parameter's attributes, which are as follows:","title":"Supported Attributes"},{"location":"gears/writegear/non_compression/params/#a-opencv-parameters","text":"WriteGear provides access to all available OpenCV's VideoWriter API parameters in Non-Compression Mode. Parameters Description -fourcc 4-character code of codec used to encode frames -fps controls the framerate of output video(Default value: 25) -backend (optional) In case of multiple backends, this parameter allows us to specify VideoWriter API's backends to use. Its valid values are CAP_FFMPEG or CAP_GSTREAMER (if enabled) -color (optional) If it is not zero(0), the encoder will expect and encode color frames, otherwise it will work with grayscale frames (the flag is currently supported on Windows only) -height and -width parameter are no longer supported and are automatically derived from the input frames.","title":"A. OpenCV Parameters"},{"location":"gears/writegear/non_compression/params/#b-exclusive-parameters","text":"In addition to OpenCV Parameters, WriteGear API also provides few exclusive attribute, which are as follows: -gst_pipeline_mode : a boolean attribute to enable GStreamer Pipeline Mode to supports GStreamer Pipeline as input to its output_filename parameter in Non-Compression Mode. Enabling -gst_pipeline_mode will enforce -backend parameter value to \"CAP_GSTREAMER\" New in v0.2.5 -gst_pipeline_mode attribute was added in v0.2.5 . Its usage example can be found here \u27b6 . Usage: To assign desired parameters in Non-Compression Mode, you can format it as dictionary attribute and pass through this( output_params ) parameter as follows: # format parameter as dictionary attribute output_params = { \"-fps\" : 30 } # and then, assign it WriteGear ( output_filename = 'output.mp4' , ** output_params ) Its usage example can be found here \u27b6 .","title":"B. Exclusive Parameters"},{"location":"gears/writegear/non_compression/params/#supported-fourcc-codecs","text":"FOURCC is a 4-character code of the codec used to encode video in Non-Compression Mode(OpenCV's VideoWriter API) without compression. List of all supported FOURCC codecs can found here \u27b6 Usage: To select desired FOURCC codec in Non-Compression Mode, you can format it as dictionary attribute and pass through this( output_params ) parameter. For example, using MJPG as codec, we can: # format codec as dictionary attribute output_params = { \"-fourcc\" : \"MJPG\" } # and then, assign it WriteGear ( output_filename = 'output.mp4' , ** output_params ) Its usage example can be found here \u27b6 .","title":"Supported FOURCC Codecs"},{"location":"gears/writegear/non_compression/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WriteGear ( output_filename = 'output.mp4' , logging = True )","title":"logging"},{"location":"gears/writegear/non_compression/usage/","text":"WriteGear API Usage Examples: Non-Compression Mode \u2693 Important Information DO NOT feed frames to WriteGear with different dimensions or channels, or-else WriteGear API will exit with ValueError . In case WriteGear API fails to detect valid FFmpeg executables on your system, it will auto-switches to this(Non-Compression) Mode. Always use writer.close() at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior. After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6 \u2009 Bare-Minimum Usage \u2693 Following is the bare-minimum code you need to get started with WriteGear API in Non-Compression Mode: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = \"myvideo.avi\" ) . start () # Define writer with Non-compression mode and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , compression_mode = False ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Non-Compression Mode with VideoCapture Gears \u2693 In Non-Compression mode, WriteGear API provides flexible control over OpenCV's VideoWriter API parameters through its output_param dictionary parameter by formating them as dictionary attributes. Moreover, WriteGear API can be used in conjunction with any other Gears/APIs effortlessly. All supported attributes for output_param can be found here \u27b6 The complete usage example is as follows: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # define suitable tweak parameters for writer output_params = { \"-fourcc\" : \"MJPG\" , \"-fps\" : 30 } # open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 , logging = True ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , compression_mode = False , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Non-Compression Mode with OpenCV \u2693 You can easily use WriterGear API directly with any Video Processing library( For e.g OpenCV itself ) in Non-Compression Mode. The complete usage example is as follows: # import required libraries from vidgear.gears import WriteGear import cv2 # define suitable tweak parameters for writer output_params = { \"-fourcc\" : \"MJPG\" , \"-fps\" : 30 } # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , compression_mode = False , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . close () Using Non-Compression Mode with GStreamer Pipeline \u2693 WriteGear API's Non-Compression Mode also supports GStreamer Pipeline as input to its output_filename parameter, when GStreamer Pipeline Mode is enabled. This provides flexible way to write video frames to file or network stream with controlled framerate and bitrate. The complete usage example is as follows: Requirement for GStreamer Pipelining GStreamer Pipelining in WriteGear requires your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. New in v0.2.5 This example was added in v0.2.5 . In this example we will be constructing GStreamer pipeline to write video-frames into a file( foo.mp4 ) at 1M video-bitrate. # import required libraries from vidgear.gears import WriteGear import cv2 # enable GStreamer Pipeline Mode for writer output_params = { \"-gst_pipeline_mode\" : True } # open live video stream on webcam at first index(i.e. 0) device stream = cv2 . VideoCapture ( 0 ) # gst pipeline to write to a file `foo.mp4` at 1M video-bitrate GSTPipeline = \"appsrc ! videoconvert ! avenc_mpeg4 bitrate=100000 ! mp4mux ! filesink location= {} \" . format ( \"foo.mp4\" ) # Define writer with defined parameters and with our Gstreamer pipeline writer = WriteGear ( output_filename = GSTPipeline , compression_mode = False , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . close ()","title":"Usage Examples"},{"location":"gears/writegear/non_compression/usage/#writegear-api-usage-examples-non-compression-mode","text":"Important Information DO NOT feed frames to WriteGear with different dimensions or channels, or-else WriteGear API will exit with ValueError . In case WriteGear API fails to detect valid FFmpeg executables on your system, it will auto-switches to this(Non-Compression) Mode. Always use writer.close() at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior. After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6","title":"WriteGear API Usage Examples: Non-Compression Mode"},{"location":"gears/writegear/non_compression/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with WriteGear API in Non-Compression Mode: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = \"myvideo.avi\" ) . start () # Define writer with Non-compression mode and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , compression_mode = False ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Bare-Minimum Usage"},{"location":"gears/writegear/non_compression/usage/#using-non-compression-mode-with-videocapture-gears","text":"In Non-Compression mode, WriteGear API provides flexible control over OpenCV's VideoWriter API parameters through its output_param dictionary parameter by formating them as dictionary attributes. Moreover, WriteGear API can be used in conjunction with any other Gears/APIs effortlessly. All supported attributes for output_param can be found here \u27b6 The complete usage example is as follows: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # define suitable tweak parameters for writer output_params = { \"-fourcc\" : \"MJPG\" , \"-fps\" : 30 } # open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 , logging = True ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , compression_mode = False , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Non-Compression Mode with VideoCapture Gears"},{"location":"gears/writegear/non_compression/usage/#using-non-compression-mode-with-opencv","text":"You can easily use WriterGear API directly with any Video Processing library( For e.g OpenCV itself ) in Non-Compression Mode. The complete usage example is as follows: # import required libraries from vidgear.gears import WriteGear import cv2 # define suitable tweak parameters for writer output_params = { \"-fourcc\" : \"MJPG\" , \"-fps\" : 30 } # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , compression_mode = False , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . close ()","title":"Using Non-Compression Mode with OpenCV"},{"location":"gears/writegear/non_compression/usage/#using-non-compression-mode-with-gstreamer-pipeline","text":"WriteGear API's Non-Compression Mode also supports GStreamer Pipeline as input to its output_filename parameter, when GStreamer Pipeline Mode is enabled. This provides flexible way to write video frames to file or network stream with controlled framerate and bitrate. The complete usage example is as follows: Requirement for GStreamer Pipelining GStreamer Pipelining in WriteGear requires your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. New in v0.2.5 This example was added in v0.2.5 . In this example we will be constructing GStreamer pipeline to write video-frames into a file( foo.mp4 ) at 1M video-bitrate. # import required libraries from vidgear.gears import WriteGear import cv2 # enable GStreamer Pipeline Mode for writer output_params = { \"-gst_pipeline_mode\" : True } # open live video stream on webcam at first index(i.e. 0) device stream = cv2 . VideoCapture ( 0 ) # gst pipeline to write to a file `foo.mp4` at 1M video-bitrate GSTPipeline = \"appsrc ! videoconvert ! avenc_mpeg4 bitrate=100000 ! mp4mux ! filesink location= {} \" . format ( \"foo.mp4\" ) # Define writer with defined parameters and with our Gstreamer pipeline writer = WriteGear ( output_filename = GSTPipeline , compression_mode = False , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . close ()","title":"Using Non-Compression Mode with GStreamer Pipeline"},{"location":"help/camgear_ex/","text":"CamGear Examples \u2693 Synchronizing Two Sources in CamGear \u2693 In this example both streams and corresponding frames will be processed synchronously i.e. with no delay: Using same source with more than one instances of CamGear can lead to Global Interpreter Lock (GIL) that degrades performance even when it is not a bottleneck. # import required libraries from vidgear.gears import CamGear import cv2 import time # define and start the stream on first source ( For e.g #0 index device) stream1 = CamGear ( source = 0 , logging = True ) . start () # define and start the stream on second source ( For e.g #1 index device) stream2 = CamGear ( source = 1 , logging = True ) . start () # infinite loop while True : frameA = stream1 . read () # read frames from stream1 frameB = stream2 . read () # read frames from stream2 # check if any of two frame is None if frameA is None or frameB is None : #if True break the infinite loop break # do something with both frameA and frameB here cv2 . imshow ( \"Output Frame1\" , frameA ) cv2 . imshow ( \"Output Frame2\" , frameB ) # Show output window of stream1 and stream 2 separately key = cv2 . waitKey ( 1 ) & 0xFF # check for 'q' key-press if key == ord ( \"q\" ): #if 'q' key-pressed break out break if key == ord ( \"w\" ): #if 'w' key-pressed save both frameA and frameB at same time cv2 . imwrite ( \"Image-1.jpg\" , frameA ) cv2 . imwrite ( \"Image-2.jpg\" , frameB ) #break #uncomment this line to break out after taking images cv2 . destroyAllWindows () # close output window # safely close both video streams stream1 . stop () stream2 . stop () Using variable yt_dlp parameters in CamGear \u2693 CamGear provides exclusive attributes STREAM_RESOLUTION (for specifying stream resolution) & STREAM_PARAMS (for specifying underlying API(e.g. yt_dlp ) parameters) with its options dictionary parameter. The complete usage example is as follows: More information on STREAM_RESOLUTION & STREAM_PARAMS attributes can be found here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # specify attributes options = { \"STREAM_RESOLUTION\" : \"720p\" , \"STREAM_PARAMS\" : { \"nocheckcertificate\" : True }} # Add YouTube Video URL as input source (for e.g https://youtu.be/bvetuLwJIkA) # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://youtu.be/bvetuLwJIkA\" , stream_mode = True , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using CamGear for capturing RSTP/RTMP URLs \u2693 You can open any network stream (such as RTSP/RTMP) just by providing its URL directly to CamGear's source parameter. Here's a high-level wrapper code around CamGear API to enable auto-reconnection during capturing: New in v0.2.2 This example was added in v0.2.2 . Enforcing UDP stream You can easily enforce UDP for RSTP streams inplace of default TCP, by putting following lines of code on the top of your existing code: # import required libraries import os # enforce UDP os . environ [ \"OPENCV_FFMPEG_CAPTURE_OPTIONS\" ] = \"rtsp_transport;udp\" Finally, use backend parameter value as backend=cv2.CAP_FFMPEG in CamGear. from vidgear.gears import CamGear import cv2 import datetime import time class Reconnecting_CamGear : def __init__ ( self , cam_address , reset_attempts = 50 , reset_delay = 5 ): self . cam_address = cam_address self . reset_attempts = reset_attempts self . reset_delay = reset_delay self . source = CamGear ( source = self . cam_address ) . start () self . running = True def read ( self ): if self . source is None : return None if self . running and self . reset_attempts > 0 : frame = self . source . read () if frame is None : self . source . stop () self . reset_attempts -= 1 print ( \"Re-connection Attempt- {} occured at time: {} \" . format ( str ( self . reset_attempts ), datetime . datetime . now () . strftime ( \"%m- %d -%Y %I:%M:%S%p\" ), ) ) time . sleep ( self . reset_delay ) self . source = CamGear ( source = self . cam_address ) . start () # return previous frame return self . frame else : self . frame = frame return frame else : return None def stop ( self ): self . running = False self . reset_attempts = 0 self . frame = None if not self . source is None : self . source . stop () if __name__ == \"__main__\" : # open any valid video stream stream = Reconnecting_CamGear ( cam_address = \"rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov\" , reset_attempts = 20 , reset_delay = 5 , ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"CamGear Examples"},{"location":"help/camgear_ex/#camgear-examples","text":"","title":"CamGear Examples"},{"location":"help/camgear_ex/#synchronizing-two-sources-in-camgear","text":"In this example both streams and corresponding frames will be processed synchronously i.e. with no delay: Using same source with more than one instances of CamGear can lead to Global Interpreter Lock (GIL) that degrades performance even when it is not a bottleneck. # import required libraries from vidgear.gears import CamGear import cv2 import time # define and start the stream on first source ( For e.g #0 index device) stream1 = CamGear ( source = 0 , logging = True ) . start () # define and start the stream on second source ( For e.g #1 index device) stream2 = CamGear ( source = 1 , logging = True ) . start () # infinite loop while True : frameA = stream1 . read () # read frames from stream1 frameB = stream2 . read () # read frames from stream2 # check if any of two frame is None if frameA is None or frameB is None : #if True break the infinite loop break # do something with both frameA and frameB here cv2 . imshow ( \"Output Frame1\" , frameA ) cv2 . imshow ( \"Output Frame2\" , frameB ) # Show output window of stream1 and stream 2 separately key = cv2 . waitKey ( 1 ) & 0xFF # check for 'q' key-press if key == ord ( \"q\" ): #if 'q' key-pressed break out break if key == ord ( \"w\" ): #if 'w' key-pressed save both frameA and frameB at same time cv2 . imwrite ( \"Image-1.jpg\" , frameA ) cv2 . imwrite ( \"Image-2.jpg\" , frameB ) #break #uncomment this line to break out after taking images cv2 . destroyAllWindows () # close output window # safely close both video streams stream1 . stop () stream2 . stop ()","title":"Synchronizing Two Sources in CamGear"},{"location":"help/camgear_ex/#using-variable-yt_dlp-parameters-in-camgear","text":"CamGear provides exclusive attributes STREAM_RESOLUTION (for specifying stream resolution) & STREAM_PARAMS (for specifying underlying API(e.g. yt_dlp ) parameters) with its options dictionary parameter. The complete usage example is as follows: More information on STREAM_RESOLUTION & STREAM_PARAMS attributes can be found here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # specify attributes options = { \"STREAM_RESOLUTION\" : \"720p\" , \"STREAM_PARAMS\" : { \"nocheckcertificate\" : True }} # Add YouTube Video URL as input source (for e.g https://youtu.be/bvetuLwJIkA) # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://youtu.be/bvetuLwJIkA\" , stream_mode = True , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using variable yt_dlp parameters in CamGear"},{"location":"help/camgear_ex/#using-camgear-for-capturing-rstprtmp-urls","text":"You can open any network stream (such as RTSP/RTMP) just by providing its URL directly to CamGear's source parameter. Here's a high-level wrapper code around CamGear API to enable auto-reconnection during capturing: New in v0.2.2 This example was added in v0.2.2 . Enforcing UDP stream You can easily enforce UDP for RSTP streams inplace of default TCP, by putting following lines of code on the top of your existing code: # import required libraries import os # enforce UDP os . environ [ \"OPENCV_FFMPEG_CAPTURE_OPTIONS\" ] = \"rtsp_transport;udp\" Finally, use backend parameter value as backend=cv2.CAP_FFMPEG in CamGear. from vidgear.gears import CamGear import cv2 import datetime import time class Reconnecting_CamGear : def __init__ ( self , cam_address , reset_attempts = 50 , reset_delay = 5 ): self . cam_address = cam_address self . reset_attempts = reset_attempts self . reset_delay = reset_delay self . source = CamGear ( source = self . cam_address ) . start () self . running = True def read ( self ): if self . source is None : return None if self . running and self . reset_attempts > 0 : frame = self . source . read () if frame is None : self . source . stop () self . reset_attempts -= 1 print ( \"Re-connection Attempt- {} occured at time: {} \" . format ( str ( self . reset_attempts ), datetime . datetime . now () . strftime ( \"%m- %d -%Y %I:%M:%S%p\" ), ) ) time . sleep ( self . reset_delay ) self . source = CamGear ( source = self . cam_address ) . start () # return previous frame return self . frame else : self . frame = frame return frame else : return None def stop ( self ): self . running = False self . reset_attempts = 0 self . frame = None if not self . source is None : self . source . stop () if __name__ == \"__main__\" : # open any valid video stream stream = Reconnecting_CamGear ( cam_address = \"rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov\" , reset_attempts = 20 , reset_delay = 5 , ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using CamGear for capturing RSTP/RTMP URLs"},{"location":"help/camgear_faqs/","text":"CamGear FAQs \u2693 What is CamGear API and what does it do? \u2693 Answer: CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format (upto 4k tested), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. In addition to this, it also supports live Gstreamer's RAW pipelines and YouTube video/livestreams URLs. For more info. see CamGear doc \u27b6 . I'm only familiar with OpenCV, how to get started with CamGear API? \u2693 Answer: First, see Switching from OpenCV , then go through CamGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel. How to change OpenCV source backend in CamGear API? \u2693 Answer: See its Parameters \u27b6 . Its, backend (int) parameter sets the backend of the source. Its value can be for e.g. backend = cv2.CAP_DSHOW in case of Direct Show. How to get framerate of the source in CamGear API? \u2693 Answer: CamGear's framerate global variable can be used to retrieve framerate of the input video stream. See this example \u27b6 . How to compile OpenCV with GStreamer support? \u2693 Answer: For compiling OpenCV with GSstreamer( >=v1.0.0 ) support: Linux Windows MacOS Follow this tutorial \u27b6 Follow this tutorial \u27b6 Follow this tutorial \u27b6 How to change quality and parameters of YouTube Streams with CamGear? \u2693 Answer: CamGear provides exclusive attributes STREAM_RESOLUTION (for specifying stream resolution) & STREAM_PARAMS (for specifying underlying API(e.g. yt_dlp ) parameters) with its options dictionary parameter. See this bonus example \u27b6 . How to open RSTP network streams with CamGear? \u2693 Answer: You can open any local network stream (such as RTSP) just by providing its URL directly to CamGear's source parameter. See this bonus example \u27b6 . How to set Camera Settings with CamGear? \u2693 Answer: See this usage example \u27b6 . Can I play 4K/8k video with CamGear API? \u2693 Answer: Yes, you can if your System Hardware supports it. How to synchronize between two cameras? \u2693 Answer: See this bonus example \u27b6 . Can I use GPU to decode the video source? \u2693 Answer: See this issue comment \u27b6 . Why CamGear is throwing warning that Threaded Queue Mode is disabled? \u2693 Answer: That's a normal behavior. Please read about Threaded Queue Mode \u27b6","title":"CamGear FAQs"},{"location":"help/camgear_faqs/#camgear-faqs","text":"","title":"CamGear FAQs"},{"location":"help/camgear_faqs/#what-is-camgear-api-and-what-does-it-do","text":"Answer: CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format (upto 4k tested), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. In addition to this, it also supports live Gstreamer's RAW pipelines and YouTube video/livestreams URLs. For more info. see CamGear doc \u27b6 .","title":"What is CamGear API and what does it do?"},{"location":"help/camgear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-camgear-api","text":"Answer: First, see Switching from OpenCV , then go through CamGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"I'm only familiar with OpenCV, how to get started with CamGear API?"},{"location":"help/camgear_faqs/#how-to-change-opencv-source-backend-in-camgear-api","text":"Answer: See its Parameters \u27b6 . Its, backend (int) parameter sets the backend of the source. Its value can be for e.g. backend = cv2.CAP_DSHOW in case of Direct Show.","title":"How to change OpenCV source backend in CamGear API?"},{"location":"help/camgear_faqs/#how-to-get-framerate-of-the-source-in-camgear-api","text":"Answer: CamGear's framerate global variable can be used to retrieve framerate of the input video stream. See this example \u27b6 .","title":"How to get framerate of the source in CamGear API?"},{"location":"help/camgear_faqs/#how-to-compile-opencv-with-gstreamer-support","text":"Answer: For compiling OpenCV with GSstreamer( >=v1.0.0 ) support: Linux Windows MacOS Follow this tutorial \u27b6 Follow this tutorial \u27b6 Follow this tutorial \u27b6","title":"How to compile OpenCV with GStreamer support?"},{"location":"help/camgear_faqs/#how-to-change-quality-and-parameters-of-youtube-streams-with-camgear","text":"Answer: CamGear provides exclusive attributes STREAM_RESOLUTION (for specifying stream resolution) & STREAM_PARAMS (for specifying underlying API(e.g. yt_dlp ) parameters) with its options dictionary parameter. See this bonus example \u27b6 .","title":"How to change quality and parameters of YouTube Streams with CamGear?"},{"location":"help/camgear_faqs/#how-to-open-rstp-network-streams-with-camgear","text":"Answer: You can open any local network stream (such as RTSP) just by providing its URL directly to CamGear's source parameter. See this bonus example \u27b6 .","title":"How to open RSTP network streams with CamGear?"},{"location":"help/camgear_faqs/#how-to-set-camera-settings-with-camgear","text":"Answer: See this usage example \u27b6 .","title":"How to set Camera Settings with CamGear?"},{"location":"help/camgear_faqs/#can-i-play-4k8k-video-with-camgear-api","text":"Answer: Yes, you can if your System Hardware supports it.","title":"Can I play 4K/8k video with CamGear API?"},{"location":"help/camgear_faqs/#how-to-synchronize-between-two-cameras","text":"Answer: See this bonus example \u27b6 .","title":"How to synchronize between two cameras?"},{"location":"help/camgear_faqs/#can-i-use-gpu-to-decode-the-video-source","text":"Answer: See this issue comment \u27b6 .","title":"Can I use GPU to decode the video source?"},{"location":"help/camgear_faqs/#why-camgear-is-throwing-warning-that-threaded-queue-mode-is-disabled","text":"Answer: That's a normal behavior. Please read about Threaded Queue Mode \u27b6","title":"Why CamGear is throwing warning that Threaded Queue Mode is disabled?"},{"location":"help/general_faqs/","text":"General FAQs \u2693 \"I'm new to Python Programming or its usage in OpenCV Library\", How to use vidgear in my projects? \u2693 Answer: Before using vidgear, It's recommended to first go through the following dedicated blog sites and learn how OpenCV-Python syntax works (with examples) : PyImageSearch.com \u27b6 is the best resource for learning OpenCV and its Python implementation. Adrian Rosebrock provides many practical OpenCV techniques with tutorials, code examples, blogs, and books at PyImageSearch.com. Highly recommended! learnopencv.com \u27b6 Maintained by OpenCV CEO Satya Mallick. This blog is for programmers, hackers, engineers, scientists, students, and self-starters interested in Computer Vision and Machine Learning. There's also the official OpenCV Tutorials \u27b6 curated by the OpenCV developers. Once done, visit Switching from OpenCV \u27b6 to easily replace OpenCV APIs with suitable Gears \u27b6 in your project. All the best! If you run into any trouble or have any questions, then refer our Help section. \"VidGear is using Multi-threading, but Python is notorious for its poor performance in multithreading?\" \u2693 Answer: Refer vidgear's Threaded-Queue-Mode \u27b6 ModuleNotFoundError: No module named 'vidgear.gears'. 'vidgear' is not a package? \u2693 Answer: This error means you either have a file named vidgear.py in your python path or you've named your python script vidgear.py . Replace vidgear name with anything else to fix this error. How to log to a file in VidGear? \u2693 Answer: VidGear provides exclusive VIDGEAR_LOGFILE environment variable to enable logging to a file while logging is enabled (i.e. logging=True ) on respective Gear. You just have to set directory pathname (automatically creates vidgear.log file) or a log file pathname itself as value for this environment variable. This can be done on various platfroms/OSes as follows: Remember enabling this logging to a file will completely disable any output on the terminal. Linux OS Windows OS (Powershell) OSX/Mac OS # path to file export VIDGEAR_LOGFILE = \" $HOME /foo.log\" # or just directory path # !!! Make sure `foo` path already exists !!! export VIDGEAR_LOGFILE = \" $HOME /foo\" # to remove unset VIDGEAR_LOGFILE # path to file $Env:VIDGEAR_LOGFILE = \"D:\\foo.log\" # or just directory path # !!! Make sure `foo` path already exists !!! $Env:VIDGEAR_LOGFILE = \"D:\\foo\" # to remove $Env:VIDGEAR_LOGFILE = \"\" # path to file export VIDGEAR_LOGFILE = \" $HOME /foo.log\" # or just directory path # !!! Make sure `foo` path already exists !!! export VIDGEAR_LOGFILE = \" $HOME /foo\" # to remove unset VIDGEAR_LOGFILE Can I perform Deep Learning task with VidGear? \u2693 Answer: VidGear is a powerful Video Processing library (similar to OpenCV, FFmpeg, etc.) that can read, write, process, send & receive a sequence of video-frames in an optimized manner. But for Deep Learning or Machine Learning tasks, you have to use a third-party library. That being said, all VidGear's APIs can be used with any third-party Library(such as PyTorch, Tensorflow, etc.) that can leverage the overall performance if you're processing video/audio streams/frames in your application with Deep Learning tasks. Also, it eases the workflow since you have to write way fewer lines of code to read/store/process output videos. Can I ask my question directly without raising an issue? \u2693 Answer: Yes, please join our Gitter \u27b6 Community channel. How to contribute to VidGear development? \u2693 Answer: See our Contribution Guidelines \u27b6 What OSes are supported by VidGear? \u2693 Answer: See Supported Systems \u27b6 What Python versions are supported by VidGear? \u2693 Answer: See Supported Python legacies \u27b6 Can I include VidGear in my project commercially or not? \u2693 Answer: Yes, you can, but strictly under the Terms and Conditions given in VidGear License \u27b6 \"I Love using VidGear for my projects\", How can I support it? \u2693 Answer: See Helping VidGear \u27b6","title":"General FAQs"},{"location":"help/general_faqs/#general-faqs","text":"","title":"General FAQs"},{"location":"help/general_faqs/#im-new-to-python-programming-or-its-usage-in-opencv-library-how-to-use-vidgear-in-my-projects","text":"Answer: Before using vidgear, It's recommended to first go through the following dedicated blog sites and learn how OpenCV-Python syntax works (with examples) : PyImageSearch.com \u27b6 is the best resource for learning OpenCV and its Python implementation. Adrian Rosebrock provides many practical OpenCV techniques with tutorials, code examples, blogs, and books at PyImageSearch.com. Highly recommended! learnopencv.com \u27b6 Maintained by OpenCV CEO Satya Mallick. This blog is for programmers, hackers, engineers, scientists, students, and self-starters interested in Computer Vision and Machine Learning. There's also the official OpenCV Tutorials \u27b6 curated by the OpenCV developers. Once done, visit Switching from OpenCV \u27b6 to easily replace OpenCV APIs with suitable Gears \u27b6 in your project. All the best! If you run into any trouble or have any questions, then refer our Help section.","title":"\"I'm new to Python Programming or its usage in OpenCV Library\", How to use vidgear in my projects?"},{"location":"help/general_faqs/#vidgear-is-using-multi-threading-but-python-is-notorious-for-its-poor-performance-in-multithreading","text":"Answer: Refer vidgear's Threaded-Queue-Mode \u27b6","title":"\"VidGear is using Multi-threading, but Python is notorious for its poor performance in multithreading?\""},{"location":"help/general_faqs/#modulenotfounderror-no-module-named-vidgeargears-vidgear-is-not-a-package","text":"Answer: This error means you either have a file named vidgear.py in your python path or you've named your python script vidgear.py . Replace vidgear name with anything else to fix this error.","title":"ModuleNotFoundError: No module named 'vidgear.gears'. 'vidgear' is not a package?"},{"location":"help/general_faqs/#how-to-log-to-a-file-in-vidgear","text":"Answer: VidGear provides exclusive VIDGEAR_LOGFILE environment variable to enable logging to a file while logging is enabled (i.e. logging=True ) on respective Gear. You just have to set directory pathname (automatically creates vidgear.log file) or a log file pathname itself as value for this environment variable. This can be done on various platfroms/OSes as follows: Remember enabling this logging to a file will completely disable any output on the terminal. Linux OS Windows OS (Powershell) OSX/Mac OS # path to file export VIDGEAR_LOGFILE = \" $HOME /foo.log\" # or just directory path # !!! Make sure `foo` path already exists !!! export VIDGEAR_LOGFILE = \" $HOME /foo\" # to remove unset VIDGEAR_LOGFILE # path to file $Env:VIDGEAR_LOGFILE = \"D:\\foo.log\" # or just directory path # !!! Make sure `foo` path already exists !!! $Env:VIDGEAR_LOGFILE = \"D:\\foo\" # to remove $Env:VIDGEAR_LOGFILE = \"\" # path to file export VIDGEAR_LOGFILE = \" $HOME /foo.log\" # or just directory path # !!! Make sure `foo` path already exists !!! export VIDGEAR_LOGFILE = \" $HOME /foo\" # to remove unset VIDGEAR_LOGFILE","title":"How to log to a file in VidGear?"},{"location":"help/general_faqs/#can-i-perform-deep-learning-task-with-vidgear","text":"Answer: VidGear is a powerful Video Processing library (similar to OpenCV, FFmpeg, etc.) that can read, write, process, send & receive a sequence of video-frames in an optimized manner. But for Deep Learning or Machine Learning tasks, you have to use a third-party library. That being said, all VidGear's APIs can be used with any third-party Library(such as PyTorch, Tensorflow, etc.) that can leverage the overall performance if you're processing video/audio streams/frames in your application with Deep Learning tasks. Also, it eases the workflow since you have to write way fewer lines of code to read/store/process output videos.","title":"Can I perform Deep Learning task with VidGear?"},{"location":"help/general_faqs/#can-i-ask-my-question-directly-without-raising-an-issue","text":"Answer: Yes, please join our Gitter \u27b6 Community channel.","title":"Can I ask my question directly without raising an issue?"},{"location":"help/general_faqs/#how-to-contribute-to-vidgear-development","text":"Answer: See our Contribution Guidelines \u27b6","title":"How to contribute to VidGear development?"},{"location":"help/general_faqs/#what-oses-are-supported-by-vidgear","text":"Answer: See Supported Systems \u27b6","title":"What OSes are supported by VidGear?"},{"location":"help/general_faqs/#what-python-versions-are-supported-by-vidgear","text":"Answer: See Supported Python legacies \u27b6","title":"What Python versions are supported by VidGear?"},{"location":"help/general_faqs/#can-i-include-vidgear-in-my-project-commercially-or-not","text":"Answer: Yes, you can, but strictly under the Terms and Conditions given in VidGear License \u27b6","title":"Can I include VidGear in my project commercially or not?"},{"location":"help/general_faqs/#i-love-using-vidgear-for-my-projects-how-can-i-support-it","text":"Answer: See Helping VidGear \u27b6","title":"\"I Love using VidGear for my projects\", How can I support it?"},{"location":"help/get_help/","text":"Getting Help \u2693 Courtesy - Pinterest Would you like to get help with VidGear? There are several ways to get help with VidGear: \u2009 Frequently Asked Questions \u2693 Got a question related to VidGear Working? Checkout the Frequently Asked Questions - a curated list of all the questions with adequate answer that we commonly receive for quickly troubleshooting your problems: General FAQs \u27b6 CamGear FAQs \u27b6 PiGear FAQs \u27b6 ScreenGear FAQs \u27b6 StreamGear FAQs \u27b6 WriteGear FAQs \u27b6 NetGear FAQs \u27b6 WebGear FAQs \u27b6 WebGear_RTC FAQs \u27b6 VideoGear FAQs \u27b6 NetGear_Async FAQs \u27b6 Stabilizer Class FAQs \u27b6 \u2009 Bonus Examples \u2693 How we do this with that API? Checkout the Bonus Examples - a curated list of all experimental examples with unusual configuration that aren't included in general usage examples: CamGear Examples \u27b6 PiGear Examples \u27b6 ScreenGear Examples \u27b6 StreamGear Examples \u27b6 WriteGear Examples \u27b6 NetGear Examples \u27b6 WebGear Examples \u27b6 WebGear_RTC Examples \u27b6 VideoGear Examples \u27b6 NetGear_Async Examples \u27b6 Stabilizer Class Examples \u27b6 \u2009 Join our Gitter Community channel \u2693 Have you come up with some new idea \ud83d\udca1 or looking for the fastest way troubleshoot your problems Join and chat on our Gitter Community channel: There you can ask quick questions, swiftly troubleshoot your problems, help others, share ideas & information, etc. \u2009 This is what you do when... \u2693 Got a question or problem? Found a typo? Found a bug? Missing a feature/improvement? \u2009 Reporting an issues \u2693 Want to report a bug? Suggest a new feature? Before you do, please read our guidelines \u27b6 \u2009 Preparing a Pull Request \u2693 Interested in contributing to VidGear? Before you do, please read our guidelines \u27b6","title":"Getting Help"},{"location":"help/get_help/#getting-help","text":"Courtesy - Pinterest Would you like to get help with VidGear? There are several ways to get help with VidGear:","title":"Getting Help"},{"location":"help/get_help/#frequently-asked-questions","text":"Got a question related to VidGear Working? Checkout the Frequently Asked Questions - a curated list of all the questions with adequate answer that we commonly receive for quickly troubleshooting your problems: General FAQs \u27b6 CamGear FAQs \u27b6 PiGear FAQs \u27b6 ScreenGear FAQs \u27b6 StreamGear FAQs \u27b6 WriteGear FAQs \u27b6 NetGear FAQs \u27b6 WebGear FAQs \u27b6 WebGear_RTC FAQs \u27b6 VideoGear FAQs \u27b6 NetGear_Async FAQs \u27b6 Stabilizer Class FAQs \u27b6","title":"Frequently Asked Questions "},{"location":"help/get_help/#bonus-examples","text":"How we do this with that API? Checkout the Bonus Examples - a curated list of all experimental examples with unusual configuration that aren't included in general usage examples: CamGear Examples \u27b6 PiGear Examples \u27b6 ScreenGear Examples \u27b6 StreamGear Examples \u27b6 WriteGear Examples \u27b6 NetGear Examples \u27b6 WebGear Examples \u27b6 WebGear_RTC Examples \u27b6 VideoGear Examples \u27b6 NetGear_Async Examples \u27b6 Stabilizer Class Examples \u27b6","title":"Bonus Examples "},{"location":"help/get_help/#join-our-gitter-community-channel","text":"Have you come up with some new idea \ud83d\udca1 or looking for the fastest way troubleshoot your problems Join and chat on our Gitter Community channel: There you can ask quick questions, swiftly troubleshoot your problems, help others, share ideas & information, etc.","title":"Join our Gitter Community channel "},{"location":"help/get_help/#this-is-what-you-do-when","text":"Got a question or problem? Found a typo? Found a bug? Missing a feature/improvement?","title":"This is what you do when... "},{"location":"help/get_help/#reporting-an-issues","text":"Want to report a bug? Suggest a new feature? Before you do, please read our guidelines \u27b6","title":"Reporting an issues"},{"location":"help/get_help/#preparing-a-pull-request","text":"Interested in contributing to VidGear? Before you do, please read our guidelines \u27b6","title":"Preparing a Pull Request"},{"location":"help/netgear_async_ex/","text":"NetGear_Async Examples \u2693 Using NetGear_Async with WebGear \u2693 The complete usage example is as follows: New in v0.2.2 This example was added in v0.2.2 . Client + WebGear Server \u2693 Open a terminal on Client System where you want to display the input frames (and setup WebGear server) received from the Server and execute the following python code: After running this code, Make sure to open Browser immediately otherwise NetGear_Async will soon exit with TimeoutError . You can also try setting timeout parameter to a higher value to extend this timeout. Make sure you use different port value for NetGear_Async and WebGear API. High CPU utilization may occur on Client's end. User discretion is advised. Note down the IP-address of this system (required at Server's end) by executing the hostname -I command and also replace it in the following code.\" # import libraries from vidgear.gears.asyncio import NetGear_Async from vidgear.gears.asyncio import WebGear from vidgear.gears.asyncio.helper import reducer import uvicorn , asyncio , cv2 # Define NetGear_Async Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear_Async ( receive_mode = True , pattern = 1 , logging = True , ) . launch () # create your own custom frame producer async def my_frame_producer (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # {do something with received frames here} # reducer frames size if you want more performance otherwise comment this line frame = await reducer ( frame , percentage = 30 , interpolation = cv2 . INTER_AREA ) # reduce frame by 30% # handle JPEG encoding encodedImage = cv2 . imencode ( \".jpg\" , frame )[ 1 ] . tobytes () # yield frame in byte format yield ( b \"--frame \\r\\n Content-Type:image/jpeg \\r\\n\\r\\n \" + encodedImage + b \" \\r\\n \" ) await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) # initialize WebGear app without any source web = WebGear ( logging = True ) # add your custom frame producer to config with adequate IP address web . config [ \"generator\" ] = my_frame_producer # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # safely close client client . close () # close app safely web . shutdown () On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in your Client's Browser. Server \u2693 Now, Open the terminal on another Server System (with a webcam connected to it at index 0) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. # import library from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # initialize Server without any source server = NetGear_Async ( source = None , address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ) # Create a async frame generator as custom source async def my_frame_generator (): # !!! define your own video source here !!! # Open any video stream such as live webcam # video stream on first index(i.e. 0) device stream = cv2 . VideoCapture ( 0 ) # loop over stream until its terminated while True : # read frames ( grabbed , frame ) = stream . read () # check if frame empty if not grabbed : break # do something with the frame to be sent here # yield frame yield frame # sleep for sometime await asyncio . sleep ( 0 ) # close stream stream . release () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) # Add your custom source generator to Server configuration server . config [ \"generator\" ] = my_frame_generator () # Launch the Server server . launch () try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close ()","title":"NetGear_Async Examples"},{"location":"help/netgear_async_ex/#netgear_async-examples","text":"","title":"NetGear_Async Examples"},{"location":"help/netgear_async_ex/#using-netgear_async-with-webgear","text":"The complete usage example is as follows: New in v0.2.2 This example was added in v0.2.2 .","title":"Using NetGear_Async with WebGear"},{"location":"help/netgear_async_ex/#client-webgear-server","text":"Open a terminal on Client System where you want to display the input frames (and setup WebGear server) received from the Server and execute the following python code: After running this code, Make sure to open Browser immediately otherwise NetGear_Async will soon exit with TimeoutError . You can also try setting timeout parameter to a higher value to extend this timeout. Make sure you use different port value for NetGear_Async and WebGear API. High CPU utilization may occur on Client's end. User discretion is advised. Note down the IP-address of this system (required at Server's end) by executing the hostname -I command and also replace it in the following code.\" # import libraries from vidgear.gears.asyncio import NetGear_Async from vidgear.gears.asyncio import WebGear from vidgear.gears.asyncio.helper import reducer import uvicorn , asyncio , cv2 # Define NetGear_Async Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear_Async ( receive_mode = True , pattern = 1 , logging = True , ) . launch () # create your own custom frame producer async def my_frame_producer (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # {do something with received frames here} # reducer frames size if you want more performance otherwise comment this line frame = await reducer ( frame , percentage = 30 , interpolation = cv2 . INTER_AREA ) # reduce frame by 30% # handle JPEG encoding encodedImage = cv2 . imencode ( \".jpg\" , frame )[ 1 ] . tobytes () # yield frame in byte format yield ( b \"--frame \\r\\n Content-Type:image/jpeg \\r\\n\\r\\n \" + encodedImage + b \" \\r\\n \" ) await asyncio . sleep ( 0 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) # initialize WebGear app without any source web = WebGear ( logging = True ) # add your custom frame producer to config with adequate IP address web . config [ \"generator\" ] = my_frame_producer # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # safely close client client . close () # close app safely web . shutdown () On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in your Client's Browser.","title":"Client + WebGear Server"},{"location":"help/netgear_async_ex/#server","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. # import library from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # initialize Server without any source server = NetGear_Async ( source = None , address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ) # Create a async frame generator as custom source async def my_frame_generator (): # !!! define your own video source here !!! # Open any video stream such as live webcam # video stream on first index(i.e. 0) device stream = cv2 . VideoCapture ( 0 ) # loop over stream until its terminated while True : # read frames ( grabbed , frame ) = stream . read () # check if frame empty if not grabbed : break # do something with the frame to be sent here # yield frame yield frame # sleep for sometime await asyncio . sleep ( 0 ) # close stream stream . release () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) # Add your custom source generator to Server configuration server . config [ \"generator\" ] = my_frame_generator () # Launch the Server server . launch () try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close ()","title":"Server"},{"location":"help/netgear_async_faqs/","text":"NetGear_Async FAQs \u2693 What is NetGear_Async API and what does it do? \u2693 Answer: NetGear_Async is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. Basically, this API is able to transfer thousands of frames in just a few seconds without causing any significant load on your system. For more info. see NetGear_Async doc \u27b6 How to get started with NetGear_Async API? \u2693 Answer: See NetGear_Async doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel. \"NetGear_Async is throwing ModuleNotFoundError on importing\", Why? \u2693 Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6 . What is the key difference between NetGear_Async and NetGear APIs? \u2693 Answer: NetGear: implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. NetGear_Async: is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to high-speed and lag-free video streaming over the network with minimal resource constraints. Key Difference: NetGear_Async is highly memory efficient, but has less features as compared to NetGear API which is marginally faster too. Can I use Multi-Server, Bi-Directional like modes in NetGear_Async? \u2693 Answer: No, NetGear_Async does NOT provide support for any NetGear's Exclusive modes yet. How to use NetGear_Async with custom Server Source from OpenCV? \u2693 Answer: See this usage example \u27b6 . Why NetGear_Async is running slow? \u2693 Answer: Checkout tips suggested in this answer \u27b6","title":"NetGear_Async FAQs"},{"location":"help/netgear_async_faqs/#netgear_async-faqs","text":"","title":"NetGear_Async FAQs"},{"location":"help/netgear_async_faqs/#what-is-netgear_async-api-and-what-does-it-do","text":"Answer: NetGear_Async is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. Basically, this API is able to transfer thousands of frames in just a few seconds without causing any significant load on your system. For more info. see NetGear_Async doc \u27b6","title":"What is NetGear_Async API and what does it do?"},{"location":"help/netgear_async_faqs/#how-to-get-started-with-netgear_async-api","text":"Answer: See NetGear_Async doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"How to get started with NetGear_Async API?"},{"location":"help/netgear_async_faqs/#netgear_async-is-throwing-modulenotfounderror-on-importing-why","text":"Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6 .","title":"\"NetGear_Async is throwing ModuleNotFoundError on importing\", Why?"},{"location":"help/netgear_async_faqs/#what-is-the-key-difference-between-netgear_async-and-netgear-apis","text":"Answer: NetGear: implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. NetGear_Async: is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to high-speed and lag-free video streaming over the network with minimal resource constraints. Key Difference: NetGear_Async is highly memory efficient, but has less features as compared to NetGear API which is marginally faster too.","title":"What is the key difference between NetGear_Async and NetGear APIs?"},{"location":"help/netgear_async_faqs/#can-i-use-multi-server-bi-directional-like-modes-in-netgear_async","text":"Answer: No, NetGear_Async does NOT provide support for any NetGear's Exclusive modes yet.","title":"Can I use Multi-Server, Bi-Directional like modes in NetGear_Async?"},{"location":"help/netgear_async_faqs/#how-to-use-netgear_async-with-custom-server-source-from-opencv","text":"Answer: See this usage example \u27b6 .","title":"How to use NetGear_Async with custom Server Source from OpenCV?"},{"location":"help/netgear_async_faqs/#why-netgear_async-is-running-slow","text":"Answer: Checkout tips suggested in this answer \u27b6","title":"Why NetGear_Async is running slow?"},{"location":"help/netgear_ex/","text":"NetGear Examples \u2693 Using NetGear with WebGear \u2693 The complete usage example is as follows: New in v0.2.2 This example was added in v0.2.2 . Client + WebGear Server \u2693 Open a terminal on Client System where you want to display the input frames (and setup WebGear server) received from the Server and execute the following python code: After running this code, Make sure to open Browser immediately otherwise NetGear will soon exit with RuntimeError . You can also try setting max_retries and request_timeout like attributes to a higher value to avoid this. Make sure you use different port value for NetGear and WebGear API. High CPU utilization may occur on Client's end. User discretion is advised. Note down the local IP-address of this system (required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. # import necessary libs import uvicorn , asyncio , cv2 from vidgear.gears import NetGear from vidgear.gears.asyncio import WebGear from vidgear.gears.asyncio.helper import reducer # initialize WebGear app without any source web = WebGear ( logging = True ) # activate jpeg encoding and specify other related parameters options = { \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # create your own custom frame producer async def my_frame_producer (): # initialize global params # Define NetGear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( receive_mode = True , address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options , ) # loop over frames while True : # receive frames from network frame = client . recv () # if NoneType if frame is None : break # do something with your OpenCV frame here # reducer frames size if you want more performance otherwise comment this line frame = await reducer ( frame , percentage = 30 , interpolation = cv2 . INTER_AREA ) # reduce frame by 30% # handle JPEG encoding encodedImage = cv2 . imencode ( \".jpg\" , frame )[ 1 ] . tobytes () # yield frame in byte format yield ( b \"--frame \\r\\n Content-Type:image/jpeg \\r\\n\\r\\n \" + encodedImage + b \" \\r\\n \" ) await asyncio . sleep ( 0 ) # close stream client . close () # add your custom frame producer to config with adequate IP address web . config [ \"generator\" ] = my_frame_producer # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in your Client's Browser. Server \u2693 Now, Open the terminal on another Server System (with a webcam connected to it at index 0) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # activate jpeg encoding and specify other related parameters options = { \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Using NetGear with WebGear_RTC \u2693 The complete usage example is as follows: New in v0.2.4 This example was added in v0.2.4 . Client + WebGear_RTC Server \u2693 Open a terminal on Client System where you want to display the input frames (and setup WebGear_RTC server) received from the Server and execute the following python code: After running this code, Make sure to open Browser immediately otherwise NetGear will soon exit with RuntimeError . You can also try setting max_retries and request_timeout like attributes to a higher value to avoid this. Make sure you use different port value for NetGear and WebGear_RTC API. High CPU utilization may occur on Client's end. User discretion is advised. Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. For VideoCapture APIs you also need to implement start() in addition to read() and stop() methods in your Custom Streaming Class as shown in following example, otherwise WebGear_RTC will fail to work! # import necessary libs import uvicorn , cv2 from vidgear.gears import NetGear from vidgear.gears.helper import reducer from vidgear.gears.asyncio import WebGear_RTC # create your own custom streaming class class Custom_Stream_Class : \"\"\" Custom Streaming using NetGear Receiver \"\"\" def __init__ ( self , address = None , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options , ): # initialize global params # Define NetGear Client at given IP address and define parameters self . client = NetGear ( receive_mode = True , address = address , port = port , protocol = protocol , pattern = pattern , logging = logging , ** options ) self . running = False def start ( self ): # don't forget this function!!! # This function is specific to VideoCapture APIs only if not self . source is None : self . source . start () def read ( self ): # don't forget this function!!! # check if source was initialized or not if self . source is None : return None # check if we're still running if self . running : # receive frames from network frame = self . client . recv () # check if frame is available if not ( frame is None ): # do something with your OpenCV frame here # reducer frames size if you want more performance otherwise comment this line frame = reducer ( frame , percentage = 20 ) # reduce frame by 20% # return our gray frame return frame else : # signal we're not running now self . running = False # return None-type return None def stop ( self ): # don't forget this function!!! # flag that we're not running self . running = False # close stream if not ( self . client is None ): self . client . close () self . client = None # activate jpeg encoding and specify NetGear related parameters options = { \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # assign your Custom Streaming Class with adequate NetGear parameters # to `custom_stream` attribute in options parameter of WebGear_RTC. options = { \"custom_stream\" : Custom_Stream_Class ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) } # initialize WebGear_RTC app without any source web = WebGear_RTC ( logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in your Client's Browser. Server \u2693 Now, Open the terminal on another Server System (with a webcam connected to it at index 0) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # activate jpeg encoding and specify other related parameters options = { \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"NetGear Examples"},{"location":"help/netgear_ex/#netgear-examples","text":"","title":"NetGear Examples"},{"location":"help/netgear_ex/#using-netgear-with-webgear","text":"The complete usage example is as follows: New in v0.2.2 This example was added in v0.2.2 .","title":"Using NetGear with WebGear"},{"location":"help/netgear_ex/#client-webgear-server","text":"Open a terminal on Client System where you want to display the input frames (and setup WebGear server) received from the Server and execute the following python code: After running this code, Make sure to open Browser immediately otherwise NetGear will soon exit with RuntimeError . You can also try setting max_retries and request_timeout like attributes to a higher value to avoid this. Make sure you use different port value for NetGear and WebGear API. High CPU utilization may occur on Client's end. User discretion is advised. Note down the local IP-address of this system (required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. # import necessary libs import uvicorn , asyncio , cv2 from vidgear.gears import NetGear from vidgear.gears.asyncio import WebGear from vidgear.gears.asyncio.helper import reducer # initialize WebGear app without any source web = WebGear ( logging = True ) # activate jpeg encoding and specify other related parameters options = { \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # create your own custom frame producer async def my_frame_producer (): # initialize global params # Define NetGear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( receive_mode = True , address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options , ) # loop over frames while True : # receive frames from network frame = client . recv () # if NoneType if frame is None : break # do something with your OpenCV frame here # reducer frames size if you want more performance otherwise comment this line frame = await reducer ( frame , percentage = 30 , interpolation = cv2 . INTER_AREA ) # reduce frame by 30% # handle JPEG encoding encodedImage = cv2 . imencode ( \".jpg\" , frame )[ 1 ] . tobytes () # yield frame in byte format yield ( b \"--frame \\r\\n Content-Type:image/jpeg \\r\\n\\r\\n \" + encodedImage + b \" \\r\\n \" ) await asyncio . sleep ( 0 ) # close stream client . close () # add your custom frame producer to config with adequate IP address web . config [ \"generator\" ] = my_frame_producer # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in your Client's Browser.","title":"Client + WebGear Server"},{"location":"help/netgear_ex/#server","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # activate jpeg encoding and specify other related parameters options = { \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server"},{"location":"help/netgear_ex/#using-netgear-with-webgear_rtc","text":"The complete usage example is as follows: New in v0.2.4 This example was added in v0.2.4 .","title":"Using NetGear with WebGear_RTC"},{"location":"help/netgear_ex/#client-webgear_rtc-server","text":"Open a terminal on Client System where you want to display the input frames (and setup WebGear_RTC server) received from the Server and execute the following python code: After running this code, Make sure to open Browser immediately otherwise NetGear will soon exit with RuntimeError . You can also try setting max_retries and request_timeout like attributes to a higher value to avoid this. Make sure you use different port value for NetGear and WebGear_RTC API. High CPU utilization may occur on Client's end. User discretion is advised. Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose. For VideoCapture APIs you also need to implement start() in addition to read() and stop() methods in your Custom Streaming Class as shown in following example, otherwise WebGear_RTC will fail to work! # import necessary libs import uvicorn , cv2 from vidgear.gears import NetGear from vidgear.gears.helper import reducer from vidgear.gears.asyncio import WebGear_RTC # create your own custom streaming class class Custom_Stream_Class : \"\"\" Custom Streaming using NetGear Receiver \"\"\" def __init__ ( self , address = None , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options , ): # initialize global params # Define NetGear Client at given IP address and define parameters self . client = NetGear ( receive_mode = True , address = address , port = port , protocol = protocol , pattern = pattern , logging = logging , ** options ) self . running = False def start ( self ): # don't forget this function!!! # This function is specific to VideoCapture APIs only if not self . source is None : self . source . start () def read ( self ): # don't forget this function!!! # check if source was initialized or not if self . source is None : return None # check if we're still running if self . running : # receive frames from network frame = self . client . recv () # check if frame is available if not ( frame is None ): # do something with your OpenCV frame here # reducer frames size if you want more performance otherwise comment this line frame = reducer ( frame , percentage = 20 ) # reduce frame by 20% # return our gray frame return frame else : # signal we're not running now self . running = False # return None-type return None def stop ( self ): # don't forget this function!!! # flag that we're not running self . running = False # close stream if not ( self . client is None ): self . client . close () self . client = None # activate jpeg encoding and specify NetGear related parameters options = { \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # assign your Custom Streaming Class with adequate NetGear parameters # to `custom_stream` attribute in options parameter of WebGear_RTC. options = { \"custom_stream\" : Custom_Stream_Class ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) } # initialize WebGear_RTC app without any source web = WebGear_RTC ( logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in your Client's Browser.","title":"Client + WebGear_RTC Server"},{"location":"help/netgear_ex/#server_1","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # activate jpeg encoding and specify other related parameters options = { \"jpeg_compression\" : True , \"jpeg_compression_quality\" : 90 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : True , } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server"},{"location":"help/netgear_faqs/","text":"NetGear FAQs \u2693 What is NetGear API and what does it do? \u2693 Answer: NetGear is exclusively designed to transfer video frames & data synchronously (Pair & Request/Reply) as well as asynchronously (Publish/Subscribe) between various interconnecting systems over the network in real-time. For more info. see NetGear doc \u27b6 How to get started with NetGear API? \u2693 Answer: See NetGear doc \u27b6 . Still in doubt, then discuss on Gitter \u27b6 Community channel. What Exclusive Modes are compatible with each other in NetGear API? \u2693 Here's the compatibility chart for NetGear's Exclusive Modes : Exclusive Modes Multi-Servers Multi-Clients Secure Bidirectional SSH Tunneling Multi-Servers - No (throws error) Yes Yes No (throws error) Multi-Clients No (throws error) - Yes Yes No (throws error) Secure Yes Yes - Yes Yes Bidirectional Yes Yes Yes - Yes SSH Tunneling No (throws error) No (throws error) Yes Yes - Why NetGear is running slow? \u2693 Answer: Here are few tips to troubleshoot performance on your machine: Update ZMQ to latest: Update your pyzmq lib as follows: sudo pip3 install -U pyzmq Install testing branch: The testing branch may contain many latest performance updates, which are not yet merged into master branch. Therefore, you can try them earlier, by installing testing branch directly \u27b6 . Use PUB/SUB pattern if you're live streaming : Try different pattern values, as each of them suits different settings. For example, you can use its Publisher/Subscriber pattern (i.e. pattern=2 ) for asynchronous high-speed transmission over real-time streams, and it works faster than other synchronous patterns for this scenario. Use Wired connection instead of Wireless connection : Remember typical 802.11g Wireless has a theoretical maximum of 54Mbps. Typical wired 10/100/1000 Ethernet has a theoretical maximum of 100 Gbps. So in theory wired is faster. However, these speeds are only on your local network. So chose your network configuration wisely. Enable all Performance Attributes with Frame Compression : You can also try enabling Frame Compression with its all Performance Attributes for NetGear API. Reduce Frame Size: Use VidGear's real-time Frame-Size Reducer ( reducer ) method for reducing frame-size on-the-go for additional performance (see this usage example \u27b6 ) . Remember, sending large HQ video-frames may required more network bandwidth and packet size, which can lead to additional latency! Systematically, check for Hardware/Network Issues \u27b6 Finally, if nothing works then, checkout NetGear_Async API \u27b6 How to find local IP-address on different OS platforms? \u2693 Answer: For finding local IP-address of your machine: On Linux OS On Windows OS On MAC OS Follow this tutorial \u27b6 Follow this tutorial \u27b6 Follow this tutorial \u27b6 How to send data along with frames in Multi-Servers and Multi-Clients Modes? \u2693 Answer: See Multi-Servers usage example \u27b6 and Multi-Clients usage example \u27b6 How to use enable Encryption and Authentication in NetGear API? \u2693 Answer: See its Secure Mode doc \u27b6 . How to send custom data along with frames bidirectionally in NetGear API? \u2693 Answer: See its Bidirectional Mode doc \u27b6 . How to access NetGear API outside network or remotely? \u2693 Answer: See its SSH Tunneling Mode doc \u27b6 . Are there any side-effect of sending data with frames? \u2693 Answer: Yes, it may lead to additional LATENCY depending upon the size/amount of the data being transferred. User discretion is advised. Why NetGear API not working correctly? \u2693 Answer: First, carefully go through NetGear doc \u27b6 that contains detailed information. Also, checkout PyZmq Docs \u27b6 for its various settings/parameters. If still it doesn't work for you, then let us know on Gitter \u27b6 How to solve zmq.error.ZMQError errors? \u2693 Answer: For those used to the idea that a \"server\" provides their address to a client, then you should recheck your preconceptions ! Please read the Netgear instructions carefully, and you will note that it is the client device that defines the IP that is provided to the server config. If you get this the wrong way (using the server IP on the client), then you will get a zmq.error.ZMQError error. Make sure it is the client's IP shared across the two systems.","title":"NetGear FAQs"},{"location":"help/netgear_faqs/#netgear-faqs","text":"","title":"NetGear FAQs"},{"location":"help/netgear_faqs/#what-is-netgear-api-and-what-does-it-do","text":"Answer: NetGear is exclusively designed to transfer video frames & data synchronously (Pair & Request/Reply) as well as asynchronously (Publish/Subscribe) between various interconnecting systems over the network in real-time. For more info. see NetGear doc \u27b6","title":"What is NetGear API and what does it do?"},{"location":"help/netgear_faqs/#how-to-get-started-with-netgear-api","text":"Answer: See NetGear doc \u27b6 . Still in doubt, then discuss on Gitter \u27b6 Community channel.","title":"How to get started with NetGear API?"},{"location":"help/netgear_faqs/#what-exclusive-modes-are-compatible-with-each-other-in-netgear-api","text":"Here's the compatibility chart for NetGear's Exclusive Modes : Exclusive Modes Multi-Servers Multi-Clients Secure Bidirectional SSH Tunneling Multi-Servers - No (throws error) Yes Yes No (throws error) Multi-Clients No (throws error) - Yes Yes No (throws error) Secure Yes Yes - Yes Yes Bidirectional Yes Yes Yes - Yes SSH Tunneling No (throws error) No (throws error) Yes Yes -","title":"What Exclusive Modes are compatible with each other in NetGear API?"},{"location":"help/netgear_faqs/#why-netgear-is-running-slow","text":"Answer: Here are few tips to troubleshoot performance on your machine: Update ZMQ to latest: Update your pyzmq lib as follows: sudo pip3 install -U pyzmq Install testing branch: The testing branch may contain many latest performance updates, which are not yet merged into master branch. Therefore, you can try them earlier, by installing testing branch directly \u27b6 . Use PUB/SUB pattern if you're live streaming : Try different pattern values, as each of them suits different settings. For example, you can use its Publisher/Subscriber pattern (i.e. pattern=2 ) for asynchronous high-speed transmission over real-time streams, and it works faster than other synchronous patterns for this scenario. Use Wired connection instead of Wireless connection : Remember typical 802.11g Wireless has a theoretical maximum of 54Mbps. Typical wired 10/100/1000 Ethernet has a theoretical maximum of 100 Gbps. So in theory wired is faster. However, these speeds are only on your local network. So chose your network configuration wisely. Enable all Performance Attributes with Frame Compression : You can also try enabling Frame Compression with its all Performance Attributes for NetGear API. Reduce Frame Size: Use VidGear's real-time Frame-Size Reducer ( reducer ) method for reducing frame-size on-the-go for additional performance (see this usage example \u27b6 ) . Remember, sending large HQ video-frames may required more network bandwidth and packet size, which can lead to additional latency! Systematically, check for Hardware/Network Issues \u27b6 Finally, if nothing works then, checkout NetGear_Async API \u27b6","title":"Why NetGear is running slow?"},{"location":"help/netgear_faqs/#how-to-find-local-ip-address-on-different-os-platforms","text":"Answer: For finding local IP-address of your machine: On Linux OS On Windows OS On MAC OS Follow this tutorial \u27b6 Follow this tutorial \u27b6 Follow this tutorial \u27b6","title":"How to find local IP-address on different OS platforms?"},{"location":"help/netgear_faqs/#how-to-send-data-along-with-frames-in-multi-servers-and-multi-clients-modes","text":"Answer: See Multi-Servers usage example \u27b6 and Multi-Clients usage example \u27b6","title":"How to send data along with frames in Multi-Servers and Multi-Clients Modes?"},{"location":"help/netgear_faqs/#how-to-use-enable-encryption-and-authentication-in-netgear-api","text":"Answer: See its Secure Mode doc \u27b6 .","title":"How to use enable Encryption and Authentication in NetGear API?"},{"location":"help/netgear_faqs/#how-to-send-custom-data-along-with-frames-bidirectionally-in-netgear-api","text":"Answer: See its Bidirectional Mode doc \u27b6 .","title":"How to send custom data along with frames bidirectionally in NetGear API?"},{"location":"help/netgear_faqs/#how-to-access-netgear-api-outside-network-or-remotely","text":"Answer: See its SSH Tunneling Mode doc \u27b6 .","title":"How to access NetGear API outside network or remotely?"},{"location":"help/netgear_faqs/#are-there-any-side-effect-of-sending-data-with-frames","text":"Answer: Yes, it may lead to additional LATENCY depending upon the size/amount of the data being transferred. User discretion is advised.","title":"Are there any side-effect of sending data with frames?"},{"location":"help/netgear_faqs/#why-netgear-api-not-working-correctly","text":"Answer: First, carefully go through NetGear doc \u27b6 that contains detailed information. Also, checkout PyZmq Docs \u27b6 for its various settings/parameters. If still it doesn't work for you, then let us know on Gitter \u27b6","title":"Why NetGear API not working correctly?"},{"location":"help/netgear_faqs/#how-to-solve-zmqerrorzmqerror-errors","text":"Answer: For those used to the idea that a \"server\" provides their address to a client, then you should recheck your preconceptions ! Please read the Netgear instructions carefully, and you will note that it is the client device that defines the IP that is provided to the server config. If you get this the wrong way (using the server IP on the client), then you will get a zmq.error.ZMQError error. Make sure it is the client's IP shared across the two systems.","title":"How to solve zmq.error.ZMQError errors?"},{"location":"help/pigear_ex/","text":"PiGear Examples \u2693 Setting variable picamera parameters for Camera Module at runtime \u2693 You can use stream global parameter in PiGear to feed any picamera parameters at runtime. In this example we will set initial Camera Module's brightness value 80 , and will change it 50 when z key is pressed at runtime: # import required libraries from vidgear.gears import PiGear import cv2 # initial parameters options = { \"brightness\" : 80 } # set brightness to 80 # open pi video stream with default parameters stream = PiGear ( logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # check for 'z' key if pressed if key == ord ( \"z\" ): # change brightness to 50 stream . stream . brightness = 50 # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"PiGear Examples"},{"location":"help/pigear_ex/#pigear-examples","text":"","title":"PiGear Examples"},{"location":"help/pigear_ex/#setting-variable-picamera-parameters-for-camera-module-at-runtime","text":"You can use stream global parameter in PiGear to feed any picamera parameters at runtime. In this example we will set initial Camera Module's brightness value 80 , and will change it 50 when z key is pressed at runtime: # import required libraries from vidgear.gears import PiGear import cv2 # initial parameters options = { \"brightness\" : 80 } # set brightness to 80 # open pi video stream with default parameters stream = PiGear ( logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # check for 'z' key if pressed if key == ord ( \"z\" ): # change brightness to 50 stream . stream . brightness = 50 # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Setting variable picamera parameters for Camera Module at runtime"},{"location":"help/pigear_faqs/","text":"PiGear FAQs \u2693 What is PiGear API and what does it do? \u2693 Answer: PiGear is similar to CamGear but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module ). For more info. see PiGear doc \u27b6 I'm only familiar with OpenCV, how to get started with PiGear API? \u2693 Answer: First, see Switching from OpenCV , then go through PiGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel. Why my camera module is not detected by PiGear? \u2693 Answer: Make sure to enable Raspberry Pi hardware-specific settings \u27b6 before using PiGear. Also, recheck/change your Camera Module's ribbon-cable and Camera Module itself, if it damaged or got broken somehow. How to select camera index on Pi Compute IO board with two Cameras attached? \u2693 Answer: See PiGear's camera_num parameter \u27b6 Why PiGear is throwing SystemError ? \u2693 Answer: This means your Raspberry Pi CSI ribbon-cable is not connected properly to your Camera Module, or damaged, or even both. How to assign picamera settings for Camera Module with PiGear? \u2693 Answer: See this usage example \u27b6 \"Video output is too dark with PiGear\", Why? \u2693 Answer: Seems like the settings are wrong. Kindly see picamera docs for available parameters, and look for parameters are sensor_mode , shutter_speed and exposure_mode , try changing those values. Also, maybe your framerate value is too high. Try lowering it. How to change picamera settings for Camera Module at runtime? \u2693 Answer: You can use stream global parameter in PiGear to feed any picamera setting at runtime. See this bonus example \u27b6","title":"PiGear FAQs"},{"location":"help/pigear_faqs/#pigear-faqs","text":"","title":"PiGear FAQs"},{"location":"help/pigear_faqs/#what-is-pigear-api-and-what-does-it-do","text":"Answer: PiGear is similar to CamGear but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module ). For more info. see PiGear doc \u27b6","title":"What is PiGear API and what does it do?"},{"location":"help/pigear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-pigear-api","text":"Answer: First, see Switching from OpenCV , then go through PiGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"I'm only familiar with OpenCV, how to get started with PiGear API?"},{"location":"help/pigear_faqs/#why-my-camera-module-is-not-detected-by-pigear","text":"Answer: Make sure to enable Raspberry Pi hardware-specific settings \u27b6 before using PiGear. Also, recheck/change your Camera Module's ribbon-cable and Camera Module itself, if it damaged or got broken somehow.","title":"Why my camera module is not detected by PiGear?"},{"location":"help/pigear_faqs/#how-to-select-camera-index-on-pi-compute-io-board-with-two-cameras-attached","text":"Answer: See PiGear's camera_num parameter \u27b6","title":"How to select camera index on Pi Compute IO board with two Cameras attached?"},{"location":"help/pigear_faqs/#why-pigear-is-throwing-systemerror","text":"Answer: This means your Raspberry Pi CSI ribbon-cable is not connected properly to your Camera Module, or damaged, or even both.","title":"Why PiGear is throwing SystemError?"},{"location":"help/pigear_faqs/#how-to-assign-picamera-settings-for-camera-module-with-pigear","text":"Answer: See this usage example \u27b6","title":"How to assign picamera settings for Camera Module with PiGear?"},{"location":"help/pigear_faqs/#video-output-is-too-dark-with-pigear-why","text":"Answer: Seems like the settings are wrong. Kindly see picamera docs for available parameters, and look for parameters are sensor_mode , shutter_speed and exposure_mode , try changing those values. Also, maybe your framerate value is too high. Try lowering it.","title":"\"Video output is too dark with PiGear\", Why?"},{"location":"help/pigear_faqs/#how-to-change-picamera-settings-for-camera-module-at-runtime","text":"Answer: You can use stream global parameter in PiGear to feed any picamera setting at runtime. See this bonus example \u27b6","title":"How to change picamera settings for Camera Module at runtime?"},{"location":"help/screengear_ex/","text":"ScreenGear Examples \u2693 Using ScreenGear with NetGear and WriteGear \u2693 The complete usage example is as follows: New in v0.2.2 This example was added in v0.2.2 . Client + WriteGear \u2693 Open a terminal on Client System (where you want to save the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import WriteGear import cv2 # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # close output window cv2 . destroyAllWindows () # safely close client client . close () # safely close writer writer . close () Server + ScreenGear \u2693 Now, Open the terminal on another Server System (with a montior/display attached to it) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import ScreenGear from vidgear.gears import NetGear # define dimensions of screen w.r.t to given monitor to be captured options = { \"top\" : 40 , \"left\" : 0 , \"width\" : 100 , \"height\" : 100 } # open stream with defined parameters stream = ScreenGear ( logging = True , ** options ) . start () # define various netgear tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Using ScreenGear with WebGear_RTC \u2693 The complete usage example is as follows: New in v0.2.4 This example was added in v0.2.4 . Bare-Minimum Advanced # import necessary libs import uvicorn , cv2 from vidgear.gears import ScreenGear from vidgear.gears.asyncio import WebGear_RTC # assign your ScreenGear class with adequate parameters # to `custom_stream` attribute in options parameter options = { \"custom_stream\" : ScreenGear ( logging = True )} # initialize WebGear_RTC app without any source web = WebGear_RTC ( logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () For VideoCapture APIs you also need to implement start() in addition to read() and stop() methods in your Custom Streaming Class as shown in following example, otherwise WebGear_RTC will fail to work! # import necessary libs import uvicorn , cv2 from vidgear.gears import ScreenGear from vidgear.gears.helper import reducer from vidgear.gears.asyncio import WebGear_RTC # create your own custom streaming class class Custom_Stream_Class : \"\"\" Custom Streaming using ScreenGear \"\"\" def __init__ ( self , backend = \"mss\" , logging = False ): # !!! define your own video source here !!! self . source = ScreenGear ( backend = backend , logging = logging ) # define running flag self . running = True def start ( self ): # don't forget this function!!! # This function is specific to VideoCapture APIs only if not self . source is None : self . source . start () def read ( self ): # don't forget this function!!! # check if source was initialized or not if self . source is None : return None # check if we're still running if self . running : # read frame from provided source frame = self . source . read () # check if frame is available if not ( frame is None ): # do something with your OpenCV frame here # reducer frames size if you want more performance otherwise comment this line frame = reducer ( frame , percentage = 20 ) # reduce frame by 20% # return our gray frame return frame else : # signal we're not running now self . running = False # return None-type return None def stop ( self ): # don't forget this function!!! # flag that we're not running self . running = False # close stream if not self . source is None : self . source . stop () # assign your Custom Streaming Class with adequate ScreenGear parameters # to `custom_stream` attribute in options parameter options = { \"custom_stream\" : Custom_Stream_Class ( backend = \"pil\" , logging = True )} # initialize WebGear_RTC app without any source web = WebGear_RTC ( logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown ()","title":"ScreenGear Examples"},{"location":"help/screengear_ex/#screengear-examples","text":"","title":"ScreenGear Examples"},{"location":"help/screengear_ex/#using-screengear-with-netgear-and-writegear","text":"The complete usage example is as follows: New in v0.2.2 This example was added in v0.2.2 .","title":"Using ScreenGear with NetGear and WriteGear"},{"location":"help/screengear_ex/#client-writegear","text":"Open a terminal on Client System (where you want to save the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import WriteGear import cv2 # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # close output window cv2 . destroyAllWindows () # safely close client client . close () # safely close writer writer . close ()","title":"Client + WriteGear"},{"location":"help/screengear_ex/#server-screengear","text":"Now, Open the terminal on another Server System (with a montior/display attached to it) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import ScreenGear from vidgear.gears import NetGear # define dimensions of screen w.r.t to given monitor to be captured options = { \"top\" : 40 , \"left\" : 0 , \"width\" : 100 , \"height\" : 100 } # open stream with defined parameters stream = ScreenGear ( logging = True , ** options ) . start () # define various netgear tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server + ScreenGear"},{"location":"help/screengear_ex/#using-screengear-with-webgear_rtc","text":"The complete usage example is as follows: New in v0.2.4 This example was added in v0.2.4 . Bare-Minimum Advanced # import necessary libs import uvicorn , cv2 from vidgear.gears import ScreenGear from vidgear.gears.asyncio import WebGear_RTC # assign your ScreenGear class with adequate parameters # to `custom_stream` attribute in options parameter options = { \"custom_stream\" : ScreenGear ( logging = True )} # initialize WebGear_RTC app without any source web = WebGear_RTC ( logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () For VideoCapture APIs you also need to implement start() in addition to read() and stop() methods in your Custom Streaming Class as shown in following example, otherwise WebGear_RTC will fail to work! # import necessary libs import uvicorn , cv2 from vidgear.gears import ScreenGear from vidgear.gears.helper import reducer from vidgear.gears.asyncio import WebGear_RTC # create your own custom streaming class class Custom_Stream_Class : \"\"\" Custom Streaming using ScreenGear \"\"\" def __init__ ( self , backend = \"mss\" , logging = False ): # !!! define your own video source here !!! self . source = ScreenGear ( backend = backend , logging = logging ) # define running flag self . running = True def start ( self ): # don't forget this function!!! # This function is specific to VideoCapture APIs only if not self . source is None : self . source . start () def read ( self ): # don't forget this function!!! # check if source was initialized or not if self . source is None : return None # check if we're still running if self . running : # read frame from provided source frame = self . source . read () # check if frame is available if not ( frame is None ): # do something with your OpenCV frame here # reducer frames size if you want more performance otherwise comment this line frame = reducer ( frame , percentage = 20 ) # reduce frame by 20% # return our gray frame return frame else : # signal we're not running now self . running = False # return None-type return None def stop ( self ): # don't forget this function!!! # flag that we're not running self . running = False # close stream if not self . source is None : self . source . stop () # assign your Custom Streaming Class with adequate ScreenGear parameters # to `custom_stream` attribute in options parameter options = { \"custom_stream\" : Custom_Stream_Class ( backend = \"pil\" , logging = True )} # initialize WebGear_RTC app without any source web = WebGear_RTC ( logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown ()","title":"Using ScreenGear with WebGear_RTC"},{"location":"help/screengear_faqs/","text":"ScreenGear FAQs \u2693 What is ScreenGear API and what does it do? \u2693 Answer: ScreenGear is designed exclusively for ultra-fast Screencasting, that means it can grab frames from your monitor in real-time, either by define an area on the computer screen, or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends. For more info. see ScreenGear doc \u27b6 I'm only familiar with OpenCV, how to get started with ScreenGear API? \u2693 Answer: First, see Switching from OpenCV , then go through ScreenGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel. ScreenGear is Slow? \u2693 Answer: This maybe due to selected backend for ScreenGear API is not compatibile with your machine. See this usage example to change backend \u27b6 . Try different backends, and select which works the best for your machine. How to define area on screen to record with ScreenGear? \u2693 Answer: See this usage example \u27b6 How to record video from all connected screens? \u2693 Answer: See ScreenGear's monitor parameter that sets the index of the monitor to grab a frame from. If its value is -1 , it will record from all monitors. More information can be found here \u27b6","title":"ScreenGear FAQs"},{"location":"help/screengear_faqs/#screengear-faqs","text":"","title":"ScreenGear FAQs"},{"location":"help/screengear_faqs/#what-is-screengear-api-and-what-does-it-do","text":"Answer: ScreenGear is designed exclusively for ultra-fast Screencasting, that means it can grab frames from your monitor in real-time, either by define an area on the computer screen, or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends. For more info. see ScreenGear doc \u27b6","title":"What is ScreenGear API and what does it do?"},{"location":"help/screengear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-screengear-api","text":"Answer: First, see Switching from OpenCV , then go through ScreenGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"I'm only familiar with OpenCV, how to get started with ScreenGear API?"},{"location":"help/screengear_faqs/#screengear-is-slow","text":"Answer: This maybe due to selected backend for ScreenGear API is not compatibile with your machine. See this usage example to change backend \u27b6 . Try different backends, and select which works the best for your machine.","title":"ScreenGear is Slow?"},{"location":"help/screengear_faqs/#how-to-define-area-on-screen-to-record-with-screengear","text":"Answer: See this usage example \u27b6","title":"How to define area on screen to record with ScreenGear?"},{"location":"help/screengear_faqs/#how-to-record-video-from-all-connected-screens","text":"Answer: See ScreenGear's monitor parameter that sets the index of the monitor to grab a frame from. If its value is -1 , it will record from all monitors. More information can be found here \u27b6","title":"How to record video from all connected screens?"},{"location":"help/stabilizer_ex/","text":"Stabilizer Class Examples \u2693 Saving Stabilizer Class output with Live Audio Input \u2693 In this example code, we will merging the audio from a Audio Device (for e.g. Webcam inbuilt mic input) with Stablized frames incoming from the Stabilizer Class (which is also using same Webcam video input through OpenCV) , and save the final output as a compressed video file, all in real time: New in v0.2.2 This example was added in v0.2.2 . Example Assumptions You're running are Linux machine. You already have appropriate audio driver and software installed on your machine. Identifying and Specifying sound card on different OS platforms On Windows On Linux On MacOS Windows OS users can use the dshow (DirectShow) to list audio input device which is the preferred option for Windows users. You can refer following steps to identify and specify your sound card: [OPTIONAL] Enable sound card(if disabled): First enable your Stereo Mix by opening the \"Sound\" window and select the \"Recording\" tab, then right click on the window and select \"Show Disabled Devices\" to toggle the Stereo Mix device visibility. Follow this post \u27b6 for more details. Identify Sound Card: Then, You can locate your soundcard using dshow as follows: c: \\> ffmpeg -list_devices true -f dshow -i dummy ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ dshow @ 03ACF580 ] DirectShow video devices [ dshow @ 03ACF580 ] \"Integrated Camera\" [ dshow @ 03ACF580 ] \"USB2.0 Camera\" [ dshow @ 03ACF580 ] DirectShow audio devices [ dshow @ 03ACF580 ] \"Microphone (Realtek High Definition Audio)\" [ dshow @ 03ACF580 ] \"Microphone (USB2.0 Camera)\" dummy: Immediate exit requested Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows: # assign appropriate input audio-source output_params = { \"-f\" : \"dshow\" , # !!! warning: always keep this line above \"-i\" parameter !!! \"-i\" : \"audio=Microphone (USB2.0 Camera)\" , \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-acodec\" : \"aac\" , \"-ar\" : \"44100\" , } If audio still doesn't work then checkout this troubleshooting guide \u27b6 or reach us out on Gitter \u27b6 Community channel Linux OS users can use the alsa to list input device to capture live audio input such as from a webcam. You can refer following steps to identify and specify your sound card: Identify Sound Card: To get the list of all installed cards on your machine, you can type arecord -l or arecord -L (longer output) . arecord -l **** List of CAPTURE Hardware Devices **** card 0 : ICH5 [ Intel ICH5 ] , device 0 : Intel ICH [ Intel ICH5 ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 1 : Intel ICH - MIC ADC [ Intel ICH5 - MIC ADC ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 2 : Intel ICH - MIC2 ADC [ Intel ICH5 - MIC2 ADC ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 3 : Intel ICH - ADC2 [ Intel ICH5 - ADC2 ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 1 : U0x46d0x809 [ USB Device 0x46d:0x809 ] , device 0 : USB Audio [ USB Audio ] Subdevices: 1 /1 Subdevice #0: subdevice #0 Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows: The easiest thing to do is to reference sound card directly, namely \"card 0\" (Intel ICH5) and \"card 1\" (Microphone on the USB web cam), as hw:0 or hw:1 # assign appropriate input audio-source output_params = { \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-ar\" : \"48000\" , \"-f\" : \"alsa\" , # !!! warning: always keep this line above \"-i\" parameter !!! \"-i\" : \"hw:1\" , } If audio still doesn't work then reach us out on Gitter \u27b6 Community channel MAC OS users can use the avfoundation to list input devices for grabbing audio from integrated iSight cameras as well as cameras connected via USB or FireWire. You can refer following steps to identify and specify your sound card on MacOS/OSX machines: Identify Sound Card: Then, You can locate your soundcard using avfoundation as follows: ffmpeg -f qtkit -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows: # assign appropriate input audio-source output_params = { \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-ar\" : \"48000\" , \"-f\" : \"avfoundation\" , # !!! warning: always keep this line above \"-audio_device_index\" parameter !!! \"-audio_device_index\" : \"0\" , } If audio still doesn't work then reach us out on Gitter \u27b6 Community channel Make sure this -i audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all. You MUST use -input_framerate attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams. # import required libraries from vidgear.gears import WriteGear from vidgear.gears.stabilizer import Stabilizer import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # initiate stabilizer object with defined parameters stab = Stabilizer ( smoothing_radius = 30 , crop_n_zoom = True , border_size = 5 , logging = True ) # change with your webcam soundcard, plus add additional required FFmpeg parameters for your writer output_params = { \"-input_framerate\" : stream . get ( cv2 . CAP_PROP_FPS ), \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-ar\" : \"48000\" , \"-f\" : \"alsa\" , # !!! warning: always keep this line above \"-i\" parameter !!! \"-i\" : \"hw:1\" , } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4 writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized frame here} # write stabilized frame to writer writer . write ( stabilized_frame ) # clear stabilizer resources stab . clean () # safely close video stream stream . release () # safely close writer writer . close () Saving Stabilizer Class output with File Audio Input \u2693 In this example code, we will be directly merging the audio from a Video-File (to be stabilized) with its processed stabilized frames into a compressed video output in real time: New in v0.2.4 This example was added in v0.2.4 . Make sure this input video-file (to be stabilized) contains valid audio source, otherwise you could encounter multiple errors or no output at all. You MUST use -input_framerate attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams. Use -disable_force_termination flag when video duration is too short(<60sec), otherwise WriteGear will not produce any valid output. # import required libraries from vidgear.gears import WriteGear from vidgear.gears.stabilizer import Stabilizer import cv2 # Give suitable video file path to be stabilized unstablized_videofile = \"test.mp4\" # open stream on given path stream = cv2 . VideoCapture ( unstablized_videofile ) # initiate stabilizer object with defined parameters stab = Stabilizer ( smoothing_radius = 30 , crop_n_zoom = True , border_size = 5 , logging = True ) # define required FFmpeg optimizing parameters for your writer output_params = { \"-i\" : unstablized_videofile , \"-c:a\" : \"aac\" , \"-input_framerate\" : stream . get ( cv2 . CAP_PROP_FPS ), \"-clones\" : [ \"-shortest\" ], # !!! Uncomment following line if video duration is too short(<60sec). !!! #\"-disable_force_termination\": True, } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4 writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized frame here} # write stabilized frame to writer writer . write ( stabilized_frame ) # clear stabilizer resources stab . clean () # safely close video stream stream . release () # safely close writer writer . close ()","title":"Stabilizer Class Examples"},{"location":"help/stabilizer_ex/#stabilizer-class-examples","text":"","title":"Stabilizer Class Examples"},{"location":"help/stabilizer_ex/#saving-stabilizer-class-output-with-live-audio-input","text":"In this example code, we will merging the audio from a Audio Device (for e.g. Webcam inbuilt mic input) with Stablized frames incoming from the Stabilizer Class (which is also using same Webcam video input through OpenCV) , and save the final output as a compressed video file, all in real time: New in v0.2.2 This example was added in v0.2.2 . Example Assumptions You're running are Linux machine. You already have appropriate audio driver and software installed on your machine. Identifying and Specifying sound card on different OS platforms On Windows On Linux On MacOS Windows OS users can use the dshow (DirectShow) to list audio input device which is the preferred option for Windows users. You can refer following steps to identify and specify your sound card: [OPTIONAL] Enable sound card(if disabled): First enable your Stereo Mix by opening the \"Sound\" window and select the \"Recording\" tab, then right click on the window and select \"Show Disabled Devices\" to toggle the Stereo Mix device visibility. Follow this post \u27b6 for more details. Identify Sound Card: Then, You can locate your soundcard using dshow as follows: c: \\> ffmpeg -list_devices true -f dshow -i dummy ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ dshow @ 03ACF580 ] DirectShow video devices [ dshow @ 03ACF580 ] \"Integrated Camera\" [ dshow @ 03ACF580 ] \"USB2.0 Camera\" [ dshow @ 03ACF580 ] DirectShow audio devices [ dshow @ 03ACF580 ] \"Microphone (Realtek High Definition Audio)\" [ dshow @ 03ACF580 ] \"Microphone (USB2.0 Camera)\" dummy: Immediate exit requested Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows: # assign appropriate input audio-source output_params = { \"-f\" : \"dshow\" , # !!! warning: always keep this line above \"-i\" parameter !!! \"-i\" : \"audio=Microphone (USB2.0 Camera)\" , \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-acodec\" : \"aac\" , \"-ar\" : \"44100\" , } If audio still doesn't work then checkout this troubleshooting guide \u27b6 or reach us out on Gitter \u27b6 Community channel Linux OS users can use the alsa to list input device to capture live audio input such as from a webcam. You can refer following steps to identify and specify your sound card: Identify Sound Card: To get the list of all installed cards on your machine, you can type arecord -l or arecord -L (longer output) . arecord -l **** List of CAPTURE Hardware Devices **** card 0 : ICH5 [ Intel ICH5 ] , device 0 : Intel ICH [ Intel ICH5 ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 1 : Intel ICH - MIC ADC [ Intel ICH5 - MIC ADC ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 2 : Intel ICH - MIC2 ADC [ Intel ICH5 - MIC2 ADC ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 0 : ICH5 [ Intel ICH5 ] , device 3 : Intel ICH - ADC2 [ Intel ICH5 - ADC2 ] Subdevices: 1 /1 Subdevice #0: subdevice #0 card 1 : U0x46d0x809 [ USB Device 0x46d:0x809 ] , device 0 : USB Audio [ USB Audio ] Subdevices: 1 /1 Subdevice #0: subdevice #0 Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows: The easiest thing to do is to reference sound card directly, namely \"card 0\" (Intel ICH5) and \"card 1\" (Microphone on the USB web cam), as hw:0 or hw:1 # assign appropriate input audio-source output_params = { \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-ar\" : \"48000\" , \"-f\" : \"alsa\" , # !!! warning: always keep this line above \"-i\" parameter !!! \"-i\" : \"hw:1\" , } If audio still doesn't work then reach us out on Gitter \u27b6 Community channel MAC OS users can use the avfoundation to list input devices for grabbing audio from integrated iSight cameras as well as cameras connected via USB or FireWire. You can refer following steps to identify and specify your sound card on MacOS/OSX machines: Identify Sound Card: Then, You can locate your soundcard using avfoundation as follows: ffmpeg -f qtkit -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows: # assign appropriate input audio-source output_params = { \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-ar\" : \"48000\" , \"-f\" : \"avfoundation\" , # !!! warning: always keep this line above \"-audio_device_index\" parameter !!! \"-audio_device_index\" : \"0\" , } If audio still doesn't work then reach us out on Gitter \u27b6 Community channel Make sure this -i audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all. You MUST use -input_framerate attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams. # import required libraries from vidgear.gears import WriteGear from vidgear.gears.stabilizer import Stabilizer import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # initiate stabilizer object with defined parameters stab = Stabilizer ( smoothing_radius = 30 , crop_n_zoom = True , border_size = 5 , logging = True ) # change with your webcam soundcard, plus add additional required FFmpeg parameters for your writer output_params = { \"-input_framerate\" : stream . get ( cv2 . CAP_PROP_FPS ), \"-thread_queue_size\" : \"512\" , \"-ac\" : \"2\" , \"-ar\" : \"48000\" , \"-f\" : \"alsa\" , # !!! warning: always keep this line above \"-i\" parameter !!! \"-i\" : \"hw:1\" , } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4 writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized frame here} # write stabilized frame to writer writer . write ( stabilized_frame ) # clear stabilizer resources stab . clean () # safely close video stream stream . release () # safely close writer writer . close ()","title":"Saving Stabilizer Class output with Live Audio Input"},{"location":"help/stabilizer_ex/#saving-stabilizer-class-output-with-file-audio-input","text":"In this example code, we will be directly merging the audio from a Video-File (to be stabilized) with its processed stabilized frames into a compressed video output in real time: New in v0.2.4 This example was added in v0.2.4 . Make sure this input video-file (to be stabilized) contains valid audio source, otherwise you could encounter multiple errors or no output at all. You MUST use -input_framerate attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams. Use -disable_force_termination flag when video duration is too short(<60sec), otherwise WriteGear will not produce any valid output. # import required libraries from vidgear.gears import WriteGear from vidgear.gears.stabilizer import Stabilizer import cv2 # Give suitable video file path to be stabilized unstablized_videofile = \"test.mp4\" # open stream on given path stream = cv2 . VideoCapture ( unstablized_videofile ) # initiate stabilizer object with defined parameters stab = Stabilizer ( smoothing_radius = 30 , crop_n_zoom = True , border_size = 5 , logging = True ) # define required FFmpeg optimizing parameters for your writer output_params = { \"-i\" : unstablized_videofile , \"-c:a\" : \"aac\" , \"-input_framerate\" : stream . get ( cv2 . CAP_PROP_FPS ), \"-clones\" : [ \"-shortest\" ], # !!! Uncomment following line if video duration is too short(<60sec). !!! #\"-disable_force_termination\": True, } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4 writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized frame here} # write stabilized frame to writer writer . write ( stabilized_frame ) # clear stabilizer resources stab . clean () # safely close video stream stream . release () # safely close writer writer . close ()","title":"Saving Stabilizer Class output with File Audio Input"},{"location":"help/stabilizer_faqs/","text":"Stabilizer Class FAQs \u2693 What is Stabilizer Class and what does it do? \u2693 Answer: Stabilizer Class is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. For more info. see Stabilizer Class doc \u27b6 How much latency you would typically expect with Stabilizer Class? \u2693 Answer: The stabilizer will be Slower for High-Quality videos-frames. Try reducing frames size (Use reducer() method) before feeding them for reducing latency. Also, see smoothing_radius parameter of Stabilizer class that handles the quality of stabilization at the expense of latency and sudden panning. The larger its value, the less will be panning, more will be latency, and vice-versa. How to remove black borders in output video after stabilizing it? \u2693 Answer: See crop_n_zoom parameter of Stabilizer class, that enables the feature, where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the feature available in Adobe AfterEffects) . It works in conjunction with the border_size parameter, i.e. when this parameter is enabled border_size will be used for cropping border instead of making them. Its default value is False . Can I use Stabilizer directly with OpenCV? \u2693 Answer: Yes, see this usage example \u27b6 . Why stabilization is not working properly for my video? \u2693 Answer: The Stabilizer may not perform well against High-frequency jitter in video. But,you can check if increasing smoothing_radius parameter value helps but it will add latency too.","title":"Stabilizer Class FAQs"},{"location":"help/stabilizer_faqs/#stabilizer-class-faqs","text":"","title":"Stabilizer Class FAQs"},{"location":"help/stabilizer_faqs/#what-is-stabilizer-class-and-what-does-it-do","text":"Answer: Stabilizer Class is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. For more info. see Stabilizer Class doc \u27b6","title":"What is Stabilizer Class and what does it do?"},{"location":"help/stabilizer_faqs/#how-much-latency-you-would-typically-expect-with-stabilizer-class","text":"Answer: The stabilizer will be Slower for High-Quality videos-frames. Try reducing frames size (Use reducer() method) before feeding them for reducing latency. Also, see smoothing_radius parameter of Stabilizer class that handles the quality of stabilization at the expense of latency and sudden panning. The larger its value, the less will be panning, more will be latency, and vice-versa.","title":"How much latency you would typically expect with Stabilizer Class?"},{"location":"help/stabilizer_faqs/#how-to-remove-black-borders-in-output-video-after-stabilizing-it","text":"Answer: See crop_n_zoom parameter of Stabilizer class, that enables the feature, where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the feature available in Adobe AfterEffects) . It works in conjunction with the border_size parameter, i.e. when this parameter is enabled border_size will be used for cropping border instead of making them. Its default value is False .","title":"How to remove black borders in output video after stabilizing it?"},{"location":"help/stabilizer_faqs/#can-i-use-stabilizer-directly-with-opencv","text":"Answer: Yes, see this usage example \u27b6 .","title":"Can I use Stabilizer directly with OpenCV?"},{"location":"help/stabilizer_faqs/#why-stabilization-is-not-working-properly-for-my-video","text":"Answer: The Stabilizer may not perform well against High-frequency jitter in video. But,you can check if increasing smoothing_radius parameter value helps but it will add latency too.","title":"Why stabilization is not working properly for my video?"},{"location":"help/streamgear_ex/","text":"StreamGear Examples \u2693 \u2009 StreamGear Live-Streaming Usage with PiGear \u2693 In this example, we will be Live-Streaming video-frames from Raspberry Pi (with Camera Module connected) using PiGear API and StreamGear API's Real-time Frames Mode: New in v0.2.2 This example was added in v0.2.2 . Use -window_size & -extra_window_size FFmpeg parameters for controlling number of frames to be kept in Chunks. Less these value, less will be latency. After every few chunks (equal to the sum of -window_size & -extra_window_size values) , all chunks will be overwritten in Live-Streaming. Thereby, since newer chunks in manifest/playlist will contain NO information of any older ones, and therefore resultant DASH/HLS stream will play only the most recent frames. In this mode, StreamGear DOES NOT automatically maps video-source audio to generated streams. You need to manually assign separate audio-source through -audio attribute of stream_params dictionary parameter. DASH HLS # import required libraries from vidgear.gears import PiGear from vidgear.gears import StreamGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # enable livestreaming and retrieve framerate from CamGear Stream and # pass it as `-input_framerate` parameter for controlled framerate stream_params = { \"-input_framerate\" : stream . framerate , \"-livestream\" : True } # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import PiGear from vidgear.gears import StreamGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # enable livestreaming and retrieve framerate from CamGear Stream and # pass it as `-input_framerate` parameter for controlled framerate stream_params = { \"-input_framerate\" : stream . framerate , \"-livestream\" : True } # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"StreamGear Examples"},{"location":"help/streamgear_ex/#streamgear-examples","text":"","title":"StreamGear Examples"},{"location":"help/streamgear_ex/#streamgear-live-streaming-usage-with-pigear","text":"In this example, we will be Live-Streaming video-frames from Raspberry Pi (with Camera Module connected) using PiGear API and StreamGear API's Real-time Frames Mode: New in v0.2.2 This example was added in v0.2.2 . Use -window_size & -extra_window_size FFmpeg parameters for controlling number of frames to be kept in Chunks. Less these value, less will be latency. After every few chunks (equal to the sum of -window_size & -extra_window_size values) , all chunks will be overwritten in Live-Streaming. Thereby, since newer chunks in manifest/playlist will contain NO information of any older ones, and therefore resultant DASH/HLS stream will play only the most recent frames. In this mode, StreamGear DOES NOT automatically maps video-source audio to generated streams. You need to manually assign separate audio-source through -audio attribute of stream_params dictionary parameter. DASH HLS # import required libraries from vidgear.gears import PiGear from vidgear.gears import StreamGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # enable livestreaming and retrieve framerate from CamGear Stream and # pass it as `-input_framerate` parameter for controlled framerate stream_params = { \"-input_framerate\" : stream . framerate , \"-livestream\" : True } # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () # import required libraries from vidgear.gears import PiGear from vidgear.gears import StreamGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # enable livestreaming and retrieve framerate from CamGear Stream and # pass it as `-input_framerate` parameter for controlled framerate stream_params = { \"-input_framerate\" : stream . framerate , \"-livestream\" : True } # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"hls_out.m3u8\" , format = \"hls\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"StreamGear Live-Streaming Usage with PiGear"},{"location":"help/streamgear_faqs/","text":"StreamGear FAQs \u2693 \u2009 What is StreamGear API and what does it do? \u2693 Answer: StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats (such as MPEG-DASH) in just few lines of python code. For more info. see StreamGear doc \u27b6 \u2009 How to get started with StreamGear API? \u2693 Answer: See StreamGear doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel. \u2009 What is .mpd file created with StreamGear? \u2693 Answer: SteamGear also creates a Manifest file (such as MPD in-case of DASH) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and bit rates) and is provided to the client before the streaming session. \u2009 How to play Streaming Assets created with StreamGear API? \u2693 Answer: You can easily feed Manifest file( .mpd ) to DASH Supported Players Input but sure encoded chunks are present along with it. See this list of recommended players \u27b6 \u2009 What Adaptive Streaming Formats are supported yet? \u2693 Answer: SteamGear currently only supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon. \u2009 Is DRM Encryption supported in StreamGear API? \u2693 Answer: No, DRM Encryption is NOT supported yet. \u2009 How to create additional streams in StreamGear API? \u2693 Answer: See this example \u27b6 \u2009 How to use StreamGear API with OpenCV? \u2693 Answer: See this example \u27b6 \u2009 How to use StreamGear API with real-time frames? \u2693 Answer: See Real-time Frames Mode \u27b6 \u2009 Is Real-time Frames Mode only used for Live-Streaming? \u2693 Answer: Real-time Frame Modes and Live-Streaming are completely different terms and not directly related. Real-time Frame Mode is one of primary mode for directly transcoding real-time numpy.ndarray video-frames (as opposed to a entire file) into a sequence of multiple smaller chunks/segments for streaming. Live-Streaming is feature of StreamGear's primary modes that activates behaviour where chunks will contain information for few new frames only and forgets all previous ones for low latency streaming. It can be activated for any primary mode using exclusive -livestream attribute of stream_params dictionary parameter. How to use Hardware/GPU encoder for StreamGear trancoding? \u2693 Answer: See this example \u27b6","title":"StreamGear FAQs"},{"location":"help/streamgear_faqs/#streamgear-faqs","text":"","title":"StreamGear FAQs"},{"location":"help/streamgear_faqs/#what-is-streamgear-api-and-what-does-it-do","text":"Answer: StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats (such as MPEG-DASH) in just few lines of python code. For more info. see StreamGear doc \u27b6","title":"What is StreamGear API and what does it do?"},{"location":"help/streamgear_faqs/#how-to-get-started-with-streamgear-api","text":"Answer: See StreamGear doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"How to get started with StreamGear API?"},{"location":"help/streamgear_faqs/#what-is-mpd-file-created-with-streamgear","text":"Answer: SteamGear also creates a Manifest file (such as MPD in-case of DASH) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and bit rates) and is provided to the client before the streaming session.","title":"What is .mpd file created with StreamGear?"},{"location":"help/streamgear_faqs/#how-to-play-streaming-assets-created-with-streamgear-api","text":"Answer: You can easily feed Manifest file( .mpd ) to DASH Supported Players Input but sure encoded chunks are present along with it. See this list of recommended players \u27b6","title":"How to play Streaming Assets created with StreamGear API?"},{"location":"help/streamgear_faqs/#what-adaptive-streaming-formats-are-supported-yet","text":"Answer: SteamGear currently only supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon.","title":"What Adaptive Streaming Formats are supported yet?"},{"location":"help/streamgear_faqs/#is-drm-encryption-supported-in-streamgear-api","text":"Answer: No, DRM Encryption is NOT supported yet.","title":"Is DRM Encryption supported in StreamGear API?"},{"location":"help/streamgear_faqs/#how-to-create-additional-streams-in-streamgear-api","text":"Answer: See this example \u27b6","title":"How to create additional streams in StreamGear API?"},{"location":"help/streamgear_faqs/#how-to-use-streamgear-api-with-opencv","text":"Answer: See this example \u27b6","title":"How to use StreamGear API with OpenCV?"},{"location":"help/streamgear_faqs/#how-to-use-streamgear-api-with-real-time-frames","text":"Answer: See Real-time Frames Mode \u27b6","title":"How to use StreamGear API with real-time frames?"},{"location":"help/streamgear_faqs/#is-real-time-frames-mode-only-used-for-live-streaming","text":"Answer: Real-time Frame Modes and Live-Streaming are completely different terms and not directly related. Real-time Frame Mode is one of primary mode for directly transcoding real-time numpy.ndarray video-frames (as opposed to a entire file) into a sequence of multiple smaller chunks/segments for streaming. Live-Streaming is feature of StreamGear's primary modes that activates behaviour where chunks will contain information for few new frames only and forgets all previous ones for low latency streaming. It can be activated for any primary mode using exclusive -livestream attribute of stream_params dictionary parameter.","title":"Is Real-time Frames Mode only used for Live-Streaming?"},{"location":"help/streamgear_faqs/#how-to-use-hardwaregpu-encoder-for-streamgear-trancoding","text":"Answer: See this example \u27b6","title":"How to use Hardware/GPU encoder for StreamGear trancoding?"},{"location":"help/videogear_ex/","text":"VideoGear Examples \u2693 Using VideoGear with ROS(Robot Operating System) \u2693 We will be using cv_bridge to convert OpenCV frames to ROS image messages and vice-versa. In this example, we'll create a node that convert OpenCV frames into ROS image messages, and then publishes them over ROS. New in v0.2.2 This example was added in v0.2.2 . This example is vidgear implementation of this wiki example . # import roslib import roslib roslib . load_manifest ( \"my_package\" ) # import other required libraries import sys import rospy import cv2 from std_msgs.msg import String from sensor_msgs.msg import Image from cv_bridge import CvBridge , CvBridgeError from vidgear.gears import VideoGear # custom publisher class class image_publisher : def __init__ ( self , source = 0 , logging = False ): # create CV bridge self . bridge = CvBridge () # define publisher topic self . image_pub = rospy . Publisher ( \"image_topic_pub\" , Image ) # open stream with given parameters self . stream = VideoGear ( source = source , logging = logging ) . start () # define publisher topic rospy . Subscriber ( \"image_topic_sub\" , Image , self . callback ) def callback ( self , data ): # {do something with received ROS node data here} # read frames frame = self . stream . read () # check for frame if None-type if not ( frame is None ): # {do something with the frame here} # publish our frame try : self . image_pub . publish ( self . bridge . cv2_to_imgmsg ( frame , \"bgr8\" )) except CvBridgeError as e : # catch any errors print ( e ) def close ( self ): # stop stream self . stream . stop () def main ( args ): # !!! define your own video source here !!! # Open any video stream such as live webcam # video stream on first index(i.e. 0) device # define publisher ic = image_publisher ( source = 0 , logging = True ) # initiate ROS node on publisher rospy . init_node ( \"image_publisher\" , anonymous = True ) try : # run node rospy . spin () except KeyboardInterrupt : print ( \"Shutting down\" ) finally : # close publisher ic . close () if __name__ == \"__main__\" : main ( sys . argv ) Using VideoGear for capturing RSTP/RTMP URLs \u2693 Here's a high-level wrapper code around VideoGear API to enable auto-reconnection during capturing, plus stabilization is enabled ( stabilize=True ) in order to stabilize captured frames on-the-go: New in v0.2.2 This example was added in v0.2.2 . Enforcing UDP stream You can easily enforce UDP for RSTP streams inplace of default TCP, by putting following lines of code on the top of your existing code: # import required libraries import os # enforce UDP os . environ [ \"OPENCV_FFMPEG_CAPTURE_OPTIONS\" ] = \"rtsp_transport;udp\" Finally, use backend parameter value as backend=cv2.CAP_FFMPEG in VideoGear. from vidgear.gears import VideoGear import cv2 import datetime import time class Reconnecting_VideoGear : def __init__ ( self , cam_address , stabilize = False , reset_attempts = 50 , reset_delay = 5 ): self . cam_address = cam_address self . stabilize = stabilize self . reset_attempts = reset_attempts self . reset_delay = reset_delay self . source = VideoGear ( source = self . cam_address , stabilize = self . stabilize ) . start () self . running = True def read ( self ): if self . source is None : return None if self . running and self . reset_attempts > 0 : frame = self . source . read () if frame is None : self . source . stop () self . reset_attempts -= 1 print ( \"Re-connection Attempt- {} occured at time: {} \" . format ( str ( self . reset_attempts ), datetime . datetime . now () . strftime ( \"%m- %d -%Y %I:%M:%S%p\" ), ) ) time . sleep ( self . reset_delay ) self . source = VideoGear ( source = self . cam_address , stabilize = self . stabilize ) . start () # return previous frame return self . frame else : self . frame = frame return frame else : return None def stop ( self ): self . running = False self . reset_attempts = 0 self . frame = None if not self . source is None : self . source . stop () if __name__ == \"__main__\" : # open any valid video stream stream = Reconnecting_VideoGear ( cam_address = \"rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov\" , reset_attempts = 20 , reset_delay = 5 , ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using VideoGear for Real-time Stabilization with Audio Encoding \u2693 In this example code, we will be directly merging the audio from a Video-File (to be stabilized) with its processed stabilized frames into a compressed video output in real time: New in v0.2.4 This example was added in v0.2.4 . Make sure this input video-file (to be stabilized) contains valid audio source, otherwise you could encounter multiple errors or no output at all. You MUST use -input_framerate attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams. Use -disable_force_termination flag when video duration is too short(<60sec), otherwise WriteGear will not produce any valid output. # import required libraries from vidgear.gears import WriteGear from vidgear.gears import VideoGear import cv2 # Give suitable video file path to be stabilized unstablized_videofile = \"test.mp4\" # open any valid video path with stabilization enabled(`stabilize = True`) stream_stab = VideoGear ( source = unstablized_videofile , stabilize = True , logging = True ) . start () # define required FFmpeg optimizing parameters for your writer output_params = { \"-i\" : unstablized_videofile , \"-c:a\" : \"aac\" , \"-input_framerate\" : stream_stab . framerate , \"-clones\" : [ \"-shortest\" ], # !!! Uncomment following line if video duration is too short(<60sec). !!! #\"-disable_force_termination\": True, } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4 writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame_stab = stream_stab . read () # check for frame if not grabbed if frame_stab is None : break # {do something with the stabilized frame here} # write stabilized frame to writer writer . write ( frame_stab ) # safely close streams stream_stab . stop () # safely close writer writer . close ()","title":"VideoGear Examples"},{"location":"help/videogear_ex/#videogear-examples","text":"","title":"VideoGear Examples"},{"location":"help/videogear_ex/#using-videogear-with-rosrobot-operating-system","text":"We will be using cv_bridge to convert OpenCV frames to ROS image messages and vice-versa. In this example, we'll create a node that convert OpenCV frames into ROS image messages, and then publishes them over ROS. New in v0.2.2 This example was added in v0.2.2 . This example is vidgear implementation of this wiki example . # import roslib import roslib roslib . load_manifest ( \"my_package\" ) # import other required libraries import sys import rospy import cv2 from std_msgs.msg import String from sensor_msgs.msg import Image from cv_bridge import CvBridge , CvBridgeError from vidgear.gears import VideoGear # custom publisher class class image_publisher : def __init__ ( self , source = 0 , logging = False ): # create CV bridge self . bridge = CvBridge () # define publisher topic self . image_pub = rospy . Publisher ( \"image_topic_pub\" , Image ) # open stream with given parameters self . stream = VideoGear ( source = source , logging = logging ) . start () # define publisher topic rospy . Subscriber ( \"image_topic_sub\" , Image , self . callback ) def callback ( self , data ): # {do something with received ROS node data here} # read frames frame = self . stream . read () # check for frame if None-type if not ( frame is None ): # {do something with the frame here} # publish our frame try : self . image_pub . publish ( self . bridge . cv2_to_imgmsg ( frame , \"bgr8\" )) except CvBridgeError as e : # catch any errors print ( e ) def close ( self ): # stop stream self . stream . stop () def main ( args ): # !!! define your own video source here !!! # Open any video stream such as live webcam # video stream on first index(i.e. 0) device # define publisher ic = image_publisher ( source = 0 , logging = True ) # initiate ROS node on publisher rospy . init_node ( \"image_publisher\" , anonymous = True ) try : # run node rospy . spin () except KeyboardInterrupt : print ( \"Shutting down\" ) finally : # close publisher ic . close () if __name__ == \"__main__\" : main ( sys . argv )","title":"Using VideoGear with ROS(Robot Operating System)"},{"location":"help/videogear_ex/#using-videogear-for-capturing-rstprtmp-urls","text":"Here's a high-level wrapper code around VideoGear API to enable auto-reconnection during capturing, plus stabilization is enabled ( stabilize=True ) in order to stabilize captured frames on-the-go: New in v0.2.2 This example was added in v0.2.2 . Enforcing UDP stream You can easily enforce UDP for RSTP streams inplace of default TCP, by putting following lines of code on the top of your existing code: # import required libraries import os # enforce UDP os . environ [ \"OPENCV_FFMPEG_CAPTURE_OPTIONS\" ] = \"rtsp_transport;udp\" Finally, use backend parameter value as backend=cv2.CAP_FFMPEG in VideoGear. from vidgear.gears import VideoGear import cv2 import datetime import time class Reconnecting_VideoGear : def __init__ ( self , cam_address , stabilize = False , reset_attempts = 50 , reset_delay = 5 ): self . cam_address = cam_address self . stabilize = stabilize self . reset_attempts = reset_attempts self . reset_delay = reset_delay self . source = VideoGear ( source = self . cam_address , stabilize = self . stabilize ) . start () self . running = True def read ( self ): if self . source is None : return None if self . running and self . reset_attempts > 0 : frame = self . source . read () if frame is None : self . source . stop () self . reset_attempts -= 1 print ( \"Re-connection Attempt- {} occured at time: {} \" . format ( str ( self . reset_attempts ), datetime . datetime . now () . strftime ( \"%m- %d -%Y %I:%M:%S%p\" ), ) ) time . sleep ( self . reset_delay ) self . source = VideoGear ( source = self . cam_address , stabilize = self . stabilize ) . start () # return previous frame return self . frame else : self . frame = frame return frame else : return None def stop ( self ): self . running = False self . reset_attempts = 0 self . frame = None if not self . source is None : self . source . stop () if __name__ == \"__main__\" : # open any valid video stream stream = Reconnecting_VideoGear ( cam_address = \"rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov\" , reset_attempts = 20 , reset_delay = 5 , ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using VideoGear for capturing RSTP/RTMP URLs"},{"location":"help/videogear_ex/#using-videogear-for-real-time-stabilization-with-audio-encoding","text":"In this example code, we will be directly merging the audio from a Video-File (to be stabilized) with its processed stabilized frames into a compressed video output in real time: New in v0.2.4 This example was added in v0.2.4 . Make sure this input video-file (to be stabilized) contains valid audio source, otherwise you could encounter multiple errors or no output at all. You MUST use -input_framerate attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams. Use -disable_force_termination flag when video duration is too short(<60sec), otherwise WriteGear will not produce any valid output. # import required libraries from vidgear.gears import WriteGear from vidgear.gears import VideoGear import cv2 # Give suitable video file path to be stabilized unstablized_videofile = \"test.mp4\" # open any valid video path with stabilization enabled(`stabilize = True`) stream_stab = VideoGear ( source = unstablized_videofile , stabilize = True , logging = True ) . start () # define required FFmpeg optimizing parameters for your writer output_params = { \"-i\" : unstablized_videofile , \"-c:a\" : \"aac\" , \"-input_framerate\" : stream_stab . framerate , \"-clones\" : [ \"-shortest\" ], # !!! Uncomment following line if video duration is too short(<60sec). !!! #\"-disable_force_termination\": True, } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4 writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame_stab = stream_stab . read () # check for frame if not grabbed if frame_stab is None : break # {do something with the stabilized frame here} # write stabilized frame to writer writer . write ( frame_stab ) # safely close streams stream_stab . stop () # safely close writer writer . close ()","title":"Using VideoGear for Real-time Stabilization with Audio Encoding"},{"location":"help/videogear_faqs/","text":"VideoGear FAQs \u2693 What is VideoGear API and what does it do? \u2693 Answer: VideoGear provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. It also act as a Common API, that provided an internal access to both CamGear and PiGear APIs and their parameters, with a special enablePiCamera boolean flag. For more info. see VideoGear doc \u27b6 What's the need of VideoGear API? \u2693 Answer: VideoGear is basically ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum efforts and using way fewer lines of code. It also serve as backend for other powerful APIs, such WebGear and NetGear_Async . Which APIs are accessible with VideoGear API? \u2693 Answer: VideoGear provided an internal access to both CamGear and PiGear APIs and their parameters, also it contains wrapper around Video Stabilizer class. Can we access WriteGear API or NetGear API too with VideoGear? \u2693 Answer: No, only selected VideoCapture APIs (anwsered above) are accessible. Does using VideoGear instead of CamGear API directly, affects performance? \u2693 Answer: No, there's no difference, as VideoGear just a high-level wrapper around CamGear API and without any modifications in-between.","title":"VideoGear FAQs"},{"location":"help/videogear_faqs/#videogear-faqs","text":"","title":"VideoGear FAQs"},{"location":"help/videogear_faqs/#what-is-videogear-api-and-what-does-it-do","text":"Answer: VideoGear provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. It also act as a Common API, that provided an internal access to both CamGear and PiGear APIs and their parameters, with a special enablePiCamera boolean flag. For more info. see VideoGear doc \u27b6","title":"What is VideoGear API and what does it do?"},{"location":"help/videogear_faqs/#whats-the-need-of-videogear-api","text":"Answer: VideoGear is basically ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum efforts and using way fewer lines of code. It also serve as backend for other powerful APIs, such WebGear and NetGear_Async .","title":"What's the need of VideoGear API?"},{"location":"help/videogear_faqs/#which-apis-are-accessible-with-videogear-api","text":"Answer: VideoGear provided an internal access to both CamGear and PiGear APIs and their parameters, also it contains wrapper around Video Stabilizer class.","title":"Which APIs are accessible with VideoGear API?"},{"location":"help/videogear_faqs/#can-we-access-writegear-api-or-netgear-api-too-with-videogear","text":"Answer: No, only selected VideoCapture APIs (anwsered above) are accessible.","title":"Can we access WriteGear API or NetGear API too with VideoGear?"},{"location":"help/videogear_faqs/#does-using-videogear-instead-of-camgear-api-directly-affects-performance","text":"Answer: No, there's no difference, as VideoGear just a high-level wrapper around CamGear API and without any modifications in-between.","title":"Does using VideoGear instead of CamGear API directly, affects performance?"},{"location":"help/webgear_ex/","text":"WebGear Examples \u2693 Using WebGear with RaspberryPi Camera Module \u2693 Because of WebGear API's flexible internal wapper around VideoGear, it can easily access any parameter of CamGear and PiGear videocapture APIs. Following usage examples are just an idea of what can be done with WebGear API, you can try various VideoGear , CamGear and PiGear parameters directly in WebGear API in the similar manner. Here's a bare-minimum example of using WebGear API with the Raspberry Pi camera module while tweaking its various properties in just one-liner: # import libs import uvicorn from vidgear.gears.asyncio import WebGear # various webgear performance and Raspberry Pi camera tweaks options = { \"frame_size_reduction\" : 40 , \"jpeg_compression_quality\" : 80 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : False , \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # initialize WebGear app web = WebGear ( enablePiCamera = True , resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () Using WebGear with real-time Video Stabilization enabled \u2693 Here's an example of using WebGear API with real-time Video Stabilization enabled: # import libs import uvicorn from vidgear.gears.asyncio import WebGear # various webgear performance tweaks options = { \"frame_size_reduction\" : 40 , \"jpeg_compression_quality\" : 80 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : False , } # initialize WebGear app with a raw source and enable video stabilization(`stabilize=True`) web = WebGear ( source = \"foo.mp4\" , stabilize = True , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () Display Two Sources Simultaneously in WebGear \u2693 In this example, we'll be displaying two video feeds side-by-side simultaneously on browser using WebGear API by defining two separate frame generators: New in v0.2.2 This example was added in v0.2.2 . Step-1 (Trigger Auto-Generation Process): Firstly, run this bare-minimum code to trigger the Auto-generation process, this will create .vidgear directory at current location (directory where you'll run this code) : # import required libraries import uvicorn from vidgear.gears.asyncio import WebGear # provide current directory to save data files options = { \"custom_data_location\" : \"./\" } # initialize WebGear app web = WebGear ( source = 0 , logging = True , ** options ) # close app safely web . shutdown () Step-2 (Replace HTML file): Now, go inside .vidgear webgear templates directory at current location of your machine, and there replace content of index.html file with following: {% extends \"base.html\" %} {% block content %} < h1 class = \"glow\" > WebGear Video Feed </ h1 > < div class = \"rows\" > < img src = \"/video\" alt = \"Feed\" /> < img src = \"/video2\" alt = \"Feed\" /> </ div > {% endblock %} Step-3 (Build your own Frame Producers): Now, create a python script code with OpenCV source, as follows: # import necessary libs import uvicorn , asyncio , cv2 from vidgear.gears.asyncio import WebGear from vidgear.gears.asyncio.helper import reducer from starlette.responses import StreamingResponse from starlette.routing import Route # provide current directory to load data files options = { \"custom_data_location\" : \"./\" } # initialize WebGear app without any source web = WebGear ( logging = True , ** options ) # create your own custom frame producer async def my_frame_producer1 (): # !!! define your first video source here !!! # Open any video stream such as \"foo1.mp4\" stream = cv2 . VideoCapture ( \"foo1.mp4\" ) # loop over frames while True : # read frame from provided source ( grabbed , frame ) = stream . read () # break if NoneType if not grabbed : break # do something with your OpenCV frame here # reducer frames size if you want more performance otherwise comment this line frame = await reducer ( frame , percentage = 30 ) # reduce frame by 30% # handle JPEG encoding encodedImage = cv2 . imencode ( \".jpg\" , frame )[ 1 ] . tobytes () # yield frame in byte format yield ( b \"--frame \\r\\n Content-Type:video/jpeg2000 \\r\\n\\r\\n \" + encodedImage + b \" \\r\\n \" ) await asyncio . sleep ( 0.00001 ) # close stream stream . release () # create your own custom frame producer async def my_frame_producer2 (): # !!! define your second video source here !!! # Open any video stream such as \"foo2.mp4\" stream = cv2 . VideoCapture ( \"foo2.mp4\" ) # loop over frames while True : # read frame from provided source ( grabbed , frame ) = stream . read () # break if NoneType if not grabbed : break # do something with your OpenCV frame here # reducer frames size if you want more performance otherwise comment this line frame = await reducer ( frame , percentage = 30 ) # reduce frame by 30% # handle JPEG encoding encodedImage = cv2 . imencode ( \".jpg\" , frame )[ 1 ] . tobytes () # yield frame in byte format yield ( b \"--frame \\r\\n Content-Type:video/jpeg2000 \\r\\n\\r\\n \" + encodedImage + b \" \\r\\n \" ) await asyncio . sleep ( 0.00001 ) # close stream stream . release () async def custom_video_response ( scope ): \"\"\" Return a async video streaming response for `my_frame_producer2` generator \"\"\" assert scope [ \"type\" ] in [ \"http\" , \"https\" ] await asyncio . sleep ( 0.00001 ) return StreamingResponse ( my_frame_producer2 (), media_type = \"multipart/x-mixed-replace; boundary=frame\" , ) # add your custom frame producer to config web . config [ \"generator\" ] = my_frame_producer1 # append new route i.e. new custom route with custom response web . routes . append ( Route ( \"/video2\" , endpoint = custom_video_response ) ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in Browser.","title":"WebGear Examples"},{"location":"help/webgear_ex/#webgear-examples","text":"","title":"WebGear Examples"},{"location":"help/webgear_ex/#using-webgear-with-raspberrypi-camera-module","text":"Because of WebGear API's flexible internal wapper around VideoGear, it can easily access any parameter of CamGear and PiGear videocapture APIs. Following usage examples are just an idea of what can be done with WebGear API, you can try various VideoGear , CamGear and PiGear parameters directly in WebGear API in the similar manner. Here's a bare-minimum example of using WebGear API with the Raspberry Pi camera module while tweaking its various properties in just one-liner: # import libs import uvicorn from vidgear.gears.asyncio import WebGear # various webgear performance and Raspberry Pi camera tweaks options = { \"frame_size_reduction\" : 40 , \"jpeg_compression_quality\" : 80 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : False , \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # initialize WebGear app web = WebGear ( enablePiCamera = True , resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown ()","title":"Using WebGear with RaspberryPi Camera Module"},{"location":"help/webgear_ex/#using-webgear-with-real-time-video-stabilization-enabled","text":"Here's an example of using WebGear API with real-time Video Stabilization enabled: # import libs import uvicorn from vidgear.gears.asyncio import WebGear # various webgear performance tweaks options = { \"frame_size_reduction\" : 40 , \"jpeg_compression_quality\" : 80 , \"jpeg_compression_fastdct\" : True , \"jpeg_compression_fastupsample\" : False , } # initialize WebGear app with a raw source and enable video stabilization(`stabilize=True`) web = WebGear ( source = \"foo.mp4\" , stabilize = True , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown ()","title":"Using WebGear with real-time Video Stabilization enabled"},{"location":"help/webgear_ex/#display-two-sources-simultaneously-in-webgear","text":"In this example, we'll be displaying two video feeds side-by-side simultaneously on browser using WebGear API by defining two separate frame generators: New in v0.2.2 This example was added in v0.2.2 . Step-1 (Trigger Auto-Generation Process): Firstly, run this bare-minimum code to trigger the Auto-generation process, this will create .vidgear directory at current location (directory where you'll run this code) : # import required libraries import uvicorn from vidgear.gears.asyncio import WebGear # provide current directory to save data files options = { \"custom_data_location\" : \"./\" } # initialize WebGear app web = WebGear ( source = 0 , logging = True , ** options ) # close app safely web . shutdown () Step-2 (Replace HTML file): Now, go inside .vidgear webgear templates directory at current location of your machine, and there replace content of index.html file with following: {% extends \"base.html\" %} {% block content %} < h1 class = \"glow\" > WebGear Video Feed </ h1 > < div class = \"rows\" > < img src = \"/video\" alt = \"Feed\" /> < img src = \"/video2\" alt = \"Feed\" /> </ div > {% endblock %} Step-3 (Build your own Frame Producers): Now, create a python script code with OpenCV source, as follows: # import necessary libs import uvicorn , asyncio , cv2 from vidgear.gears.asyncio import WebGear from vidgear.gears.asyncio.helper import reducer from starlette.responses import StreamingResponse from starlette.routing import Route # provide current directory to load data files options = { \"custom_data_location\" : \"./\" } # initialize WebGear app without any source web = WebGear ( logging = True , ** options ) # create your own custom frame producer async def my_frame_producer1 (): # !!! define your first video source here !!! # Open any video stream such as \"foo1.mp4\" stream = cv2 . VideoCapture ( \"foo1.mp4\" ) # loop over frames while True : # read frame from provided source ( grabbed , frame ) = stream . read () # break if NoneType if not grabbed : break # do something with your OpenCV frame here # reducer frames size if you want more performance otherwise comment this line frame = await reducer ( frame , percentage = 30 ) # reduce frame by 30% # handle JPEG encoding encodedImage = cv2 . imencode ( \".jpg\" , frame )[ 1 ] . tobytes () # yield frame in byte format yield ( b \"--frame \\r\\n Content-Type:video/jpeg2000 \\r\\n\\r\\n \" + encodedImage + b \" \\r\\n \" ) await asyncio . sleep ( 0.00001 ) # close stream stream . release () # create your own custom frame producer async def my_frame_producer2 (): # !!! define your second video source here !!! # Open any video stream such as \"foo2.mp4\" stream = cv2 . VideoCapture ( \"foo2.mp4\" ) # loop over frames while True : # read frame from provided source ( grabbed , frame ) = stream . read () # break if NoneType if not grabbed : break # do something with your OpenCV frame here # reducer frames size if you want more performance otherwise comment this line frame = await reducer ( frame , percentage = 30 ) # reduce frame by 30% # handle JPEG encoding encodedImage = cv2 . imencode ( \".jpg\" , frame )[ 1 ] . tobytes () # yield frame in byte format yield ( b \"--frame \\r\\n Content-Type:video/jpeg2000 \\r\\n\\r\\n \" + encodedImage + b \" \\r\\n \" ) await asyncio . sleep ( 0.00001 ) # close stream stream . release () async def custom_video_response ( scope ): \"\"\" Return a async video streaming response for `my_frame_producer2` generator \"\"\" assert scope [ \"type\" ] in [ \"http\" , \"https\" ] await asyncio . sleep ( 0.00001 ) return StreamingResponse ( my_frame_producer2 (), media_type = \"multipart/x-mixed-replace; boundary=frame\" , ) # add your custom frame producer to config web . config [ \"generator\" ] = my_frame_producer1 # append new route i.e. new custom route with custom response web . routes . append ( Route ( \"/video2\" , endpoint = custom_video_response ) ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in Browser.","title":"Display Two Sources Simultaneously in WebGear"},{"location":"help/webgear_faqs/","text":"WebGear FAQs \u2693 What is WebGear API and what does it do? \u2693 Answer: WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting Motion-JPEG -frames from a single source to multiple recipients via the browser. For more info. see WebGear doc \u27b6 How to get started with WebGear API? \u2693 Answer: See WebGear doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel. \"WebGear is throwing ModuleNotFoundError on importing\", Why? \u2693 Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6 . Can WebGear always need Active Internet Connection? \u2693 Answer: No, it just need internet only once during its Auto-Generation Process \u27b6 to download default data-files and it takes few seconds. You can also download files manually from Github Server , otherwise you can also add your own custom files . For more information see Data-Files Auto-Generation WorkFlow \u27b6 Is it possible to stream on a different device on the network with WebGear? \u2693 If you set \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine, then you must still use http://localhost:8000/ to access stream on that same host machine browser. For accessing WebGear on different Client Devices on the network, use \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine. Then type the IP-address of source machine followed by the defined port value in your desired Client Device's browser (for e.g. http://192.27.0.101:8000 ) to access the stream. Can I manually place default files for WebGear? \u2693 Answer: Yes, you can either download default files from Github Server , and manually place at default location , OR, you can yourself create the require three critical files (i.e index.html , 404.html & 500.html ) inside templates folder at the default location , thereby you don't need any internet connection at all. For more information see Data-Files Auto-Generation WorkFlow \u27b6 How to send OpenCV frames directly to Webgear Server? \u2693 Answer: See this usage example \u27b6 . How can I add my custom WebPage to WebGear? \u2693 Answer: See this usage example \u27b6 . How can to add CORS headers to WebGear? \u2693 Answer: See this usage example \u27b6 . Can I change the default location? \u2693 Answer: Yes, you can use WebGear's custom_data_location attribute of option parameter in WebGear API, to change default location to somewhere else. Can I delete/rename the WebGear default data? \u2693 Answer: Yes, but you've to follow these rules \u27b6 What Web browser are supported by WebGear API? \u2693 Answer: All modern browser with Javascript support are supported by WebGear. If not, then discuss with us on Gitter \u27b6 Community channel.","title":"WebGear FAQs"},{"location":"help/webgear_faqs/#webgear-faqs","text":"","title":"WebGear FAQs"},{"location":"help/webgear_faqs/#what-is-webgear-api-and-what-does-it-do","text":"Answer: WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting Motion-JPEG -frames from a single source to multiple recipients via the browser. For more info. see WebGear doc \u27b6","title":"What is WebGear API and what does it do?"},{"location":"help/webgear_faqs/#how-to-get-started-with-webgear-api","text":"Answer: See WebGear doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"How to get started with WebGear API?"},{"location":"help/webgear_faqs/#webgear-is-throwing-modulenotfounderror-on-importing-why","text":"Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6 .","title":"\"WebGear is throwing ModuleNotFoundError on importing\", Why?"},{"location":"help/webgear_faqs/#can-webgear-always-need-active-internet-connection","text":"Answer: No, it just need internet only once during its Auto-Generation Process \u27b6 to download default data-files and it takes few seconds. You can also download files manually from Github Server , otherwise you can also add your own custom files . For more information see Data-Files Auto-Generation WorkFlow \u27b6","title":"Can WebGear always need Active Internet Connection?"},{"location":"help/webgear_faqs/#is-it-possible-to-stream-on-a-different-device-on-the-network-with-webgear","text":"If you set \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine, then you must still use http://localhost:8000/ to access stream on that same host machine browser. For accessing WebGear on different Client Devices on the network, use \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine. Then type the IP-address of source machine followed by the defined port value in your desired Client Device's browser (for e.g. http://192.27.0.101:8000 ) to access the stream.","title":"Is it possible to stream on a different device on the network with WebGear?"},{"location":"help/webgear_faqs/#can-i-manually-place-default-files-for-webgear","text":"Answer: Yes, you can either download default files from Github Server , and manually place at default location , OR, you can yourself create the require three critical files (i.e index.html , 404.html & 500.html ) inside templates folder at the default location , thereby you don't need any internet connection at all. For more information see Data-Files Auto-Generation WorkFlow \u27b6","title":"Can I manually place default files for WebGear?"},{"location":"help/webgear_faqs/#how-to-send-opencv-frames-directly-to-webgear-server","text":"Answer: See this usage example \u27b6 .","title":"How to send OpenCV frames directly to Webgear Server?"},{"location":"help/webgear_faqs/#how-can-i-add-my-custom-webpage-to-webgear","text":"Answer: See this usage example \u27b6 .","title":"How can I add my custom WebPage to WebGear?"},{"location":"help/webgear_faqs/#how-can-to-add-cors-headers-to-webgear","text":"Answer: See this usage example \u27b6 .","title":"How can to add CORS headers to WebGear?"},{"location":"help/webgear_faqs/#can-i-change-the-default-location","text":"Answer: Yes, you can use WebGear's custom_data_location attribute of option parameter in WebGear API, to change default location to somewhere else.","title":"Can I change the default location?"},{"location":"help/webgear_faqs/#can-i-deleterename-the-webgear-default-data","text":"Answer: Yes, but you've to follow these rules \u27b6","title":"Can I delete/rename the WebGear default data?"},{"location":"help/webgear_faqs/#what-web-browser-are-supported-by-webgear-api","text":"Answer: All modern browser with Javascript support are supported by WebGear. If not, then discuss with us on Gitter \u27b6 Community channel.","title":"What Web browser are supported by WebGear API?"},{"location":"help/webgear_rtc_ex/","text":"WebGear_RTC_RTC Examples \u2693 Using WebGear_RTC with RaspberryPi Camera Module \u2693 Because of WebGear_RTC API's flexible internal wapper around VideoGear, it can easily access any parameter of CamGear and PiGear videocapture APIs. Following usage examples are just an idea of what can be done with WebGear_RTC API, you can try various VideoGear , CamGear and PiGear parameters directly in WebGear_RTC API in the similar manner. Here's a bare-minimum example of using WebGear_RTC API with the Raspberry Pi camera module while tweaking its various properties in just one-liner: # import libs import uvicorn from vidgear.gears.asyncio import WebGear_RTC # various webgear_rtc performance and Raspberry Pi camera tweaks options = { \"frame_size_reduction\" : 25 , \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # initialize WebGear_RTC app web = WebGear_RTC ( enablePiCamera = True , resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () Using WebGear_RTC with real-time Video Stabilization enabled \u2693 Here's an example of using WebGear_RTC API with real-time Video Stabilization enabled: # import libs import uvicorn from vidgear.gears.asyncio import WebGear_RTC # various webgear_rtc performance tweaks options = { \"frame_size_reduction\" : 25 , } # initialize WebGear_RTC app with a raw source and enable video stabilization(`stabilize=True`) web = WebGear_RTC ( source = \"foo.mp4\" , stabilize = True , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () Display Two Sources Simultaneously in WebGear_RTC \u2693 In this example, we'll be displaying two video feeds side-by-side simultaneously on browser using WebGear_RTC API by simply concatenating frames in real-time: New in v0.2.4 This example was added in v0.2.4 . # import necessary libs import uvicorn , cv2 import numpy as np from vidgear.gears.helper import reducer from vidgear.gears.asyncio import WebGear_RTC # initialize WebGear_RTC app without any source web = WebGear_RTC ( logging = True ) # frame concatenator def get_conc_frame ( frame1 , frame2 ): h1 , w1 = frame1 . shape [: 2 ] h2 , w2 = frame2 . shape [: 2 ] # create empty matrix vis = np . zeros (( max ( h1 , h2 ), w1 + w2 , 3 ), np . uint8 ) # combine 2 frames vis [: h1 , : w1 , : 3 ] = frame1 vis [: h2 , w1 : w1 + w2 , : 3 ] = frame2 return vis # create your own custom streaming class class Custom_Stream_Class : \"\"\" Custom Streaming using two OpenCV sources \"\"\" def __init__ ( self , source1 = None , source2 = None ): # !!! define your own video source here !!! # check is source are provided if source1 is None or source2 is None : raise ValueError ( \"Provide both source\" ) # initialize global params # define both source here self . stream1 = cv2 . VideoCapture ( source1 ) self . stream2 = cv2 . VideoCapture ( source2 ) # define running flag self . running = True def read ( self ): # don't forget this function!!! # check if sources were initialized or not if self . stream1 is None or self . stream2 is None : return None # check if we're still running if self . running : # read video frame ( grabbed1 , frame1 ) = self . stream1 . read () ( grabbed2 , frame2 ) = self . stream2 . read () # if NoneType if not grabbed1 or not grabbed2 : # do something with your OpenCV frame here # concatenate frame frame = get_conc_frame ( frame1 , frame2 ) # reducer frames size if you want more performance otherwise comment this line # frame = await reducer(frame, percentage=30) # reduce frame by 30% # return our gray frame return frame else : # signal we're not running now self . running = False # return None-type return None def stop ( self ): # don't forget this function!!! # flag that we're not running self . running = False # close stream if not ( self . stream1 is None ): self . stream1 . release () self . stream1 = None if not ( self . stream2 is None ): self . stream2 . release () self . stream2 = None # assign your Custom Streaming Class with adequate two sources # to `custom_stream` attribute in options parameter options = { \"custom_stream\" : Custom_Stream_Class ( source1 = \"foo1.mp4\" , source2 = \"foo2.mp4\" ) } # initialize WebGear_RTC app without any source web = WebGear_RTC ( logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in Browser.","title":"WebGear_RTC Examples"},{"location":"help/webgear_rtc_ex/#webgear_rtc_rtc-examples","text":"","title":"WebGear_RTC_RTC Examples"},{"location":"help/webgear_rtc_ex/#using-webgear_rtc-with-raspberrypi-camera-module","text":"Because of WebGear_RTC API's flexible internal wapper around VideoGear, it can easily access any parameter of CamGear and PiGear videocapture APIs. Following usage examples are just an idea of what can be done with WebGear_RTC API, you can try various VideoGear , CamGear and PiGear parameters directly in WebGear_RTC API in the similar manner. Here's a bare-minimum example of using WebGear_RTC API with the Raspberry Pi camera module while tweaking its various properties in just one-liner: # import libs import uvicorn from vidgear.gears.asyncio import WebGear_RTC # various webgear_rtc performance and Raspberry Pi camera tweaks options = { \"frame_size_reduction\" : 25 , \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # initialize WebGear_RTC app web = WebGear_RTC ( enablePiCamera = True , resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown ()","title":"Using WebGear_RTC with RaspberryPi Camera Module"},{"location":"help/webgear_rtc_ex/#using-webgear_rtc-with-real-time-video-stabilization-enabled","text":"Here's an example of using WebGear_RTC API with real-time Video Stabilization enabled: # import libs import uvicorn from vidgear.gears.asyncio import WebGear_RTC # various webgear_rtc performance tweaks options = { \"frame_size_reduction\" : 25 , } # initialize WebGear_RTC app with a raw source and enable video stabilization(`stabilize=True`) web = WebGear_RTC ( source = \"foo.mp4\" , stabilize = True , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown ()","title":"Using WebGear_RTC with real-time Video Stabilization enabled"},{"location":"help/webgear_rtc_ex/#display-two-sources-simultaneously-in-webgear_rtc","text":"In this example, we'll be displaying two video feeds side-by-side simultaneously on browser using WebGear_RTC API by simply concatenating frames in real-time: New in v0.2.4 This example was added in v0.2.4 . # import necessary libs import uvicorn , cv2 import numpy as np from vidgear.gears.helper import reducer from vidgear.gears.asyncio import WebGear_RTC # initialize WebGear_RTC app without any source web = WebGear_RTC ( logging = True ) # frame concatenator def get_conc_frame ( frame1 , frame2 ): h1 , w1 = frame1 . shape [: 2 ] h2 , w2 = frame2 . shape [: 2 ] # create empty matrix vis = np . zeros (( max ( h1 , h2 ), w1 + w2 , 3 ), np . uint8 ) # combine 2 frames vis [: h1 , : w1 , : 3 ] = frame1 vis [: h2 , w1 : w1 + w2 , : 3 ] = frame2 return vis # create your own custom streaming class class Custom_Stream_Class : \"\"\" Custom Streaming using two OpenCV sources \"\"\" def __init__ ( self , source1 = None , source2 = None ): # !!! define your own video source here !!! # check is source are provided if source1 is None or source2 is None : raise ValueError ( \"Provide both source\" ) # initialize global params # define both source here self . stream1 = cv2 . VideoCapture ( source1 ) self . stream2 = cv2 . VideoCapture ( source2 ) # define running flag self . running = True def read ( self ): # don't forget this function!!! # check if sources were initialized or not if self . stream1 is None or self . stream2 is None : return None # check if we're still running if self . running : # read video frame ( grabbed1 , frame1 ) = self . stream1 . read () ( grabbed2 , frame2 ) = self . stream2 . read () # if NoneType if not grabbed1 or not grabbed2 : # do something with your OpenCV frame here # concatenate frame frame = get_conc_frame ( frame1 , frame2 ) # reducer frames size if you want more performance otherwise comment this line # frame = await reducer(frame, percentage=30) # reduce frame by 30% # return our gray frame return frame else : # signal we're not running now self . running = False # return None-type return None def stop ( self ): # don't forget this function!!! # flag that we're not running self . running = False # close stream if not ( self . stream1 is None ): self . stream1 . release () self . stream1 = None if not ( self . stream2 is None ): self . stream2 . release () self . stream2 = None # assign your Custom Streaming Class with adequate two sources # to `custom_stream` attribute in options parameter options = { \"custom_stream\" : Custom_Stream_Class ( source1 = \"foo1.mp4\" , source2 = \"foo2.mp4\" ) } # initialize WebGear_RTC app without any source web = WebGear_RTC ( logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in Browser.","title":"Display Two Sources Simultaneously in WebGear_RTC"},{"location":"help/webgear_rtc_faqs/","text":"WebGear_RTC FAQs \u2693 What is WebGear_RTC API and what does it do? \u2693 Answer: WebGear_RTC utilizes WebRTC technology under the hood, which makes it suitable for building powerful video-streaming solutions for all modern browsers as well as native clients available on all major platforms. For more info. see WebGear_RTC doc \u27b6 How to get started with WebGear_RTC API? \u2693 Answer: See WebGear_RTC doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel. How WebGear_RTC is different to WebGear API, which should I choose? \u2693 Answer: WebGear_RTC is similar to WeGear API in many aspects but utilizes WebRTC technology under the hood instead of Motion JPEG. You can choose any API according to your application, but the quality would be better on WebGear API, on-the-other-hand latency would be better on WebGear_RTC API. Also, WebRTC protocol accepts a wide range of devices, whereas WebGear is limited only to modern browsers. \"WebGear_RTC is throwing ModuleNotFoundError on importing\", Why? \u2693 Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6 . Can WebGear_RTC always need Active Internet Connection? \u2693 Answer: No, it just need internet only once during its Auto-Generation Process \u27b6 to download default data-files and it takes few seconds. You can also download files manually from Github Server , otherwise you can also add your own custom files . For more information see Data-Files Auto-Generation WorkFlow \u27b6 Is it possible to stream on a different device on the network with WebGear_RTC? \u2693 If you set \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine, then you must still use http://localhost:8000/ to access stream on your host machine browser. For accessing WebGear_RTC on different Client Devices on the network, use \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine. Then type the IP-address of source machine followed by the defined port value in your desired Client Device's browser (for e.g. http://192.27.0.101:8000 ) to access the stream. Can I manually place default files for WebGear_RTC? \u2693 Answer: Yes, you can either download default files from Github Server , and manually place at default location , OR, you can yourself create the require three critical files (i.e index.html , 404.html & 500.html ) inside templates folder at the default location , thereby you don't need any internet connection at all. For more information see Data-Files Auto-Generation WorkFlow \u27b6 How to stream Webgear_RTC Server output to multiple clients? \u2693 Answer: See this usage example \u27b6 . How to send OpenCV frames directly to Webgear_RTC Server? \u2693 Answer: See this usage example \u27b6 . How can I add my custom WebPage to WebGear_RTC? \u2693 Answer: See this usage example \u27b6 . How can to add CORS headers to WebGear_RTC? \u2693 Answer: See this usage example \u27b6 . Can I change the default location? \u2693 Answer: Yes, you can use WebGear_RTC's custom_data_location attribute of option parameter in WebGear_RTC API, to change default location to somewhere else. Can I delete/rename the WebGear_RTC default data? \u2693 Answer: Yes, but you've to follow these rules \u27b6","title":"WebGear_RTC FAQs"},{"location":"help/webgear_rtc_faqs/#webgear_rtc-faqs","text":"","title":"WebGear_RTC FAQs"},{"location":"help/webgear_rtc_faqs/#what-is-webgear_rtc-api-and-what-does-it-do","text":"Answer: WebGear_RTC utilizes WebRTC technology under the hood, which makes it suitable for building powerful video-streaming solutions for all modern browsers as well as native clients available on all major platforms. For more info. see WebGear_RTC doc \u27b6","title":"What is WebGear_RTC API and what does it do?"},{"location":"help/webgear_rtc_faqs/#how-to-get-started-with-webgear_rtc-api","text":"Answer: See WebGear_RTC doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"How to get started with WebGear_RTC API?"},{"location":"help/webgear_rtc_faqs/#how-webgear_rtc-is-different-to-webgear-api-which-should-i-choose","text":"Answer: WebGear_RTC is similar to WeGear API in many aspects but utilizes WebRTC technology under the hood instead of Motion JPEG. You can choose any API according to your application, but the quality would be better on WebGear API, on-the-other-hand latency would be better on WebGear_RTC API. Also, WebRTC protocol accepts a wide range of devices, whereas WebGear is limited only to modern browsers.","title":"How WebGear_RTC is different to WebGear API, which should I choose?"},{"location":"help/webgear_rtc_faqs/#webgear_rtc-is-throwing-modulenotfounderror-on-importing-why","text":"Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6 .","title":"\"WebGear_RTC is throwing ModuleNotFoundError on importing\", Why?"},{"location":"help/webgear_rtc_faqs/#can-webgear_rtc-always-need-active-internet-connection","text":"Answer: No, it just need internet only once during its Auto-Generation Process \u27b6 to download default data-files and it takes few seconds. You can also download files manually from Github Server , otherwise you can also add your own custom files . For more information see Data-Files Auto-Generation WorkFlow \u27b6","title":"Can WebGear_RTC always need Active Internet Connection?"},{"location":"help/webgear_rtc_faqs/#is-it-possible-to-stream-on-a-different-device-on-the-network-with-webgear_rtc","text":"If you set \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine, then you must still use http://localhost:8000/ to access stream on your host machine browser. For accessing WebGear_RTC on different Client Devices on the network, use \"0.0.0.0\" as host value instead of \"localhost\" on Host Machine. Then type the IP-address of source machine followed by the defined port value in your desired Client Device's browser (for e.g. http://192.27.0.101:8000 ) to access the stream.","title":"Is it possible to stream on a different device on the network with WebGear_RTC?"},{"location":"help/webgear_rtc_faqs/#can-i-manually-place-default-files-for-webgear_rtc","text":"Answer: Yes, you can either download default files from Github Server , and manually place at default location , OR, you can yourself create the require three critical files (i.e index.html , 404.html & 500.html ) inside templates folder at the default location , thereby you don't need any internet connection at all. For more information see Data-Files Auto-Generation WorkFlow \u27b6","title":"Can I manually place default files for WebGear_RTC?"},{"location":"help/webgear_rtc_faqs/#how-to-stream-webgear_rtc-server-output-to-multiple-clients","text":"Answer: See this usage example \u27b6 .","title":"How to stream Webgear_RTC Server output to multiple clients?"},{"location":"help/webgear_rtc_faqs/#how-to-send-opencv-frames-directly-to-webgear_rtc-server","text":"Answer: See this usage example \u27b6 .","title":"How to send OpenCV frames directly to Webgear_RTC Server?"},{"location":"help/webgear_rtc_faqs/#how-can-i-add-my-custom-webpage-to-webgear_rtc","text":"Answer: See this usage example \u27b6 .","title":"How can I add my custom WebPage to WebGear_RTC?"},{"location":"help/webgear_rtc_faqs/#how-can-to-add-cors-headers-to-webgear_rtc","text":"Answer: See this usage example \u27b6 .","title":"How can to add CORS headers to WebGear_RTC?"},{"location":"help/webgear_rtc_faqs/#can-i-change-the-default-location","text":"Answer: Yes, you can use WebGear_RTC's custom_data_location attribute of option parameter in WebGear_RTC API, to change default location to somewhere else.","title":"Can I change the default location?"},{"location":"help/webgear_rtc_faqs/#can-i-deleterename-the-webgear_rtc-default-data","text":"Answer: Yes, but you've to follow these rules \u27b6","title":"Can I delete/rename the WebGear_RTC default data?"},{"location":"help/writegear_ex/","text":"WriteGear Examples \u2693 Using WriteGear's Compression Mode for RSTP/RTP Live-Streaming \u2693 In Compression Mode, you can use WriteGear for livestreaming with traditional protocols such as RSTP/RTP. The example to achieve that is as follows: New in v0.2.6 This example was added in v0.2.6 . This example assume you already have a RSTP Server running at specified RSTP address with format rtsp://[RTSP_ADDRESS]:[RTSP_PORT]/[RTSP_PATH] for publishing video frames. Creating your own RSTP Server locally If you want to create your RSTP Server locally, then checkout rtsp-simple-server - a ready-to-use and zero-dependency server and proxy that allows users to publish, read and proxy live video and audio streams through various protocols such as RSTP, RTMP etc. Make sure to change RSTP address rtsp://localhost:8554/mystream with yours in following code before running! # import required libraries import cv2 from vidgear.gears import CamGear from vidgear.gears import WriteGear # open any valid video stream(for e.g `foo.mp4` file) stream = CamGear ( source = \"foo.mp4\" ) . start () # define required FFmpeg parameters for your writer output_params = { \"-f\" : \"rtsp\" , \"-rtsp_transport\" : \"tcp\" } # Define writer with defined parameters and RSTP address # [WARNING] Change your RSTP address `rtsp://localhost:8554/mystream` with yours! writer = WriteGear ( output_filename = \"rtsp://localhost:8554/mystream\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # safely close video stream stream . stop () # safely close writer writer . close () Using WriteGear's Compression Mode for YouTube-Live Streaming \u2693 In Compression Mode, you can also use WriteGear for Youtube-Livestreaming. The example is as follows: New in v0.2.1 This example was added in v0.2.1 . This example assume you already have a YouTube Account with Live-Streaming enabled for publishing video. Make sure to change YouTube-Live Stream Key with yours in following code before running! Without Audio With Audio # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # define and open video source stream = CamGear ( source = \"/home/foo/foo.mp4\" , logging = True ) . start () # define required FFmpeg parameters for your writer output_params = { \"-clones\" : [ \"-f\" , \"lavfi\" , \"-i\" , \"anullsrc\" ], \"-vcodec\" : \"libx264\" , \"-preset\" : \"medium\" , \"-b:v\" : \"4500k\" , \"-bufsize\" : \"512k\" , \"-pix_fmt\" : \"yuv420p\" , \"-f\" : \"flv\" , } # [WARNING] Change your YouTube-Live Stream Key here: YOUTUBE_STREAM_KEY = \"xxxx-xxxx-xxxx-xxxx-xxxx\" # Define writer with defined parameters writer = WriteGear ( output_filename = \"rtmp://a.rtmp.youtube.com/live2/ {} \" . format ( YOUTUBE_STREAM_KEY ), logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # safely close video stream stream . stop () # safely close writer writer . close () This code assume given input video source contains valid audio stream. # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # define video source(with audio) here VIDEO_SOURCE = \"/home/foo/foo.mp4\" # Open stream stream = CamGear ( source = VIDEO_SOURCE , logging = True ) . start () # define required FFmpeg parameters for your writer # [NOTE]: Added VIDEO_SOURCE as audio-source output_params = { \"-i\" : VIDEO_SOURCE , \"-acodec\" : \"aac\" , \"-ar\" : 44100 , \"-b:a\" : 712000 , \"-vcodec\" : \"libx264\" , \"-preset\" : \"medium\" , \"-b:v\" : \"4500k\" , \"-bufsize\" : \"512k\" , \"-pix_fmt\" : \"yuv420p\" , \"-f\" : \"flv\" , } # [WARNING] Change your YouTube-Live Stream Key here: YOUTUBE_STREAM_KEY = \"xxxx-xxxx-xxxx-xxxx-xxxx\" # Define writer with defined parameters writer = WriteGear ( output_filename = \"rtmp://a.rtmp.youtube.com/live2/ {} \" . format ( YOUTUBE_STREAM_KEY ), logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # safely close video stream stream . stop () # safely close writer writer . close () Using WriteGear's Compression Mode with v4l2loopback Virtual Cameras \u2693 With WriteGear's Compression Mode, you can directly feed video-frames to v4l2loopback generated Virtual Camera devices on Linux Machines. The complete usage example is as follows: New in v0.3.0 This example was added in v0.3.0 . Example Assumptions You're running are a Linux machine. WriteGear API's backend FFmpeg binaries are compiled with v4l2/v4l2loopback demuxer support. You already have v4l2loopback Virtual Camera device running at address: /dev/video0 Creating your own Virtual Camera device with v4l2loopback module. To install and create a v4l2loopback virtual camera device on Linux Mint OS/Ubuntu (may slightly differ for other distros) , run following two terminal commands: $ sudo apt-get install v4l2loopback-dkms v4l2loopback-utils linux-modules-extra- $( uname -r ) $ sudo modprobe v4l2loopback devices = 1 video_nr = 0 exclusive_caps = 1 card_label = 'VCamera' For further information on parameters used, checkout v4l2loopback docs Finally, You can check the loopback device you just created by listing contents of /sys/devices/virtual/video4linux directory with terminal command: $ sudo ls -1 /sys/devices/virtual/video4linux video0 Now you can use /dev/video0 Virtual Camera device path in WriteGear API. v4l2: open /dev/videoX: Permission denied If you got this error, then you must add your username to the video group by running following commands: $ sudo adduser $( whoami ) video $ sudo usermod -a -G video $( whoami ) Afterwards, restart your computer to finialize these changes. Note: If the problem still persists, then try to run your python script as superuser with sudo command. Default libx264 encoder is incompatible with v4l2loopback module. Kindly use other encoders such as libxvid , mpeg4 etc. # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `foo.mp4` file) stream = CamGear ( source = \"foo.mp4\" ) . start () # define required FFmpeg parameters for your writer # also retrieve framerate from CamGear Stream and pass it as `-input_framerate` parameter output_params = { \"-input_framerate\" : stream . framerate , \"-vcodec\" : \"libxvid\" , \"-f\" : \"v4l2\" , \"-pix_fmt\" : \"yuv420p\" , } # Define writer with \"/dev/video0\" as source and user-defined parameters writer = WriteGear ( output_filename = \"/dev/video0\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () The data sent to the v4l2loopback device /dev/video0 in this example with WriteGear API, can then be read by any v4l2-capable application (such as OpenCV, VLC, ffplay etc.) Using WriteGear's Compression Mode for creating MP4 segments \u2693 In Compression Mode, you can also use WriteGear for creating MP4 segments from almost any video source. The example is as follows: New in v0.2.1 This example was added in v0.2.1 . # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # Open any video source `foo.mp4` stream = VideoGear ( source = \"foo.mp4\" , logging = True ) . start () # define required FFmpeg optimizing parameters for your writer output_params = { \"-c:v\" : \"libx264\" , \"-crf\" : 22 , \"-map\" : 0 , \"-segment_time\" : 9 , \"-g\" : 9 , \"-sc_threshold\" : 0 , \"-force_key_frames\" : \"expr:gte(t,n_forced*9)\" , \"-clones\" : [ \"-f\" , \"segment\" ], } # Define writer with defined parameters writer = WriteGear ( output_filename = \"output %03d .mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using WriteGear's Compression Mode to add external audio file input to video frames \u2693 You can also use WriteGear for merging external audio with live video-source: New in v0.2.1 This example was added in v0.2.1 . Make sure this -i audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all. # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `foo_video.mp4` file) stream = CamGear ( source = \"foo_video.mp4\" ) . start () # add various parameters, along with custom audio stream_params = { \"-input_framerate\" : stream . framerate , # controlled framerate for audio-video sync !!! don't forget this line !!! \"-i\" : \"foo_audio.aac\" , # assigns input audio-source: \"foo_audio.aac\" } # Define writer with defined parameters writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using WriteGear's Compression Mode for generating Timely Accurate Video \u2693 If you need timely accurate video with exactly same speed as real-time input, then you need to use FFmpeg directly through its execute_ffmpeg_cmd method: New in v0.2.4 This example was added in v0.2.4 . In this example we are capturing video from desktop screen in a Timely Accurate manner. Windows Linux macOS # import required libraries from vidgear.gears import WriteGear # Define writer with defined parameters and with some dummy name writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True ) # format FFmpeg command to generate time accurate video ffmpeg_command = [ \"-y\" , \"-f\" , \"gdigrab\" , \"-framerate\" , \"30\" , \"-i\" , \"desktop\" , \"Output.mkv\" , ] # `-y` parameter is to overwrite outputfile if exists # execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command ) # safely close writer writer . close () # import required libraries from vidgear.gears import WriteGear # Define writer with defined parameters and with some dummy name writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True ) # format FFmpeg command to generate time accurate video ffmpeg_command = [ \"-y\" , \"-f\" , \"x11grab\" , \"-framerate\" , \"30\" , \"-i\" , \"default\" , \"Output.mkv\" , ] # `-y` parameter is to overwrite outputfile if exists # execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command ) # safely close writer writer . close () # import required libraries from vidgear.gears import WriteGear # Define writer with defined parameters and with some dummy name writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True ) # format FFmpeg command to generate time accurate video ffmpeg_command = [ \"-y\" , \"-f\" , \"avfoundation\" , \"-framerate\" , \"30\" , \"-i\" , \"default\" , \"Output.mkv\" , ] # `-y` parameter is to overwrite outputfile if exists # execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command ) # safely close writer writer . close () Using WriteGear with ROS(Robot Operating System) \u2693 We will be using cv_bridge to convert OpenCV frames to ROS image messages and vice-versa. In this example, we'll create a node that listens to a ROS image message topic, converts the recieved images messages into OpenCV frames, draws a circle on it, and then process these frames into a lossless compressed file format in real-time. New in v0.2.2 This example was added in v0.2.2 . This example is vidgear implementation of this wiki example . # import roslib import roslib roslib . load_manifest ( \"my_package\" ) # import other required libraries import sys import rospy import cv2 from std_msgs.msg import String from sensor_msgs.msg import Image from cv_bridge import CvBridge , CvBridgeError from vidgear.gears import WriteGear # custom publisher class class image_subscriber : def __init__ ( self , output_filename = \"Output.mp4\" ): # create CV bridge self . bridge = CvBridge () # define publisher topic self . image_pub = rospy . Subscriber ( \"image_topic_sub\" , Image , self . callback ) # Define writer with default parameters self . writer = WriteGear ( output_filename = output_filename ) def callback ( self , data ): # convert recieved data to frame try : cv_image = self . bridge . imgmsg_to_cv2 ( data , \"bgr8\" ) except CvBridgeError as e : print ( e ) # check if frame is valid if cv_image : # {do something with the frame here} # let's add a circle ( rows , cols , channels ) = cv_image . shape if cols > 60 and rows > 60 : cv2 . circle ( cv_image , ( 50 , 50 ), 10 , 255 ) # write frame to writer self . writer . write ( cv_image ) def close ( self ): # safely close video stream self . writer . close () def main ( args ): # define publisher with suitable output filename # such as `Output.mp4` for saving output ic = image_subscriber ( output_filename = \"Output.mp4\" ) # initiate ROS node on publisher rospy . init_node ( \"image_subscriber\" , anonymous = True ) try : # run node rospy . spin () except KeyboardInterrupt : print ( \"Shutting down\" ) finally : # close publisher ic . close () if __name__ == \"__main__\" : main ( sys . argv )","title":"WriteGear Examples"},{"location":"help/writegear_ex/#writegear-examples","text":"","title":"WriteGear Examples"},{"location":"help/writegear_ex/#using-writegears-compression-mode-for-rstprtp-live-streaming","text":"In Compression Mode, you can use WriteGear for livestreaming with traditional protocols such as RSTP/RTP. The example to achieve that is as follows: New in v0.2.6 This example was added in v0.2.6 . This example assume you already have a RSTP Server running at specified RSTP address with format rtsp://[RTSP_ADDRESS]:[RTSP_PORT]/[RTSP_PATH] for publishing video frames. Creating your own RSTP Server locally If you want to create your RSTP Server locally, then checkout rtsp-simple-server - a ready-to-use and zero-dependency server and proxy that allows users to publish, read and proxy live video and audio streams through various protocols such as RSTP, RTMP etc. Make sure to change RSTP address rtsp://localhost:8554/mystream with yours in following code before running! # import required libraries import cv2 from vidgear.gears import CamGear from vidgear.gears import WriteGear # open any valid video stream(for e.g `foo.mp4` file) stream = CamGear ( source = \"foo.mp4\" ) . start () # define required FFmpeg parameters for your writer output_params = { \"-f\" : \"rtsp\" , \"-rtsp_transport\" : \"tcp\" } # Define writer with defined parameters and RSTP address # [WARNING] Change your RSTP address `rtsp://localhost:8554/mystream` with yours! writer = WriteGear ( output_filename = \"rtsp://localhost:8554/mystream\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using WriteGear's Compression Mode for RSTP/RTP Live-Streaming"},{"location":"help/writegear_ex/#using-writegears-compression-mode-for-youtube-live-streaming","text":"In Compression Mode, you can also use WriteGear for Youtube-Livestreaming. The example is as follows: New in v0.2.1 This example was added in v0.2.1 . This example assume you already have a YouTube Account with Live-Streaming enabled for publishing video. Make sure to change YouTube-Live Stream Key with yours in following code before running! Without Audio With Audio # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # define and open video source stream = CamGear ( source = \"/home/foo/foo.mp4\" , logging = True ) . start () # define required FFmpeg parameters for your writer output_params = { \"-clones\" : [ \"-f\" , \"lavfi\" , \"-i\" , \"anullsrc\" ], \"-vcodec\" : \"libx264\" , \"-preset\" : \"medium\" , \"-b:v\" : \"4500k\" , \"-bufsize\" : \"512k\" , \"-pix_fmt\" : \"yuv420p\" , \"-f\" : \"flv\" , } # [WARNING] Change your YouTube-Live Stream Key here: YOUTUBE_STREAM_KEY = \"xxxx-xxxx-xxxx-xxxx-xxxx\" # Define writer with defined parameters writer = WriteGear ( output_filename = \"rtmp://a.rtmp.youtube.com/live2/ {} \" . format ( YOUTUBE_STREAM_KEY ), logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # safely close video stream stream . stop () # safely close writer writer . close () This code assume given input video source contains valid audio stream. # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # define video source(with audio) here VIDEO_SOURCE = \"/home/foo/foo.mp4\" # Open stream stream = CamGear ( source = VIDEO_SOURCE , logging = True ) . start () # define required FFmpeg parameters for your writer # [NOTE]: Added VIDEO_SOURCE as audio-source output_params = { \"-i\" : VIDEO_SOURCE , \"-acodec\" : \"aac\" , \"-ar\" : 44100 , \"-b:a\" : 712000 , \"-vcodec\" : \"libx264\" , \"-preset\" : \"medium\" , \"-b:v\" : \"4500k\" , \"-bufsize\" : \"512k\" , \"-pix_fmt\" : \"yuv420p\" , \"-f\" : \"flv\" , } # [WARNING] Change your YouTube-Live Stream Key here: YOUTUBE_STREAM_KEY = \"xxxx-xxxx-xxxx-xxxx-xxxx\" # Define writer with defined parameters writer = WriteGear ( output_filename = \"rtmp://a.rtmp.youtube.com/live2/ {} \" . format ( YOUTUBE_STREAM_KEY ), logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using WriteGear's Compression Mode for YouTube-Live Streaming"},{"location":"help/writegear_ex/#using-writegears-compression-mode-with-v4l2loopback-virtual-cameras","text":"With WriteGear's Compression Mode, you can directly feed video-frames to v4l2loopback generated Virtual Camera devices on Linux Machines. The complete usage example is as follows: New in v0.3.0 This example was added in v0.3.0 . Example Assumptions You're running are a Linux machine. WriteGear API's backend FFmpeg binaries are compiled with v4l2/v4l2loopback demuxer support. You already have v4l2loopback Virtual Camera device running at address: /dev/video0 Creating your own Virtual Camera device with v4l2loopback module. To install and create a v4l2loopback virtual camera device on Linux Mint OS/Ubuntu (may slightly differ for other distros) , run following two terminal commands: $ sudo apt-get install v4l2loopback-dkms v4l2loopback-utils linux-modules-extra- $( uname -r ) $ sudo modprobe v4l2loopback devices = 1 video_nr = 0 exclusive_caps = 1 card_label = 'VCamera' For further information on parameters used, checkout v4l2loopback docs Finally, You can check the loopback device you just created by listing contents of /sys/devices/virtual/video4linux directory with terminal command: $ sudo ls -1 /sys/devices/virtual/video4linux video0 Now you can use /dev/video0 Virtual Camera device path in WriteGear API. v4l2: open /dev/videoX: Permission denied If you got this error, then you must add your username to the video group by running following commands: $ sudo adduser $( whoami ) video $ sudo usermod -a -G video $( whoami ) Afterwards, restart your computer to finialize these changes. Note: If the problem still persists, then try to run your python script as superuser with sudo command. Default libx264 encoder is incompatible with v4l2loopback module. Kindly use other encoders such as libxvid , mpeg4 etc. # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `foo.mp4` file) stream = CamGear ( source = \"foo.mp4\" ) . start () # define required FFmpeg parameters for your writer # also retrieve framerate from CamGear Stream and pass it as `-input_framerate` parameter output_params = { \"-input_framerate\" : stream . framerate , \"-vcodec\" : \"libxvid\" , \"-f\" : \"v4l2\" , \"-pix_fmt\" : \"yuv420p\" , } # Define writer with \"/dev/video0\" as source and user-defined parameters writer = WriteGear ( output_filename = \"/dev/video0\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () The data sent to the v4l2loopback device /dev/video0 in this example with WriteGear API, can then be read by any v4l2-capable application (such as OpenCV, VLC, ffplay etc.)","title":"Using WriteGear's Compression Mode with v4l2loopback Virtual Cameras"},{"location":"help/writegear_ex/#using-writegears-compression-mode-for-creating-mp4-segments","text":"In Compression Mode, you can also use WriteGear for creating MP4 segments from almost any video source. The example is as follows: New in v0.2.1 This example was added in v0.2.1 . # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # Open any video source `foo.mp4` stream = VideoGear ( source = \"foo.mp4\" , logging = True ) . start () # define required FFmpeg optimizing parameters for your writer output_params = { \"-c:v\" : \"libx264\" , \"-crf\" : 22 , \"-map\" : 0 , \"-segment_time\" : 9 , \"-g\" : 9 , \"-sc_threshold\" : 0 , \"-force_key_frames\" : \"expr:gte(t,n_forced*9)\" , \"-clones\" : [ \"-f\" , \"segment\" ], } # Define writer with defined parameters writer = WriteGear ( output_filename = \"output %03d .mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using WriteGear's Compression Mode for creating MP4 segments"},{"location":"help/writegear_ex/#using-writegears-compression-mode-to-add-external-audio-file-input-to-video-frames","text":"You can also use WriteGear for merging external audio with live video-source: New in v0.2.1 This example was added in v0.2.1 . Make sure this -i audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all. # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `foo_video.mp4` file) stream = CamGear ( source = \"foo_video.mp4\" ) . start () # add various parameters, along with custom audio stream_params = { \"-input_framerate\" : stream . framerate , # controlled framerate for audio-video sync !!! don't forget this line !!! \"-i\" : \"foo_audio.aac\" , # assigns input audio-source: \"foo_audio.aac\" } # Define writer with defined parameters writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using WriteGear's Compression Mode to add external audio file input to video frames"},{"location":"help/writegear_ex/#using-writegears-compression-mode-for-generating-timely-accurate-video","text":"If you need timely accurate video with exactly same speed as real-time input, then you need to use FFmpeg directly through its execute_ffmpeg_cmd method: New in v0.2.4 This example was added in v0.2.4 . In this example we are capturing video from desktop screen in a Timely Accurate manner. Windows Linux macOS # import required libraries from vidgear.gears import WriteGear # Define writer with defined parameters and with some dummy name writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True ) # format FFmpeg command to generate time accurate video ffmpeg_command = [ \"-y\" , \"-f\" , \"gdigrab\" , \"-framerate\" , \"30\" , \"-i\" , \"desktop\" , \"Output.mkv\" , ] # `-y` parameter is to overwrite outputfile if exists # execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command ) # safely close writer writer . close () # import required libraries from vidgear.gears import WriteGear # Define writer with defined parameters and with some dummy name writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True ) # format FFmpeg command to generate time accurate video ffmpeg_command = [ \"-y\" , \"-f\" , \"x11grab\" , \"-framerate\" , \"30\" , \"-i\" , \"default\" , \"Output.mkv\" , ] # `-y` parameter is to overwrite outputfile if exists # execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command ) # safely close writer writer . close () # import required libraries from vidgear.gears import WriteGear # Define writer with defined parameters and with some dummy name writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True ) # format FFmpeg command to generate time accurate video ffmpeg_command = [ \"-y\" , \"-f\" , \"avfoundation\" , \"-framerate\" , \"30\" , \"-i\" , \"default\" , \"Output.mkv\" , ] # `-y` parameter is to overwrite outputfile if exists # execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command ) # safely close writer writer . close ()","title":"Using WriteGear's Compression Mode for generating Timely Accurate Video"},{"location":"help/writegear_ex/#using-writegear-with-rosrobot-operating-system","text":"We will be using cv_bridge to convert OpenCV frames to ROS image messages and vice-versa. In this example, we'll create a node that listens to a ROS image message topic, converts the recieved images messages into OpenCV frames, draws a circle on it, and then process these frames into a lossless compressed file format in real-time. New in v0.2.2 This example was added in v0.2.2 . This example is vidgear implementation of this wiki example . # import roslib import roslib roslib . load_manifest ( \"my_package\" ) # import other required libraries import sys import rospy import cv2 from std_msgs.msg import String from sensor_msgs.msg import Image from cv_bridge import CvBridge , CvBridgeError from vidgear.gears import WriteGear # custom publisher class class image_subscriber : def __init__ ( self , output_filename = \"Output.mp4\" ): # create CV bridge self . bridge = CvBridge () # define publisher topic self . image_pub = rospy . Subscriber ( \"image_topic_sub\" , Image , self . callback ) # Define writer with default parameters self . writer = WriteGear ( output_filename = output_filename ) def callback ( self , data ): # convert recieved data to frame try : cv_image = self . bridge . imgmsg_to_cv2 ( data , \"bgr8\" ) except CvBridgeError as e : print ( e ) # check if frame is valid if cv_image : # {do something with the frame here} # let's add a circle ( rows , cols , channels ) = cv_image . shape if cols > 60 and rows > 60 : cv2 . circle ( cv_image , ( 50 , 50 ), 10 , 255 ) # write frame to writer self . writer . write ( cv_image ) def close ( self ): # safely close video stream self . writer . close () def main ( args ): # define publisher with suitable output filename # such as `Output.mp4` for saving output ic = image_subscriber ( output_filename = \"Output.mp4\" ) # initiate ROS node on publisher rospy . init_node ( \"image_subscriber\" , anonymous = True ) try : # run node rospy . spin () except KeyboardInterrupt : print ( \"Shutting down\" ) finally : # close publisher ic . close () if __name__ == \"__main__\" : main ( sys . argv )","title":"Using WriteGear with ROS(Robot Operating System)"},{"location":"help/writegear_faqs/","text":"WriteGear FAQs \u2693 What is WriteGear API and what does it do? \u2693 Answer: WriteGear handles various powerful Writer Tools that provide us the freedom to do almost anything imagine with multimedia files. For more info. see WriteGear doc \u27b6 I'm only familiar with OpenCV, how to get started with WriteGear API? \u2693 Answer: First, see Switching from OpenCV , then go through WriteGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel. Why WriteGear is throwing ValueError ? \u2693 Answer: WriteGear will exit with ValueError if you feed frames of different dimensions or channels. How to install and configure FFmpeg correctly for WriteGear on my machine? \u2693 Answer: Follow these Installation Instructions \u27b6 for its installation. Can I use WriteGear directly with OpenCV? \u2693 Answer: Yes, For Compression Mode: See this usage example \u27b6 . For Non-Compression Mode: See this usage example \u27b6 What FFmpeg's encoders and parameters are supported by WriteGear in compression mode? \u2693 Answer: See Supported Parameters \u27b6 and Supported encoders \u27b6 What OpenCV's FOURCC and parameters are supported by WriteGear in non-compression mode? \u2693 Answer: See Supported Parameters \u27b6 and Supported FOURCC \u27b6 . Why this FOURCC is not working for me? \u2693 Answer: Remember not all the FOURCC and Video extensions are compatible and supported by OpenCV VideoWriter Class. You\u2019ll need to try different combinations of FourCC and file extensions. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error . Can I pass my custom FFmpeg commands directly in WriteGear API? \u2693 Answer: Yes, See Custom FFmpeg Commands in WriteGear API \u27b6 . How to use specific Hardware Encoder in WriteGear? \u2693 Answer: See this usage example \u27b6 How to add live audio to WriteGear? \u2693 Answer: See this doc \u27b6 How to separate and merge audio from/to video? \u2693 Answer: See these usage examples \u27b6 Can I live stream to Twitch with WriteGear API? \u2693 Answer: Yes, See this usage example \u27b6 Is YouTube-Live Streaming possibe with WriteGear? \u2693 Answer: Yes, See this bonus example \u27b6 . How to Live-Streaming using RSTP/RTP protocol with WriteGear? \u2693 Answer: See this bonus example \u27b6 . How to create MP4 segments from a video stream with WriteGear? \u2693 Answer: See this bonus example \u27b6 . How add external audio file input to video frames? \u2693 Answer: See this bonus example \u27b6 . Why this FFmpeg parameter is not working for me in compression mode? \u2693 Answer: If some FFmpeg parameter doesn't work for you, then tell us on Gitter \u27b6 , and if that doesn't help, then finally report an issue \u27b6 Why WriteGear is switching to Non-compression Mode, even if it is not enable? \u2693 Answer: In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it will automatically fallback to Non-Compression Mode. Follow Installation Instructions \u27b6 for FFmpeg installation.","title":"WriteGear FAQs"},{"location":"help/writegear_faqs/#writegear-faqs","text":"","title":"WriteGear FAQs"},{"location":"help/writegear_faqs/#what-is-writegear-api-and-what-does-it-do","text":"Answer: WriteGear handles various powerful Writer Tools that provide us the freedom to do almost anything imagine with multimedia files. For more info. see WriteGear doc \u27b6","title":"What is WriteGear API and what does it do?"},{"location":"help/writegear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-writegear-api","text":"Answer: First, see Switching from OpenCV , then go through WriteGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"I'm only familiar with OpenCV, how to get started with WriteGear API?"},{"location":"help/writegear_faqs/#why-writegear-is-throwing-valueerror","text":"Answer: WriteGear will exit with ValueError if you feed frames of different dimensions or channels.","title":"Why WriteGear is throwing ValueError?"},{"location":"help/writegear_faqs/#how-to-install-and-configure-ffmpeg-correctly-for-writegear-on-my-machine","text":"Answer: Follow these Installation Instructions \u27b6 for its installation.","title":"How to install and configure FFmpeg correctly for WriteGear on my machine?"},{"location":"help/writegear_faqs/#can-i-use-writegear-directly-with-opencv","text":"Answer: Yes, For Compression Mode: See this usage example \u27b6 . For Non-Compression Mode: See this usage example \u27b6","title":"Can I use WriteGear directly with OpenCV?"},{"location":"help/writegear_faqs/#what-ffmpegs-encoders-and-parameters-are-supported-by-writegear-in-compression-mode","text":"Answer: See Supported Parameters \u27b6 and Supported encoders \u27b6","title":"What FFmpeg's encoders and parameters are supported by WriteGear in compression mode?"},{"location":"help/writegear_faqs/#what-opencvs-fourcc-and-parameters-are-supported-by-writegear-in-non-compression-mode","text":"Answer: See Supported Parameters \u27b6 and Supported FOURCC \u27b6 .","title":"What OpenCV's FOURCC and parameters are supported by WriteGear in non-compression mode?"},{"location":"help/writegear_faqs/#why-this-fourcc-is-not-working-for-me","text":"Answer: Remember not all the FOURCC and Video extensions are compatible and supported by OpenCV VideoWriter Class. You\u2019ll need to try different combinations of FourCC and file extensions. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error .","title":"Why this FOURCC is not working for me?"},{"location":"help/writegear_faqs/#can-i-pass-my-custom-ffmpeg-commands-directly-in-writegear-api","text":"Answer: Yes, See Custom FFmpeg Commands in WriteGear API \u27b6 .","title":"Can I pass my custom FFmpeg commands directly in WriteGear API?"},{"location":"help/writegear_faqs/#how-to-use-specific-hardware-encoder-in-writegear","text":"Answer: See this usage example \u27b6","title":"How to use specific Hardware Encoder in WriteGear?"},{"location":"help/writegear_faqs/#how-to-add-live-audio-to-writegear","text":"Answer: See this doc \u27b6","title":"How to add live audio to WriteGear?"},{"location":"help/writegear_faqs/#how-to-separate-and-merge-audio-fromto-video","text":"Answer: See these usage examples \u27b6","title":"How to separate and merge audio from/to video?"},{"location":"help/writegear_faqs/#can-i-live-stream-to-twitch-with-writegear-api","text":"Answer: Yes, See this usage example \u27b6","title":"Can I live stream to Twitch with WriteGear API?"},{"location":"help/writegear_faqs/#is-youtube-live-streaming-possibe-with-writegear","text":"Answer: Yes, See this bonus example \u27b6 .","title":"Is YouTube-Live Streaming possibe with WriteGear?"},{"location":"help/writegear_faqs/#how-to-live-streaming-using-rstprtp-protocol-with-writegear","text":"Answer: See this bonus example \u27b6 .","title":"How to Live-Streaming using RSTP/RTP protocol with WriteGear?"},{"location":"help/writegear_faqs/#how-to-create-mp4-segments-from-a-video-stream-with-writegear","text":"Answer: See this bonus example \u27b6 .","title":"How to create MP4 segments from a video stream with WriteGear?"},{"location":"help/writegear_faqs/#how-add-external-audio-file-input-to-video-frames","text":"Answer: See this bonus example \u27b6 .","title":"How add external audio file input to video frames?"},{"location":"help/writegear_faqs/#why-this-ffmpeg-parameter-is-not-working-for-me-in-compression-mode","text":"Answer: If some FFmpeg parameter doesn't work for you, then tell us on Gitter \u27b6 , and if that doesn't help, then finally report an issue \u27b6","title":"Why this FFmpeg parameter is not working for me in compression mode?"},{"location":"help/writegear_faqs/#why-writegear-is-switching-to-non-compression-mode-even-if-it-is-not-enable","text":"Answer: In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it will automatically fallback to Non-Compression Mode. Follow Installation Instructions \u27b6 for FFmpeg installation.","title":"Why WriteGear is switching to Non-compression Mode, even if it is not enable?"},{"location":"installation/pip_install/","text":"Install using pip \u2693 Best option for easily getting stable VidGear installed. Prerequisites \u2693 When installing VidGear with pip , you need to manually install following prerequisites: Upgrade your pip It strongly advised to upgrade to latest pip before installing vidgear to avoid any undesired installation error(s). There are two mechanisms to upgrade pip : pip ensurepip You can use existing pip to upgrade itself: Install pip if not present Download the script, from https://bootstrap.pypa.io/get-pip.py . Open a terminal/command prompt, cd to the folder containing the get-pip.py file and run: Linux / MacOS Windows python get-pip.py py get-pip.py More details about this script can be found in pypa/get-pip\u2019s README . Linux / MacOS Windows python -m pip install pip --upgrade py -m pip install pip --upgrade Python also comes with an ensurepip module 1 , which can easily upgrade/install pip in any Python environment. Linux / MacOS Windows python -m ensurepip --upgrade py -m ensurepip --upgrade Critical Prerequisites \u2693 OpenCV \u2693 Must require OpenCV(3.0+) python binaries installed for all core functions. You easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python API Specific Prerequisites \u2693 FFmpeg \u2693 Require only for the video compression and encoding compatibility within StreamGear API and WriteGear API's Compression Mode . FFmpeg Installation For WriteGear API's Compression Mode : Follow this dedicated FFmpeg Installation doc for its installation. For StreamGear API : Follow this dedicated FFmpeg Installation doc for its installation. Picamera \u2693 Required only if you're using Raspberry Pi Camera Modules with its PiGear API. You can easily install it via pip: Make sure to enable Raspberry Pi hardware-specific settings prior to using this library, otherwise it won't work. pip install picamera Uvloop \u2693 Required only if you're using the NetGear_Async API on UNIX machines for maximum performance. You can easily install it via pip: uvloop is NOT yet supported on Windows Machines . pip install uvloop Installation \u2693 Installation command with pip has been changed in v0.2.4 The legacy pip install vidgear command now installs critical bare-minimum dependencies only. Therefore in order to automatically install all the API specific dependencies as previous versions, use pip install vidgear [ core ] command instead. v0.2.4 and newer Older # Install latest stable release with all Core dependencies pip install -U vidgear [ core ] [core] keyword isn't available in versions older than v0.2.4 # Install older stable release with all Core dependencies pip install vidgear< 0 .2.4 Similarly in your python project files like setup.py or requirements.txt or setup.cfg , use vidgear dependency as vidgear [ core ] > = 0 .2.4 instead. This change does not affects pip install vidgear [ asyncio ] command. Installation is as simple as: Installing vidgear with only selective dependencies Starting with version v0.2.2 , you can now run any VidGear API by installing only just specific dependencies required by the API in use(except for some Core dependencies). This is useful when you want to manually review, select and install minimal API-specific dependencies on bare-minimum vidgear from scratch on your system: Install bare-minimum vidgear as follows: v0.2.4 and newer Older # Install stable release with bare-minimum dependencies pip install -U vidgear # Install stable without any dependencies pip install --no-deps vidgear< 0 .2.4 Then, you must install Critical dependencies (if not already): v0.2.4 and newer Older # Install opencv(only if not installed previously) pip install opencv-python # Install critical dependencies pip install cython, numpy, requests, tqdm, colorlog # Install opencv(only if not installed previously) pip install opencv-python Finally, manually install your API-specific dependencies as required by your API(in use): # Just copy-&-paste from table below pip install <API-specific dependencies> v0.2.4 and newer Older APIs Dependencies CamGear yt_dlp PiGear picamera VideoGear Based on CamGear or PiGear backend in use ScreenGear mss , pyscreenshot , Pillow WriteGear FFmpeg: See this doc \u27b6 StreamGear FFmpeg: See this doc \u27b6 NetGear pyzmq , simplejpeg WebGear starlette , jinja2 , uvicorn , simplejpeg WebGear_RTC aiortc , starlette , jinja2 , uvicorn NetGear_Async pyzmq , msgpack , msgpack_numpy , uvloop Stabilizer Class - APIs Dependencies CamGear pafy , yt_dlp , streamlink PiGear picamera VideoGear Based on CamGear or PiGear backend in use ScreenGear mss , pyscreenshot , Pillow WriteGear FFmpeg: See this doc \u27b6 StreamGear FFmpeg: See this doc \u27b6 NetGear pyzmq , simplejpeg WebGear starlette , jinja2 , uvicorn , simplejpeg WebGear_RTC aiortc , starlette , jinja2 , uvicorn NetGear_Async pyzmq , msgpack , msgpack_numpy , uvloop Stabilizer Class - Windows Installation If you are using Windows, some of the commands given below, may not work out-of-the-box. A quick solution may be to preface every Python command with python -m like this: # Install latest stable release with all Core dependencies python -m pip install -U vidgear [ core ] # Or Install latest stable release with all Core & Asyncio dependencies python -m pip install -U vidgear [ asyncio ] And, If you don't have the privileges to the directory you're installing package. Then use --user flag, that makes pip install packages in your home directory instead: # Install latest stable release with all Core dependencies python -m pip install --upgrade --user vidgear [ core ] # Or Install latest stable release with all Core & Asyncio dependencies python -m pip install --upgrade --user vidgear [ asyncio ] Or, If you're using py as alias for installed python, then: # Install latest stable release with all Core dependencies py -m pip install --upgrade --user vidgear [ core ] # Or Install latest stable release with all Core & Asyncio dependencies py -m pip install --upgrade --user vidgear [ asyncio ] # Install latest stable release with all Core dependencies pip install -U vidgear [ core ] # Or Install latest stable release with all Core & Asyncio dependencies pip install -U vidgear [ asyncio ] And if you prefer to install VidGear directly from the repository: # Install latest stable release with all Core dependencies pip install git+git://github.com/abhiTronix/vidgear@master#egg = vidgear [ core ] # Or Install latest stable release with all Core & Asyncio dependencies pip install git+git://github.com/abhiTronix/vidgear@master#egg = vidgear [ asyncio ] Or you can also download its wheel ( .whl ) package from our repository's releases section, and thereby can be installed as follows: # Install latest stable release with all Core dependencies pip install vidgear-0.2.5-py3-none-any.whl [ core ] # Or Install latest stable release with all Core & Asyncio dependencies pip install vidgear-0.2.5-py3-none-any.whl [ asyncio ] The ensurepip module is missing/disabled on Ubuntu. Use pip method only. \u21a9","title":"Install using pip"},{"location":"installation/pip_install/#install-using-pip","text":"Best option for easily getting stable VidGear installed.","title":"Install using pip"},{"location":"installation/pip_install/#prerequisites","text":"When installing VidGear with pip , you need to manually install following prerequisites: Upgrade your pip It strongly advised to upgrade to latest pip before installing vidgear to avoid any undesired installation error(s). There are two mechanisms to upgrade pip : pip ensurepip You can use existing pip to upgrade itself: Install pip if not present Download the script, from https://bootstrap.pypa.io/get-pip.py . Open a terminal/command prompt, cd to the folder containing the get-pip.py file and run: Linux / MacOS Windows python get-pip.py py get-pip.py More details about this script can be found in pypa/get-pip\u2019s README . Linux / MacOS Windows python -m pip install pip --upgrade py -m pip install pip --upgrade Python also comes with an ensurepip module 1 , which can easily upgrade/install pip in any Python environment. Linux / MacOS Windows python -m ensurepip --upgrade py -m ensurepip --upgrade","title":"Prerequisites"},{"location":"installation/pip_install/#critical-prerequisites","text":"","title":"Critical Prerequisites"},{"location":"installation/pip_install/#opencv","text":"Must require OpenCV(3.0+) python binaries installed for all core functions. You easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python","title":"OpenCV"},{"location":"installation/pip_install/#api-specific-prerequisites","text":"","title":"API Specific Prerequisites"},{"location":"installation/pip_install/#ffmpeg","text":"Require only for the video compression and encoding compatibility within StreamGear API and WriteGear API's Compression Mode . FFmpeg Installation For WriteGear API's Compression Mode : Follow this dedicated FFmpeg Installation doc for its installation. For StreamGear API : Follow this dedicated FFmpeg Installation doc for its installation.","title":"FFmpeg"},{"location":"installation/pip_install/#picamera","text":"Required only if you're using Raspberry Pi Camera Modules with its PiGear API. You can easily install it via pip: Make sure to enable Raspberry Pi hardware-specific settings prior to using this library, otherwise it won't work. pip install picamera","title":"Picamera"},{"location":"installation/pip_install/#uvloop","text":"Required only if you're using the NetGear_Async API on UNIX machines for maximum performance. You can easily install it via pip: uvloop is NOT yet supported on Windows Machines . pip install uvloop","title":"Uvloop"},{"location":"installation/pip_install/#installation","text":"Installation command with pip has been changed in v0.2.4 The legacy pip install vidgear command now installs critical bare-minimum dependencies only. Therefore in order to automatically install all the API specific dependencies as previous versions, use pip install vidgear [ core ] command instead. v0.2.4 and newer Older # Install latest stable release with all Core dependencies pip install -U vidgear [ core ] [core] keyword isn't available in versions older than v0.2.4 # Install older stable release with all Core dependencies pip install vidgear< 0 .2.4 Similarly in your python project files like setup.py or requirements.txt or setup.cfg , use vidgear dependency as vidgear [ core ] > = 0 .2.4 instead. This change does not affects pip install vidgear [ asyncio ] command. Installation is as simple as: Installing vidgear with only selective dependencies Starting with version v0.2.2 , you can now run any VidGear API by installing only just specific dependencies required by the API in use(except for some Core dependencies). This is useful when you want to manually review, select and install minimal API-specific dependencies on bare-minimum vidgear from scratch on your system: Install bare-minimum vidgear as follows: v0.2.4 and newer Older # Install stable release with bare-minimum dependencies pip install -U vidgear # Install stable without any dependencies pip install --no-deps vidgear< 0 .2.4 Then, you must install Critical dependencies (if not already): v0.2.4 and newer Older # Install opencv(only if not installed previously) pip install opencv-python # Install critical dependencies pip install cython, numpy, requests, tqdm, colorlog # Install opencv(only if not installed previously) pip install opencv-python Finally, manually install your API-specific dependencies as required by your API(in use): # Just copy-&-paste from table below pip install <API-specific dependencies> v0.2.4 and newer Older APIs Dependencies CamGear yt_dlp PiGear picamera VideoGear Based on CamGear or PiGear backend in use ScreenGear mss , pyscreenshot , Pillow WriteGear FFmpeg: See this doc \u27b6 StreamGear FFmpeg: See this doc \u27b6 NetGear pyzmq , simplejpeg WebGear starlette , jinja2 , uvicorn , simplejpeg WebGear_RTC aiortc , starlette , jinja2 , uvicorn NetGear_Async pyzmq , msgpack , msgpack_numpy , uvloop Stabilizer Class - APIs Dependencies CamGear pafy , yt_dlp , streamlink PiGear picamera VideoGear Based on CamGear or PiGear backend in use ScreenGear mss , pyscreenshot , Pillow WriteGear FFmpeg: See this doc \u27b6 StreamGear FFmpeg: See this doc \u27b6 NetGear pyzmq , simplejpeg WebGear starlette , jinja2 , uvicorn , simplejpeg WebGear_RTC aiortc , starlette , jinja2 , uvicorn NetGear_Async pyzmq , msgpack , msgpack_numpy , uvloop Stabilizer Class - Windows Installation If you are using Windows, some of the commands given below, may not work out-of-the-box. A quick solution may be to preface every Python command with python -m like this: # Install latest stable release with all Core dependencies python -m pip install -U vidgear [ core ] # Or Install latest stable release with all Core & Asyncio dependencies python -m pip install -U vidgear [ asyncio ] And, If you don't have the privileges to the directory you're installing package. Then use --user flag, that makes pip install packages in your home directory instead: # Install latest stable release with all Core dependencies python -m pip install --upgrade --user vidgear [ core ] # Or Install latest stable release with all Core & Asyncio dependencies python -m pip install --upgrade --user vidgear [ asyncio ] Or, If you're using py as alias for installed python, then: # Install latest stable release with all Core dependencies py -m pip install --upgrade --user vidgear [ core ] # Or Install latest stable release with all Core & Asyncio dependencies py -m pip install --upgrade --user vidgear [ asyncio ] # Install latest stable release with all Core dependencies pip install -U vidgear [ core ] # Or Install latest stable release with all Core & Asyncio dependencies pip install -U vidgear [ asyncio ] And if you prefer to install VidGear directly from the repository: # Install latest stable release with all Core dependencies pip install git+git://github.com/abhiTronix/vidgear@master#egg = vidgear [ core ] # Or Install latest stable release with all Core & Asyncio dependencies pip install git+git://github.com/abhiTronix/vidgear@master#egg = vidgear [ asyncio ] Or you can also download its wheel ( .whl ) package from our repository's releases section, and thereby can be installed as follows: # Install latest stable release with all Core dependencies pip install vidgear-0.2.5-py3-none-any.whl [ core ] # Or Install latest stable release with all Core & Asyncio dependencies pip install vidgear-0.2.5-py3-none-any.whl [ asyncio ] The ensurepip module is missing/disabled on Ubuntu. Use pip method only. \u21a9","title":"Installation"},{"location":"installation/source_install/","text":"Install from source \u2693 Best option for trying latest patches(maybe experimental), forking for Pull Requests, or automatically installing all prerequisites(with a few exceptions). Prerequisites \u2693 When installing VidGear from source, FFmpeg is the only API specific prerequisites you need to install manually: What about rest of the prerequisites? Any other python prerequisites (Critical/API specific) will be automatically installed based on your OS/System specifications. Upgrade your pip It strongly advised to upgrade to latest pip before installing vidgear to avoid any undesired installation error(s). There are two mechanisms to upgrade pip : pip ensurepip You can use existing pip to upgrade itself: Install pip if not present Download the script, from https://bootstrap.pypa.io/get-pip.py . Open a terminal/command prompt, cd to the folder containing the get-pip.py file and run: Linux/MacOS Windows python get-pip.py py get-pip.py More details about this script can be found in pypa/get-pip\u2019s README . Linux/MacOS Windows python -m pip install pip --upgrade py -m pip install pip --upgrade Python also comes with an ensurepip module 1 , which can easily upgrade/install pip in any Python environment. Linux/MacOS Windows python -m ensurepip --upgrade py -m ensurepip --upgrade API Specific Prerequisites \u2693 FFmpeg \u2693 Require only for the video compression and encoding compatibility within StreamGear API and WriteGear API's Compression Mode . FFmpeg Installation For WriteGear API's Compression Mode : Follow this dedicated FFmpeg Installation doc for its installation. For StreamGear API : Follow this dedicated FFmpeg Installation doc for its installation. Installation \u2693 If you want to checkout the latest beta testing branch , you can do so with the following commands: This can be useful if you want to provide feedback for a new feature or bug fix in the testing branch. DO NOT clone or install any other branch other than testing unless advised, as it is not tested with CI environments and possibly very unstable or unusable. Installing vidgear with only selective dependencies Starting with version v0.2.2 , you can now run any VidGear API by installing only just specific dependencies required by the API in use(except for some Core dependencies). This is useful when you want to manually review, select and install minimal API-specific dependencies on bare-minimum vidgear from scratch on your system: To clone and install bare-minimum vidgear without any dependencies do as follows: # clone the repository and get inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing # Install stable release with bare-minimum dependencies pip install . Then, you must install Critical dependencies (if not already): # Install opencv(only if not installed previously) pip install opencv-python Finally, manually install your API-specific dependencies as required by your API(in use): # Just copy-&-paste from table below pip install <API-specific dependencies> APIs Dependencies CamGear yt_dlp PiGear picamera VideoGear Based on CamGear or PiGear backend in use ScreenGear mss , pyscreenshot , Pillow WriteGear FFmpeg: See this doc \u27b6 StreamGear FFmpeg: See this doc \u27b6 NetGear pyzmq , simplejpeg WebGear starlette , jinja2 , uvicorn , simplejpeg WebGear_RTC aiortc , starlette , jinja2 , uvicorn NetGear_Async pyzmq , msgpack , msgpack_numpy , uvloop Stabilizer Class - Windows Installation If you are using Windows, some of the commands given below, may not work out-of-the-box. A quick solution may be to preface every Python command with python -m like this: # Install latest stable release with all Core dependencies python -m pip install -U . [ core ] # Or Install latest stable release with all Core & Asyncio dependencies python -m pip install -U . [ asyncio ] And, If you don't have the privileges to the directory you're installing package. Then use --user flag, that makes pip install packages in your home directory instead: # Install latest stable release with all Core dependencies python -m pip install --upgrade --user . [ core ] # Or Install latest stable release with all Core & Asyncio dependencies python -m pip install --upgrade --user . [ asyncio ] Or, If you're using py as alias for installed python, then: # Install latest stable release with all Core dependencies py -m pip install --upgrade --user . [ core ] # Or Install latest stable release with all Core & Asyncio dependencies py -m pip install --upgrade --user . [ asyncio ] # clone the repository and get inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing # Install latest stable release with all Core dependencies pip install -U . [ core ] # Or Install latest stable release with all Core & Asyncio dependencies pip install -U . [ asyncio ] The ensurepip module is missing/disabled on Ubuntu. Use pip method only. \u21a9","title":"Install from source"},{"location":"installation/source_install/#install-from-source","text":"Best option for trying latest patches(maybe experimental), forking for Pull Requests, or automatically installing all prerequisites(with a few exceptions).","title":"Install from source"},{"location":"installation/source_install/#prerequisites","text":"When installing VidGear from source, FFmpeg is the only API specific prerequisites you need to install manually: What about rest of the prerequisites? Any other python prerequisites (Critical/API specific) will be automatically installed based on your OS/System specifications. Upgrade your pip It strongly advised to upgrade to latest pip before installing vidgear to avoid any undesired installation error(s). There are two mechanisms to upgrade pip : pip ensurepip You can use existing pip to upgrade itself: Install pip if not present Download the script, from https://bootstrap.pypa.io/get-pip.py . Open a terminal/command prompt, cd to the folder containing the get-pip.py file and run: Linux/MacOS Windows python get-pip.py py get-pip.py More details about this script can be found in pypa/get-pip\u2019s README . Linux/MacOS Windows python -m pip install pip --upgrade py -m pip install pip --upgrade Python also comes with an ensurepip module 1 , which can easily upgrade/install pip in any Python environment. Linux/MacOS Windows python -m ensurepip --upgrade py -m ensurepip --upgrade","title":"Prerequisites"},{"location":"installation/source_install/#api-specific-prerequisites","text":"","title":"API Specific Prerequisites"},{"location":"installation/source_install/#ffmpeg","text":"Require only for the video compression and encoding compatibility within StreamGear API and WriteGear API's Compression Mode . FFmpeg Installation For WriteGear API's Compression Mode : Follow this dedicated FFmpeg Installation doc for its installation. For StreamGear API : Follow this dedicated FFmpeg Installation doc for its installation.","title":"FFmpeg"},{"location":"installation/source_install/#installation","text":"If you want to checkout the latest beta testing branch , you can do so with the following commands: This can be useful if you want to provide feedback for a new feature or bug fix in the testing branch. DO NOT clone or install any other branch other than testing unless advised, as it is not tested with CI environments and possibly very unstable or unusable. Installing vidgear with only selective dependencies Starting with version v0.2.2 , you can now run any VidGear API by installing only just specific dependencies required by the API in use(except for some Core dependencies). This is useful when you want to manually review, select and install minimal API-specific dependencies on bare-minimum vidgear from scratch on your system: To clone and install bare-minimum vidgear without any dependencies do as follows: # clone the repository and get inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing # Install stable release with bare-minimum dependencies pip install . Then, you must install Critical dependencies (if not already): # Install opencv(only if not installed previously) pip install opencv-python Finally, manually install your API-specific dependencies as required by your API(in use): # Just copy-&-paste from table below pip install <API-specific dependencies> APIs Dependencies CamGear yt_dlp PiGear picamera VideoGear Based on CamGear or PiGear backend in use ScreenGear mss , pyscreenshot , Pillow WriteGear FFmpeg: See this doc \u27b6 StreamGear FFmpeg: See this doc \u27b6 NetGear pyzmq , simplejpeg WebGear starlette , jinja2 , uvicorn , simplejpeg WebGear_RTC aiortc , starlette , jinja2 , uvicorn NetGear_Async pyzmq , msgpack , msgpack_numpy , uvloop Stabilizer Class - Windows Installation If you are using Windows, some of the commands given below, may not work out-of-the-box. A quick solution may be to preface every Python command with python -m like this: # Install latest stable release with all Core dependencies python -m pip install -U . [ core ] # Or Install latest stable release with all Core & Asyncio dependencies python -m pip install -U . [ asyncio ] And, If you don't have the privileges to the directory you're installing package. Then use --user flag, that makes pip install packages in your home directory instead: # Install latest stable release with all Core dependencies python -m pip install --upgrade --user . [ core ] # Or Install latest stable release with all Core & Asyncio dependencies python -m pip install --upgrade --user . [ asyncio ] Or, If you're using py as alias for installed python, then: # Install latest stable release with all Core dependencies py -m pip install --upgrade --user . [ core ] # Or Install latest stable release with all Core & Asyncio dependencies py -m pip install --upgrade --user . [ asyncio ] # clone the repository and get inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing # Install latest stable release with all Core dependencies pip install -U . [ core ] # Or Install latest stable release with all Core & Asyncio dependencies pip install -U . [ asyncio ] The ensurepip module is missing/disabled on Ubuntu. Use pip method only. \u21a9","title":"Installation"}]}